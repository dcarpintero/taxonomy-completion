{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# An LLM-Approach to Semantic Clustering and Topic Modeling of Academic Literature"
      ],
      "metadata": {
        "id": "ohasq_p_8DMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Clustering](https://en.wikipedia.org/wiki/Cluster_analysis) stands as a fundamental task in unsupervised learning, where the goal is to group unlabeled data into related categories; whereas [Topic Modeling](https://en.wikipedia.org/wiki/Topic_model) focuses on identifying thematic structures within a collection of documents. These techniques find applications across various domains, enabling tasks such as information retrieval, anomaly detection, trend analysis, and biomedical research.\n",
        "\n",
        "This notebook provides an end-to-end guide to building an LLM-based pipeline for automatic categorization of research articles into latent topics using open-source tools and models. Our playground is a  [dataset of 25,000 research arXiv publications](https://huggingface.co/datasets/dcarpintero/arxiv.cs.CL.25k) from Computational Linguistics (Natural Language Processing) published before July 2024.\n",
        "\n",
        "At its core, the clustering problem relies on finding similar examples. This is a natural task for embeddings, as they capture the semantic relationships in a corpus, and can be provided as input features to a clustering algorithm to establish similarity links among the examples. We begin by transforming the `title:abstract` pairs of our dataset into an embeddings representation using  [Jina-Embeddings-v2](https://arxiv.org/abs/2310.19923), a BERT-ALiBi based attention model supporting 8192 sequence length, and subsequently applying HDBSCAN [2] in a reduced dimensional space. Topic modeling is then performed at cluster level using a random subset of `titles` within each cluster. This latter process combines [LangChain](https://www.langchain.com/) and [Pydantic](https://docs.pydantic.dev/) with [Mistral-7B-Instruct](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2) to construct a topic pipeline that generates structured `JSON` output.\n",
        "\n",
        "To measure the clustering and topic modeling effectiveness, we visualize the outcomes after further applying [UMAP](https://en.wikipedia.org/wiki/Uniform_Manifold_Approximation_and_Projection) [1] dimensionality reduction.\n",
        "\n",
        "The results hint at emerging research topics in the field of Computational Linguistics such as: '**Vision-Language-Models**', '**Medical NLP**', '**Large Language Model Alignment via Human Preference**', '**Multilingual Language Models**', '**Attacks on LLMs**', '**Bias in LLMs**', '**LLM-based Agents**', '**Hallucination in LLMs**', and '**Language Model Compression and Acceleration**'. A similar approach could be used to create a more granular arXiv taxonomy for categorization and retrieval of sub-topics in the field of Computational Linguistics.\n",
        "\n",
        "<figure>\n",
        "  <img style=\"margin: 0 auto; display: block;\" src=\"https://cdn-uploads.huggingface.co/production/uploads/64a13b68b14ab77f9e3eb061/iE3e4VJSY84JyyTR9krmf.png\">\n",
        "  <figcaption style=\"text-align: center;\">LLM-based Pipeline for Semantic Clustering and Topic Modeling of Academic Literature </figcaption>\n",
        "</figure>"
      ],
      "metadata": {
        "id": "7Dc0nbdRAaRy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uKSN9LlQ7caJ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install altair datasets hdbscan scikit-learn umap-learn sentence-transformers --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Embeddings Transformation"
      ],
      "metadata": {
        "id": "H7Dbk-Pw8HJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings are numerical representations of real-world objects like text, images, and audio that encapsulate semantic information of the data they represent. They are used by AI models to understand complex knowledge domains in downstream applications such as clustering, as well as information retrieval and classification tasks.\n",
        "\n",
        "We implement this step with [Jina-Embeddings-v2](https://arxiv.org/abs/2310.19923), an open-source text embedding model capable of accommodating up to 8192 tokens. This provides a sufficiently large sequence length for `title:abstract` pairs and other document sections that might be relevant.\n",
        "\n",
        "To overcome the conventional 512-token limit, Jina-Embeddings-v2 incorporates bidirectional [ALiBi](https://arxiv.org/abs/2108.12409) into the BERT framework. AliBi (Attention with Linear Biases) enables input length extrapolation (i.e. sequences exceeding 2048 tokens) by encoding positional information directly within the\n",
        "self-attention layer, instead of introducing positional embeddings. In practice, it biases query-key attention scores with a penalty that is proportional to their distance, ensuring that proximate tokens demonstrate stronger mutual attention.\n",
        "\n",
        "The semantic similarity between corpora can be trivially computed as the inner product of the embeddings. In the following heat map each entry [x, y] is colored based on said embeddings product for sentences [x] and [y].\n",
        "\n",
        "<figure>\n",
        "  <img style=\"margin: 0 auto; display: block;\" src=\"https://cdn-uploads.huggingface.co/production/uploads/64a13b68b14ab77f9e3eb061/4djmELIe2LkZ8_Tofc91Q.png\">\n",
        "  <figcaption style=\"text-align: center;\">Semantic Similary in arXiv 'titles' w/ Jina-Embeddings-v2</figcaption>\n",
        "</figure>"
      ],
      "metadata": {
        "id": "I2mWlEpLNJTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer('jinaai/jina-embeddings-v2-base-en', trust_remote_code=True)"
      ],
      "metadata": {
        "id": "NBDy5Lkajitn",
        "outputId": "d117f825-cc63-442f-bd0d-578a30a70f9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627,
          "referenced_widgets": [
            "ce9f01de318f49328141aa4082f7e443",
            "b53306ed9ebe4a50aa996b673d700872",
            "ac1ffcb274274f67acb51f39f70433c7",
            "15f9f3b78b1140e6b4c484690a907de8",
            "87f614bcd12445f8b3a858e3d792a082",
            "b552e74a87f34bc2a734977c5d45bfb4",
            "b1f1e62d1f2641c489b12d3ce4716c7b",
            "27c34349e7b44d549597f669596fd7bd",
            "b822b40d18624718a094ebca90f765cd",
            "342c377108bc4a4d99dcf91545ecd410",
            "b4a4c259104944528cd94621cb2097c5",
            "4a02d6a68e8043cbb9564643c2aadc7b",
            "3503968046cc4ea4a7d818f39777f95d",
            "07e797a02035492f859dd787ea0cb8fe",
            "49e1da5e87b149b0aaecd80150d33482",
            "4523f237d8f0410087a115b1024146c0",
            "08688f23e0534a808c9007b8221af177",
            "b49430a127ce4fa296ced8967b90309d",
            "64cd4470c25843ebb75df77b4b90f0dd",
            "0cf578ad25d84e90a896b53551b68d1c",
            "ef39f467b3dc4508a91d5de27fa6aa26",
            "1b0c2d029890450b8e5654fc85893322",
            "8bb0ea39b7df41c8ac06fe80734811b4",
            "6ce399235f7e4284a806ba353eafe9fa",
            "46b37e8d4c7842a29c08e45aa4586d32",
            "e38bf6a22dd54475be7d2c607cb2e473",
            "d201030a0c0445d1ae82463e361feb2e",
            "8657cb405ed543acabded93c336127c8",
            "0e2bb0c3899947989ae504327023a4e7",
            "43fc509b6af840c699202bcd8eb87429",
            "619029d0630e467aaa597e8ea5a82d22",
            "309d1c5db5364f97a84034402bb404a4",
            "53dfb2b1fce049269ba546e03e066915",
            "eb7f2a9373184d37afe8be1bbc4d755e",
            "8826ce2894124e6993569fb95434cb08",
            "ffdd395a69fa48d897d10c17abd3d5a6",
            "710b8554d3c44f9db8baa50eb5766182",
            "151a94610046456197d8c854ac2fc309",
            "828df104ebf14490871bab42cbf7e59c",
            "e5a89cea437a479aa965348e7664854a",
            "83f4161c855c4eab99b61d54378b9c85",
            "4a53ae3e38d64ac680e1348a60659825",
            "35ac412c0e874cf1b53b5142c21d7c50",
            "9b72d06da8e44dd89ffb87bb8f2f8719",
            "c2a8d9c326b4483c9142cf89e21ab5f5",
            "8d0593c8eeba43f99564342870abef9c",
            "69592a9157a54d8e948454da5aaa3cac",
            "747a5acd712940a39b09d9e3d724d1cb",
            "a61b20382b904af488583f48126c8311",
            "89a994e968df485fb326bfcb755b723d",
            "c71af86b37bb47799c2ef74499817609",
            "44825a6f8a604cb9bdddb84a39bdcb59",
            "577c1484b8e945ab8346d47ca5ba74a0",
            "0312394ced074c47910b59ac25552823",
            "5aa22ca6c62c4880994626fbc790cd37",
            "f3d0229290cf4f2da224d24f955267e0",
            "267f1b05e2004202a8e1c5afbdc42da7",
            "dc54bae145644df8b3ac5410651eb537",
            "7579dc18ccc74cb5ab1ad8292f763e01",
            "570302592ee2444997cd1dec91639809",
            "835e76794b764ce9b4f19c21722110a7",
            "ea9959aad60a4fa3abaf84da6b1e7255",
            "c6d0d3decff941219a6f6ecbec7d1373",
            "1879ed3ae3944070bbcf254c2321df71",
            "49f02842a2b94dafb2470122c56e9d31",
            "87108e58563442ed9e820c909e0eae50",
            "8f9312e2fa67405698ff887e3dce5519",
            "281cd288d5ca4eaabde32028fd556736",
            "d42d9c45737b4d71a4cd917b8ce0361b",
            "909a63ad4ee54557b9ac6704884bf4b0",
            "ebaa0daab5294ce194143a107ea6d40a",
            "5ec8ca73b2444c6e86a61d4722aa442c",
            "4a256da087a147ee96b4d5cc86c4c37c",
            "ea2d85e01d3f4ba7aded1fbe5546795e",
            "f304c67bbf894e4f87822a9be904a79c",
            "8911c5ece5bc48429b1c0da04cdfeba1",
            "7b41ad5fb42f4966bf7f41db80b346d0",
            "96f9e75862e94e028246e4012446e751",
            "ed5da8a8c8f744a59f0468bd94e1fb3d",
            "b6f3727cc1fd40bda6b0a65ad5cfa656",
            "0aa4b1500dcf47898930dd5c661126bc",
            "49f72371702e42f79fa4ca65baa5156d",
            "90c0165b94884f05b16dcfd93d4a540b",
            "5f55ba99af5841bdb48b12d77f491717",
            "7202abba15c64751929156e7a4e18085",
            "7e38e357e9494e90bcb002b13ee4ec77",
            "71d12919d4c140f6ac254ce9a5142fc1",
            "989859c42f4940bea1a2086d25a94b77",
            "412ce4e5687e4cf0970e6c49716fbf97",
            "a434e54e561e4f79a4eb17ac21b97fca",
            "50be2b2706ab4c2d9fc08aab0a9fa340",
            "5415f9ec74854d1989157a82fe3662c0",
            "22b459f08d7747ab95e7dfcf638aedd5",
            "d6d362dc26a54c73b02dbc309d57c346",
            "2774916cfb4d4264985a5c5aec73053d",
            "8543cd975cd8425db3e4f8083321f88b",
            "382f31752c714cf390b8f8cbed889667",
            "97cbed154d144037be9f799f9160ca61",
            "9477a8f1eb244c7684e298f6dcb99571",
            "d493ec267f09428bb8d0672b0c57c7e2",
            "6ff8d130605f4e0cb5f4ab9672308907",
            "cab88500a4284a5bae59d188bc1e54e2",
            "91b5d621ecdb4d40ad6640de1d4715a2",
            "67453b5851aa4673a3fa6e5ef4c1bb40",
            "a7d92714a0184413b1dc7be0f204cd5f",
            "23c2fc3bc2cf419aacc24f5e0329362c",
            "1d3b7ca98ae2487e96e2fb9d27dde328",
            "d5f0ba938b3a4d97a1e1e5e77e5a3dc0",
            "04430ca6826c40e29385200a6f476fd5",
            "ba880061c3524364bdd7ca22166e206e",
            "9f176028bcd54c11babfeb13f0bdec4d",
            "aac079b9522d472696f3a6f82ac8f704",
            "38b311911d5944b59df69919317a7791",
            "ed514f905cd64eee994f1eb36eb23f20",
            "361f1e6f832342bdadf164f55f3fa638",
            "156e40178525453db7ed4a4c988a8f67",
            "cdd9827b42a648e48a0cdefc9c09630c",
            "0c79ceec5dd64d72b382d4b61080ac2d",
            "2ebc3c6697974d31938c3c137a0d49b8",
            "6606ba7527ef40e892511deed04a5e7d",
            "ecfc74a4c5bc4f8dac29baeb4b0ac0c8",
            "11069fa5997244b188f15c2fdc32ccb0",
            "b69b3e52aee74c56954d8ff9d0ddb5b6",
            "2727a0af9e294c9d8f477f497e0d56e3",
            "e3d9016b2e4f418e82e1226b5fe143e9",
            "9d530d6cfc604dc88fc1cdfa1aa33c29",
            "4b43c2f21de449c9abbace483d8768d8",
            "76f058c799f14ddc9e5a5458e0111f55",
            "9fe583a6e67844b08f80935ed39cf7d5",
            "061c73c6d54d47c299c0428f896c6ddb",
            "12240f85d1c248d5ad3486cfdc20bf12",
            "e37f42e752fe42b99591b0af4353101f",
            "a4498e612202433e8b89680d0e14924f",
            "d9b70cfdab104c2d92e0a45ffc64a6a6",
            "4be375bb1256483384018e38cc6b4f26",
            "bfb2b61d505248c496d4c1e77bb6c17a",
            "3541b7ddf7bd477088f5d976493a362e",
            "1308f9801f8f4d6191be48d222439a20",
            "2ccde0fea33f4ee7837fe5e8ce7f21b2",
            "bb52d1c37def402289f1f577dea32cfa",
            "4cb920b40d75435e9133ecada674a84a",
            "f0e626b0979f45b0acf28cbeedbdc567",
            "3b06d2a810ff46a9aed80695287019d6"
          ]
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce9f01de318f49328141aa4082f7e443"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/117 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a02d6a68e8043cbb9564643c2aadc7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/71.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8bb0ea39b7df41c8ac06fe80734811b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb7f2a9373184d37afe8be1bbc4d755e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2a8d9c326b4483c9142cf89e21ab5f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "configuration_bert.py:   0%|          | 0.00/8.24k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3d0229290cf4f2da224d24f955267e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-bert-implementation:\n",
            "- configuration_bert.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modeling_bert.py:   0%|          | 0.00/97.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f9312e2fa67405698ff887e3dce5519"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-bert-implementation:\n",
            "- modeling_bert.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/275M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96f9e75862e94e028246e4012446e751"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/373 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "412ce4e5687e4cf0970e6c49716fbf97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d493ec267f09428bb8d0672b0c57c7e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f176028bcd54c11babfeb13f0bdec4d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11069fa5997244b188f15c2fdc32ccb0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4498e612202433e8b89680d0e14924f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "ds = load_dataset(\"dcarpintero/arxiv.cs.CL.25k\", split=\"train\")"
      ],
      "metadata": {
        "id": "5hH5MSrD19r2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "id": "AYBg2Tr32DGn",
        "outputId": "4f662306-a877-4d2f-dc86-68a401b20690",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['publication_date', 'doc_url', 'id', 'authors', 'update_date', 'category_all', 'abstract', 'category_primary', 'title'],\n",
              "    num_rows: 25107\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [title + ': ' + abstract for title, abstract in zip(ds['title'], ds['abstract'])]\n",
        "f32_embeddings = model.encode(corpus, batch_size=128, show_progress_bar=True)"
      ],
      "metadata": {
        "id": "oKyq217e3qnF",
        "outputId": "637bda33-7986-470b-a032-7e6c27d9ecec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9a714a64bbdb4b9b81a4f4ba36d85aa5",
            "23ecfe650a084c178a11d0d606d9bcf4",
            "a7cd716c75454d93a7d5b82bfa3e636e",
            "308c040d14614c18aca9bcb95557b119",
            "dd0f2d787b8b4d058909144f6eee84eb",
            "848a4e80474348219d5b716e16a3661e",
            "213ed3d74cfb4221ba5d5ddbe243efca",
            "318e41eeb18b4c9e9c7b62277acfd6c0",
            "cc50ec877941494db18391fbade36a4f",
            "e6c353f4f5ab41fc940094f817636cb1",
            "4505fdc24d124feeb287d795287a6b2b"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/197 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a714a64bbdb4b9b81a4f4ba36d85aa5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sentence_transformers.quantization import quantize_embeddings\n",
        "\n",
        "int8_embeddings = quantize_embeddings(\n",
        "    np.array(f32_embeddings),\n",
        "    precision=\"int8\",\n",
        "    calibration_embeddings=np.array(f32_embeddings[:10000]),\n",
        ")"
      ],
      "metadata": {
        "id": "jBEr4Z6O4Brl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f32_embeddings.dtype, f32_embeddings.shape, f32_embeddings.nbytes, (np.max(f32_embeddings), np.min(f32_embeddings))"
      ],
      "metadata": {
        "id": "BpOZsOvU63EJ",
        "outputId": "f88bc4ce-1356-45a1-a2f5-379e8c450aa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('float32'), (25107, 768), 77128704, (2.074683, -2.0162134))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "int8_embeddings.dtype, int8_embeddings.shape, int8_embeddings.nbytes, (np.max(int8_embeddings), np.min(int8_embeddings))"
      ],
      "metadata": {
        "id": "lyr9Z1b-4bjj",
        "outputId": "00d89ed9-c930-4acf-fe95-83094893978b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('int8'), (25107, 768), 19282176, (127, -128))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# histogram - embeddings distribution\n",
        "plt.hist(f32_embeddings.flatten(), bins=250, edgecolor='C0')\n",
        "plt.xlabel('Embeddings')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of FP32 Embeddings')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2L1FWJyYGDr4",
        "outputId": "7fe9e6dd-4be7-4153-ba36-e92fba69db63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAHHCAYAAACWQK1nAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABWA0lEQVR4nO3deVxUZfs/8M+AzLDIIiogiogb7pqohJkrCbmkqU9uFRouFZiIe4tbi2XuuWCPBWZZZo9LLmEEomm4oTwuj5KYioIDpsAAsXP//vDH+TosAsPALHzer9e8dO5zz5nrzOJc3ue67yMTQggQERERUY2Y6DoAIiIiImPApIqIiIhIC5hUEREREWkBkyoiIiIiLWBSRURERKQFTKqIiIiItIBJFREREZEWMKkiIiIi0gImVURERERawKSKqA4sW7YMMpmsTp5r4MCBGDhwoHQ/OjoaMpkMP/30U508/5QpU9CqVas6eS5NZWVlYdq0aXBycoJMJkNQUJCuQzJYdfn5qs73SCaTYdmyZdL9sLAwyGQy3L59u3aCIwKTKqJqK/nHueRmbm4OZ2dn+Pj4YOPGjcjMzNTK8yQnJ2PZsmWIi4vTyv60SZ9jq4pPPvkEYWFheOutt7Bz50689tprFfZt1aqV2vv95C03NxdA+Z+J9u3bIzAwECkpKdK+kpOT8eqrr8Ld3R3W1taws7NDnz59sGPHDpS+YtjevXsxfvx4tG7dGpaWlnB3d8fcuXORnp5epWMcOHBghXF36NCh+i8aEVWqga4DIDJUK1asgJubGwoKCqBUKhEdHY2goCCsXbsWP//8M7p16yb1ff/997Fo0aJq7T85ORnLly9Hq1at0KNHjyo/7tdff63W82jiabH9+9//RnFxca3HUBNRUVF49tlnsXTp0ir179GjB+bOnVumXS6Xq90v+Uzk5ubi5MmT2Lp1K44cOYIrV67A0tISf//9N+7du4dx48ahZcuWKCgoQEREBKZMmYL4+Hh88skn0r5mzJgBZ2dnvPrqq2jZsiUuX76MTZs24ciRI7hw4QIsLCwqjbtFixZYuXJlmXZbW9sqHbcxee211zBhwgQoFApdh0JGjEkVkYZefPFF9OrVS7q/ePFiREVFYcSIEXjppZdw7do16YevQYMGaNCgdr9u//zzDywtLcv80Nc1MzMznT5/VaSmpqJTp05V7t+8eXO8+uqrlfZ78jMxbdo0NG7cGGvXrsWBAwcwceJEdOvWDdHR0WqPCQwMxMiRI7Fx40Z8+OGHMDU1BQD89NNPaqdxAcDDwwN+fn747rvvMG3atErjsbW1rVLc9YGpqan02hLVFp7+I9KiwYMH44MPPsCdO3fw7bffSu3l1YJERESgX79+sLOzQ8OGDeHu7o53330XwOM6ld69ewMApk6dKp22CQsLA/D41E6XLl0QGxuL/v37w9LSUnps6ZqqEkVFRXj33Xfh5OQEKysrvPTSS7h7965an1atWmHKlCllHvvkPiuLrbyaquzsbMydOxcuLi5QKBRwd3fH6tWry5zykslkCAwMxP79+9GlSxcoFAp07twZ4eHh5b/gpaSmpsLf3x+Ojo4wNzdH9+7dsWPHDml7Sf3PrVu3cPjwYSn22qqzGTx4MADg1q1bT+3XqlUr/PPPP8jPz5faynsPX375ZQDAtWvXtBZjyWfzzz//xKuvvgpbW1s0bdoUH3zwAYQQuHv3LkaNGgUbGxs4OTlhzZo15e6nKp8vADhz5gx8fX1ha2sLS0tLDBgwAKdOnSrT7+TJk+jduzfMzc3Rpk0bbNu2rdznzcvLw5w5c9C0aVNYW1vjpZdewr1798r0K6+mqlWrVhgxYgROnjyJPn36wNzcHK1bt8Y333xT5vGXLl3CgAEDYGFhgRYtWuCjjz5CaGhomX2eP38ePj4+aNKkCSwsLODm5oY33nij3NjJ+HCkikjLXnvtNbz77rv49ddfMX369HL7XL16FSNGjEC3bt2wYsUKKBQKJCQkSD8uHTt2xIoVK7BkyRLMmDEDzz//PACgb9++0j4ePnyIF198ERMmTMCrr74KR0fHp8b18ccfQyaTYeHChUhNTcX69evh7e2NuLi4Kp1KKlGV2J4khMBLL72EY8eOwd/fHz169MDRo0cxf/58JCUlYd26dWr9T548ib179+Ltt9+GtbU1Nm7ciLFjxyIxMRGNGzeuMK6cnBwMHDgQCQkJCAwMhJubG/bs2YMpU6YgPT0ds2fPRseOHbFz507MmTMHLVq0kE7pNW3a9KnHXFBQgL///lutzdLSEpaWlk993M2bNwGgTNw5OTnIzs5GVlYWjh8/jtDQUHh5eVX6PiiVSgBAkyZNntqvRFFRUZm4AcDCwgJWVlZqbePHj0fHjh3x6aef4vDhw/joo49gb2+Pbdu2YfDgwfjss8/w3XffYd68eejduzf69++v9viqfL6ioqLw4osvwsPDA0uXLoWJiQlCQ0MxePBg/P777+jTpw8A4PLlyxg6dCiaNm2KZcuWobCwEEuXLi33Mz5t2jR8++23mDRpEvr27YuoqCgMHz68Sq8PACQkJGDcuHHw9/eHn58fvv76a0yZMgUeHh7o3LkzACApKQmDBg2CTCbD4sWLYWVlhe3bt5c5lZiamirFvWjRItjZ2eH27dvYu3dvleMhAyeIqFpCQ0MFAHHu3LkK+9ja2opnnnlGur906VLx5Ndt3bp1AoB48OBBhfs4d+6cACBCQ0PLbBswYIAAIEJCQsrdNmDAAOn+sWPHBADRvHlzoVKppPYff/xRABAbNmyQ2lxdXYWfn1+l+3xabH5+fsLV1VW6v3//fgFAfPTRR2r9xo0bJ2QymUhISJDaAAi5XK7W9t///lcAEF988UWZ53rS+vXrBQDx7bffSm35+fnCy8tLNGzYUO3YXV1dxfDhw5+6vyf7AihzW7p0qdSn5DPx22+/iQcPHoi7d++KH374QTRu3FhYWFiIe/fuqe1z5cqVavsaMmSISExMrDQWf39/YWpqKv78889K+5Z8Rsq7zZw5U+pX8tmcMWOG1FZYWChatGghZDKZ+PTTT6X2tLQ0YWFhofYZqernq7i4WLRr1074+PiI4uJiqd8///wj3NzcxAsvvCC1jR49Wpibm4s7d+5Ibf/73/+Eqamp2vcoLi5OABBvv/222rFPmjSpwvfo1q1bUlvJe3vixAmpLTU1VSgUCjF37lypbdasWUImk4mLFy9KbQ8fPhT29vZq+9y3b1+l/zaQcePpP6Ja0LBhw6fOArSzswMAHDhwQOOiboVCgalTp1a5/+uvvw5ra2vp/rhx49CsWTMcOXJEo+evqiNHjsDU1BTvvPOOWvvcuXMhhMAvv/yi1u7t7Y02bdpI97t16wYbGxv89ddflT6Pk5MTJk6cKLWZmZnhnXfekUaENOXp6YmIiAi12+uvv16mn7e3N5o2bQoXFxdMmDABDRs2xL59+9C8eXO1fhMnTkRERAR27dqFSZMmAXg8evU0u3btwldffYW5c+eiXbt2VYq7VatWZeKOiIgodwmJJ2u0TE1N0atXLwgh4O/vL7Xb2dnB3d293Peiss9XXFwcbty4gUmTJuHhw4f4+++/8ffffyM7OxtDhgzBiRMnUFxcjKKiIhw9ehSjR49Gy5Ytpf117NgRPj4+as9Zsu/Sn63qLJHRqVMnabQVeDxqWfoYw8PD4eXlpTYpw97eHpMnT1bbV8n3+tChQygoKKhyDGQ8ePqPqBZkZWXBwcGhwu3jx4/H9u3bMW3aNCxatAhDhgzBmDFjMG7cOJiYVO3/Os2bN69WUXrpH2KZTIa2bdvW+ro9d+7cgbOzs9oPLvD4R7Jk+5Oe/CEt0ahRI6SlpVX6PO3atSvz+lX0PNXRpEkTeHt7V9pv8+bNaN++PRo0aABHR0e4u7uX+366urrC1dUVwOMEa8aMGfD29kZ8fHy5pwB///13+Pv7w8fHBx9//HGV47aysqpS3EDZ193W1hbm5uZlTjXa2tri4cOHZR5f2efrxo0bAAA/P78KY8jIyEBeXh5ycnLKTRzd3d3V/hNw584dmJiYqCXhJf2qqiqftzt37sDLy6tMv7Zt26rdHzBgAMaOHYvly5dj3bp1GDhwIEaPHo1JkyZx1mE9waSKSMvu3buHjIyMMv/gPsnCwgInTpzAsWPHcPjwYYSHh2P37t0YPHgwfv311yrNUqpOHVRVVbSwYlFRUZ3NnKroeUSponZ91KdPH7UZoVU1btw4/Pvf/8aJEyfKjMb897//xUsvvYQuXbrgp59+qrVZpOW97tp8L0pGZD///PMKlwhp2LAh8vLyqr3vmtDmMZYsgnr69GkcPHgQR48exRtvvIE1a9bg9OnTaNiwYU3DJT3H039EWrZz504AKPPjWJqJiQmGDBmCtWvX4n//+x8+/vhjREVF4dixYwAqTnA0VTJSUEIIgYSEBLWZeo0aNSp3ccnSozzVic3V1RXJycllTodev35d2q4Nrq6uuHHjRpnTqdp+ntpQcuovIyNDrf3mzZvw9fWFg4MDjhw5otc/ypV9vkpGk2xsbODt7V3uzczMDE2bNoWFhUWZ/QFAfHy82n1XV1cUFxdLEwIq6ldTrq6uSEhIKNNeXhsAPPvss/j4449x/vx5fPfdd7h69Sp++OEHrcZE+olJFZEWRUVF4cMPP4Sbm1uZeosnPXr0qExbyf/eS/6nXjI7q6oraFfmm2++UUtsfvrpJ9y/fx8vvvii1NamTRucPn1abWr/oUOHykyNr05sw4YNQ1FRETZt2qTWvm7dOshkMrXnr4lhw4ZBqVRi9+7dUlthYSG++OILNGzYEAMGDNDK89TEgwcPym3/6quvIJPJ0LNnT6lNqVRi6NChMDExwdGjRyudoahrlX2+PDw80KZNG6xevRpZWVllHl/y2piamsLHxwf79+9HYmKitP3atWs4evSo2mNK9r1x40a19vXr12vlmEr4+PggJiZG7QoCjx49wnfffafWLy0trcwIV+nvNRk3nv4j0tAvv/yC69evo7CwECkpKYiKikJERARcXV3x888/w9zcvMLHrlixAidOnMDw4cPh6uqK1NRUbNmyBS1atEC/fv0APE5w7OzsEBISAmtra1hZWcHT0xNubm4axWtvb49+/fph6tSpSElJwfr169G2bVu1ZR+mTZuGn376Cb6+vnjllVdw8+ZNfPvtt2VqVqoT28iRIzFo0CC89957uH37Nrp3745ff/0VBw4cQFBQUJl9a2rGjBnYtm0bpkyZgtjYWLRq1Qo//fQTTp06hfXr15ep6dKFjz/+GKdOnYKvry9atmyJR48e4T//+Q/OnTuHWbNmqZ0y9vX1xV9//YUFCxbg5MmTOHnypLTN0dERL7zwQqXPl5GRobZe2pO0vShoZZ8vExMTbN++HS+++CI6d+6MqVOnonnz5khKSsKxY8dgY2ODgwcPAgCWL1+O8PBwPP/883j77bel5Lhz5864dOmS9Jw9evTAxIkTsWXLFmRkZKBv376IjIyscARJUwsWLMC3336LF154AbNmzZKWVCh5D0tGbnfs2IEtW7bg5ZdfRps2bZCZmYl///vfsLGxwbBhw7QaE+kp3U08JDJMJVOzS25yuVw4OTmJF154QWzYsEFtWnmJ0ksqREZGilGjRglnZ2chl8uFs7OzmDhxYpmp8gcOHBCdOnUSDRo0UFvCYMCAAaJz587lxlfRkgrff/+9WLx4sXBwcBAWFhZi+PDhalPWS6xZs0Y0b95cKBQK8dxzz4nz58+X2efTYiu9pIIQQmRmZoo5c+YIZ2dnYWZmJtq1ayc+//xztan1QjxeUiEgIKBMTBUt9VBaSkqKmDp1qmjSpImQy+Wia9eu5S77UN0lFSrrW5VlNoQQ4tdffxUjRoyQXgdra2vx3HPPidDQ0HJfi4pupd+L8jxtSYUnP4sln83Sy3v4+fkJKyurcvf75Gevup+vixcvijFjxojGjRsLhUIhXF1dxSuvvCIiIyPV+h0/flx4eHgIuVwuWrduLUJCQsp8j4QQIicnR7zzzjuicePGwsrKSowcOVLcvXu3yksqlPfelvd5v3jxonj++eeFQqEQLVq0ECtXrhQbN24UAIRSqRRCCHHhwgUxceJE0bJlS6FQKISDg4MYMWKEOH/+fJnnIOMkE8IAqj+JiIj0TFBQELZt24asrCxeAocAsKaKiIioUqXXEXv48CF27tyJfv36MaEiCWuqiIiIKuHl5YWBAweiY8eOSElJwVdffQWVSoUPPvhA16GRHmFSRUREVIlhw4bhp59+wpdffinN1Pzqq6/KXAOR6jfWVBERERFpAWuqiIiIiLSASRURERGRFrCmqg4VFxcjOTkZ1tbWWr8ECREREdUOIQQyMzPh7Oz81IveM6mqQ8nJyXBxcdF1GERERKSBu3fvokWLFhVuZ1JVh0ouk3H37l3Y2NjoOBoiIiKqCpVKBRcXl0ovd8Wkqg6VnPKzsbFhUkVERGRgKivdYaE6ERERkRYwqSIiIiLSAiZVRERERFrApIqIiIhIC5hUEREREWkBkyoiIiIiLWBSRURERKQFTKqIiIiItIBJFREREZEWMKkiIiIi0gKdJlUrV65E7969YW1tDQcHB4wePRrx8fFqfQYOHAiZTKZ2e/PNN9X6JCYmYvjw4bC0tISDgwPmz5+PwsJCtT7R0dHo2bMnFAoF2rZti7CwsDLxbN68Ga1atYK5uTk8PT1x9uxZte25ubkICAhA48aN0bBhQ4wdOxYpKSnaeTGIiIjIoOk0qTp+/DgCAgJw+vRpREREoKCgAEOHDkV2drZav+nTp+P+/fvSbdWqVdK2oqIiDB8+HPn5+fjjjz+wY8cOhIWFYcmSJVKfW7duYfjw4Rg0aBDi4uIQFBSEadOm4ejRo1Kf3bt3Izg4GEuXLsWFCxfQvXt3+Pj4IDU1VeozZ84cHDx4EHv27MHx48eRnJyMMWPG1OIrRERERAZD6JHU1FQBQBw/flxqGzBggJg9e3aFjzly5IgwMTERSqVSatu6dauwsbEReXl5QgghFixYIDp37qz2uPHjxwsfHx/pfp8+fURAQIB0v6ioSDg7O4uVK1cKIYRIT08XZmZmYs+ePVKfa9euCQAiJiamSseXkZEhAIiMjIwq9SciIiLdq+rvt17VVGVkZAAA7O3t1dq/++47NGnSBF26dMHixYvxzz//SNtiYmLQtWtXODo6Sm0+Pj5QqVS4evWq1Mfb21ttnz4+PoiJiQEA5OfnIzY2Vq2PiYkJvL29pT6xsbEoKChQ69OhQwe0bNlS6lNaXl4eVCqV2o2IiIiMUwNdB1CiuLgYQUFBeO6559ClSxepfdKkSXB1dYWzszMuXbqEhQsXIj4+Hnv37gUAKJVKtYQKgHRfqVQ+tY9KpUJOTg7S0tJQVFRUbp/r169L+5DL5bCzsyvTp+R5Slu5ciWWL19ezVeCiPRBUnoO0rLzkVdYDEUDEzSykqO5nYWuwyIiPaY3SVVAQACuXLmCkydPqrXPmDFD+nvXrl3RrFkzDBkyBDdv3kSbNm3qOsxqWbx4MYKDg6X7KpUKLi4uOoyIiKoiKT0Hg1dHI6+wWGqTm8oQ8lov2FqYAQATLSIqQy+SqsDAQBw6dAgnTpxAixYtntrX09MTAJCQkIA2bdrAycmpzCy9khl5Tk5O0p+lZ+mlpKTAxsYGFhYWMDU1hampabl9ntxHfn4+0tPT1UarnuxTmkKhgEKhqOToiUifJKXn4NytR2oJFQDkFwm8EXZOrU3RwARR8wYCANKy85lkEdVzOq2pEkIgMDAQ+/btQ1RUFNzc3Cp9TFxcHACgWbNmAAAvLy9cvnxZbZZeREQEbGxs0KlTJ6lPZGSk2n4iIiLg5eUFAJDL5fDw8FDrU1xcjMjISKmPh4cHzMzM1PrEx8cjMTFR6kNEhi32ThoGfR6NoN1xVeqfV1iMX68oMejzaIz44iQGr45GUnpO7QZJRHpLpyNVAQEB2LVrFw4cOABra2upNsnW1hYWFha4efMmdu3ahWHDhqFx48a4dOkS5syZg/79+6Nbt24AgKFDh6JTp0547bXXsGrVKiiVSrz//vsICAiQRonefPNNbNq0CQsWLMAbb7yBqKgo/Pjjjzh8+LAUS3BwMPz8/NCrVy/06dMH69evR3Z2NqZOnSrF5O/vj+DgYNjb28PGxgazZs2Cl5cXnn322Tp+5YhIG56sm8rIyceMb2JRWCyqtY/lh/4n/T2vsBhp2fkcrSKqp3SaVG3duhXA4wU+nxQaGoopU6ZALpfjt99+kxIcFxcXjB07Fu+//77U19TUFIcOHcJbb70FLy8vWFlZwc/PDytWrJD6uLm54fDhw5gzZw42bNiAFi1aYPv27fDx8ZH6jB8/Hg8ePMCSJUugVCrRo0cPhIeHqxWvr1u3DiYmJhg7dizy8vLg4+ODLVu21NKrQ0S1qby6KW1ISM3iaUCiekomhKjef8tIYyqVCra2tsjIyICNjY2uwyGqt0rqpqp6mq+6Sora3Z2smVwRGYGq/n7rRaE6EVFdqa0RqieVFLXLTWX4foYXPFwb1dpzEZH+0KvFP4mIaltJDVVdyC8SmPBlDIvXieoJJlVEVG8kpecgITWrTp+zoEggLTu/Tp+TiHSDp/+IqF6oi9N+FWHxOlH9wJEqIqoX6vK0X2lBu+O4hhVRPcCkioioDuQVFuPcrUdMrIiMGJMqIqoXUjPzdB0CR6yIjBxrqojIqCWl5yBeqcKMb2J1HQqA/xuxgps9a6yIjAyTKiIyWrosTn+aoN1x0sWYmVgRGQ+e/iMio6XL4vTKlFwnkIiMB5MqIiIdSUjNYn0VkRFhUkVERkkXC31WFwvXiYwLa6qIyOjoay1VeUpOA7K2isjwcaSKiIyOPtdSlSc1M1fXIRCRFjCpIiKjYgin/UqbuTOWpwCJjABP/xGR0TCk035PKrnoMk8BEhk2jlQRkdEwtNN+T+JMQCLDx6SKiEgPcCYgkeFjUkVEpCe4ICiRYWNSRURERKQFTKqIyCgY4qy/8rC2ishwcfYfERk8Q531Vx5ebJnIcHGkiogMniHP+isPa6uIDBOTKiIiPcTTgESGh0kVERm81Mw8XYegdVxigcjwMKkiIoOWlJ6DmTvP6zqMWsHTgESGhUkVERm0tOx8FBQJXYdBRMSkiohIn7G2ishwMKkiItJjrK0iMhxMqoiI9Bxrq4gMA5MqIiIDkJqZq+sQiKgSTKqIyGAZy6VpqmLmzlieAiTSc7xMDREZJGO6NE1VFBQJpGXn89I1RHqMI1VEZJCM7dI0RGT4mFQRERkILq9ApN+YVBERGQgur0Ck35hUEREZEC6vQKS/mFQRkcGpT7P+iMhwcPYfERmU+jbrj4gMB0eqiMigcNYfC9aJ9BWTKiIiA8OCdSL9xKSKiMgAsWCdSP8wqSIig8ECdSLSZyxUJyKDwAJ1ItJ3HKkiIoPAAvWyWLBOpF+YVBERGSgWrBPpFyZVREQGjAXrRPqDSRUR6T0WqD8dTwMS6QcWqhORXmOBeuWCdsdB0cAEUfMGormdha7DIaq3OFJFRHqNBepVw9OARLrHpIqIiIhIC5hUEREREWkBkyoiIiIiLWBSRUR6LTUzT9chGIzUzFxdh0BUrzGpIiK9lZSeg5k7z+s6DIMxc2csl1Yg0iEmVUSkt9Ky81FQJHQdhsEoKBKcAUikQ0yqiIiIiLSASRURERGRFjCpIiIyIrxkDZHu6DSpWrlyJXr37g1ra2s4ODhg9OjRiI+PV+uTm5uLgIAANG7cGA0bNsTYsWORkpKi1icxMRHDhw+HpaUlHBwcMH/+fBQWFqr1iY6ORs+ePaFQKNC2bVuEhYWViWfz5s1o1aoVzM3N4enpibNnz1Y7FiIiXQraHYfBq6OZWBHpgE6TquPHjyMgIACnT59GREQECgoKMHToUGRnZ0t95syZg4MHD2LPnj04fvw4kpOTMWbMGGl7UVERhg8fjvz8fPzxxx/YsWMHwsLCsGTJEqnPrVu3MHz4cAwaNAhxcXEICgrCtGnTcPToUanP7t27ERwcjKVLl+LChQvo3r07fHx8kJqaWuVYiEh7eBFlzfGSNUS6IRNC6M3UmgcPHsDBwQHHjx9H//79kZGRgaZNm2LXrl0YN24cAOD69evo2LEjYmJi8Oyzz+KXX37BiBEjkJycDEdHRwBASEgIFi5ciAcPHkAul2PhwoU4fPgwrly5Ij3XhAkTkJ6ejvDwcACAp6cnevfujU2bNgEAiouL4eLiglmzZmHRokVViqUyKpUKtra2yMjIgI2NjVZfOyJjwoso19yhWf3QpbmtrsMgMgpV/f3Wq5qqjIwMAIC9vT0AIDY2FgUFBfD29pb6dOjQAS1btkRMTAwAICYmBl27dpUSKgDw8fGBSqXC1atXpT5P7qOkT8k+8vPzERsbq9bHxMQE3t7eUp+qxEJE2sGLKBORIWqg6wBKFBcXIygoCM899xy6dOkCAFAqlZDL5bCzs1Pr6+joCKVSKfV5MqEq2V6y7Wl9VCoVcnJykJaWhqKionL7XL9+vcqxlJaXl4e8vP9bDVqlUlX2MhAREZGB0puRqoCAAFy5cgU//PCDrkPRmpUrV8LW1la6ubi46DokIiIiqiV6kVQFBgbi0KFDOHbsGFq0aCG1Ozk5IT8/H+np6Wr9U1JS4OTkJPUpPQOv5H5lfWxsbGBhYYEmTZrA1NS03D5P7qOyWEpbvHgxMjIypNvdu3er8GoQEdUcl1Ygqns6TaqEEAgMDMS+ffsQFRUFNzc3te0eHh4wMzNDZGSk1BYfH4/ExER4eXkBALy8vHD58mW1WXoRERGwsbFBp06dpD5P7qOkT8k+5HI5PDw81PoUFxcjMjJS6lOVWEpTKBSwsbFRuxHR03HWn3ZwaQWiuqfTmqqAgADs2rULBw4cgLW1tVSbZGtrCwsLC9ja2sLf3x/BwcGwt7eHjY0NZs2aBS8vL2m23dChQ9GpUye89tprWLVqFZRKJd5//30EBARAoVAAAN58801s2rQJCxYswBtvvIGoqCj8+OOPOHz4sBRLcHAw/Pz80KtXL/Tp0wfr169HdnY2pk6dKsVUWSxEVDOc9addJUsrNLez0HUoRPWCTpOqrVu3AgAGDhyo1h4aGoopU6YAANatWwcTExOMHTsWeXl58PHxwZYtW6S+pqamOHToEN566y14eXnBysoKfn5+WLFihdTHzc0Nhw8fxpw5c7Bhwwa0aNEC27dvh4+Pj9Rn/PjxePDgAZYsWQKlUokePXogPDxcrXi9sliIqGY464+IDJlerVNl7LhOFdHTXUnKwIgvTuo6DKOyfnwP9Haz52gVUQ0Y5DpVRESkXaytIqo7TKqIiIwcL1tDVDeYVBERERFpAZMqItILXEqBiAyd3lymhojqLy6lQETGgCNVRKRzXEqBiIwBkyoionqAl60hqn1MqoiI6gEurUBU+5hUEZFOsUC97nBpBaLaxUJ1ItIZFqgTkTHhSBUR6QwL1InImDCpIiKqR1Izc3UdApHRYlJFRFSPzNwZy2J1olrCpIqIqB4pKBIsVieqJUyqiIiIiLSASRUR6UxqZp6uQyAi0homVUSkE0npOZi587yuwyAi0homVUSkE2nZ+SgoEroOg4hIa5hUEREREWkBkyoionqGF1cmqh1MqoiI6hleXJmodjCpIiKqh3hxZSLtY1JFREREpAVMqoioziWl5yAhNUvXYRARaVUDXQdARPVLUnoOBq+ORl5hsa5DqfcSUrPQyEqO5nYWug6FyChwpIqI6lRadj4TKj3BgnUi7WJSRURUj7FgnUh7mFQRERERaQGTKiIiIiItYFJFRHWGs/6IyJhx9h8R1QnO+iMiY8eRKiKqE5z1p794LUAi7WBSRURUz3FpBSLtYFJFRERcWoFIC5hUEREREWkBkyoiIiIiLWBSRURERKQFTKqIiAgAZwES1RSTKiKqdVz00zBwFiBRzXDxTyKqVVz007CUzAJsbmeh61CIDA5HqoioVnHRTyKqL5hUEREREWkBkyoiIiIiLWBSRURERKQFTKqIiEhNamaurkMgMkhMqoio1nApBcM0c2csl1Ug0gCXVCCiWsGlFAxXQZHgsgpEGuBIFRHVCi6lQET1DZMqIiIiIi1gUkVERESkBUyqiIiIiLSASRUREZWRkJrFGYBE1cSkioiIygjaHYfBq6OZWBFVA5MqIiIqV15hMdKy83UdBpHBYFJFRLUiNTNP1yEQEdUpJlVEpHVJ6TmYufO8rsMgIqpTTKqISOvSsvNRUCR0HQYRUZ1iUkVERBXiLECiqtMoqfrrr7+0HQcREekhzgIkqjqNkqq2bdti0KBB+Pbbb5Gbm6vtmIiISI9wFiBR1WiUVF24cAHdunVDcHAwnJycMHPmTJw9e7ba+zlx4gRGjhwJZ2dnyGQy7N+/X237lClTIJPJ1G6+vr5qfR49eoTJkyfDxsYGdnZ28Pf3R1ZWllqfS5cu4fnnn4e5uTlcXFywatWqMrHs2bMHHTp0gLm5Obp27YojR46obRdCYMmSJWjWrBksLCzg7e2NGzduVPuYiYiIyDhplFT16NEDGzZsQHJyMr7++mvcv38f/fr1Q5cuXbB27Vo8ePCgSvvJzs5G9+7dsXnz5gr7+Pr64v79+9Lt+++/V9s+efJkXL16FRERETh06BBOnDiBGTNmSNtVKhWGDh0KV1dXxMbG4vPPP8eyZcvw5ZdfSn3++OMPTJw4Ef7+/rh48SJGjx6N0aNH48qVK1KfVatWYePGjQgJCcGZM2dgZWUFHx8fjtQRlZKUnoOE1KzKOxIRGRmZEKLGU3Ty8vKwZcsWLF68GPn5+ZDL5XjllVfw2WefoVmzZlULRCbDvn37MHr0aKltypQpSE9PLzOCVeLatWvo1KkTzp07h169egEAwsPDMWzYMNy7dw/Ozs7YunUr3nvvPSiVSsjlcgDAokWLsH//fly/fh0AMH78eGRnZ+PQoUPSvp999ln06NEDISEhEELA2dkZc+fOxbx58wAAGRkZcHR0RFhYGCZMmFClY1SpVLC1tUVGRgZsbGyq9BgiQ5KUnoPBq6ORV1is61BIyw7N6ocuzW11HQaRTlT197tGs//Onz+Pt99+G82aNcPatWsxb9483Lx5ExEREUhOTsaoUaNqsnsAQHR0NBwcHODu7o633noLDx8+lLbFxMTAzs5OSqgAwNvbGyYmJjhz5ozUp3///lJCBQA+Pj6Ij49HWlqa1Mfb21vteX18fBATEwMAuHXrFpRKpVofW1tbeHp6Sn3Kk5eXB5VKpXYjMmZp2flMqIwUZwESVa6BJg9au3YtQkNDER8fj2HDhuGbb77BsGHDYGLyOEdzc3NDWFgYWrVqVaPgfH19MWbMGLi5ueHmzZt499138eKLLyImJgampqZQKpVwcHBQP6AGDWBvbw+lUgkAUCqVcHNzU+vj6OgobWvUqBGUSqXU9mSfJ/fx5OPK61OelStXYvny5RocORGRfgnaHQdFAxNEzRuI5nYWug6HSC9plFRt3boVb7zxBqZMmVLh6T0HBwd89dVXNQruydNqXbt2Rbdu3dCmTRtER0djyJAhNdp3XVi8eDGCg4Ol+yqVCi4uLjqMiIhIcyWzAJlUEZVPo6SqKrPe5HI5/Pz8NNl9hVq3bo0mTZogISEBQ4YMgZOTE1JTU9X6FBYW4tGjR3BycgIAODk5ISUlRa1Pyf3K+jy5vaTtySQyJSUFPXr0qDBehUIBhUKhwZESERGRodGopio0NBR79uwp075nzx7s2LGjxkFV5N69e3j48KGU2Hh5eSE9PR2xsbFSn6ioKBQXF8PT01Pqc+LECRQUFEh9IiIi4O7ujkaNGkl9IiMj1Z4rIiICXl5eAB6fznRyclLro1KpcObMGakPERER1W8aJVUrV65EkyZNyrQ7ODjgk08+qfJ+srKyEBcXh7i4OACPC8Lj4uKQmJiIrKwszJ8/H6dPn8bt27cRGRmJUaNGoW3btvDx8QEAdOzYEb6+vpg+fTrOnj2LU6dOITAwEBMmTICzszMAYNKkSZDL5fD398fVq1exe/dubNiwQe203OzZsxEeHo41a9bg+vXrWLZsGc6fP4/AwEAAj2cmBgUF4aOPPsLPP/+My5cv4/XXX4ezs7PabEUiIiKqvzQ6/ZeYmFim+BsAXF1dkZiYWOX9nD9/HoMGDZLulyQ6fn5+2Lp1Ky5duoQdO3YgPT0dzs7OGDp0KD788EO1U2rfffcdAgMDMWTIEJiYmGDs2LHYuHGjtN3W1ha//vorAgIC4OHhgSZNmmDJkiVqa1n17dsXu3btwvvvv493330X7dq1w/79+9GlSxepz4IFC5CdnY0ZM2YgPT0d/fr1Q3h4OMzNzat8vETGjOtTEVF9p9E6VS1btsSmTZvw0ksvqbUfOHAAAQEBuHfvntYCNCZcp4qMFdenqj/Wj++B3m72LFaneqVW16maOHEi3nnnHRw7dgxFRUUoKipCVFQUZs+eXeWFMInIeHB9qvqDF1gmqphGp/8+/PBD3L59G0OGDEGDBo93UVxcjNdff71aNVVERGR4uLQCUfk0Sqrkcjl2796NDz/8EP/9739hYWGBrl27wtXVVdvxERERERkEjZKqEu3bt0f79u21FQsRERGRwdIoqSoqKkJYWBgiIyORmpqK4mL1WoqoqCitBEdERERkKDRKqmbPno2wsDAMHz4cXbp0gUwm03ZcRGQguJQCEdFjGiVVP/zwA3788UcMGzZM2/EQkQHhUgpERP9HoyUV5HI52rZtq+1YiMjAcCmF+is1M1fXIRDpHY2Sqrlz52LDhg3QYN1QIiIyAjN3xnKtKqJSNDr9d/LkSRw7dgy//PILOnfuDDMzM7Xte/fu1UpwRESknwqKBNeqIipFo6TKzs4OL7/8srZjISIiIjJYGiVVoaGh2o6DiIiIyKBpVFMFAIWFhfjtt9+wbds2ZGZmAgCSk5ORlcWp1URERFT/aDRSdefOHfj6+iIxMRF5eXl44YUXYG1tjc8++wx5eXkICQnRdpxEpGe4PhUlpGahkZWcdVVE/59GI1WzZ89Gr169kJaWBguL//syvfzyy4iMjNRacESkn0rWpwraHafrUEiHgnbHYfDqaM4CJPr/NBqp+v333/HHH39ALpertbdq1QpJSUlaCYyI9BfXp6ISeYXFnAVI9P9pNFJVXFyMoqKiMu337t2DtbV1jYMiIiIiMjQaJVVDhw7F+vXrpfsymQxZWVlYunQpL11DRERE9ZJGp//WrFkDHx8fdOrUCbm5uZg0aRJu3LiBJk2a4Pvvv9d2jERERER6T6OkqkWLFvjvf/+LH374AZcuXUJWVhb8/f0xefJktcJ1IiIiovpCo6QKABo0aIBXX31Vm7EQEZEB4tIKRI9plFR98803T93++uuvaxQMERmG1Mw8XYdAeiRodxwUDUwQNW8gEyuq1zRKqmbPnq12v6CgAP/88w/kcjksLS2ZVBEZsaT0HMzceV7XYZCe4dIKRBrO/ktLS1O7ZWVlIT4+Hv369WOhOpGRS8vOR0GR0HUYRER6R+Nr/5XWrl07fPrpp2VGsYiIiIjqA60lVcDj4vXk5GRt7pKIiIjIIGhUU/Xzzz+r3RdC4P79+9i0aROee+45rQRGRESGhbMAqb7TKKkaPXq02n2ZTIamTZti8ODBWLNmjTbiIiI9lJSeg4TULF2HQXqKswCpvtMoqSou5oVUieqbpPQcDF4dzQsp01NxFiDVZ1qtqSIi45WWnc+EiojoKTQaqQoODq5y37Vr12ryFEREREQGRaOk6uLFi7h48SIKCgrg7u4OAPjzzz9hamqKnj17Sv1kMpl2oiQiIiLScxolVSNHjoS1tTV27NiBRo0aAXi8IOjUqVPx/PPPY+7cuVoNkoiIiEjfaVRTtWbNGqxcuVJKqACgUaNG+Oijjzj7j4ionktIzUJSeo6uwyCqcxolVSqVCg8ePCjT/uDBA2RmZtY4KCIiMlxBu+MweHU0EyuqdzRKql5++WVMnToVe/fuxb1793Dv3j385z//gb+/P8aMGaPtGIlIx7g+FVVXydIKRPWJRjVVISEhmDdvHiZNmoSCgoLHO2rQAP7+/vj888+1GiAR6RbXpyIiqhqNkipLS0ts2bIFn3/+OW7evAkAaNOmDaysrLQaHBHpHtenIiKqmhot/nn//n3cv38f7dq1g5WVFYQQ2oqLiIiIyKBolFQ9fPgQQ4YMQfv27TFs2DDcv38fAODv78/lFIiIiKhe0iipmjNnDszMzJCYmAhLS0upffz48QgPD9dacERERESGQqOaql9//RVHjx5FixYt1NrbtWuHO3fuaCUwIiIybKmZuQBsdR0GUZ3RaKQqOztbbYSqxKNHj6BQKGocFBERGb6ZO2O5VhXVKxolVc8//zy++eYb6b5MJkNxcTFWrVqFQYMGaS04ItItrk9FNVFQJLhWFdUrGp3+W7VqFYYMGYLz588jPz8fCxYswNWrV/Ho0SOcOnVK2zESkQ5wfSoiourRaKSqS5cu+PPPP9GvXz+MGjUK2dnZGDNmDC5evIg2bdpoO0Yi0gGuT0VEVD3VHqkqKCiAr68vQkJC8N5779VGTEREZCQSUrPQyEqO5nYWug6FqNZVe6TKzMwMly5dqo1YiIjIyPDiylSfaHT679VXX8VXX32l7ViIiMgI8eLKVF9oVKheWFiIr7/+Gr/99hs8PDzKXPNv7dq1WgmOiIiIyFBUK6n666+/0KpVK1y5cgU9e/YEAPz5559qfWQymfaiIyKd4FIKRETVV62kql27drh//z6OHTsG4PFlaTZu3AhHR8daCY6I6h6XUiAi0ky1aqqEEGr3f/nlF2RnZ2s1ICLSLS6lQESkGY0K1UuUTrKIiIiI6qtqJVUymaxMzRRrqIiIqDIJqVlcVoGMXrVqqoQQmDJlinTR5NzcXLz55ptlZv/t3btXexESEZHBC9odB0UDE0TNG8iFQMloVSup8vPzU7v/6quvajUYIiIyXiXrVTGpImNVraQqNDS0tuIgIj2Rmpmn6xCIiAxSjQrVici4JKXnYObO87oOg4jIIOk0qTpx4gRGjhwJZ2dnyGQy7N+/X227EAJLlixBs2bNYGFhAW9vb9y4cUOtz6NHjzB58mTY2NjAzs4O/v7+yMpSX7Tw0qVLeP7552Fubg4XFxesWrWqTCx79uxBhw4dYG5ujq5du+LIkSPVjoXI0KVl56OgiLN6iYg0odOkKjs7G927d8fmzZvL3b5q1Sps3LgRISEhOHPmDKysrODj44Pc3Fypz+TJk3H16lVERETg0KFDOHHiBGbMmCFtV6lUGDp0KFxdXREbG4vPP/8cy5Ytw5dffin1+eOPPzBx4kT4+/vj4sWLGD16NEaPHo0rV65UKxYiIiKqv2RCTxabkslk2LdvH0aPHg3g8ciQs7Mz5s6di3nz5gEAMjIy4OjoiLCwMEyYMAHXrl1Dp06dcO7cOfTq1QsAEB4ejmHDhuHevXtwdnbG1q1b8d5770GpVEIulwMAFi1ahP379+P69esAHq8Mn52djUOHDknxPPvss+jRowdCQkKqFEtVqFQq2NraIiMjAzY2Nlp53Yi06UpSBkZ8cVLXYZARWz++B3q72bNYnQxKVX+/9bam6tatW1AqlfD29pbabG1t4enpiZiYGABATEwM7OzspIQKALy9vWFiYoIzZ85Iffr37y8lVADg4+OD+Ph4pKWlSX2efJ6SPiXPU5VYiIiockG74zB4dTTXrCKjpLdJlVKpBIAy1xV0dHSUtimVSjg4OKhtb9CgAezt7dX6lLePJ5+joj5Pbq8slvLk5eVBpVKp3YiI6ruSpRWIjI3eJlXGYOXKlbC1tZVuLi4uug6JqEJJ6TlISM2qvCMREZVLb5MqJycnAEBKSopae0pKirTNyckJqampatsLCwvx6NEjtT7l7ePJ56ioz5PbK4ulPIsXL0ZGRoZ0u3v3biVHTaQbSek5GLw6GkG743QdChGRwdLbpMrNzQ1OTk6IjIyU2lQqFc6cOQMvLy8AgJeXF9LT0xEbGyv1iYqKQnFxMTw9PaU+J06cQEFBgdQnIiIC7u7uaNSokdTnyecp6VPyPFWJpTwKhQI2NjZqNyJ9lJadj7zCYl2HQURk0HSaVGVlZSEuLg5xcXEAHheEx8XFITExETKZDEFBQfjoo4/w888/4/Lly3j99dfh7OwszRDs2LEjfH19MX36dJw9exanTp1CYGAgJkyYAGdnZwDApEmTIJfL4e/vj6tXr2L37t3YsGEDgoODpThmz56N8PBwrFmzBtevX8eyZctw/vx5BAYGAkCVYiEioqrjBZbJGOl0SYXo6GgMGjSoTLufnx/CwsIghMDSpUvx5ZdfIj09Hf369cOWLVvQvn17qe+jR48QGBiIgwcPwsTEBGPHjsXGjRvRsGFDqc+lS5cQEBCAc+fOoUmTJpg1axYWLlyo9px79uzB+++/j9u3b6Ndu3ZYtWoVhg0bJm2vSiyV4ZIKpK+4lALpAi+wTIaiqr/ferNOVX3ApIr0FZMq0pVDs/qhS3NbXYdB9FQGv04VERERkSFhUkVUz3EpBSIi7Wig6wCISHdKllLgzD8ioprjSBVRPcalFEjXUjN5UXoyHkyqiIhIZ2bujOXSCmQ0mFQREZHOFBQJXgeQjAaTKiIiIiItYFJFREREpAVMqojqKS6lQESkXVxSgage4lIKpE8SUrPQyErOy9WQweNIFVE9xKUUSJ8E7Y7D4NXRnAVIBo9JFRER6VxeYTFnAZLBY1JFREREpAVMqoiIiIi0gEkVERERkRYwqSKqZ7iUAhFR7eCSCkT1CJdSIH3GpRXI0HGkiqge4VIKpM+4tAIZOiZVRESkN7i0AhkyJlVEREREWsCkioiIiEgLmFQR1SOpmXm6DoGIyGgxqSKqJ5LSczBz53ldh0FEZLSYVBHVE2nZ+SgoEroOg6hSCalZnAFIBolJFRER6RUurUCGikkVERHpHS6tQIaISRURERGRFjCpIqoHeL0/IqLax2v/ERk5Xu+PDBWvBUiGhiNVREaO1/sjQ8WCdTI0TKqIiEhvsWCdDAmTKiIiIiItYFJFREREpAVMqoiMGGf9ERHVHc7+IzJSnPVHxiI1MxeAra7DIKoUR6qIjBRn/ZGxmLkzljMAySAwqSIiIr1WUCQ4A5AMApMqIiIiIi1gUkVERESkBUyqiIwQZ/0REdU9zv4jMjKc9UdEpBscqSIyMpz1R8YoITWLMwBJ7zGpIiIivceLK5MhYFJFREQGgRdXJn3HpIqIiIhIC5hUEREREWkBkyoiI8KlFMjYsWCd9BmXVCAyElxKgeqDoN1xUDQwQdS8gWhuZ6HrcIjUcKSKyEhwKQWqL1iwTvqKSRURERGRFjCpIjISqZl5ug6BiKheY1JFZASS0nMwc+d5XYdBVGdYsE76iEkVkRFIy85HQZHQdRhEdYYrrJM+YlJFREQGiQXrpG+YVBERERFpAZMqIiIiIi1gUkVk4LiKOhGRfuCK6kQGjKuoU32XkJqFRlZyrq5OeoEjVUQGjKuoU33HWYCkT5hUERGRQeMsQNIXep1ULVu2DDKZTO3WoUMHaXtubi4CAgLQuHFjNGzYEGPHjkVKSoraPhITEzF8+HBYWlrCwcEB8+fPR2FhoVqf6Oho9OzZEwqFAm3btkVYWFiZWDZv3oxWrVrB3Nwcnp6eOHv2bK0cMxERERkmvU6qAKBz5864f/++dDt58qS0bc6cOTh48CD27NmD48ePIzk5GWPGjJG2FxUVYfjw4cjPz8cff/yBHTt2ICwsDEuWLJH63Lp1C8OHD8egQYMQFxeHoKAgTJs2DUePHpX67N69G8HBwVi6dCkuXLiA7t27w8fHB6mpqXXzIhCVgwXqRP8nNTNX1yEQQSaE0NtlmJctW4b9+/cjLi6uzLaMjAw0bdoUu3btwrhx4wAA169fR8eOHRETE4Nnn30Wv/zyC0aMGIHk5GQ4OjoCAEJCQrBw4UI8ePAAcrkcCxcuxOHDh3HlyhVp3xMmTEB6ejrCw8MBAJ6enujduzc2bdoEACguLoaLiwtmzZqFRYsWVfl4VCoVbG1tkZGRARsbG01fFiIWqBOVYmYqQ/T8QSxYp1pR1d9vvR+punHjBpydndG6dWtMnjwZiYmJAIDY2FgUFBTA29tb6tuhQwe0bNkSMTExAICYmBh07dpVSqgAwMfHByqVClevXpX6PLmPkj4l+8jPz0dsbKxaHxMTE3h7e0t9KpKXlweVSqV2I9IGFqgTqSsoEqyrIp3T66TK09MTYWFhCA8Px9atW3Hr1i08//zzyMzMhFKphFwuh52dndpjHB0doVQqAQBKpVItoSrZXrLtaX1UKhVycnLw999/o6ioqNw+JfuoyMqVK2FrayvdXFxcqv0aEBERkWHQ63WqXnzxRenv3bp1g6enJ1xdXfHjjz/CwkL/h3gXL16M4OBg6b5KpWJiRUREZKT0eqSqNDs7O7Rv3x4JCQlwcnJCfn4+0tPT1fqkpKTAyckJAODk5FRmNmDJ/cr62NjYwMLCAk2aNIGpqWm5fUr2URGFQgEbGxu1GxER1Y6E1CyuV0U6ZVBJVVZWFm7evIlmzZrBw8MDZmZmiIyMlLbHx8cjMTERXl5eAAAvLy9cvnxZbZZeREQEbGxs0KlTJ6nPk/so6VOyD7lcDg8PD7U+xcXFiIyMlPoQ1SXO+iMqHxcCJV3T69N/8+bNw8iRI+Hq6ork5GQsXboUpqammDhxImxtbeHv74/g4GDY29vDxsYGs2bNgpeXF5599lkAwNChQ9GpUye89tprWLVqFZRKJd5//30EBARAoVAAAN58801s2rQJCxYswBtvvIGoqCj8+OOPOHz4sBRHcHAw/Pz80KtXL/Tp0wfr169HdnY2pk6dqpPXheovzvojerqShUA5C5B0Qa+Tqnv37mHixIl4+PAhmjZtin79+uH06dNo2rQpAGDdunUwMTHB2LFjkZeXBx8fH2zZskV6vKmpKQ4dOoS33noLXl5esLKygp+fH1asWCH1cXNzw+HDhzFnzhxs2LABLVq0wPbt2+Hj4yP1GT9+PB48eIAlS5ZAqVSiR48eCA8PL1O8TlTbOOuPiEh/6fU6VcaG61RRTV1JysCIL05W3pGoHjs0qx+6NLfVdRhkRIxmnSoiIqLqYME66QqTKiIDwQJ1oqphwTrpil7XVBHRYyxQJ6oeFqyTLnCkisgAsECdiEj/MakiIiKjxNoqqmtMqoj0HGupiDTD2iqqa6ypItJjrKUiqhnWVlFd4kgVkR5jLRURkeFgUkVERESkBUyqiPRYamaerkMgMngsWKe6wqSKSE8lpedg5s7zug6DyOCxYJ3qCpMqIj2Vlp2PgiJempNIG0oK1olqE5MqIiIiIi1gUkVERPUCa6uotjGpItJDXPCTSPtYW0W1jYt/EukZLvhJVHu4GCjVJo5UEekZLvhJRGSYmFQREVG9kpqZq+sQyEgxqSLSI6ylIqp9M3fGsq6KagVrqoj0BGupiOpGQZFgXRXVCo5UEekJ1lIR1R0ur0C1gUkVERHVO1xegWoDkyoiPcBaKqK6x0vXkLaxpopIx1hLRaQ7CalZaGQlZ30VaQVHqoh0jLVURLrD04CkTUyqiIioXuNpQNIWJlVEOsRaKiIi48GaKiIdYS0Vkf5gbRVpA0eqiHSEtVRE+oO1VaQNTKqIdCQ1M0/XIRDRE1hbRTXFpIpIB5LSczBz53ldh0FEpXCldaoJJlVEOpCWnY+CIqHrMIioFJ4GpJpgUkVUxzjjj0i/8TQgaYqz/4jqEGf8ERmG1MxcALa6DoMMDEeqiOoQZ/wRGYaZO2N5CpCqjUkVUR3haT8iw1FQJHDu1iMmVlQtPP1HVAd42o/I8ATtjoOigQmi5g3koqBUJRypIqplSek5OHfrERMqIgPEonWqDo5UEdUijlARGT5ewoaqiiNVRLWIhelEho9rV1FVMakiqiUsTCcyHnmFxSxcp0rx9B9RLeBpPyLjw8J1qgxHqohqQbwykwkVkRHiiBU9DZMqIi3jxZKJjBtrrKgiTKqItKhk+QReLJnIuOUVFiNeqdJ1GKRnmFQRaUlJHVXQ7jhdh0JEdYCXsqHSmFQRaQEX+CSqf3gpGyqNs/+Iaogz/YjqL84IpCdxpIqoBjhCRUScEUglOFJFpCGOUBFRiaDdcZCbyhDyWi+4O1lz1KqeYlJFpAGOUBFRaflFAm+EnWNyVY8xqSKqptg7aZj45WnkFzGhIqKySpIr1lrVP6ypIqqGpPQcTPgyhgkVEVWKa1nVP0yqiKqIC3sSUXXN+OY8oq6nsoi9nuDpP6JKJKXnIF6pwps7L3CEioiqpbAYrLOqR5hUEVWAyRQRaQuL2OsHJlVEpTCZIqLawuTKuDGpInoCZ/YRUV14MrnaOLEnWjSyQCMrORMsA8ekiuq1pPQcpGXnI6+wGBk5+ZjxTSwKi1mITkR1I79I4M1vYwGAo1dGgElVNW3evBmff/45lEolunfvji+++AJ9+vTRdVhURaWTKJ7iIyJ9UfrUoK2FGRQNTDiCZUCYVFXD7t27ERwcjJCQEHh6emL9+vXw8fFBfHw8HBwcdB0eVaAkkbqXloN3vr/IJIqI9FpJclXiyVOEeYXFTLT0mEwIwXMdVeTp6YnevXtj06ZNAIDi4mK4uLhg1qxZWLRoUaWPV6lUsLW1RUZGBmxsbGo73HolKT0HyoxcKBqYSP/ocDSKiIxV6dGsvMJiONmaM9GqJVX9/eZIVRXl5+cjNjYWixcvltpMTEzg7e2NmJgYHUZm+J48JVc6KSr5E0CF2zJy8jHzm1gUsBaKiOqJ0qNZAGBmIsO219UTrer8W8rkrOaYVFXR33//jaKiIjg6Oqq1Ozo64vr16+U+Ji8vD3l5edL9jIwMAI8zXm17oMrFg6w8mMiAYoFy/wQq3ladPtrc38PsPLzz/X9RwJEkIqIayQMwZdvxGu/HQm6C1f/qAUdruUH9npjIgMZWCjS1Ma/xa1Baye92ZSf3mFTVopUrV2L58uVl2l1cXHQQDRERUdW8tErXEeinzMxM2NraVridSVUVNWnSBKampkhJSVFrT0lJgZOTU7mPWbx4MYKDg6X7xcXFePToERo3bgyZTKb1GFUqFVxcXHD37l2jq9nisRkuYz4+Hpth4rEZJl0emxACmZmZcHZ2fmo/JlVVJJfL4eHhgcjISIwePRrA4yQpMjISgYGB5T5GoVBAoVCotdnZ2dVypICNjY3RfZlK8NgMlzEfH4/NMPHYDJOuju1pI1QlmFRVQ3BwMPz8/NCrVy/06dMH69evR3Z2NqZOnarr0IiIiEjHmFRVw/jx4/HgwQMsWbIESqUSPXr0QHh4eJnidSIiIqp/mFRVU2BgYIWn+3RNoVBg6dKlZU45GgMem+Ey5uPjsRkmHpthMoRj4+KfRERERFpgousAiIiIiIwBkyoiIiIiLWBSRURERKQFTKqIiIiItIBJlQG7ffs2/P394ebmBgsLC7Rp0wZLly5Ffn7+Ux+Xm5uLgIAANG7cGA0bNsTYsWPLrBSvDz7++GP07dsXlpaWVV40dcqUKZDJZGo3X1/f2g1UA5ocmxACS5YsQbNmzWBhYQFvb2/cuHGjdgPVwKNHjzB58mTY2NjAzs4O/v7+yMrKeupjBg4cWOZ9e/PNN+so4qfbvHkzWrVqBXNzc3h6euLs2bNP7b9nzx506NAB5ubm6Nq1K44cOVJHkVZfdY4tLCyszHtkbq79a6zV1IkTJzBy5Eg4OztDJpNh//79lT4mOjoaPXv2hEKhQNu2bREWFlbrcWqquscXHR1d5n2TyWRQKpV1E3AVrVy5Er1794a1tTUcHBwwevRoxMfHV/o4ffu+MakyYNevX0dxcTG2bduGq1evYt26dQgJCcG777771MfNmTMHBw8exJ49e3D8+HEkJydjzJgxdRR11eXn5+Nf//oX3nrrrWo9ztfXF/fv35du33//fS1FqDlNjm3VqlXYuHEjQkJCcObMGVhZWcHHxwe5ubm1GGn1TZ48GVevXkVERAQOHTqEEydOYMaMGZU+bvr06Wrv26pVur/42O7duxEcHIylS5fiwoUL6N69O3x8fJCamlpu/z/++AMTJ06Ev78/Ll68iNGjR2P06NG4cuVKHUdeueoeG/B4Jesn36M7d+7UYcRVk52dje7du2Pz5s1V6n/r1i0MHz4cgwYNQlxcHIKCgjBt2jQcPXq0liPVTHWPr0R8fLzae+fg4FBLEWrm+PHjCAgIwOnTpxEREYGCggIMHToU2dnZFT5GL79vgozKqlWrhJubW4Xb09PThZmZmdizZ4/Udu3aNQFAxMTE1EWI1RYaGipsbW2r1NfPz0+MGjWqVuPRpqoeW3FxsXBychKff/651Jaeni4UCoX4/vvvazHC6vnf//4nAIhz585Jbb/88ouQyWQiKSmpwscNGDBAzJ49uw4irJ4+ffqIgIAA6X5RUZFwdnYWK1euLLf/K6+8IoYPH67W5unpKWbOnFmrcWqiusdWne+hvgAg9u3b99Q+CxYsEJ07d1ZrGz9+vPDx8anFyLSjKsd37NgxAUCkpaXVSUzakpqaKgCI48ePV9hHH79vHKkyMhkZGbC3t69we2xsLAoKCuDt7S21dejQAS1btkRMTExdhFjroqOj4eDgAHd3d7z11lt4+PChrkOqsVu3bkGpVKq9b7a2tvD09NSr9y0mJgZ2dnbo1auX1Obt7Q0TExOcOXPmqY/97rvv0KRJE3Tp0gWLFy/GP//8U9vhPlV+fj5iY2PVXnMTExN4e3tX+JrHxMSo9QcAHx8fvXqPAM2ODQCysrLg6uoKFxcXjBo1ClevXq2LcGuVobxnNdWjRw80a9YML7zwAk6dOqXrcCqVkZEBAE/9PdPH944rqhuRhIQEfPHFF1i9enWFfZRKJeRyeZk6HkdHR707x64JX19fjBkzBm5ubrh58ybeffddvPjii4iJiYGpqamuw9NYyXtT+pJI+va+KZXKMqcVGjRoAHt7+6fGOWnSJLi6usLZ2RmXLl3CwoULER8fj71799Z2yBX6+++/UVRUVO5rfv369XIfo1Qq9f49AjQ7Nnd3d3z99dfo1q0bMjIysHr1avTt2xdXr15FixYt6iLsWlHRe6ZSqZCTkwMLCwsdRaYdzZo1Q0hICHr16oW8vDxs374dAwcOxJkzZ9CzZ09dh1eu4uJiBAUF4bnnnkOXLl0q7KeP3zeOVOmhRYsWlVtY+OSt9D98SUlJ8PX1xb/+9S9Mnz5dR5FXTpNjq44JEybgpZdeQteuXTF69GgcOnQI586dQ3R0tPYOogK1fWy6VNvHNmPGDPj4+KBr166YPHkyvvnmG+zbtw83b97U4lFQTXh5eeH1119Hjx49MGDAAOzduxdNmzbFtm3bdB0aPYW7uztmzpwJDw8P9O3bF19//TX69u2LdevW6Tq0CgUEBODKlSv44YcfdB1KtXGkSg/NnTsXU6ZMeWqf1q1bS39PTk7GoEGD0LdvX3z55ZdPfZyTkxPy8/ORnp6uNlqVkpICJyenmoRdJdU9tppq3bo1mjRpgoSEBAwZMkRr+y1PbR5byXuTkpKCZs2aSe0pKSno0aOHRvusjqoem5OTU5lC58LCQjx69Khany9PT08Aj0df27RpU+14taFJkyYwNTUtMzP2ad8VJyenavXXFU2OrTQzMzM888wzSEhIqI0Q60xF75mNjY3Bj1JVpE+fPjh58qSuwyhXYGCgNMGlshFQffy+ManSQ02bNkXTpk2r1DcpKQmDBg2Ch4cHQkNDYWLy9MFHDw8PmJmZITIyEmPHjgXweFZIYmIivLy8ahx7ZapzbNpw7949PHz4UC0RqS21eWxubm5wcnJCZGSklESpVCqcOXOm2rMjNVHVY/Py8kJ6ejpiY2Ph4eEBAIiKikJxcbGUKFVFXFwcANTJ+1YRuVwODw8PREZGYvTo0QAen5aIjIys8KLqXl5eiIyMRFBQkNQWERFRJ9+t6tDk2EorKirC5cuXMWzYsFqMtPZ5eXmVmYavj++ZNsXFxen0u1UeIQRmzZqFffv2ITo6Gm5ubpU+Ri+/bzorkacau3fvnmjbtq0YMmSIuHfvnrh//750e7KPu7u7OHPmjNT25ptvipYtW4qoqChx/vx54eXlJby8vHRxCE91584dcfHiRbF8+XLRsGFDcfHiRXHx4kWRmZkp9XF3dxd79+4VQgiRmZkp5s2bJ2JiYsStW7fEb7/9Jnr27CnatWsncnNzdXUY5arusQkhxKeffirs7OzEgQMHxKVLl8SoUaOEm5ubyMnJ0cUhVMjX11c888wz4syZM+LkyZOiXbt2YuLEidL20p/JhIQEsWLFCnH+/Hlx69YtceDAAdG6dWvRv39/XR2C5IcffhAKhUKEhYWJ//3vf2LGjBnCzs5OKJVKIYQQr732mli0aJHU/9SpU6JBgwZi9erV4tq1a2Lp0qXCzMxMXL58WVeHUKHqHtvy5cvF0aNHxc2bN0VsbKyYMGGCMDc3F1evXtXVIZQrMzNT+j4BEGvXrhUXL14Ud+7cEUIIsWjRIvHaa69J/f/66y9haWkp5s+fL65duyY2b94sTE1NRXh4uK4O4amqe3zr1q0T+/fvFzdu3BCXL18Ws2fPFiYmJuK3337T1SGU66233hK2trYiOjpa7bfsn3/+kfoYwveNSZUBCw0NFQDKvZW4deuWACCOHTsmteXk5Ii3335bNGrUSFhaWoqXX35ZLRHTF35+fuUe25PHAkCEhoYKIYT4559/xNChQ0XTpk2FmZmZcHV1FdOnT5d+JPRJdY9NiMfLKnzwwQfC0dFRKBQKMWTIEBEfH1/3wVfi4cOHYuLEiaJhw4bCxsZGTJ06VS1ZLP2ZTExMFP379xf29vZCoVCItm3bivnz54uMjAwdHYG6L774QrRs2VLI5XLRp08fcfr0aWnbgAEDhJ+fn1r/H3/8UbRv317I5XLRuXNncfjw4TqOuOqqc2xBQUFSX0dHRzFs2DBx4cIFHUT9dCVLCJS+lRyLn5+fGDBgQJnH9OjRQ8jlctG6dWu1752+qe7xffbZZ6JNmzbC3Nxc2Nvbi4EDB4qoqCjdBP8UFf2WPfleGML3TSaEELU5EkZERERUH3D2HxEREZEWMKkiIiIi0gImVURERERawKSKiIiISAuYVBERERFpAZMqIiIiIi1gUkVERESkBUyqiKheWrZsWa1cN/H27duQyWTSpXbKEx0dDZlMhvT0dABAWFiY2rU4icgwMakiIr03ZcoUyGSyMjdfX19dh6YV48ePx59//qnrMIiohnhBZSIyCL6+vggNDVVrUygUOopGuywsLGBhYaHrMIiohjhSRUQGQaFQwMnJSe3WqFEjAIBMJsO2bdswYsQIWFpaomPHjoiJiUFCQgIGDhwIKysr9O3bFzdv3iyz323btsHFxQWWlpZ45ZVXkJGRobZ9+/bt6NixI8zNzdGhQwds2bJFbfvZs2fxzDPPwNzcHL169cLFixfLPMeRI0fQvn17WFhYYNCgQbh9+7ba9tKn/0pOTe7cuROtWrWCra0tJkyYgMzMTKlPZmYmJk+eDCsrKzRr1gzr1q3DwIEDERQUJPXZsmUL2rVrB3Nzczg6OmLcuHFVfbmJSANMqojIKHz44Yd4/fXXERcXhw4dOmDSpEmYOXMmFi9ejPPnz0MIgcDAQLXHJCQk4Mcff8TBgwcRHh6Oixcv4u2335a2f/fdd1iyZAk+/vhjXLt2DZ988gk++OAD7NixAwCQlZWFESNGoFOnToiNjcWyZcswb948tee4e/cuxowZg5EjRyIuLg7Tpk3DokWLKj2emzdvYv/+/Th06BAOHTqE48eP49NPP5W2BwcH49SpU/j5558RERGB33//HRcuXJC2nz9/Hu+88w5WrFiB+Ph4hIeHo3///hq9tkRURTq9nDMRURX4+fkJU1NTYWVlpXb7+OOPhRCPr3D//vvvS/1jYmIEAPHVV19Jbd9//70wNzeX7i9dulSYmpqKe/fuSW2//PKLMDExEffv3xdCCNGmTRuxa9cutVg+/PBD4eXlJYQQYtu2baJx48YiJydH2r5161YBQFy8eFEIIcTixYtFp06d1PaxcOFCAUCkpaUJIYQIDQ0Vtra2arFZWloKlUoltc2fP194enoKIYRQqVTCzMxM7NmzR9qenp4uLC0txezZs4UQQvznP/8RNjY2avsgotrFmioiMgiDBg3C1q1b1drs7e2lv3fr1k36u6OjIwCga9euam25ublQqVSwsbEBALRs2RLNmzeX+nh5eaG4uBjx8fGwtrbGzZs34e/vj+nTp0t9CgsLYWtrCwC4du0aunXrBnNzc7V9POnatWvw9PRUayvdpzytWrWCtbW1dL9Zs2ZITU0FAPz1118oKChAnz59pO22trZwd3eX7r/wwgtwdXVF69at4evrC19fX7z88suwtLSs9LmJSDNMqojIIFhZWaFt27YVbjczM5P+LpPJKmwrLi6u0vNlZWUBAP7973+XSYpMTU2rFnQNPBk78Dj+qsYOANbW1rhw4QKio6Px66+/YsmSJVi2bBnOnTvH5RuIaglrqoio3kpMTERycrJ0//Tp0zAxMYG7uzscHR3h7OyMv/76C23btlW7ubm5AQA6duyIS5cuITc3V20fT+rYsSPOnj2r1la6T3W1bt0aZmZmOHfunNSWkZFRZlmGBg0awNvbG6tWrcKlS5dw+/ZtREVF1ei5iahiHKkiIoOQl5cHpVKp1tagQQM0adJE432am5vDz88Pq1evhkqlwjvvvINXXnkFTk5OAIDly5fjnXfega2tLXx9fZGXl4fz588jLS0NwcHBmDRpEt577z1Mnz4dixcvxu3bt7F69Wq153jzzTexZs0azJ8/H9OmTUNsbCzCwsI0jhl4PArl5+eH+fPnw97eHg4ODli6dClMTEykEblDhw7hr7/+Qv/+/dGoUSMcOXIExcXFaqcIiUi7OFJFRAYhPDwczZo1U7v169evRvts27YtxowZg2HDhmHo0KHo1q2b2pIJ06ZNw/bt2xEaGoquXbtiwIABCAsLk0aqGjZsiIMHD+Ly5ct45pln8N577+Gzzz5Te46WLVviP//5D/bv34/u3bsjJCQEn3zySY3iBoC1a9fCy8sLI0aMgLe3N5577jlp6QcAsLOzw969ezF48GB07NgRISEh+P7779G5c+caPzcRlU8mhBC6DoKIiGomOzsbzZs3x5o1a+Dv76/rcIjqJZ7+IyIyQBcvXsT169fRp08fZGRkYMWKFQCAUaNG6TgyovqLSRURkYFavXo14uPjIZfL4eHhgd9//71GNWZEVDM8/UdERESkBSxUJyIiItICJlVEREREWsCkioiIiEgLmFQRERERaQGTKiIiIiItYFJFREREpAVMqoiIiIi0gEkVERERkRYwqSIiIiLSgv8H7+lV89KUs5QAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "calibration_embeddings = f32_embeddings[:10000]\n",
        "f_min = np.min(calibration_embeddings)\n",
        "f_max = np.max(calibration_embeddings)\n",
        "\n",
        "# calculate percentage in range\n",
        "values_in_range = np.sum((f32_embeddings >= f_min) & (f32_embeddings <= f_max))\n",
        "percentage_in_range = (values_in_range / f32_embeddings.size) * 100\n",
        "\n",
        "print(f\"[f_min, f_max] calibration embeddings: [{f_min, f_max}]\")\n",
        "print(f\"Percentage of embeddings within [f_min, f_max]: {percentage_in_range:.4f}%\")"
      ],
      "metadata": {
        "id": "pTmQ7QOlpSp0",
        "outputId": "f153d4cf-2e58-4109-eb96-6317b8276792",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max value: 2.0746829509735107\n",
            "Min value: -2.0162134170532227\n",
            "Percentage of values within [-2.0, +2.0]: 99.99997%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(f32_embeddings[1000][:25]).reshape(5, 5)\n",
        "f32_embeddings[1000][:25]"
      ],
      "metadata": {
        "id": "91TB26gKIw6V",
        "outputId": "e7b107d4-0608-4dcd-8f1b-52d8598cfad7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.09335478, -0.5977759 ,  0.07759342, -0.20578717, -0.37967288,\n",
              "        0.28887537, -0.31568018,  0.05953625, -0.3389973 ,  0.66473234,\n",
              "       -0.4395536 , -0.49926084, -0.48578802, -0.3860658 , -0.37590823,\n",
              "        1.0048815 ,  0.39084274, -0.070282  ,  0.1424382 ,  0.03794623,\n",
              "       -0.10923411, -0.5995008 , -0.41349494,  0.02398205,  0.18937029],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(int8_embeddings[1000][:25]).reshape(5, 5)"
      ],
      "metadata": {
        "id": "UL6WiWehHTVE",
        "outputId": "53f9425e-5640-4bce-fb2d-551ab6ebce90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 20,   7, -65, -59, -26],\n",
              "       [  8, -25,  74, -61,  34],\n",
              "       [ 10, -19,  10, -65, -16],\n",
              "       [  6,  56, -10,  23,  26],\n",
              "       [ 39, -16,  21,  43, -36]], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "PjZ-Scq34CAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "corpus = load_dataset(\"dcarpintero/arxiv.cs.CL.25k\", split=\"train[:1000]\")[\"question\"]\n",
        "\n",
        "ARXIV_JSON='./arxiv.cs.CL.25k.desc.json'\n",
        "ARXIV_EMBEDDINGS_JSONL='./arxiv.cs.CL.embeddings.25k.jina.jsonl'\n",
        "BATCH_SIZE=64\n",
        "\n",
        "df = pd.read_json(ARXIV_JSON)\n",
        "embeddings = model.encode(df['title'] + ': ' + df['abstract'],\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          show_progress_bar=True)\n",
        "embeddings.shape"
      ],
      "metadata": {
        "id": "HQbkr0kPji1f",
        "outputId": "7c03db8c-c93c-4ead-b55b-87ad8a533bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "89e580233c514001b366cbc10388a6d2",
            "6fb9154ef24f4ce09fd2e186d974b888",
            "f962e923bda1493d93d7723c2ad1f4b2",
            "02a7098d021546439019097aa61b4690",
            "658984d8d29d4f73a8737d14f2ed7c14",
            "00dcae144bb24b08864113536c8c0829",
            "a8c1137204e0431fb68fb16cddee9564",
            "a9112e783801453692ae8ef6ed60006d",
            "4c73f8060e87472ab2eaff693d308131",
            "1acdfcaa110c497d845e705ad8d41458",
            "4130501d45f74cc2abb375f9b1b8ae85"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/393 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89e580233c514001b366cbc10388a6d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25107, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As an alternative you might just load the prepared dataset with embeddings from HuggingFace."
      ],
      "metadata": {
        "id": "LyVLW5G6kp2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import tqdm as notebook_tqdm\n",
        "\n",
        "ds_fp32 = load_dataset(\"dcarpintero/arxiv.cs.CL.25k.embeddings.jina\", split=\"train\")\n",
        "ds_int8 = load_dataset(\"dcarpintero/arxiv.cs.CL.25k.int8.embeddings.jina\", split=\"train\")"
      ],
      "metadata": {
        "id": "_9-6JBvV7e28"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sentence_transformers.quantization import quantize_embeddings\n",
        "\n",
        "int8_embeddings = quantize_embeddings(\n",
        "    np.array(ds_fp32[\"embeddings\"]),\n",
        "    precision=\"int8\",\n",
        "    calibration_embeddings=np.array(ds_fp32[\"embeddings\"][:10000]),\n",
        ")"
      ],
      "metadata": {
        "id": "YpRtgupXzbPf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.array(int8_embeddings[1000][:25]).reshape(5, 5)"
      ],
      "metadata": {
        "id": "tDq3WoNhz6Z2",
        "outputId": "b5bb67d2-165a-4d4a-b5eb-d29fdd26d247",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 20,   7, -65, -59, -26],\n",
              "       [  8, -25,  74, -61,  34],\n",
              "       [ 10, -19,  10, -65, -16],\n",
              "       [  6,  56, -10,  23,  26],\n",
              "       [ 39, -16,  21,  43, -36]], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings=int8_embeddings"
      ],
      "metadata": {
        "id": "lGUqM0QPz_cs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Projecting Embeddings for Dimensionality Reduction"
      ],
      "metadata": {
        "id": "1xzN9ohN8xVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then project our (`title:abstract`) embeddings pairs from a high-dimensional space (768) to a lower-dimensional one (5) using\n",
        "[dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction). This process will reduce the computational complexity and memory usage during clustering.\n",
        "\n",
        "To implement this step, we use [UMAP](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction#Uniform_manifold_approximation_and_projection) [1], a popular technique known for its effectiveness in preserving both the local and global data structures. In practice, this makes it a preferred choice for handling complex datasets with high-dimensional embeddings."
      ],
      "metadata": {
        "id": "rvIphImiArUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import umap\n",
        "\n",
        "embedding_5d = umap.UMAP(n_neighbors=100,\n",
        "                         n_components=5,\n",
        "                         min_dist=0.1,\n",
        "                         metric='cosine').fit_transform(embeddings)\n",
        "\n",
        "embedding_2d = umap.UMAP(n_neighbors=100,\n",
        "                         n_components=2,\n",
        "                         min_dist=0.1,\n",
        "                         metric='cosine').fit_transform(embeddings)"
      ],
      "metadata": {
        "id": "uD51VhMG8yrI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our implementation, we configure UMAP with:\n",
        "- `n_neighbors=100` to consider 100 nearest neighbors for each point (arXiv publication);\n",
        "- `n_components=5` to reduce the embeddings from 768 to 5 dimensions;\n",
        "- `min_dist=0.1` to maintain a balance between the local and global structure; and,\n",
        "- `metric='cosine'` to measure the distance between points using the cosine similarity metric.\n",
        "\n",
        "Note that when we apply HDBSCAN clustering in the next step, the clusters found will be influenced by how UMAP preserved the local structures. A smaller `n_neighbors` value means UMAP will focus more on local structures, whereas a larger value allows to capture more global representations, which might be beneficial for understanding overall patterns in the data."
      ],
      "metadata": {
        "id": "WSYIVW33A7dq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Semantic Clustering"
      ],
      "metadata": {
        "id": "1hH0Ra-x80I4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section shows how to use the reduced (`title:abstract`) embeddings pairs as input features of a clustering algorithm. This allows for the identification of related categories based on the distance between the provided embeddings.\n",
        "\n",
        "We have opted for [HDBSCAN](https://en.wikipedia.org/wiki/HDBSCAN) (Hierarchical Density-Based Spatial Clustering of Applications with Noise) [2], an advanced clustering algorithm that extends DBSCAN by adapting to varying density clusters. Unlike K-Means which requires pre-specifying the number of clusters, HDBSCAN has only one important hyperparameter, `n`, which establishes the minimum number of examples to include in a cluster. As a density-based method, it can also detect outliers in the data.\n",
        "\n",
        "HDBSCAN works by first transforming the data space according to the density of the data points, making denser regions (areas where data points are close together in high numbers) more attractive for cluster formation. The algorithm then builds a hierarchy of clusters based on the minimum cluster size established by the hyperparameter `n`. This allows it to distinguish between noise (sparse areas) and dense regions (potential clusters). Finally, HDBSCAN condenses this hierarchy to derive the most persistent clusters, efficiently identifying clusters of different densities and shapes."
      ],
      "metadata": {
        "id": "Qj0zQPWHCLoE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that while we define a minimum cluster size similar to the number of neighbors in UMAP, in practice they do not need to be equal."
      ],
      "metadata": {
        "id": "H5S6DW47Cd_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hdbscan\n",
        "\n",
        "hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=100,\n",
        "                                metric='euclidean',\n",
        "                                cluster_selection_method='leaf')\n",
        "clusters = hdbscan_model.fit_predict(embedding_5d)"
      ],
      "metadata": {
        "id": "wND3TL1O83OX",
        "outputId": "740b2fa4-94bc-461b-a302-48f80121ec2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We prepare the dataset for visualization by further reducing the number of dimensions, in this case from '5' to '2'."
      ],
      "metadata": {
        "id": "sDmhg0Yzel3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(embedding_2d, columns=['x', 'y'])\n",
        "df['cluster'] = clusters\n",
        "df['title'] = ds['title']\n",
        "df['publication_date'] = ds['publication_date']\n",
        "\n",
        "df = df[df['cluster'] != -1] # remove outliers"
      ],
      "metadata": {
        "id": "aRuZl3sV837g"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Aa1LLthXqcMA",
        "outputId": "7e8c3dc1-2424-4cb7-92d7-1ceca5e6891e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           x         y  cluster  \\\n",
              "0   6.028430  2.592616       27   \n",
              "1   8.474488  7.335292       15   \n",
              "2   5.309375  1.033876        1   \n",
              "4   5.178291  1.147729        1   \n",
              "5   9.767088  4.791462       17   \n",
              "6   3.691038  5.610329       25   \n",
              "9   3.498631  2.756207        8   \n",
              "10  3.471732  2.613416        8   \n",
              "12  9.644187  2.242630       32   \n",
              "14  6.831263  2.266203       24   \n",
              "\n",
              "                                                title      publication_date  \n",
              "0   Planetarium: A Rigorous Benchmark for Translat...  2024-07-03T17:59:53Z  \n",
              "1   InternLM-XComposer-2.5: A Versatile Large Visi...  2024-07-03T17:59:21Z  \n",
              "2   BACON: Supercharge Your VLM with Bag-of-Concep...  2024-07-03T17:55:27Z  \n",
              "4   LLM Internal States Reveal Hallucination Risk ...  2024-07-03T17:08:52Z  \n",
              "5   Evaluating Automatic Metrics with Incremental ...  2024-07-03T17:04:17Z  \n",
              "6   How Similar Are Elected Politicians and Their ...  2024-07-03T16:36:26Z  \n",
              "9   Self-Evaluation as a Defense Against Adversari...  2024-07-03T16:03:42Z  \n",
              "10  Single Character Perturbations Break LLM Align...  2024-07-03T16:03:10Z  \n",
              "12    How Does Quantization Affect Multilingual LLMs?  2024-07-03T15:39:40Z  \n",
              "14  Fine-Tuning with Divergent Chains of Thought B...  2024-07-03T15:01:18Z  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fe53c37f-c8fe-46ab-8b9d-f44a08d444e5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>cluster</th>\n",
              "      <th>title</th>\n",
              "      <th>publication_date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.028430</td>\n",
              "      <td>2.592616</td>\n",
              "      <td>27</td>\n",
              "      <td>Planetarium: A Rigorous Benchmark for Translat...</td>\n",
              "      <td>2024-07-03T17:59:53Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.474488</td>\n",
              "      <td>7.335292</td>\n",
              "      <td>15</td>\n",
              "      <td>InternLM-XComposer-2.5: A Versatile Large Visi...</td>\n",
              "      <td>2024-07-03T17:59:21Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.309375</td>\n",
              "      <td>1.033876</td>\n",
              "      <td>1</td>\n",
              "      <td>BACON: Supercharge Your VLM with Bag-of-Concep...</td>\n",
              "      <td>2024-07-03T17:55:27Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.178291</td>\n",
              "      <td>1.147729</td>\n",
              "      <td>1</td>\n",
              "      <td>LLM Internal States Reveal Hallucination Risk ...</td>\n",
              "      <td>2024-07-03T17:08:52Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9.767088</td>\n",
              "      <td>4.791462</td>\n",
              "      <td>17</td>\n",
              "      <td>Evaluating Automatic Metrics with Incremental ...</td>\n",
              "      <td>2024-07-03T17:04:17Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.691038</td>\n",
              "      <td>5.610329</td>\n",
              "      <td>25</td>\n",
              "      <td>How Similar Are Elected Politicians and Their ...</td>\n",
              "      <td>2024-07-03T16:36:26Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3.498631</td>\n",
              "      <td>2.756207</td>\n",
              "      <td>8</td>\n",
              "      <td>Self-Evaluation as a Defense Against Adversari...</td>\n",
              "      <td>2024-07-03T16:03:42Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3.471732</td>\n",
              "      <td>2.613416</td>\n",
              "      <td>8</td>\n",
              "      <td>Single Character Perturbations Break LLM Align...</td>\n",
              "      <td>2024-07-03T16:03:10Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>9.644187</td>\n",
              "      <td>2.242630</td>\n",
              "      <td>32</td>\n",
              "      <td>How Does Quantization Affect Multilingual LLMs?</td>\n",
              "      <td>2024-07-03T15:39:40Z</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>6.831263</td>\n",
              "      <td>2.266203</td>\n",
              "      <td>24</td>\n",
              "      <td>Fine-Tuning with Divergent Chains of Thought B...</td>\n",
              "      <td>2024-07-03T15:01:18Z</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe53c37f-c8fe-46ab-8b9d-f44a08d444e5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fe53c37f-c8fe-46ab-8b9d-f44a08d444e5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fe53c37f-c8fe-46ab-8b9d-f44a08d444e5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a3bca3e3-2ba2-468a-9e6c-0fcfcc973aeb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a3bca3e3-2ba2-468a-9e6c-0fcfcc973aeb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a3bca3e3-2ba2-468a-9e6c-0fcfcc973aeb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 11272,\n  \"fields\": [\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 11267,\n        \"samples\": [\n          3.321774482727051,\n          6.324245929718018,\n          3.3195395469665527\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 11264,\n        \"samples\": [\n          6.3669891357421875,\n          2.7634220123291016,\n          1.3287264108657837\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 0,\n        \"max\": 33,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          13,\n          19,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11272,\n        \"samples\": [\n          \"MuAViC: A Multilingual Audio-Visual Corpus for Robust Speech Recognition  and Robust Speech-to-Text Translation\",\n          \"On Few-Shot Prompting for Controllable Question-Answer Generation in  Narrative Comprehension\",\n          \"Efficiency at Scale: Investigating the Performance of Diminutive  Language Models in Clinical Tasks\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"publication_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 11266,\n        \"samples\": [\n          \"2024-02-25T17:43:29Z\",\n          \"2024-04-03T15:17:21Z\",\n          \"2024-02-16T11:37:05Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['cluster'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkdscDt7y_wI",
        "outputId": "134409e8-fcc7-4704-979a-f8bccad6a269"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Topic Modeling with LLMs"
      ],
      "metadata": {
        "id": "CXMs-a3X9ADN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having performed the clustering step, we now illustrate how to identify the topic of each cluster by combining an LLM such as [Mistral-7B-Instruct](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3) with [Pydantic](https://docs.pydantic.dev/) and [LangChain](https://www.langchain.com/) to create a topic modeling pipeline."
      ],
      "metadata": {
        "id": "HX-AO-1FZKKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install huggingface_hub langchain langchain_huggingface --upgrade --quiet"
      ],
      "metadata": {
        "id": "AwR9byUaHzJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "038dc7f3-a2bf-4d26-8669-052bf27e67fc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m983.6/983.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m357.9/357.9 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m127.9/127.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Pydantic Model"
      ],
      "metadata": {
        "id": "N7WIZ3YE-Fut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Pydantic Models](https://docs.pydantic.dev/latest/concepts/models/) are classes that derive from `pydantic.BaseModel`, defining fields as type-annotated attributes. They bear a strong resemblance to `Python` dataclasses. However, they have been designed with subtle but significant differences that optimize various operations such as validation, serialization, and `JSON` schema generation. Our `Topic` class defines a field named `category`. This will generate output in a structured format, rather than a free-form text block, facilitating easier processing and analysis of the topic modeling results."
      ],
      "metadata": {
        "id": "A8sTrB9LZP_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Topic(BaseModel):\n",
        "    \"\"\"\n",
        "    Pydantic Model to generate an structured Topic Model\n",
        "    \"\"\"\n",
        "    label: str = Field(..., description=\"Identified topic\")"
      ],
      "metadata": {
        "id": "O9KmSyHU-B8m"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 LangChain Prompt Template"
      ],
      "metadata": {
        "id": "vH8Dtg_B-Hl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[LangChain Prompt Templates](https://python.langchain.com/v0.2/docs/concepts/#prompt-templates) are pre-defined recipes for generating prompts for language models."
      ],
      "metadata": {
        "id": "DNrIOOovZVYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "topic_prompt = \"\"\"\n",
        "    You are a helpful Research Engineer. Your task is to analyze a set of research paper titles related to Natural Language Processing and\n",
        "    determine the overarching topic of the cluster. Based on the titles provided, you should identify and label the most relevant topic.\n",
        "    The response should be concise, clearly stating the single  identified topic. Format your response in JSON as indicated in the 'EXPECTED OUTPUT' section below.\n",
        "    No additional information or follow-up questions are needed.\n",
        "\n",
        "    EXPECTED OUTPUT:\n",
        "    {{\"label\": \"Topic Name\"}}\n",
        "\n",
        "    TITLES:\n",
        "    {titles}\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "DMRmlB-5-KiN"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Inference of Topic Identification"
      ],
      "metadata": {
        "id": "eC8YuK3E-X5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section illustrates how to compose a topic pipeline using the [LangChain Expression Language (LCEL)](https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel)."
      ],
      "metadata": {
        "id": "ji3ur9psaHjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HUGGINGFACEHUB_API_TOKEN')"
      ],
      "metadata": {
        "id": "8ZEXsbpLW_xg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "\n",
        "from typing import List\n",
        "\n",
        "def TopicModeling(titles: List[str]) -> str:\n",
        "    \"\"\"\n",
        "    Infer the common topic of the given titles w/ LangChain, Pydantic, Mistral-7B-Instruct\n",
        "    \"\"\"\n",
        "    repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "    llm = HuggingFaceEndpoint(\n",
        "        repo_id=repo_id,\n",
        "        temperature=0.2,\n",
        "        huggingfacehub_api_token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
        "    )\n",
        "    prompt = PromptTemplate.from_template(topic_prompt)\n",
        "    parser = PydanticOutputParser(pydantic_object=Topic)\n",
        "\n",
        "    topic_chain = prompt | llm | parser\n",
        "    return topic_chain.invoke({\"titles\": titles})"
      ],
      "metadata": {
        "id": "4xozoy2KIY0d"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To enable the model to infer the topic of each cluster, we provide a random subset of 25 paper titles from each cluster as input."
      ],
      "metadata": {
        "id": "aIAOMIV3axWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "topics = []\n",
        "for i, cluster in df.groupby('cluster'):\n",
        "    titles = cluster['title'].head(25).tolist()\n",
        "    topic = TopicModeling(titles)\n",
        "    topics.append(topic.label)"
      ],
      "metadata": {
        "id": "-Dv4uORJVP6B"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets assign each arXiv publication to each cluster, and see what are the top 15 topics."
      ],
      "metadata": {
        "id": "fmOoIUEca0u0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters = len(df['cluster'].unique())\n",
        "\n",
        "topic_map = dict(zip(range(n_clusters), topics))\n",
        "df['topic'] = df['cluster'].map(topic_map)"
      ],
      "metadata": {
        "id": "y543zJ6d-9u1"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['topic'].value_counts()"
      ],
      "metadata": {
        "id": "XdIOhz874Ibl",
        "outputId": "9dd96fe7-f9ab-471b-b8b6-2ddb43cbfa6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "topic\n",
              "Multimodal Language Models                                  1202\n",
              "Speech Recognition and Translation                          1167\n",
              "Natural Language Processing in Healthcare                   1077\n",
              "Multilingual Language Models and Machine Translation         775\n",
              "Reasoning Abilities of Large Language Models                 634\n",
              "Bias in Language Models                                      516\n",
              "Personalized Dialogue Systems                                481\n",
              "Knowledge Graph Question Answering                           369\n",
              "Efficient Transformer Models                                 327\n",
              "Emotion Recognition and Analysis in Conversations            305\n",
              "Preference Learning for Large Language Models                295\n",
              "Hate Speech Detection                                        261\n",
              "Large Language Models in Code Generation and Programming     254\n",
              "Prompt Optimization for Language Models                      251\n",
              "Hallucination in Language Models                             244\n",
              "Fake News Detection                                          240\n",
              "Language Model-based Autonomous Agents and Planning          234\n",
              "Legal NLP                                                    219\n",
              "Text Summarization                                           213\n",
              "Aspect-Based Sentiment Analysis                              205\n",
              "Financial Natural Language Processing                        189\n",
              "Parameter-Efficient Fine-tuning of Large Language Models     173\n",
              "In-Context Learning                                          167\n",
              "Mental Health Analysis using NLP                             164\n",
              "Retrieval-Augmented Generation                               157\n",
              "Quantization and Compression of Large Language Models        149\n",
              "Jailbreak Attacks on LLMs                                    147\n",
              "Instruction Tuning for Large Language Models                 144\n",
              "AI-Generated Text Detection                                  136\n",
              "Document-Level Relation Extraction                           131\n",
              "Knowledge Graph Completion                                   128\n",
              "Named Entity Recognition                                     115\n",
              "Adversarial Attacks on NLP Models                            103\n",
              "Knowledge Distillation for Large Language Models             100\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "O0TCIu_uEcmi",
        "outputId": "96e31dfe-79bb-4e40-da06-ad060fd797a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11272, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Visualization"
      ],
      "metadata": {
        "id": "8zhDty-P9Lz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install vegafusion[embed]>=1.5.0"
      ],
      "metadata": {
        "id": "EO0Vieeu9NY-"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import altair as alt\n",
        "alt.data_transformers.enable(\"vegafusion\")"
      ],
      "metadata": {
        "id": "VE6nzuqi-XWA",
        "outputId": "fd75d30b-5da3-475f-e81b-09ebd745ee61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataTransformerRegistry.enable('vegafusion')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_color_palette = [\n",
        "    '#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c',\n",
        "    '#98df8a', '#d62728', '#ff9896', '#9467bd', '#c5b0d5',\n",
        "    '#8c564b', '#c49c94', '#e377c2', '#f7b6d2', '#7f7f7f',\n",
        "    '#c7c7c7', '#bcbd22', '#dbdb8d', '#17becf', '#9edae5',\n",
        "    '#393b79', '#5254a3', '#6b6ecf', '#9c9ede', '#637939',\n",
        "    '#8ca252', '#b5cf6b', '#cedb9c', '#8c6d31', '#bd9e39',\n",
        "    '#e7ba52', '#e7cb94', '#843c39', '#ad494a', '#d6616b'\n",
        "]\n",
        "\n",
        "chart = alt.Chart(df).mark_circle(size=5).encode(\n",
        "    x='x',\n",
        "    y='y',\n",
        "    color=alt.Color('topic:N', scale=alt.Scale(range=custom_color_palette)),\n",
        "    tooltip=['title', 'topic']\n",
        ").interactive().properties(\n",
        "    title='25K arXiv Publications in cs.CL',\n",
        "    width=600,\n",
        "    height=400,\n",
        ")\n",
        "chart.display()"
      ],
      "metadata": {
        "id": "EQVenUdfK7eR",
        "outputId": "6e9acf2d-913f-45e2-fe83-dfc12ccadc6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  #altair-viz-94ec66a394774cfe89ff06ea16d14aaf.vega-embed {\n",
              "    width: 100%;\n",
              "    display: flex;\n",
              "  }\n",
              "\n",
              "  #altair-viz-94ec66a394774cfe89ff06ea16d14aaf.vega-embed details,\n",
              "  #altair-viz-94ec66a394774cfe89ff06ea16d14aaf.vega-embed details summary {\n",
              "    position: relative;\n",
              "  }\n",
              "</style>\n",
              "<div id=\"altair-viz-94ec66a394774cfe89ff06ea16d14aaf\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-94ec66a394774cfe89ff06ea16d14aaf\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-94ec66a394774cfe89ff06ea16d14aaf\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"$schema\": \"https://vega.github.io/schema/vega/v5.json\", \"data\": [{\"name\": \"param_5_store\"}, {\"name\": \"source_0\", \"values\": [{\"title\": \"Planetarium: A Rigorous Benchmark for Translating Text to Structured  Planning Languages\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 6.028, \"y\": 2.593}, {\"title\": \"InternLM-XComposer-2.5: A Versatile Large Vision Language Model  Supporting Long-Contextual Input and Output\", \"topic\": \"Multimodal Language Models\", \"x\": 8.474, \"y\": 7.335}, {\"title\": \"BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate  Hallucinations\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.309, \"y\": 1.034}, {\"title\": \"LLM Internal States Reveal Hallucination Risk Faced With a Query\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.178, \"y\": 1.148}, {\"title\": \"Evaluating Automatic Metrics with Incremental Machine Translation  Systems\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.767, \"y\": 4.791}, {\"title\": \"How Similar Are Elected Politicians and Their Constituents? Quantitative  Evidence From Online Social Network\", \"topic\": \"Fake News Detection\", \"x\": 3.691, \"y\": 5.61}, {\"title\": \"Self-Evaluation as a Defense Against Adversarial Attacks on LLMs\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.499, \"y\": 2.756}, {\"title\": \"Single Character Perturbations Break LLM Alignment\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.472, \"y\": 2.613}, {\"title\": \"How Does Quantization Affect Multilingual LLMs?\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.644, \"y\": 2.243}, {\"title\": \"Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through  Self-Correction in Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.831, \"y\": 2.266}, {\"title\": \"Investigating Decoder-only Large Language Models for Speech-to-text  Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.196, \"y\": 5.014}, {\"title\": \"SOS! Soft Prompt Attack Against Open-Source Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.444, \"y\": 2.519}, {\"title\": \"Enhancing Translation Accuracy of Large Language Models through  Continual Pre-Training on Parallel Data\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.642, \"y\": 4.441}, {\"title\": \"Speaker- and Text-Independent Estimation of Articulatory Movements and  Phoneme Alignments from Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.868, \"y\": 5.427}, {\"title\": \"Social Bias Evaluation for Large Language Models Requires Prompt  Variations\", \"topic\": \"Bias in Language Models\", \"x\": 3.687, \"y\": 4.238}, {\"title\": \"KeyVideoLLM: Towards Large-scale Video Keyframe Selection\", \"topic\": \"Multimodal Language Models\", \"x\": 8.838, \"y\": 7.865}, {\"title\": \"A Case Study on Context-Aware Neural Machine Translation with Multi-Task  Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.77, \"y\": 4.335}, {\"title\": \"Improving Conversational Abilities of Quantized Large Language Models  via Direct Preference Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.401, \"y\": 1.341}, {\"title\": \"JailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts  Discovery from Large-Scale Human-LLM Conversational Datasets\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.291, \"y\": 2.282}, {\"title\": \"Raw Text is All you Need: Knowledge-intensive Multi-turn Instruction  Tuning for Large Language Model\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.061, \"y\": 2.38}, {\"title\": \"Human-like Linguistic Biases in Neural Speech Models: Phonetic  Categorization and Phonotactic Constraints in Wav2Vec2.0\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.822, \"y\": 5.239}, {\"title\": \"SemioLLM: Assessing Large Language Models for Semiological Analysis in  Epilepsy Research\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.749, \"y\": 7.877}, {\"title\": \"VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values\", \"topic\": \"Multimodal Language Models\", \"x\": 8.225, \"y\": 7.694}, {\"title\": \"LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content  Moderation of Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.164, \"y\": 1.983}, {\"title\": \"Mast Kalandar at SemEval-2024 Task 8: On the Trail of Textual Origins:  RoBERTa-BiLSTM Approach to Detect AI-Generated Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 3.992, \"y\": 5.019}, {\"title\": \"FSM: A Finite State Machine Based Zero-Shot Prompting Paradigm for  Multi-Hop Question Answering\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.663, \"y\": 2.556}, {\"title\": \"Probing the Feasibility of Multilingual Speaker Anonymization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.631, \"y\": 5.18}, {\"title\": \"GPTQT: Quantize Large Language Models Twice to Push the Efficiency\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.751, \"y\": 2.168}, {\"title\": \"Contrast then Memorize: Semantic Neighbor Retrieval-Enhanced Inductive  Multimodal Knowledge Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.28, \"y\": 6.2}, {\"title\": \"Safe Unlearning: A Surprisingly Effective and Generalizable Solution to  Defend Against Jailbreak Attacks\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.364, \"y\": 2.318}, {\"title\": \"Aspect-Based Sentiment Analysis Techniques: A Comparative Study\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.221, \"y\": 6.762}, {\"title\": \"LANE: Logic Alignment of Non-tuning Large Language Models and Online  Recommendation Systems for Explainable Reason Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.953, \"y\": 2.895}, {\"title\": \"Images Speak Louder than Words: Understanding and Mitigating Bias in  Vision-Language Model from a Causal Mediation Perspective\", \"topic\": \"Bias in Language Models\", \"x\": 3.246, \"y\": 4.395}, {\"title\": \"MLKD-BERT: Multi-level Knowledge Distillation for Pre-trained Language  Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.541, \"y\": 3.834}, {\"title\": \"Emotion and Intent Joint Understanding in Multimodal Conversation: A  Benchmarking Dataset\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.325, \"y\": 7.724}, {\"title\": \"e-Health CSIRO at \\\"Discharge Me!\\\" 2024: Generating Discharge Summary  Sections with Fine-tuned Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.619, \"y\": 8.048}, {\"title\": \"Boosting Biomedical Concept Extraction by Rule-Based Data Augmentation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.218, \"y\": 7.279}, {\"title\": \"Supporters and Skeptics: LLM-based Analysis of Engagement with Mental  Health (Mis)Information Content on Video-sharing Platforms\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.154, \"y\": 7.276}, {\"title\": \"D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data  and eXpert model predictions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.235, \"y\": 8.512}, {\"title\": \"MMedAgent: Learning to Use Medical Tools with Multi-modal Agent\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.112, \"y\": 8.141}, {\"title\": \"Understanding Alignment in Multimodal LLMs: A Comprehensive Study\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 5.961, \"y\": 1.318}, {\"title\": \"Ensemble of pre-trained language models and data augmentation for hate  speech detection from Arabic tweets\", \"topic\": \"Hate Speech Detection\", \"x\": 2.77, \"y\": 5.408}, {\"title\": \"Predicting vs. Acting: A Trade-off Between World Modeling & Agent  Modeling\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.861, \"y\": 2.609}, {\"title\": \"Evaluating the Robustness of Adverse Drug Event Classification Models  Using Templates\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.546, \"y\": 7.749}, {\"title\": \"CEB: Compositional Evaluation Benchmark for Fairness in Large Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.438, \"y\": 4.309}, {\"title\": \"SafaRi:Adaptive Sequence Transformer for Weakly Supervised Referring  Expression Segmentation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.757, \"y\": 7.091}, {\"title\": \"Talking to Machines: do you read me?\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.139, \"y\": 3.86}, {\"title\": \"Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition  and Program of Thought Verification\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.278, \"y\": 1.058}, {\"title\": \"MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring  and Utilizing Latent Space\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.232, \"y\": 3.736}, {\"title\": \"RVISA: Reasoning and Verification for Implicit Sentiment Analysis\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.543, \"y\": 2.683}, {\"title\": \"Open foundation models for Azerbaijani language\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.724, \"y\": 4.124}, {\"title\": \"Why do LLaVA Vision-Language Models Reply to Images in English?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.418, \"y\": 7.567}, {\"title\": \"Efficient Sparse Attention needs Adaptive Token Release\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.755, \"y\": 2.874}, {\"title\": \"Soft Language Prompts for Language Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.199, \"y\": 4.474}, {\"title\": \"CFinBench: A Comprehensive Chinese Financial Benchmark for Large  Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.952, \"y\": 6.754}, {\"title\": \"Robust Zero-Shot Text-to-Speech Synthesis with Reverse Inference  Optimization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.556, \"y\": 5.851}, {\"title\": \"Towards a Holistic Framework for Multimodal Large Language Models in  Three-dimensional Brain CT Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.234, \"y\": 8.52}, {\"title\": \"PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt  during Large Language Model Fine-tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.645, \"y\": 3.095}, {\"title\": \"Fake News Detection: It's All in the Data!\", \"topic\": \"Fake News Detection\", \"x\": 4.058, \"y\": 5.754}, {\"title\": \"Cost-Effective Proxy Reward Model Construction with On-Policy and Active  Learning\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.211, \"y\": 1.414}, {\"title\": \"BiasDora: Exploring Hidden Biased Associations in Vision-Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.293, \"y\": 4.431}, {\"title\": \"Are Data Augmentation Methods in Named Entity Recognition Applicable for  Uncertainty Estimation?\", \"topic\": \"Named Entity Recognition\", \"x\": 7.446, \"y\": 6.714}, {\"title\": \"Fake News Detection and Manipulation Reasoning via Large Vision-Language  Models\", \"topic\": \"Fake News Detection\", \"x\": 4.064, \"y\": 5.819}, {\"title\": \"Breaking Bias, Building Bridges: Evaluation and Mitigation of Social  Biases in LLMs via Contact Hypothesis\", \"topic\": \"Bias in Language Models\", \"x\": 3.448, \"y\": 4.291}, {\"title\": \"Why does in-context learning fail sometimes? Evaluating in-context  learning on open and closed questions\", \"topic\": \"In-Context Learning\", \"x\": 8.296, \"y\": 3.413}, {\"title\": \"An End-to-End Speech Summarization Using Large Language Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.413, \"y\": 5.333}, {\"title\": \"Towards the Next Frontier in Speech Representation Learning Using  Disentanglement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.744, \"y\": 4.991}, {\"title\": \"Simple Augmentations of Logical Rules for Neuro-Symbolic Knowledge Graph  Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.065, \"y\": 5.797}, {\"title\": \"Enabling Discriminative Reasoning in LLMs for Legal Judgment Prediction\", \"topic\": \"Legal NLP\", \"x\": 5.123, \"y\": 5.703}, {\"title\": \"Extracting and Encoding: Leveraging Large Language Models and Medical  Knowledge to Enhance Radiological Text Representation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.143, \"y\": 8.518}, {\"title\": \"Certainly Uncertain: A Benchmark and Metric for Multimodal Epistemic and  Aleatoric Awareness\", \"topic\": \"Multimodal Language Models\", \"x\": 8.176, \"y\": 7.883}, {\"title\": \"Efficient-Empathy: Towards Efficient and Effective Selection of Empathy  Data\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.678, \"y\": 7.896}, {\"title\": \"Investigating the Effects of Large-Scale Pseudo-Stereo Data and  Different Speech Foundation Model on Dialogue Generative Spoken Language  Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.383, \"y\": 5.686}, {\"title\": \"Pinyin Regularization in Error Correction for Chinese Speech Recognition  with Large Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.264, \"y\": 5.611}, {\"title\": \"SoP: Unlock the Power of Social Facilitation for Automatic Jailbreak  Attack\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.312, \"y\": 2.289}, {\"title\": \"Proposal Report for the 2nd SciCAP Competition 2024\", \"topic\": \"Text Summarization\", \"x\": 5.812, \"y\": 6.41}, {\"title\": \"Survey on Knowledge Distillation for Large Language Models: Methods,  Evaluation, and Application\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.27, \"y\": 3.63}, {\"title\": \"VSP: Assessing the dual challenges of perception and reasoning in  spatial planning tasks for VLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.407, \"y\": 7.662}, {\"title\": \"Empathic Grounding: Explorations using Multimodal Interaction and Large  Language Models with Conversational Agents\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.68, \"y\": 7.891}, {\"title\": \"Deciphering the Factors Influencing the Efficacy of Chain-of-Thought:  Probability, Memorization, and Noisy Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.683, \"y\": 2.371}, {\"title\": \"Empowering 3D Visual Grounding with Reasoning Capabilities\", \"topic\": \"Multimodal Language Models\", \"x\": 8.665, \"y\": 7.383}, {\"title\": \"MMLongBench-Doc: Benchmarking Long-context Document Understanding with  Visualizations\", \"topic\": \"Multimodal Language Models\", \"x\": 7.822, \"y\": 7.36}, {\"title\": \"MIA-Bench: Towards Better Instruction Following Evaluation of Multimodal  LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.173, \"y\": 7.467}, {\"title\": \"Expressive and Generalizable Low-rank Adaptation for Large Models via  Slow Cascaded Learning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.22, \"y\": 2.064}, {\"title\": \"Agentless: Demystifying LLM-based Software Engineering Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.747, \"y\": 2.684}, {\"title\": \"DogeRM: Equipping Reward Models with Domain Knowledge through Model  Merging\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.248, \"y\": 1.44}, {\"title\": \"Retrieval-augmented generation in multilingual settings\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.037, \"y\": 4.643}, {\"title\": \"A Global-Local Attention Mechanism for Relation Classification\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.109, \"y\": 6.784}, {\"title\": \"Dynamic Few-Shot Learning for Knowledge Graph Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.725, \"y\": 5.446}, {\"title\": \"Adapting Multilingual LLMs to Low-Resource Languages with Knowledge  Graphs via Adapters\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.238, \"y\": 4.421}, {\"title\": \"POLygraph: Polish Fake News Dataset\", \"topic\": \"Fake News Detection\", \"x\": 3.994, \"y\": 5.823}, {\"title\": \"Badllama 3: removing safety finetuning from Llama 3 in minutes\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.476, \"y\": 2.296}, {\"title\": \"Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems\", \"topic\": \"Text Summarization\", \"x\": 5.642, \"y\": 6.119}, {\"title\": \"Increasing Model Capacity for Free: A Simple Strategy for Parameter  Efficient Fine-tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.031, \"y\": 2.247}, {\"title\": \"Language Portability Strategies for Open-domain Dialogue with  Pre-trained Language Models from High to Low Resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.464, \"y\": 4.673}, {\"title\": \"Lightweight Zero-shot Text-to-Speech with Mixture of Adapters\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.64, \"y\": 5.691}, {\"title\": \"We-Math: Does Your Large Multimodal Model Achieve Human-like  Mathematical Reasoning?\", \"topic\": \"Multimodal Language Models\", \"x\": 7.962, \"y\": 7.62}, {\"title\": \"Show Less, Instruct More: Enriching Prompts with Definitions and  Guidelines for Zero-Shot NER\", \"topic\": \"Named Entity Recognition\", \"x\": 7.478, \"y\": 6.746}, {\"title\": \"First Place Solution of 2023 Global Artificial Intelligence Technology  Innovation Competition Track 1\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.159, \"y\": 8.47}, {\"title\": \"The African Woman is Rhythmic and Soulful: Evaluation of Open-ended  Generation for Implicit Biases\", \"topic\": \"Bias in Language Models\", \"x\": 3.415, \"y\": 4.351}, {\"title\": \"uDistil-Whisper: Label-Free Data Filtering for Knowledge Distillation  via Large-Scale Pseudo Labelling\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.561, \"y\": 3.892}, {\"title\": \"Searching for Best Practices in Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.886, \"y\": 4.676}, {\"title\": \"Unaligning Everything: Or Aligning Any Text to Any Image in Multimodal  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.432, \"y\": 7.064}, {\"title\": \"Sociocultural Considerations in Monitoring Anti-LGBTQ+ Content on Social  Media\", \"topic\": \"Hate Speech Detection\", \"x\": 2.873, \"y\": 5.365}, {\"title\": \"BERGEN: A Benchmarking Library for Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.959, \"y\": 4.657}, {\"title\": \"M2QA: Multi-domain Multilingual Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 7.9, \"y\": 4.87}, {\"title\": \"CVLUE: A New Benchmark Dataset for Chinese Vision-Language Understanding  Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.213, \"y\": 7.754}, {\"title\": \"FRoG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.929, \"y\": 3.155}, {\"title\": \"Augmenting Document-level Relation Extraction with Efficient  Multi-Supervision\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.946, \"y\": 6.854}, {\"title\": \"DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.436, \"y\": 2.72}, {\"title\": \"MalAlgoQA: A Pedagogical Approach for Evaluating Counterfactual  Reasoning Abilities\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.499, \"y\": 3.138}, {\"title\": \"FoldGPT: Simple and Effective Large Language Model Compression Scheme\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.559, \"y\": 2.497}, {\"title\": \"Preserving Multilingual Quality While Tuning Query Encoder on English  Only\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.275, \"y\": 4.701}, {\"title\": \"FineSurE: Fine-grained Summarization Evaluation using LLMs\", \"topic\": \"Text Summarization\", \"x\": 5.54, \"y\": 6.062}, {\"title\": \"From Introspection to Best Practices: Principled Analysis of  Demonstrations in Multimodal In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.329, \"y\": 6.729}, {\"title\": \"MathCAMPS: Fine-grained Synthesis of Mathematical Problems From Human  Curricula\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.008, \"y\": 2.856}, {\"title\": \"Papez: Resource-Efficient Speech Separation with Auditory Working Memory\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.988, \"y\": 5.169}, {\"title\": \"Mechanistic Interpretation through Contextual Decomposition in  Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.567, \"y\": 3.515}, {\"title\": \"Large Language Models Are Involuntary Truth-Tellers: Exploiting Fallacy  Failure for Jailbreak Attacks\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.392, \"y\": 2.36}, {\"title\": \"Towards Robust Speech Representation Learning for Thousands of Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.599, \"y\": 5.094}, {\"title\": \"NAIST Simultaneous Speech Translation System for IWSLT 2024\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.288, \"y\": 5.184}, {\"title\": \"A Comparative Study of Quality Evaluation Methods for Text Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.571, \"y\": 6.127}, {\"title\": \"Large Language Models Struggle in Token-Level Clinical Named Entity  Recognition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.816, \"y\": 7.91}, {\"title\": \"BAPO: Base-Anchored Preference Optimization for Personalized Alignment  in Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.259, \"y\": 1.284}, {\"title\": \"LegalTurk Optimized BERT for Multi-Label Text Classification and NER\", \"topic\": \"Legal NLP\", \"x\": 5.363, \"y\": 5.896}, {\"title\": \"Iterative Nash Policy Optimization: Aligning LLMs with General  Preferences via No-Regret Learning\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.219, \"y\": 1.499}, {\"title\": \"Efficient Personalized Text-to-image Generation by Leveraging Textual  Subspace\", \"topic\": \"Multimodal Language Models\", \"x\": 8.897, \"y\": 6.792}, {\"title\": \"MasonTigers at SemEval-2024 Task 10: Emotion Discovery and Flip  Reasoning in Conversation with Ensemble of Transformers and Prompting\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.317, \"y\": 7.522}, {\"title\": \"Investigating and Mitigating the Multimodal Hallucination Snowballing in  Large Vision-Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.281, \"y\": 1.032}, {\"title\": \"Answering real-world clinical questions using large language model based  systems\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.683, \"y\": 7.886}, {\"title\": \"PFME: A Modular Approach for Fine-grained Hallucination Detection and  Editing of Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.155, \"y\": 1.085}, {\"title\": \"Towards Massive Multilingual Holistic Bias\", \"topic\": \"Bias in Language Models\", \"x\": 3.18, \"y\": 4.434}, {\"title\": \"MMEvalPro: Calibrating Multimodal Benchmarks Towards Trustworthy and  Efficient Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 7.899, \"y\": 7.633}, {\"title\": \"Self-Translate-Train: A Simple but Strong Baseline for Cross-lingual  Transfer of Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.477, \"y\": 4.726}, {\"title\": \"PerSEval: Assessing Personalization in Text Summarizers\", \"topic\": \"Text Summarization\", \"x\": 5.513, \"y\": 6.227}, {\"title\": \"A Recipe of Parallel Corpora Exploitation for Multilingual Large  Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.403, \"y\": 4.615}, {\"title\": \"Too Late to Train, Too Early To Use? A Study on Necessity and Viability  of Low-Resource Bengali LLMs\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.206, \"y\": 4.334}, {\"title\": \"The Factuality Tax of Diversity-Intervened Text-to-Image Generation:  Benchmark and Fact-Augmented Intervention\", \"topic\": \"Bias in Language Models\", \"x\": 3.658, \"y\": 4.609}, {\"title\": \"Financial Knowledge Large Language Model\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.892, \"y\": 6.821}, {\"title\": \"From RAG to RICHES: Retrieval Interlaced with Sequence Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.008, \"y\": 4.683}, {\"title\": \"Korean Aspect-Based Sentiment Analysis via Implicit-Feature Alignment  with Corpus Filtering\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.158, \"y\": 6.782}, {\"title\": \"Iterative Data Augmentation with Large Language Models for Aspect-based  Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.092, \"y\": 6.809}, {\"title\": \"From Local Concepts to Universals: Evaluating the Multicultural  Understanding of Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.303, \"y\": 7.647}, {\"title\": \"One Prompt is not Enough: Automated Construction of a Mixture-of-Expert  Prompts\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.348, \"y\": 3.168}, {\"title\": \"DiffuseDef: Improved Robustness to Adversarial Attacks\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.169, \"y\": 3.062}, {\"title\": \"EHRmonize: A Framework for Medical Concept Abstraction from Electronic  Health Records using Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.826, \"y\": 8.115}, {\"title\": \"Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of  Automatic Data Annotation Approach\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.27, \"y\": 7.159}, {\"title\": \"Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework  for Multimodal LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.179, \"y\": 7.522}, {\"title\": \"LLaRA: Supercharging Robot Learning Data for Vision-Language Policy\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 8.628, \"y\": 6.81}, {\"title\": \"Scaling Synthetic Data Creation with 1,000,000,000 Personas\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.045, \"y\": 3.713}, {\"title\": \"Understanding and Mitigating Language Confusion in LLMs\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.912, \"y\": 4.405}, {\"title\": \"BioMNER: A Dataset for Biomedical Method Entity Recognition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.426, \"y\": 7.393}, {\"title\": \"ToolBeHonest: A Multi-level Hallucination Diagnostic Benchmark for  Tool-Augmented Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.192, \"y\": 1.138}, {\"title\": \"Single Parent Family: A Spectrum of Family Members from a Single  Pre-Trained Foundation Model\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.536, \"y\": 2.414}, {\"title\": \"Simulating Financial Market via Large Language Model based Agents\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.847, \"y\": 6.748}, {\"title\": \"BESTOW: Efficient and Streamable Speech Language Model with the Best of  Two Worlds in GPT and T5\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.669, \"y\": 5.251}, {\"title\": \"From the Least to the Most: Building a Plug-and-Play Visual Reasoner via  Data Synthesis\", \"topic\": \"Multimodal Language Models\", \"x\": 8.343, \"y\": 7.757}, {\"title\": \"Untangling the Unrestricted Web: Automatic Identification of  Multilingual Registers\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.595, \"y\": 4.925}, {\"title\": \"Detecting Subtle Differences between Human and Model Languages Using  Spectrum of Relative Likelihood\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.067, \"y\": 4.716}, {\"title\": \"BeamAggR: Beam Aggregation Reasoning over Multi-source Knowledge for  Multi-hop Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.779, \"y\": 5.4}, {\"title\": \"A Simple Attention-Based Mechanism for Bimodal Emotion Classification\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.323, \"y\": 7.653}, {\"title\": \"Direct Preference Knowledge Distillation for Large Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.464, \"y\": 3.761}, {\"title\": \"Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case  Reformulation\", \"topic\": \"Legal NLP\", \"x\": 5.18, \"y\": 5.718}, {\"title\": \"Breaking the Script Barrier in Multilingual Pre-Trained Language Models  with Transliteration-Based Post-Training Alignment\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.379, \"y\": 4.802}, {\"title\": \"MM-Instruct: Generated Visual Instructions for Large Multimodal Model  Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.213, \"y\": 7.405}, {\"title\": \"Less is More: Accurate Speech Recognition & Translation without  Web-Scale Data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.886, \"y\": 5.234}, {\"title\": \"SK-VQA: Synthetic Knowledge Generation at Scale for Training  Context-Augmented Multimodal LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.988, \"y\": 7.729}, {\"title\": \"PathAlign: A vision-language model for whole slide images in  histopathology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.291, \"y\": 8.474}, {\"title\": \"Demarked: A Strategy for Enhanced Abusive Speech Moderation through  Counterspeech, Detoxification, and Message Management\", \"topic\": \"Hate Speech Detection\", \"x\": 2.847, \"y\": 5.346}, {\"title\": \"Context Matters: An Empirical Study of the Impact of Contextual  Information in Temporal Question Answering Systems\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.441, \"y\": 5.22}, {\"title\": \"Handling Ontology Gaps in Semantic Parsing\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.199, \"y\": 1.034}, {\"title\": \"TocBERT: Medical Document Structure Extraction Using Bidirectional  Transformers\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.167, \"y\": 7.372}, {\"title\": \"Development and Evaluation of a Retrieval-Augmented Generation Tool for  Creating SAPPhIRE Models of Artificial Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.844, \"y\": 4.491}, {\"title\": \"LoPT: Low-Rank Prompt Tuning for Parameter Efficient Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.654, \"y\": 3.254}, {\"title\": \"Sparse Regression for Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.758, \"y\": 4.627}, {\"title\": \"Taming Data and Transformers for Audio Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.371, \"y\": 6.117}, {\"title\": \"Suri: Multi-constraint Instruction Following for Long-form Text  Generation\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.015, \"y\": 2.478}, {\"title\": \"IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and  Toxicity Types for Indonesian Language\", \"topic\": \"Hate Speech Detection\", \"x\": 2.821, \"y\": 5.361}, {\"title\": \"Efficient Long-distance Latent Relation-aware Graph Neural Network for  Multi-modal Emotion Recognition in Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.279, \"y\": 7.731}, {\"title\": \"HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into  Multimodal LLMs at Scale\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.527, \"y\": 8.263}, {\"title\": \"Enhancing Video-Language Representations with Structural Spatio-Temporal  Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.866, \"y\": 7.801}, {\"title\": \"AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for  Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.206, \"y\": 4.566}, {\"title\": \"FlowVQA: Mapping Multimodal Logic in Visual Question Answering with  Flowcharts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.08, \"y\": 7.929}, {\"title\": \"SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented  Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.967, \"y\": 4.625}, {\"title\": \"Annotation Errors and NER: A Study with OntoNotes 5.0\", \"topic\": \"Named Entity Recognition\", \"x\": 7.365, \"y\": 6.761}, {\"title\": \"Accurate Prediction of Ligand-Protein Interaction Affinities with  Fine-Tuned Small Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.664, \"y\": 7.566}, {\"title\": \"Fairness and Bias in Multimodal AI: A Survey\", \"topic\": \"Bias in Language Models\", \"x\": 3.458, \"y\": 4.273}, {\"title\": \"A Case Study on Contextual Machine Translation in a Professional  Scenario of Subtitling\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.782, \"y\": 4.327}, {\"title\": \"EmPO: Theory-Driven Dataset Construction for Empathetic Response  Generation through Preference Optimization\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.675, \"y\": 7.898}, {\"title\": \"Applying LLMs for Rescoring N-best ASR Hypotheses of Casual  Conversations: Effects of Domain Adaptation and Context Carry-over\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.901, \"y\": 4.935}, {\"title\": \"Curriculum Learning with Quality-Driven Data Selection\", \"topic\": \"Multimodal Language Models\", \"x\": 8.262, \"y\": 7.365}, {\"title\": \"Enhanced ASR Robustness to Packet Loss with a Front-End Adaptation  Network\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.171, \"y\": 5.264}, {\"title\": \"Selective Vision is the Challenge for Visual Reasoning: A Benchmark for  Visual Argument Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.324, \"y\": 7.727}, {\"title\": \"TrustUQA: A Trustful Framework for Unified Structured Data Question  Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.683, \"y\": 5.421}, {\"title\": \"Factor-Conditioned Speaking-Style Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.242, \"y\": 7.202}, {\"title\": \"Enhancing In-Context Learning via Implicit Demonstration Augmentation\", \"topic\": \"In-Context Learning\", \"x\": 8.286, \"y\": 3.333}, {\"title\": \"SSP: Self-Supervised Prompting for Cross-Lingual Transfer to  Low-Resource Languages using Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.219, \"y\": 4.483}, {\"title\": \"DeSTA: Enhancing Speech Language Models through Descriptive Speech-Text  Alignment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.244, \"y\": 5.251}, {\"title\": \"Efficacy of Language Model Self-Play in Non-Zero-Sum Games\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.249, \"y\": 2.922}, {\"title\": \"Two-Pronged Human Evaluation of ChatGPT Self-Correction in Radiology  Report Simplification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.07, \"y\": 8.501}, {\"title\": \"FFN: a Fine-grained Chinese-English Financial Domain Parallel Corpus\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.87, \"y\": 6.844}, {\"title\": \"Learning Retrieval Augmentation for Personalized Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.348, \"y\": 3.718}, {\"title\": \"OutlierTune: Efficient Channel-Wise Quantization for Large Language  Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.741, \"y\": 2.125}, {\"title\": \"Categorical Syllogisms Revisited: A Review of the Logical Reasoning  Abilities of LLMs for Analyzing Categorical Syllogism\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.619, \"y\": 3.142}, {\"title\": \"WavRx: a Disease-Agnostic, Generalizable, and Privacy-Preserving Speech  Health Diagnostic Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 5.115, \"y\": 8.004}, {\"title\": \"Jailbreaking LLMs with Arabic Transliteration and Arabizi\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.317, \"y\": 2.27}, {\"title\": \"Learning to Correct for QA Reasoning with Black-box LLMs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.973, \"y\": 2.421}, {\"title\": \"Speakers Unembedded: Embedding-free Approach to Long-form Neural  Diarization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.861, \"y\": 5.164}, {\"title\": \"Understand What LLM Needs: Dual Preference Alignment for  Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.022, \"y\": 4.453}, {\"title\": \"Symbolic Learning Enables Self-Evolving Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.795, \"y\": 2.5}, {\"title\": \"ChronoMagic-Bench: A Benchmark for Metamorphic Evaluation of  Text-to-Time-lapse Video Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.882, \"y\": 7.784}, {\"title\": \"CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal  LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.896, \"y\": 7.683}, {\"title\": \"\\\"Is ChatGPT a Better Explainer than My Professor?\\\": Evaluating the  Explanation Capabilities of LLMs in Conversation Compared to a Human Baseline\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.616, \"y\": 3.833}, {\"title\": \"WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially)  Safer Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.351, \"y\": 2.292}, {\"title\": \"Is In-Context Learning a Type of Gradient-Based Learning? Evidence from  the Inverse Frequency Effect in Structural Priming\", \"topic\": \"In-Context Learning\", \"x\": 8.655, \"y\": 3.319}, {\"title\": \"Clustering in pure-attention hardmax transformers and its role in  sentiment analysis\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.743, \"y\": 3.369}, {\"title\": \"An LLM-based Knowledge Synthesis and Scientific Reasoning Framework for  Biomedical Discovery\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.056, \"y\": 7.507}, {\"title\": \"Dynamic Data Pruning for Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.197, \"y\": 5.253}, {\"title\": \"Research on Information Extraction of LCSTS Dataset Based on an Improved  BERTSum-LSTM Model\", \"topic\": \"Text Summarization\", \"x\": 5.364, \"y\": 6.307}, {\"title\": \"MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large  Language Models Using Odyssey Math Data\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.904, \"y\": 2.984}, {\"title\": \"Advancing Airport Tower Command Recognition: Integrating  Squeeze-and-Excitation and Broadcasted Residual Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.154, \"y\": 5.185}, {\"title\": \"AI-native Memory: A Pathway from LLMs Towards AGI\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.753, \"y\": 3.047}, {\"title\": \"MSR-86K: An Evolving, Multilingual Corpus with 86,300 Hours of  Transcribed Audio for Speech Recognition Research\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.721, \"y\": 5.475}, {\"title\": \"Hierarchical Context Pruning: Optimizing Real-World Code Completion with  Repository-Level Pretrained Code LLMs\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.62, \"y\": 2.461}, {\"title\": \"\\\"Vorbe\\u015fti Rom\\u00e2ne\\u015fte?\\\" A Recipe to Train Powerful Romanian LLMs  with English Instructions\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.825, \"y\": 4.095}, {\"title\": \"Detecting Machine-Generated Texts: Not Just \\\"AI vs Humans\\\" and  Explainability is Complicated\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.175, \"y\": 4.737}, {\"title\": \"GUIDE: A Guideline-Guided Dataset for Instructional Video Comprehension\", \"topic\": \"Multimodal Language Models\", \"x\": 8.853, \"y\": 7.848}, {\"title\": \"Selective Prompting Tuning for Personalized Conversations with LLMs\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.442, \"y\": 3.693}, {\"title\": \"LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal  Long-Context Inference\", \"topic\": \"Multimodal Language Models\", \"x\": 8.3, \"y\": 7.295}, {\"title\": \"Automatic Speech Recognition for Hindi\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.018, \"y\": 5.464}, {\"title\": \"ConvoCache: Smart Re-Use of Chatbot Responses\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.271, \"y\": 3.774}, {\"title\": \"Poisoned LangChain: Jailbreak LLMs by LangChain\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.313, \"y\": 2.27}, {\"title\": \"ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech  Recognition Using LLMs\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.341, \"y\": 5.252}, {\"title\": \"SafeAligner: Safety Alignment against Jailbreak Attacks via Response  Disparity Guidance\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.403, \"y\": 2.347}, {\"title\": \"Token-Weighted RNN-T for Learning from Flawed Data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.162, \"y\": 5.399}, {\"title\": \"Shimo Lab at \\\"Discharge Me!\\\": Discharge Summarization by Prompt-Driven  Concatenation of Electronic Health Record Sections\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.735, \"y\": 8.043}, {\"title\": \"LLM-Driven Multimodal Opinion Expression Identification\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.321, \"y\": 7.557}, {\"title\": \"EHR-Based Mobile and Web Platform for Chronic Disease Risk Prediction  Using Large Language Multimodal Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.658, \"y\": 8.215}, {\"title\": \"Multilingual Knowledge Graph Completion from Pretrained Language Models  with Knowledge Constraints\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.023, \"y\": 5.835}, {\"title\": \"Octo-planner: On-device Language Model for Planner-Action Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.955, \"y\": 2.673}, {\"title\": \"Self-Training with Pseudo-Label Scorer for Aspect Sentiment Quad  Prediction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.131, \"y\": 6.808}, {\"title\": \"Large Language Models for Cuffless Blood Pressure Measurement From  Wearable Biosignals\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.526, \"y\": 7.87}, {\"title\": \"Evaluating Quality of Answers for Retrieval-Augmented Generation: A  Strong LLM Is All You Need\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.847, \"y\": 4.643}, {\"title\": \"AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for  Memory-Efficient Large Language Models Fine-Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.142, \"y\": 2.303}, {\"title\": \"Towards Large Language Model Aided Program Refinement\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.237, \"y\": 2.489}, {\"title\": \"Improving Entity Recognition Using Ensembles of Deep Learning and  Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction  from Multiple Sources\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.007, \"y\": 7.61}, {\"title\": \"PharmaGPT: Domain-Specific Large Language Models for Bio-Pharmaceutical  and Chemistry\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.136, \"y\": 7.811}, {\"title\": \"LLMs for Doctors: Leveraging Medical LLMs to Assist Doctors, Not Replace  Them\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.64, \"y\": 7.95}, {\"title\": \"Automated Clinical Data Extraction with Knowledge Conditioned LLMs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.018, \"y\": 8.385}, {\"title\": \"JailbreakZoo: Survey, Landscapes, and Horizons in Jailbreaking Large  Language and Vision-Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.334, \"y\": 2.319}, {\"title\": \"Explicit Diversity Conditions for Effective Question Answer Generation  with Large Language Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.337, \"y\": 5.033}, {\"title\": \"Evaluating Fairness in Large Vision-Language Models Across Diverse  Demographic Attributes and Prompts\", \"topic\": \"Bias in Language Models\", \"x\": 3.383, \"y\": 4.29}, {\"title\": \"Unmasking the Imposters: In-Domain Detection of Human vs.  Machine-Generated Tweets\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.037, \"y\": 4.942}, {\"title\": \"Do they mean 'us'? Interpreting Referring Expressions in Intergroup Bias\", \"topic\": \"Bias in Language Models\", \"x\": 3.523, \"y\": 4.516}, {\"title\": \"Sequential Editing for Lifelong Training of Speech Recognition Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.133, \"y\": 5.11}, {\"title\": \"FASA: a Flexible and Automatic Speech Aligner for Extracting  High-quality Aligned Children Speech Data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.158, \"y\": 5.417}, {\"title\": \"X-ray Made Simple: Radiology Report Generation and Evaluation with  Layman's Terms\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.181, \"y\": 8.584}, {\"title\": \"CTBench: A Comprehensive Benchmark for Evaluating Language Model  Capabilities in Clinical Trial Design\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.884, \"y\": 7.762}, {\"title\": \"ET tu, CLIP? Addressing Common Object Errors for Unseen Environments\", \"topic\": \"Multimodal Language Models\", \"x\": 8.936, \"y\": 7.205}, {\"title\": \"Improving Arithmetic Reasoning Ability of Large Language Models through  Relation Tuples, Verification and Dynamic Feedback\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.967, \"y\": 2.713}, {\"title\": \"Accelerating Clinical Evidence Synthesis with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.695, \"y\": 7.699}, {\"title\": \"Following Length Constraints in Instructions\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 7.898, \"y\": 2.407}, {\"title\": \"LLM-ARC: Enhancing LLMs with an Automated Reasoning Critic\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.55, \"y\": 2.739}, {\"title\": \"ELIZA Reinterpreted: The world's first chatbot was not intended as a  chatbot at all\", \"topic\": \"Bias in Language Models\", \"x\": 4.805, \"y\": 4.15}, {\"title\": \"Banishing LLM Hallucinations Requires Rethinking Generalization\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.228, \"y\": 1.164}, {\"title\": \"Mitigate the Gap: Investigating Approaches for Improving Cross-Modal  Alignment in CLIP\", \"topic\": \"Multimodal Language Models\", \"x\": 8.792, \"y\": 7.237}, {\"title\": \"Disce aut Deficere: Evaluating LLMs Proficiency on the INVALSI Italian  Benchmark\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.604, \"y\": 3.94}, {\"title\": \"Automatic speech recognition for the Nepali language using CNN,  bidirectional LSTM and ResNet\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.875, \"y\": 5.451}, {\"title\": \"MedCare: Advancing Medical LLMs through Decoupling Clinical Alignment  and Knowledge Aggregation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.945, \"y\": 8.001}, {\"title\": \"Transformer-based Named Entity Recognition with Combined Data  Representation\", \"topic\": \"Named Entity Recognition\", \"x\": 7.35, \"y\": 6.828}, {\"title\": \"Layer-Wise Quantization: A Pragmatic and Effective Method for Quantizing  LLMs Beyond Integer Bit-Levels\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.775, \"y\": 2.152}, {\"title\": \"A Three-Pronged Approach to Cross-Lingual Adaptation with Multilingual  LLMs\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.308, \"y\": 4.374}, {\"title\": \"An Empirical Study on the Characteristics of Bias upon Context Length  Variation for Bangla\", \"topic\": \"Bias in Language Models\", \"x\": 3.225, \"y\": 4.39}, {\"title\": \"Leveraging Synthetic Audio Data for End-to-End Low-Resource Speech  Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.446, \"y\": 5.379}, {\"title\": \"Dual-Space Knowledge Distillation for Large Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.531, \"y\": 3.79}, {\"title\": \"Not All Preference Pairs Are Created Equal: A Recipe for  Annotation-Efficient Iterative Preference Learning\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.297, \"y\": 1.325}, {\"title\": \"CausalScore: An Automatic Reference-Free Metric for Assessing Response  Relevance in Open-Domain Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.348, \"y\": 3.919}, {\"title\": \"Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.983, \"y\": 7.615}, {\"title\": \"AG-LSEC: Audio Grounded Lexical Speaker Error Correction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.913, \"y\": 5.32}, {\"title\": \"Mitigating Hallucination in Fictional Character Role-Play\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.179, \"y\": 1.148}, {\"title\": \"Leveraging Parameter-Efficient Transfer Learning for Multi-Lingual  Text-to-Speech Adaptation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.537, \"y\": 5.028}, {\"title\": \"MPCODER: Multi-user Personalized Code Generator with Explicit and  Implicit Style Representation Learning\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.518, \"y\": 2.421}, {\"title\": \"CogMG: Collaborative Augmentation Between Large Language Model and  Knowledge Graph\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.838, \"y\": 5.513}, {\"title\": \"Large Language Models are Interpretable Learners\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.604, \"y\": 3.027}, {\"title\": \"CLERC: A Dataset for Legal Case Retrieval and Retrieval-Augmented  Analysis Generation\", \"topic\": \"Legal NLP\", \"x\": 5.09, \"y\": 5.677}, {\"title\": \"Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability  of Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.593, \"y\": 2.961}, {\"title\": \"DEXTER: A Benchmark for open-domain Complex Question Answering using  LLMs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.687, \"y\": 5.122}, {\"title\": \"modeLing: A Novel Dataset for Testing Linguistic Reasoning in Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.722, \"y\": 3.32}, {\"title\": \"Losing Visual Needles in Image Haystacks: Vision Language Models are  Easily Distracted in Short and Long Contexts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.311, \"y\": 7.756}, {\"title\": \"RaTEScore: A Metric for Radiology Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.134, \"y\": 8.566}, {\"title\": \"Ragnar\\u00f6k: A Reusable RAG Framework and Baselines for TREC 2024  Retrieval-Augmented Generation Track\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.976, \"y\": 4.708}, {\"title\": \"Beyond Thumbs Up/Down: Untangling Challenges of Fine-Grained Feedback  for Text-to-Image Generation\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.217, \"y\": 1.647}, {\"title\": \"RES-Q: Evaluating Code-Editing Large Language Model Systems at the  Repository Scale\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.192, \"y\": 2.737}, {\"title\": \"Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.091, \"y\": 2.145}, {\"title\": \"Blending LLMs into Cascaded Speech Translation: KIT's Offline Speech  Translation System for IWSLT 2024\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.469, \"y\": 5.21}, {\"title\": \"Towards Zero-Shot Text-To-Speech for Arabic Dialects\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.454, \"y\": 5.581}, {\"title\": \"Sparser is Faster and Less is More: Efficient Sparse Attention for  Long-Range Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.763, \"y\": 3.063}, {\"title\": \"Venturing into Uncharted Waters: The Navigation Compass from Transformer  to Mamba\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.521, \"y\": 3.412}, {\"title\": \"Large Language Models Are Cross-Lingual Knowledge-Free Reasoners\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.153, \"y\": 4.575}, {\"title\": \"OmAgent: A Multi-modal Agent Framework for Complex Video Understanding  with Task Divide-and-Conquer\", \"topic\": \"Multimodal Language Models\", \"x\": 8.737, \"y\": 7.865}, {\"title\": \"Evaluation of Language Models in the Medical Context Under  Resource-Constrained Settings\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.89, \"y\": 7.991}, {\"title\": \"Data Augmentation of Multi-turn Psychological Dialogue via  Knowledge-driven Progressive Thought Prompting\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.505, \"y\": 3.927}, {\"title\": \"EVALALIGN: Supervised Fine-Tuning Multimodal LLMs with Human-Aligned  Data for Evaluating Text-to-Image Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.743, \"y\": 7.161}, {\"title\": \"Token-based Decision Criteria Are Suboptimal in In-context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.311, \"y\": 3.369}, {\"title\": \"Towards Better Graph-based Cross-document Relation Extraction via  Non-bridge Entity Enhancement and Prediction Debiasing\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.882, \"y\": 6.689}, {\"title\": \"Evaluating the Ability of Large Language Models to Reason about Cardinal  Directions\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.516, \"y\": 3.322}, {\"title\": \"The Privileged Students: On the Value of Initialization in Multilingual  Knowledge Distillation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.513, \"y\": 3.877}, {\"title\": \"OTCE: Hybrid SSM and Attention with Cross Domain Mixture of Experts to  construct Observer-Thinker-Conceiver-Expresser\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.688, \"y\": 3.105}, {\"title\": \"eagerlearners at SemEval2024 Task 5: The Legal Argument Reasoning Task  in Civil Procedure\", \"topic\": \"Legal NLP\", \"x\": 5.028, \"y\": 5.703}, {\"title\": \"EMMI -- Empathic Multimodal Motivational Interviews Dataset: Analyses  and Annotations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.707, \"y\": 7.868}, {\"title\": \"DaLPSR: Leverage Degradation-Aligned Language Prompt for Real-World  Image Super-Resolution\", \"topic\": \"Multimodal Language Models\", \"x\": 9.003, \"y\": 6.895}, {\"title\": \"Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark  with Human-VLM Collaboration\", \"topic\": \"Multimodal Language Models\", \"x\": 8.253, \"y\": 7.803}, {\"title\": \"UNO Arena for Evaluating Sequential Decision-Making Capability of Large  Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.495, \"y\": 2.998}, {\"title\": \"UniPSDA: Unsupervised Pseudo Semantic Data Augmentation for Zero-Shot  Cross-Lingual Natural Language Understanding\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.362, \"y\": 5.121}, {\"title\": \"ADVSCORE: A Metric for the Evaluation and Creation of Adversarial  Benchmarks\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.232, \"y\": 3.036}, {\"title\": \"EHRCon: Dataset for Checking Consistency between Unstructured Notes and  Structured Tables in Electronic Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.869, \"y\": 7.89}, {\"title\": \"DemoRank: Selecting Effective Demonstrations for Large Language Models  in Ranking Task\", \"topic\": \"In-Context Learning\", \"x\": 8.152, \"y\": 3.475}, {\"title\": \"Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer  Merging\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.561, \"y\": 2.464}, {\"title\": \"What Do VLMs NOTICE? A Mechanistic Interpretability Pipeline for  Noise-free Text-Image Corruption and Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.354, \"y\": 7.682}, {\"title\": \"Cascade Reward Sampling for Efficient Decoding-Time Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.342, \"y\": 1.443}, {\"title\": \"Compensate Quantization Errors: Make Weights Hierarchical to Compensate  Each Other\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.682, \"y\": 2.147}, {\"title\": \"LangSuitE: Planning, Controlling and Interacting with Large Language  Models in Embodied Text Environments\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.801, \"y\": 2.552}, {\"title\": \"FS-RAG: A Frame Semantics Based Approach for Improved Factual Accuracy  in Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.006, \"y\": 4.672}, {\"title\": \"Towards Region-aware Bias Evaluation Metrics\", \"topic\": \"Bias in Language Models\", \"x\": 3.303, \"y\": 4.402}, {\"title\": \"Chain-of-Probe: Examing the Necessity and Accuracy of CoT Step-by-Step\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.639, \"y\": 2.303}, {\"title\": \"Crosslingual Capabilities and Knowledge Barriers in Multilingual Large  Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.157, \"y\": 4.517}, {\"title\": \"Contextualized End-to-end Automatic Speech Recognition with Intermediate  Biasing Loss\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.323, \"y\": 5.153}, {\"title\": \"Decoder-only Architecture for Streaming End-to-end Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.091, \"y\": 5.109}, {\"title\": \"EERPD: Leveraging Emotion and Emotion Regulation for Improving  Personality Detection\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.476, \"y\": 7.479}, {\"title\": \"First Heuristic Then Rational: Dynamic Use of Heuristics in Language  Model Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.51, \"y\": 2.702}, {\"title\": \"Dancing in the syntax forest: fast, accurate and explainable sentiment  analysis with SALSA\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.561, \"y\": 6.64}, {\"title\": \"Distributed Rule Vectors is A Key Mechanism in Large Language Models'  In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.392, \"y\": 3.429}, {\"title\": \"Effectiveness of ChatGPT in explaining complex medical reports to  patients\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.577, \"y\": 8.086}, {\"title\": \"Teaching LLMs to Abstain across Languages via Multilingual Feedback\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.842, \"y\": 4.17}, {\"title\": \"RuleR: Improving LLM Controllability by Rule-based Data Recycling\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.023, \"y\": 2.226}, {\"title\": \"Semantic Entropy Probes: Robust and Cheap Hallucination Detection in  LLMs\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.177, \"y\": 1.099}, {\"title\": \"Language Alignment via Nash-learning and Adaptive feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.283, \"y\": 1.413}, {\"title\": \"Real-time Speech Summarization for Medical Conversations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.587, \"y\": 7.958}, {\"title\": \"BigCodeBench: Benchmarking Code Generation with Diverse Function Calls  and Complex Instructions\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.281, \"y\": 2.591}, {\"title\": \"Uncovering Hidden Intentions: Exploring Prompt Recovery for Deeper  Insights into Generated Texts\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 4.419, \"y\": 4.041}, {\"title\": \"A multitask learning framework for leveraging subjectivity of annotators  to identify misogyny\", \"topic\": \"Hate Speech Detection\", \"x\": 3.095, \"y\": 5.591}, {\"title\": \"Speech Analysis of Language Varieties in Italy\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.512, \"y\": 5.079}, {\"title\": \"Revisiting Interpolation Augmentation for Speech-to-Text Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.674, \"y\": 5.532}, {\"title\": \"LOGIC-LM++: Multi-Step Refinement for Symbolic Formulations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.669, \"y\": 2.824}, {\"title\": \"CaT-BENCH: Benchmarking Language Model Understanding of Causal and  Temporal Dependencies in Plans\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.472, \"y\": 3.157}, {\"title\": \"A multi-speaker multi-lingual voice cloning system based on vits2 for  limmits 2024 challenge\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.68, \"y\": 5.699}, {\"title\": \"LaMSUM: A Novel Framework for Extractive Summarization of User Generated  Content using LLMs\", \"topic\": \"Text Summarization\", \"x\": 5.597, \"y\": 6.039}, {\"title\": \"What Matters in Transformers? Not All Attention is Needed\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.793, \"y\": 3.26}, {\"title\": \"Unveiling and Harnessing Hidden Attention Sinks: Enhancing Large  Language Models without Training through Attention Calibration\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.433, \"y\": 2.779}, {\"title\": \"Multimodal Segmentation for Vocal Tract Modeling\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.672, \"y\": 5.705}, {\"title\": \"TacoLM: GaTed Attention Equipped Codec Language Model are Efficient  Zero-Shot Text to Speech Synthesizers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.667, \"y\": 5.367}, {\"title\": \"Ladder: A Model-Agnostic Framework Boosting LLM-based Machine  Translation to the Next Level\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.535, \"y\": 4.175}, {\"title\": \"RankAdaptor: Hierarchical Dynamic Low-Rank Adaptation for Structural  Pruned LLMs\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.18, \"y\": 2.07}, {\"title\": \"Acoustic Feature Mixup for Balanced Multi-aspect Pronunciation  Assessment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.036, \"y\": 5.428}, {\"title\": \"Beyond the Turn-Based Game: Enabling Real-Time Conversations with Duplex  Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.406, \"y\": 3.525}, {\"title\": \"Teach Better or Show Smarter? On Instructions and Exemplars in Automatic  Prompt Optimization\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.373, \"y\": 3.222}, {\"title\": \"PI-Whisper: An Adaptive and Incremental ASR Framework for Diverse and  Evolving Speaker Characteristics\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.123, \"y\": 5.347}, {\"title\": \"Shortcomings of LLMs for Low-Resource Translation: Retrieval and  Understanding are Both the Problem\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.348, \"y\": 4.279}, {\"title\": \"Logicbreaks: A Framework for Understanding Subversion of Rule-based  Inference\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.55, \"y\": 3.023}, {\"title\": \"Detecting AI-Generated Text: Factors Influencing Detectability with  Current Methods\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.208, \"y\": 4.723}, {\"title\": \"SAIL: Self-Improving Efficient Online Alignment of Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.276, \"y\": 1.441}, {\"title\": \"Multimodal Task Vectors Enable Many-Shot Multimodal In-Context Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.465, \"y\": 7.212}, {\"title\": \"Gradient-Mask Tuning Elevates the Upper Limits of LLM Performance\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.014, \"y\": 2.472}, {\"title\": \"LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.077, \"y\": 4.685}, {\"title\": \"STARD: A Chinese Statute Retrieval Dataset with Real Queries Issued by  Non-professionals\", \"topic\": \"Legal NLP\", \"x\": 5.183, \"y\": 5.68}, {\"title\": \"NLP-KG: A System for Exploratory Search of Scientific Literature in  Natural Language Processing\", \"topic\": \"Text Summarization\", \"x\": 6.225, \"y\": 6.19}, {\"title\": \"The Greek podcast corpus: Competitive speech models for low-resourced  languages with weakly supervised data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.943, \"y\": 5.184}, {\"title\": \"Cognitive Map for Language Models: Optimal Planning via Verbally  Representing the World Model\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.935, \"y\": 2.798}, {\"title\": \"Perception of Phonological Assimilation by Neural Speech Recognition  Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.938, \"y\": 5.289}, {\"title\": \"Unsupervised Extraction of Dialogue Policies from Conversations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.391, \"y\": 3.734}, {\"title\": \"Reward Steering with Evolutionary Heuristics for Decoding-time Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.348, \"y\": 1.348}, {\"title\": \"Hybrid Alignment Training for Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.364, \"y\": 1.36}, {\"title\": \"Geneverse: A collection of Open-source Multimodal Large Language Models  for Genomic and Proteomic Research\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.275, \"y\": 7.47}, {\"title\": \"A Syntax-Injected Approach for Faster and More Accurate Sentiment  Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.355, \"y\": 6.762}, {\"title\": \"Tri-VQA: Triangular Reasoning Medical Visual Question Answering for  Multi-Attribute Analysis\", \"topic\": \"Multimodal Language Models\", \"x\": 8.097, \"y\": 8.064}, {\"title\": \"Harnessing Knowledge Retrieval with Large Language Models for Clinical  Report Error Correction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.005, \"y\": 8.367}, {\"title\": \"GiusBERTo: A Legal Language Model for Personal Data De-identification in  Italian Court of Auditors Decisions\", \"topic\": \"Legal NLP\", \"x\": 4.993, \"y\": 5.717}, {\"title\": \"MedOdyssey: A Medical Domain Benchmark for Long Context Evaluation Up to  200K Tokens\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.964, \"y\": 7.732}, {\"title\": \"Disability Representations: Finding Biases in Automatic Image Generation\", \"topic\": \"Bias in Language Models\", \"x\": 3.23, \"y\": 4.557}, {\"title\": \"Pistis-RAG: A Scalable Cascading Framework Towards Content-Centric  Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.05, \"y\": 4.617}, {\"title\": \"A Tale of Trust and Accuracy: Base vs. Instruct LLMs in RAG Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.929, \"y\": 4.514}, {\"title\": \"Domain Adaptation of Llama3-70B-Instruct through Continual Pre-Training  and Model Merging: A Comprehensive Evaluation\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.897, \"y\": 6.858}, {\"title\": \"Unlocking the Global Synergies in Low-Rank Adapters\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.189, \"y\": 2.037}, {\"title\": \"ICLEval: Evaluating In-Context Learning Ability of Large Language Models\", \"topic\": \"In-Context Learning\", \"x\": 8.361, \"y\": 3.323}, {\"title\": \"ESC-Eval: Evaluating Emotion Support Conversations in Large Language  Models\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.57, \"y\": 7.674}, {\"title\": \"Towards Retrieval Augmented Generation over Large Video Libraries\", \"topic\": \"Multimodal Language Models\", \"x\": 8.597, \"y\": 7.951}, {\"title\": \"Autonomous Agents for Collaborative Task under Information Asymmetry\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.364, \"y\": 2.921}, {\"title\": \"Talking the Talk Does Not Entail Walking the Walk: On the Limits of  Large Language Models in Lexical Entailment Recognition\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.004, \"y\": 3.659}, {\"title\": \"Generate-then-Ground in Retrieval-Augmented Generation for Multi-hop  Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.626, \"y\": 5.124}, {\"title\": \"InterBiasing: Boost Unseen Word Recognition through Biasing Intermediate  Predictions\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.073, \"y\": 5.088}, {\"title\": \"InternLM-Law: An Open Source Chinese Legal Large Language Model\", \"topic\": \"Legal NLP\", \"x\": 5.189, \"y\": 5.478}, {\"title\": \"FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for  LLM-based Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.778, \"y\": 2.737}, {\"title\": \"70B-parameter large language models in Japanese medical  question-answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.968, \"y\": 7.945}, {\"title\": \"Rethinking Pruning Large Language Models: Benefits and Pitfalls of  Reconstruction Error Minimization\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.448, \"y\": 2.437}, {\"title\": \"Direct Multi-Turn Preference Optimization for Language Agents\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.272, \"y\": 1.429}, {\"title\": \"DistiLRR: Transferring Code Repair for Low-Resource Programming  Languages\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.369, \"y\": 2.251}, {\"title\": \"From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.329, \"y\": 2.322}, {\"title\": \"Evaluating RAG-Fusion with RAGElo: an Automated Elo-based Framework\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.793, \"y\": 4.675}, {\"title\": \"ChatGPT as Research Scientist: Probing GPT's Capabilities as a Research  Librarian, Research Ethicist, Data Generator and Data Predictor\", \"topic\": \"Bias in Language Models\", \"x\": 5.094, \"y\": 4.564}, {\"title\": \"A Learn-Then-Reason Model Towards Generalization in Knowledge Base  Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.719, \"y\": 5.355}, {\"title\": \"An LLM Feature-based Framework for Dialogue Constructiveness Assessment\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.511, \"y\": 3.618}, {\"title\": \"System Description for the Displace Speaker Diarization Challenge 2023\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.979, \"y\": 5.584}, {\"title\": \"An Adapter-Based Unified Model for Multiple Spoken Language Processing  Tasks\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.879, \"y\": 5.007}, {\"title\": \"Relation Extraction with Fine-Tuned Large Language Models in Retrieval  Augmented Generation Frameworks\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.906, \"y\": 6.663}, {\"title\": \"Learning to Retrieve Iteratively for In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.222, \"y\": 3.413}, {\"title\": \"TTQA-RS- A break-down prompting approach for Multi-hop Table-Text  Question Answering with Reasoning and Summarization\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.587, \"y\": 5.245}, {\"title\": \"1+1>2: Can Large Language Models Serve as Cross-Lingual Knowledge  Aggregators?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.958, \"y\": 4.414}, {\"title\": \"Speech Prefix-Tuning with RNNT Loss for Improving LLM Predictions\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.14, \"y\": 5.048}, {\"title\": \"A Contrastive Learning Approach to Mitigate Bias in Speech Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.463, \"y\": 4.202}, {\"title\": \"Holistic Evaluation for Interleaved Text-and-Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.635, \"y\": 6.928}, {\"title\": \"Prism: A Framework for Decoupling and Assessing the Capabilities of VLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.223, \"y\": 7.748}, {\"title\": \"Investigating Mysteries of CoT-Augmented Distillation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.833, \"y\": 2.257}, {\"title\": \"Improving Expert Radiology Report Summarization by Prompting Large  Language Models with a Layperson Summary\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.11, \"y\": 8.512}, {\"title\": \"CodeRAG-Bench: Can Retrieval Augment Code Generation?\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.208, \"y\": 4.453}, {\"title\": \"African or European Swallow? Benchmarking Large Vision-Language Models  for Fine-Grained Object Classification\", \"topic\": \"Multimodal Language Models\", \"x\": 8.717, \"y\": 7.361}, {\"title\": \"Does Object Grounding Really Reduce Hallucination of Large  Vision-Language Models?\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.319, \"y\": 0.991}, {\"title\": \"On Layer-wise Representation Similarity: Application for Multi-Exit  Models with a Single Classifier\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.578, \"y\": 3.519}, {\"title\": \"A Review of Common Online Speaker Diarization Methods\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.924, \"y\": 5.561}, {\"title\": \"SynDARin: Synthesising Datasets for Automated Reasoning in Low-Resource  Languages\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.37, \"y\": 5.091}, {\"title\": \"FVEL: Interactive Formal Verification Environment with Large Language  Models via Theorem Proving\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.941, \"y\": 2.638}, {\"title\": \"SEC-QA: A Systematic Evaluation Corpus for Financial QA\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.993, \"y\": 6.818}, {\"title\": \"Jailbreaking as a Reward Misspecification Problem\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.313, \"y\": 2.302}, {\"title\": \"medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced  Clinical Diagnosis on EMRs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.831, \"y\": 8.305}, {\"title\": \"Robust Few-shot Transfer Learning for Knowledge Base Question Answering  with Unanswerable Questions\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.695, \"y\": 5.33}, {\"title\": \"Infusing clinical knowledge into tokenisers for language models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.96, \"y\": 7.999}, {\"title\": \"QuST-LLM: Integrating Large Language Models for Comprehensive Spatial  Transcriptomics Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.969, \"y\": 7.751}, {\"title\": \"Learning to Plan for Retrieval-Augmented Large Language Models from  Knowledge Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.839, \"y\": 5.331}, {\"title\": \"On the Evaluation Practices in Multilingual NLP: Can Machine Translation  Offer an Alternative to Human Translations?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.056, \"y\": 4.556}, {\"title\": \"Complexity of Symbolic Representation in Working Memory of Transformer  Correlates with the Complexity of a Task\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.556, \"y\": 3.625}, {\"title\": \"On the Representational Capacity of Neural Language Models with  Chain-of-Thought Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.949, \"y\": 2.384}, {\"title\": \"Temporal Knowledge Graph Question Answering: A Survey\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.619, \"y\": 5.581}, {\"title\": \"SimulSeamless: FBK at IWSLT 2024 Simultaneous Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.258, \"y\": 5.112}, {\"title\": \"A Data-Driven Guided Decoding Mechanism for Diagnostic Captioning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.134, \"y\": 8.431}, {\"title\": \"DIRAS: Efficient LLM-Assisted Annotation of Document Relevance in  Retrieval Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.012, \"y\": 4.726}, {\"title\": \"Watching the Watchers: A Comparative Fairness Audit of Cloud-based  Content Moderation Services\", \"topic\": \"Hate Speech Detection\", \"x\": 2.845, \"y\": 5.29}, {\"title\": \"MACAROON: Training Vision-Language Models To Be Your Engaged Partners\", \"topic\": \"Multimodal Language Models\", \"x\": 8.19, \"y\": 7.954}, {\"title\": \"Towards Event-oriented Long Video Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.845, \"y\": 7.901}, {\"title\": \"An Investigation of Prompt Variations for Zero-shot LLM-based Rankers\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.158, \"y\": 3.449}, {\"title\": \"ReaLHF: Optimized RLHF Training for Large Language Models through  Parameter Reallocation\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.263, \"y\": 1.503}, {\"title\": \"Prompt Injection Attacks in Defended Systems\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.454, \"y\": 2.576}, {\"title\": \"Taxonomy-Guided Zero-Shot Recommendations with LLMs\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.918, \"y\": 2.908}, {\"title\": \"CryptoGPT: a 7B model rivaling GPT-4 in the task of analyzing and  classifying real-time financial news\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.76, \"y\": 6.864}, {\"title\": \"Toward Infinite-Long Prefix in Transformer\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.818, \"y\": 3.127}, {\"title\": \"Two Giraffes in a Dirt Field: Using Game Play to Investigate Situation  Modelling in Large Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.138, \"y\": 7.626}, {\"title\": \"LLM Critics Help Catch Bugs in Mathematics: Towards a Better  Mathematical Verifier with Natural Language Feedback\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.928, \"y\": 2.536}, {\"title\": \"Evaluating Implicit Bias in Large Language Models by Attacking From a  Psychometric Perspective\", \"topic\": \"Bias in Language Models\", \"x\": 3.505, \"y\": 4.159}, {\"title\": \"Investigating the Pre-Training Dynamics of In-Context Learning: Task  Recognition vs. Task Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.599, \"y\": 3.369}, {\"title\": \"Seeing Through AI's Lens: Enhancing Human Skepticism Towards  LLM-Generated Fake News\", \"topic\": \"Fake News Detection\", \"x\": 4.041, \"y\": 5.456}, {\"title\": \"Information Guided Regularization for Fine-tuning Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.924, \"y\": 2.537}, {\"title\": \"\\\"Global is Good, Local is Bad?\\\": Understanding Brand Bias in LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.568, \"y\": 4.311}, {\"title\": \"MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.553, \"y\": 3.142}, {\"title\": \"Evolving to be Your Soulmate: Personalized Dialogue Agents with  Dynamically Adapted Personas\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.14, \"y\": 3.634}, {\"title\": \"AutoCAP: Towards Automatic Cross-lingual Alignment Planning for  Zero-shot Chain-of-Thought\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.413, \"y\": 4.721}, {\"title\": \"Reasoning Like a Doctor: Improving Medical Dialogue Systems via  Diagnostic Reasoning Process Alignment\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.622, \"y\": 8.247}, {\"title\": \"Large Language Models are Skeptics: False Negative Problem of  Input-conflicting Hallucination\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.246, \"y\": 1.38}, {\"title\": \"PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal  Documents\", \"topic\": \"Multimodal Language Models\", \"x\": 7.956, \"y\": 7.315}, {\"title\": \"The Use of Multimodal Large Language Models to Detect Objects from  Thermal Images: Transportation Applications\", \"topic\": \"Multimodal Language Models\", \"x\": 8.309, \"y\": 7.49}, {\"title\": \"Open Generative Large Language Models for Galician\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.854, \"y\": 4.214}, {\"title\": \"ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics  in the Real World\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.65, \"y\": 8.233}, {\"title\": \"Knowledge Tagging System on Math Questions via LLMs with Flexible  Demonstration Retriever\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.008, \"y\": 3.104}, {\"title\": \"Few-shot Knowledge Graph Relational Reasoning via Subgraph Adaptation\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.978, \"y\": 5.996}, {\"title\": \"Distributional reasoning in LLMs: Parallel reasoning processes in  multi-hop reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.602, \"y\": 2.852}, {\"title\": \"Joint vs Sequential Speaker-Role Detection and Automatic Speech  Recognition for Air-traffic Control\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.114, \"y\": 5.33}, {\"title\": \"StackRAG Agent: Improving Developer Answers with Retrieval-Augmented  Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.829, \"y\": 4.701}, {\"title\": \"Framing Social Movements on Social Media: Unpacking Diagnostic,  Prognostic, and Motivational Strategies\", \"topic\": \"Fake News Detection\", \"x\": 3.717, \"y\": 5.814}, {\"title\": \"AlanaVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.679, \"y\": 7.752}, {\"title\": \"IoT-Based Preventive Mental Health Using Knowledge Graphs and Standards  for Better Well-Being\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.318, \"y\": 7.527}, {\"title\": \"A Primal-Dual Framework for Transformers and Neural Networks\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.796, \"y\": 3.366}, {\"title\": \"Elliptical Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.875, \"y\": 3.244}, {\"title\": \"Unveiling the Hidden Structure of Self-Attention via Kernel Principal  Component Analysis\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.827, \"y\": 3.326}, {\"title\": \"GenAI-Bench: Evaluating and Improving Compositional Text-to-Visual  Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.851, \"y\": 7.465}, {\"title\": \"MMTE: Corpus and Metrics for Evaluating Machine Translation Quality of  Metaphorical Language\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.684, \"y\": 4.729}, {\"title\": \"Combinatorial Reasoning: Selecting Reasons in Generative AI Pipelines  via Combinatorial Optimization\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.531, \"y\": 2.652}, {\"title\": \"Leveraging Large Language Models to Measure Gender Bias in Gendered  Languages\", \"topic\": \"Bias in Language Models\", \"x\": 3.183, \"y\": 4.395}, {\"title\": \"ObscurePrompt: Jailbreaking Large Language Models via Obscure Input\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.396, \"y\": 2.34}, {\"title\": \"Can Few-shot Work in Long-Context? Recycling the Context to Generate  Demonstrations\", \"topic\": \"In-Context Learning\", \"x\": 8.185, \"y\": 3.563}, {\"title\": \"InstructRAG: Instructing Retrieval-Augmented Generation with Explicit  Denoising\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.069, \"y\": 4.652}, {\"title\": \"Fine-Tuning Gemma-7B for Enhanced Sentiment Analysis of Financial News  Headlines\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.758, \"y\": 6.846}, {\"title\": \"Improving Visual Commonsense in Language Models via Multiple Image  Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.359, \"y\": 7.518}, {\"title\": \"In-Context Former: Lightning-fast Compressing Context for Large Language  Model\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.545, \"y\": 2.95}, {\"title\": \"Enhancing Distractor Generation for Multiple-Choice Questions with  Retrieval Augmented Pretraining and Knowledge Graph Integration\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.335, \"y\": 4.95}, {\"title\": \"Evaluating Short-Term Temporal Fluctuations of Social Biases in Social  Media Data and Masked Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.404, \"y\": 4.582}, {\"title\": \"BiLD: Bi-directional Logits Difference Loss for Large Language Model  Distillation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.458, \"y\": 3.777}, {\"title\": \"Mitigating Social Biases in Language Models through Unlearning\", \"topic\": \"Bias in Language Models\", \"x\": 3.386, \"y\": 4.024}, {\"title\": \"ManWav: The First Manchu ASR Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.146, \"y\": 5.515}, {\"title\": \"LLMs Are Zero-Shot Context-Aware Simultaneous Translators\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.559, \"y\": 4.357}, {\"title\": \"VDebugger: Harnessing Execution Feedback for Debugging Visual Programs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.233, \"y\": 7.596}, {\"title\": \"Dual-Phase Accelerated Prompt Optimization\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.386, \"y\": 3.233}, {\"title\": \"Children's Speech Recognition through Discrete Token Enhancement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.246, \"y\": 5.325}, {\"title\": \"MoreHopQA: More Than Multi-hop Reasoning\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.588, \"y\": 5.298}, {\"title\": \"CoAct: A Global-Local Hierarchy for Autonomous Agent Collaboration\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.494, \"y\": 2.761}, {\"title\": \"VisualRWKV: Exploring Recurrent Neural Networks for Visual Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.32, \"y\": 7.557}, {\"title\": \"Improving Zero-Shot Cross-Lingual Transfer via Progressive  Code-Switching\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.598, \"y\": 4.82}, {\"title\": \"ZeroDL: Zero-shot Distribution Learning for Text Clustering via Large  Language Models\", \"topic\": \"In-Context Learning\", \"x\": 8.283, \"y\": 3.759}, {\"title\": \"Medical Spoken Named Entity Recognition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.45, \"y\": 7.603}, {\"title\": \"How effective is Multi-source pivoting for Translation of Low Resource  Indian Languages?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.702, \"y\": 4.896}, {\"title\": \"Enhancing Automated Audio Captioning via Large Language Models with  Optimized Audio Encoding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.418, \"y\": 6.101}, {\"title\": \"Investigating Low-Cost LLM Annotation for~Spoken Dialogue Understanding  Datasets\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.771, \"y\": 3.705}, {\"title\": \"R^2AG: Incorporating Retrieval Information into Retrieval Augmented  Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.057, \"y\": 4.562}, {\"title\": \"GSR-BENCH: A Benchmark for Grounded Spatial Reasoning Evaluation via  Multimodal LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.375, \"y\": 7.441}, {\"title\": \"Towards Robust Evaluation: A Comprehensive Taxonomy of Datasets and  Metrics for Open Domain Question Answering in the Era of Large Language  Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.477, \"y\": 4.945}, {\"title\": \"Probing the Emergence of Cross-lingual Alignment during LLM Training\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.22, \"y\": 4.52}, {\"title\": \"MC-MKE: A Fine-Grained Multimodal Knowledge Editing Benchmark  Emphasizing Modality Consistency\", \"topic\": \"Multimodal Language Models\", \"x\": 7.971, \"y\": 7.425}, {\"title\": \"Bridging Law and Data: Augmenting Reasoning via a Semi-Structured  Dataset with IRAC methodology\", \"topic\": \"Legal NLP\", \"x\": 5.101, \"y\": 5.703}, {\"title\": \"Multi-Meta-RAG: Improving RAG for Multi-Hop Queries using Database  Filtering with LLM-Extracted Metadata\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.005, \"y\": 4.728}, {\"title\": \"Learning Translations via Matrix Completion\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.496, \"y\": 4.866}, {\"title\": \"Synthetic Context Generation for Question Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.379, \"y\": 4.955}, {\"title\": \"Learnable In-Context Vector for Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.301, \"y\": 7.69}, {\"title\": \"Biomedical Visual Instruction Tuning with Clinician Preference Alignment\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.642, \"y\": 8.202}, {\"title\": \"Analyzing Diversity in Healthcare LLM Research: A Scientometric  Perspective\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.464, \"y\": 7.622}, {\"title\": \"DialSim: A Real-Time Simulator for Evaluating Long-Term Dialogue  Understanding of Conversational Agents\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.262, \"y\": 3.569}, {\"title\": \"Large Language Models are Biased Because They Are Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.768, \"y\": 4.107}, {\"title\": \"PathoLM: Identifying pathogenicity from the DNA sequence through the  Genome Foundation Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.177, \"y\": 7.839}, {\"title\": \"When Parts are Greater Than Sums: Individual LLM Components Can  Outperform Full Models\", \"topic\": \"In-Context Learning\", \"x\": 8.397, \"y\": 3.374}, {\"title\": \"Multi-Stage Balanced Distillation: Addressing Long-Tail Challenges in  Sequence-Level Knowledge Distillation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.481, \"y\": 3.755}, {\"title\": \"Accelerating Complex Disease Treatment through Network Medicine and  GenAI: A Case Study on Drug Repurposing for Breast Cancer\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.0, \"y\": 7.555}, {\"title\": \"Exploring and Benchmarking the Planning Capabilities of Large Language  Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 6.062, \"y\": 2.845}, {\"title\": \"Multilingual Synopses of Movie Narratives: A Dataset for Story  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.899, \"y\": 7.814}, {\"title\": \"Articulatory Encodec: Vocal Tract Kinematics as a Codec for Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.506, \"y\": 5.556}, {\"title\": \"Interpretable Preferences via Multi-Objective Reward Modeling and  Mixture-of-Experts\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.202, \"y\": 1.47}, {\"title\": \"LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional  Adaptation\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.153, \"y\": 2.148}, {\"title\": \"Composited-Nested-Learning with Data Augmentation for Nested Named  Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.39, \"y\": 6.736}, {\"title\": \"Benchmarking Multi-Image Understanding in Vision and Language Models:  Perception, Knowledge, Reasoning, and Multi-Hop Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.148, \"y\": 7.671}, {\"title\": \"Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+  Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.584, \"y\": 4.672}, {\"title\": \"Large Language Model as a Universal Clinical Multi-task Decoder\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.96, \"y\": 8.071}, {\"title\": \"Can Large Language Models Code Like a Linguist?: A Case Study in Low  Resource Sound Law Induction\", \"topic\": \"Legal NLP\", \"x\": 5.224, \"y\": 5.334}, {\"title\": \"AGLA: Mitigating Object Hallucinations in Large Vision-Language Models  with Assembly of Global and Local Attention\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.304, \"y\": 0.998}, {\"title\": \"Transforming Surgical Interventions with Embodied Intelligence for  Ultrasound Robotics\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.743, \"y\": 8.182}, {\"title\": \"DetectBench: Can Large Language Model Detect and Piece Together Implicit  Evidence?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.506, \"y\": 3.167}, {\"title\": \"Ask-before-Plan: Proactive Language Agents for Real-World Planning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.809, \"y\": 2.595}, {\"title\": \"Saliency Attention and Semantic Similarity-Driven Adversarial  Perturbation\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.167, \"y\": 3.022}, {\"title\": \"EUvsDisinfo: a Dataset for Multilingual Detection of Pro-Kremlin  Disinformation in News Articles\", \"topic\": \"Fake News Detection\", \"x\": 3.893, \"y\": 5.97}, {\"title\": \"Rapid Language Adaptation for Multilingual E2E Speech Recognition Using  Encoder Prompting\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.736, \"y\": 5.011}, {\"title\": \"Low-Redundant Optimization for Large Language Model Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.452, \"y\": 1.41}, {\"title\": \"Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.947, \"y\": 2.967}, {\"title\": \"Causal Discovery Inspired Unsupervised Domain Adaptation for  Emotion-Cause Pair Extraction\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.429, \"y\": 7.62}, {\"title\": \"Applying Ensemble Methods to Model-Agnostic Machine-Generated Text  Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.075, \"y\": 4.785}, {\"title\": \"RichRAG: Crafting Rich Responses for Multi-faceted Queries in  Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.016, \"y\": 4.713}, {\"title\": \"Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in  Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.68, \"y\": 3.108}, {\"title\": \"Unified Active Retrieval for Retrieval Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.016, \"y\": 4.773}, {\"title\": \"Code-Optimise: Self-Generated Preference Data for Correctness and  Efficiency\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.463, \"y\": 2.325}, {\"title\": \"The Power of LLM-Generated Synthetic Data for Stance Detection in Online  Political Discussions\", \"topic\": \"Fake News Detection\", \"x\": 3.539, \"y\": 5.696}, {\"title\": \"Abstraction-of-Thought Makes Language Models Better Reasoners\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.733, \"y\": 2.505}, {\"title\": \"QueerBench: Quantifying Discrimination in Language Models Toward Queer  Identities\", \"topic\": \"Bias in Language Models\", \"x\": 3.253, \"y\": 4.562}, {\"title\": \"Instruction Data Generation and Unsupervised Adaptation for Speech  Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.542, \"y\": 5.572}, {\"title\": \"EMO-KNOW: A Large Scale Dataset on Emotion and Emotion-cause\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.597, \"y\": 7.422}, {\"title\": \"Performant ASR Models for Medical Entities in Accented Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.077, \"y\": 5.628}, {\"title\": \"QOG:Question and Options Generation based on Language Model\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.276, \"y\": 4.903}, {\"title\": \"Does Context Help Mitigate Gender Bias in Neural Machine Translation?\", \"topic\": \"Bias in Language Models\", \"x\": 3.015, \"y\": 4.391}, {\"title\": \"Interpreting Bias in Large Language Models: A Feature-Based Approach\", \"topic\": \"Bias in Language Models\", \"x\": 3.452, \"y\": 4.298}, {\"title\": \"COT: A Generative Approach for Hate Speech Counter-Narratives via  Contrastive Optimal Transport\", \"topic\": \"Hate Speech Detection\", \"x\": 2.72, \"y\": 5.318}, {\"title\": \"CodeNav: Beyond tool-use to using real-world codebases with LLM agents\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.179, \"y\": 2.359}, {\"title\": \"A Hopfieldian View-based Interpretation for Chain-of-Thought Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.651, \"y\": 2.33}, {\"title\": \"TroL: Traversal of Layers for Large Language and Vision Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.526, \"y\": 7.53}, {\"title\": \"SyncVSR: Data-Efficient Visual Speech Recognition with End-to-End  Crossmodal Audio Token Synchronization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.835, \"y\": 5.566}, {\"title\": \"\\\"You Gotta be a Doctor, Lin\\\": An Investigation of Name-Based Bias of  Large Language Models in Employment Recommendations\", \"topic\": \"Bias in Language Models\", \"x\": 3.42, \"y\": 4.344}, {\"title\": \"ToxiCloakCN: Evaluating Robustness of Offensive Language Detection in  Chinese with Cloaking Perturbations\", \"topic\": \"Hate Speech Detection\", \"x\": 2.779, \"y\": 5.214}, {\"title\": \"On-Policy Fine-grained Knowledge Feedback for Hallucination Mitigation\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 5.869, \"y\": 1.493}, {\"title\": \"Interface Design for Self-Supervised Speech Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.899, \"y\": 4.958}, {\"title\": \"Aqulia-Med LLM: Pioneering Full-Process Open-Source Medical Language  Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.988, \"y\": 8.03}, {\"title\": \"BPO: Supercharging Online Preference Learning by Adhering to the  Proximity of Behavior LLM\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.268, \"y\": 1.358}, {\"title\": \"A dual task learning approach to fine-tune a multilingual semantic  speech encoder for Spoken Language Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.333, \"y\": 5.037}, {\"title\": \"Bias in Text Embedding Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.185, \"y\": 4.471}, {\"title\": \"Decoding the Narratives: Analyzing Personal Drug Experiences Shared on  Reddit\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.315, \"y\": 7.354}, {\"title\": \"Can LLMs Learn Macroeconomic Narratives from Social Media?\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.499, \"y\": 6.642}, {\"title\": \"Is poisoning a real threat to LLM alignment? Maybe more so than you  think\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.524, \"y\": 2.486}, {\"title\": \"Satyrn: A Platform for Analytics Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.88, \"y\": 4.718}, {\"title\": \"Language Models are Surprisingly Fragile to Drug Names in Biomedical  Benchmarks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.949, \"y\": 7.867}, {\"title\": \"InternalInspector $I^2$: Robust Confidence Estimation in LLMs through  Internal States\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.258, \"y\": 1.174}, {\"title\": \"Learn Beyond The Answer: Training Language Models with Reflection for  Mathematical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.041, \"y\": 2.558}, {\"title\": \"MedCalc-Bench: Evaluating Large Language Models for Medical Calculations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.721, \"y\": 8.044}, {\"title\": \"Unveiling and Mitigating Bias in Mental Health Analysis with Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.44, \"y\": 4.308}, {\"title\": \"CItruS: Chunked Instruction-aware State Eviction for Long Sequence  Modeling\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.813, \"y\": 2.919}, {\"title\": \"FinTruthQA: A Benchmark Dataset for Evaluating the Quality of Financial  Information Disclosure\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.905, \"y\": 6.809}, {\"title\": \"mDPO: Conditional Preference Optimization for Multimodal Large Language  Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.26, \"y\": 1.21}, {\"title\": \"WPO: Enhancing RLHF with Weighted Preference Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.287, \"y\": 1.383}, {\"title\": \"On Efficient Language and Vision Assistants for Visually-Situated  Natural Language Understanding: What Matters in Reading and Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.347, \"y\": 7.388}, {\"title\": \"Iterative Length-Regularized Direct Preference Optimization: A Case  Study on Improving 7B Language Models to GPT-4 Level\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.316, \"y\": 1.273}, {\"title\": \"CELL your Model: Contrastive Explanation Methods for Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.005, \"y\": 3.694}, {\"title\": \"Multi-Layer Ranking with Large Language Models for News Source  Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.948, \"y\": 2.899}, {\"title\": \"1000 African Voices: Advancing inclusive multi-speaker multi-accent  speech synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.601, \"y\": 5.642}, {\"title\": \"Zero-Shot Generalization during Instruction Tuning: Insights from  Similarity and Granularity\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.294, \"y\": 2.467}, {\"title\": \"Measuring memorization in RLHF for code completion\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.163, \"y\": 1.625}, {\"title\": \"Prompts as Auto-Optimized Training Hyperparameters: Training  Best-in-Class IR Models from Scratch with 10 Gold Labels\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.455, \"y\": 3.464}, {\"title\": \"Optimizing Instructions and Demonstrations for Multi-Stage Language  Model Programs\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.388, \"y\": 3.025}, {\"title\": \"Knowledge-to-Jailbreak: One Knowledge Point Worth One Attack\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.294, \"y\": 2.211}, {\"title\": \"BLoB: Bayesian Low-Rank Adaptation by Backpropagation for Large Language  Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.985, \"y\": 2.276}, {\"title\": \"Endor: Hardware-Friendly Sparse Format for Offloaded LLM Inference\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.576, \"y\": 2.261}, {\"title\": \"Benchmarking of LLM Detection: Comparing Two Competing Approaches\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.17, \"y\": 4.708}, {\"title\": \"\\\"Not Aligned\\\" is Not \\\"Malicious\\\": Being Careful about Hallucinations of  Large Language Models' Jailbreak\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.343, \"y\": 2.271}, {\"title\": \"See It from My Perspective: Diagnosing the Western Cultural Bias of  Large Vision-Language Models in Image Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.438, \"y\": 7.535}, {\"title\": \"A Two-dimensional Zero-shot Dialogue State Tracking Evaluation Method  using GPT-4\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.542, \"y\": 3.956}, {\"title\": \"Compress then Serve: Serving Thousands of LoRA Adapters with Little  Overhead\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.248, \"y\": 2.117}, {\"title\": \"Can Many-Shot In-Context Learning Help Long-Context LLM Judges? See  More, Judge Better!\", \"topic\": \"In-Context Learning\", \"x\": 8.076, \"y\": 3.393}, {\"title\": \"Mathematical Entities: Corpora and Benchmarks\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.224, \"y\": 3.081}, {\"title\": \"GECOBench: A Gender-Controlled Text Dataset and Benchmark for  Quantifying Biases in Explanations\", \"topic\": \"Bias in Language Models\", \"x\": 3.199, \"y\": 4.331}, {\"title\": \"GigaSpeech 2: An Evolving, Large-Scale and Multi-domain ASR Corpus for  Low-Resource Languages with Automated Crawling, Transcription and Refinement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.873, \"y\": 5.426}, {\"title\": \"Counterfactual Debating with Preset Stances for Hallucination  Elimination of LLMs\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.329, \"y\": 1.481}, {\"title\": \"GeoGPT4V: Towards Geometric Multi-modal Large Language Models with  Geometric Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.039, \"y\": 7.549}, {\"title\": \"CrAM: Credibility-Aware Attention Modification in LLMs for Combating  Misinformation in RAG\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.902, \"y\": 4.48}, {\"title\": \"Analysing zero-shot temporal relation extraction on clinical notes using  temporal consistency\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.734, \"y\": 7.778}, {\"title\": \"Vocabulary Expansion for Low-resource Cross-lingual Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.26, \"y\": 4.422}, {\"title\": \"How Far Can In-Context Alignment Go? Exploring the State of In-Context  Alignment\", \"topic\": \"In-Context Learning\", \"x\": 8.245, \"y\": 3.182}, {\"title\": \"TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for  Retrieval-Augmented Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.736, \"y\": 5.177}, {\"title\": \"Fusion Makes Perfection: An Efficient Multi-Grained Matching Approach  for Zero-Shot Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.367, \"y\": 6.591}, {\"title\": \"DiTTo-TTS: Efficient and Scalable Zero-Shot Text-to-Speech with  Diffusion Transformer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.395, \"y\": 5.863}, {\"title\": \"Dredge Word, Social Media, and Webgraph Networks for Unreliable Website  Classification and Identification\", \"topic\": \"Fake News Detection\", \"x\": 3.956, \"y\": 5.821}, {\"title\": \"CodeGemma: Open Code Models Based on Gemma\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.72, \"y\": 2.586}, {\"title\": \"Multimodal Structured Generation: CVPR's 2nd MMFM Challenge Technical  Report\", \"topic\": \"Multimodal Language Models\", \"x\": 8.128, \"y\": 7.339}, {\"title\": \"Fairer Preferences Elicit Improved Human-Aligned Large Language Model  Judgments\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.319, \"y\": 1.425}, {\"title\": \"Refiner: Restructure Retrieval Content Efficiently to Advance  Question-Answering Capabilities\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.985, \"y\": 4.572}, {\"title\": \"Self-Train Before You Transcribe\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.915, \"y\": 5.087}, {\"title\": \"JobFair: A Framework for Benchmarking Gender Hiring Bias in Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.29, \"y\": 4.3}, {\"title\": \"A Systematic Analysis of Large Language Models as Soft Reasoners: The  Case of Syllogistic Inferences\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.637, \"y\": 3.06}, {\"title\": \"Are Large Language Models True Healthcare Jacks-of-All-Trades?  Benchmarking Across Health Professions Beyond Physician Exams\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.816, \"y\": 7.936}, {\"title\": \"GUICourse: From General Vision Language Models to Versatile GUI Agents\", \"topic\": \"Multimodal Language Models\", \"x\": 8.282, \"y\": 7.473}, {\"title\": \"VideoVista: A Versatile Benchmark for Video Understanding and Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.676, \"y\": 8.002}, {\"title\": \"Optimizing and Testing Instruction-Following: Analyzing the Impact of  Fine-Grained Instruction Variants on instruction-tuned LLMs\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.226, \"y\": 2.335}, {\"title\": \"Explainable assessment of financial experts' credibility by classifying  social media forecasts and checking the predictions with actual market data\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.491, \"y\": 6.564}, {\"title\": \"Iterative Utility Judgment Framework via LLMs Inspired by Relevance in  Philosophy\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.035, \"y\": 4.795}, {\"title\": \"A Systematic Survey of Text Summarization: From Statistical Methods to  Large Language Models\", \"topic\": \"Text Summarization\", \"x\": 5.641, \"y\": 6.302}, {\"title\": \"MFC-Bench: Benchmarking Multimodal Fact-Checking with Large  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.025, \"y\": 7.608}, {\"title\": \"Small Agent Can Also Rock! Empowering Small Language Models as  Hallucination Detector\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.143, \"y\": 1.065}, {\"title\": \"Skip-Layer Attention: Bridging Abstract and Detailed Dependencies in  Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.782, \"y\": 3.346}, {\"title\": \"Mitigating Large Language Model Hallucination with Faithful Finetuning\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.306, \"y\": 1.187}, {\"title\": \"Adversarial Style Augmentation via Large Language Model for Robust Fake  News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.006, \"y\": 5.663}, {\"title\": \"Can Machines Resonate with Humans? Evaluating the Emotional and Empathic  Comprehension of LMs\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.709, \"y\": 7.843}, {\"title\": \"FamiCom: Further Demystifying Prompts for Language Models with  Task-Agnostic Performance Estimation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.237, \"y\": 3.404}, {\"title\": \"MiniConGTS: A Near Ultimate Minimalist Contrastive Grid Tagging Scheme  for Aspect Sentiment Triplet Extraction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.137, \"y\": 6.843}, {\"title\": \"Probing the Decision Boundaries of In-context Learning in Large Language  Models\", \"topic\": \"In-Context Learning\", \"x\": 8.419, \"y\": 3.41}, {\"title\": \"Enabling robots to follow abstract instructions and complete complex  dynamic tasks\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 8.676, \"y\": 6.664}, {\"title\": \"Multimodal Needle in a Haystack: Benchmarking Long-Context Capability of  Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.936, \"y\": 7.524}, {\"title\": \"ComperDial: Commonsense Persona-grounded Dialogue Dataset and Benchmark\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.339, \"y\": 3.84}, {\"title\": \"WeatherQA: Can Multimodal Language Models Reason about Severe Weather?\", \"topic\": \"Multimodal Language Models\", \"x\": 7.939, \"y\": 7.607}, {\"title\": \"MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in  Multimodal Large Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.375, \"y\": 7.273}, {\"title\": \"Beyond Boundaries: Learning a Universal Entity Taxonomy across Datasets  and Languages for Open Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.399, \"y\": 6.756}, {\"title\": \"A Survey on Human Preference Learning for Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.164, \"y\": 1.617}, {\"title\": \"Aligning Large Language Models from Self-Reference AI Feedback with one  General Principle\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.38, \"y\": 1.49}, {\"title\": \"Enhancing Criminal Case Matching through Diverse Legal Factors\", \"topic\": \"Legal NLP\", \"x\": 5.117, \"y\": 5.772}, {\"title\": \"SUGARCREPE++ Dataset: Vision-Language Model Sensitivity to Semantic and  Lexical Alterations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.629, \"y\": 7.443}, {\"title\": \"On Giant's Shoulders: Effortless Weak to Strong by Dynamic Logits Fusion\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.026, \"y\": 2.333}, {\"title\": \"How Good are LLMs at Relation Extraction under Low-Resource Scenario?  Comprehensive Evaluation\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.834, \"y\": 6.765}, {\"title\": \"Breaking Boundaries: Investigating the Effects of Model Editing on  Cross-linguistic Performance\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.185, \"y\": 4.386}, {\"title\": \"RePrompt: Planning by Automatic Prompt Engineering for Large Language  Models Agents\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.255, \"y\": 3.13}, {\"title\": \"Dynamic Order Template Prediction for Generative Aspect-Based Sentiment  Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.112, \"y\": 6.855}, {\"title\": \"Investigating Annotator Bias in Large Language Models for Hate Speech  Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.873, \"y\": 5.225}, {\"title\": \"Multiple Sources are Better Than One: Incorporating External Knowledge  in Low-Resource Glossing\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.196, \"y\": 4.477}, {\"title\": \"Exploring the Limitations of Detecting Machine-Generated Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.144, \"y\": 4.762}, {\"title\": \"WildVision: Evaluating Vision-Language Models in the Wild with Human  Preferences\", \"topic\": \"Multimodal Language Models\", \"x\": 8.291, \"y\": 7.679}, {\"title\": \"A Peek into Token Bias: Large Language Models Are Not Yet Genuine  Reasoners\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.463, \"y\": 3.219}, {\"title\": \"Evaluating the Performance of Large Language Models via Debates\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.096, \"y\": 3.806}, {\"title\": \"Scaling Synthetic Logical Reasoning Datasets with Context-Sensitive  Declarative Grammars\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.784, \"y\": 3.026}, {\"title\": \"Universal Cross-Lingual Text Classification\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.515, \"y\": 5.002}, {\"title\": \"Large Language Models for Dysfluency Detection in Stuttered Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.982, \"y\": 5.512}, {\"title\": \"Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs  Using the New York Times Connections Word Game\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.413, \"y\": 3.164}, {\"title\": \"CoSTA: Code-Switched Speech Translation using Aligned Speech-Text  Interleaving\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.386, \"y\": 5.328}, {\"title\": \"Toward Optimal LLM Alignments Using Two-Player Games\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.073, \"y\": 1.74}, {\"title\": \"Towards Supporting Legal Argumentation with NLP: Is More Data Really All  You Need?\", \"topic\": \"Legal NLP\", \"x\": 5.01, \"y\": 5.643}, {\"title\": \"DocNet: Semantic Structure in Inductive Bias Detection Models\", \"topic\": \"Fake News Detection\", \"x\": 3.73, \"y\": 5.543}, {\"title\": \"ESCoT: Towards Interpretable Emotional Support Dialogue Systems\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.589, \"y\": 7.897}, {\"title\": \"City-LEO: Toward Transparent City Management Using LLM with End-to-End  Optimization\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.706, \"y\": 2.755}, {\"title\": \"Eliminating Biased Length Reliance of Direct Preference Optimization via  Down-Sampled KL Divergence\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.269, \"y\": 1.246}, {\"title\": \"Understanding Understanding: A Pragmatic Framework Motivated by Large  Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.772, \"y\": 3.705}, {\"title\": \"Investigating Video Reasoning Capability of Large Language Models with  Tropes in Movies\", \"topic\": \"Multimodal Language Models\", \"x\": 8.768, \"y\": 7.982}, {\"title\": \"MICL: Improving In-Context Learning through Multiple-Label Words in  Demonstration\", \"topic\": \"In-Context Learning\", \"x\": 8.304, \"y\": 3.427}, {\"title\": \"Breaking the Attention Bottleneck\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.871, \"y\": 3.252}, {\"title\": \"AUTOHALLUSION: Automatic Generation of Hallucination Benchmarks for  Vision-Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.178, \"y\": 1.039}, {\"title\": \"Automatic Speech Recognition for Biomedical Data in Bengali Language\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.088, \"y\": 5.59}, {\"title\": \"SCAR: Efficient Instruction-Tuning for Large Language Models via Style  Consistency-Aware Response Ranking\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.0, \"y\": 2.148}, {\"title\": \"Teaching Large Language Models to Express Knowledge Boundary from Their  Own Signals\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.38, \"y\": 1.366}, {\"title\": \"Optimizing Automatic Speech Assessment: W-RankSim Regularization and  Hybrid Feature Fusion Strategies\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.226, \"y\": 5.381}, {\"title\": \"COOL: Comprehensive Knowledge Enhanced Prompt Learning for Domain  Adaptive Few-shot Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.066, \"y\": 5.956}, {\"title\": \"Reminding Multimodal Large Language Models of Object-aware Knowledge  with Retrieved Tags\", \"topic\": \"Multimodal Language Models\", \"x\": 8.284, \"y\": 7.333}, {\"title\": \"Exposing the Achilles' Heel: Evaluating LLMs Ability to Handle Mistakes  in Mathematical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.864, \"y\": 2.82}, {\"title\": \"Citation-Based Summarization of Landmark Judgments\", \"topic\": \"Legal NLP\", \"x\": 5.267, \"y\": 5.9}, {\"title\": \"Self-Evolution Fine-Tuning for Policy Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.517, \"y\": 1.567}, {\"title\": \"LLMFactor: Extracting Profitable Factors through Prompts for Explainable  Stock Movement Prediction\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.858, \"y\": 6.798}, {\"title\": \"Post-hoc Utterance Refining Method by Entity Mining for Faithful  Knowledge Grounded Conversations\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.289, \"y\": 1.22}, {\"title\": \"Towards Understanding Jailbreak Attacks in LLMs: A Representation Space  Analysis\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.321, \"y\": 2.291}, {\"title\": \"ShareLoRA: Parameter Efficient and Robust Large Language Model  Fine-tuning via Shared Low-Rank Adaptation\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.151, \"y\": 2.137}, {\"title\": \"RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained  Language Model for Knowledge Editing and Fine-tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.154, \"y\": 2.096}, {\"title\": \"How Should We Extract Discrete Audio Tokens from Self-Supervised Models?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.881, \"y\": 5.092}, {\"title\": \"Augmenting Biomedical Named Entity Recognition with General-domain  Resources\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.523, \"y\": 7.461}, {\"title\": \"On the Hardness of Faithful Chain-of-Thought Reasoning in Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.681, \"y\": 2.31}, {\"title\": \"Evaluating the Generalization Ability of Quantized LLMs: Benchmark,  Analysis, and Toolbox\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.675, \"y\": 2.205}, {\"title\": \"Multilingual Large Language Models and Curse of Multilinguality\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.912, \"y\": 4.451}, {\"title\": \"BlockPruner: Fine-grained Pruning for Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.533, \"y\": 2.513}, {\"title\": \"Mental Disorder Classification via Temporal Representation of Text\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.31, \"y\": 7.468}, {\"title\": \"Concentrate Attention: Towards Domain-Generalizable Prompt Optimization  for Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.546, \"y\": 3.219}, {\"title\": \"Optimization-based Structural Pruning for Large Language Models without  Back-Propagation\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.615, \"y\": 2.456}, {\"title\": \"We Care: Multimodal Depression Detection and Knowledge Infused Mental  Health Therapeutic Response Generation\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.252, \"y\": 7.663}, {\"title\": \"Lightweight Audio Segmentation for Long-form Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.657, \"y\": 5.228}, {\"title\": \"GTR-Voice: Articulatory Phonetics Informed Controllable Expressive  Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.57, \"y\": 5.845}, {\"title\": \"Benchmarking Children's ASR with Supervised and Self-supervised Speech  Foundation Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.157, \"y\": 5.279}, {\"title\": \"Task Facet Learning: A Structured Approach to Prompt Optimization\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.606, \"y\": 3.288}, {\"title\": \"Do Large Language Models Discriminate in Hiring Decisions on the Basis  of Race, Ethnicity, and Gender?\", \"topic\": \"Bias in Language Models\", \"x\": 3.502, \"y\": 4.314}, {\"title\": \"CancerLLM: A Large Language Model in Cancer Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.84, \"y\": 7.935}, {\"title\": \"TokenRec: Learning to Tokenize ID for LLM-based Generative  Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.82, \"y\": 2.818}, {\"title\": \"EWEK-QA: Enhanced Web and Efficient Knowledge Graph Retrieval for  Citation-based Question Answering Systems\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.719, \"y\": 5.645}, {\"title\": \"Efficient Prompting for LLM-based Generative Internet of Things\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.118, \"y\": 4.355}, {\"title\": \"From Pixels to Prose: A Large Dataset of Dense Image Captions\", \"topic\": \"Multimodal Language Models\", \"x\": 9.127, \"y\": 7.484}, {\"title\": \"VEGA: Learning Interleaved Image-Text Comprehension in Vision-Language  Large Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.317, \"y\": 7.435}, {\"title\": \"Short Film Dataset (SFD): A Benchmark for Story-Level Video  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.857, \"y\": 7.989}, {\"title\": \"Regularizing Hidden States Enables Learning Generalizable Reward Model  for LLMs\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.177, \"y\": 1.415}, {\"title\": \"GenQA: Generating Millions of Instructions from a Handful of Prompts\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.116, \"y\": 2.385}, {\"title\": \"A Fundamental Trade-off in Aligned Language Models and its Relation to  Sampling Adaptors\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.33, \"y\": 1.355}, {\"title\": \"Inclusive ASR for Disfluent Speech: Cascaded Large-Scale Self-Supervised  Learning with Targeted Fine-Tuning and Data Augmentation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.198, \"y\": 5.461}, {\"title\": \"Datasets for Multilingual Answer Sentence Selection\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.52, \"y\": 5.227}, {\"title\": \"Evaluation of Large Language Models: STEM education and Gender  Stereotypes\", \"topic\": \"Bias in Language Models\", \"x\": 3.449, \"y\": 4.334}, {\"title\": \"The Devil is in the Neurons: Interpreting and Mitigating Social Biases  in Pre-trained Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.342, \"y\": 4.278}, {\"title\": \"Exploring the Correlation between Human and Machine Evaluation of  Simultaneous Speech Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.826, \"y\": 4.858}, {\"title\": \"Enhancing Question Answering on Charts Through Effective Pre-training  Tasks\", \"topic\": \"Multimodal Language Models\", \"x\": 7.895, \"y\": 7.845}, {\"title\": \"On the Evaluation of Speech Foundation Models for Spoken Language  Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.658, \"y\": 4.997}, {\"title\": \"Detecting the terminality of speech-turn boundary for spoken  interactions in French TV and Radio content\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.721, \"y\": 5.446}, {\"title\": \"Simul-Whisper: Attention-Guided Streaming Whisper with Truncation  Detection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.123, \"y\": 5.169}, {\"title\": \"GLiNER multi-task: Generalist Lightweight Model for Various Information  Extraction Tasks\", \"topic\": \"Named Entity Recognition\", \"x\": 7.246, \"y\": 6.656}, {\"title\": \"FZI-WIM at SemEval-2024 Task 2: Self-Consistent CoT for Complex NLI in  Biomedical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.742, \"y\": 7.627}, {\"title\": \"Deep Bayesian Active Learning for Preference Modeling in Large Language  Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.335, \"y\": 1.452}, {\"title\": \"Group and Shuffle: Efficient Structured Orthogonal Parametrization\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.075, \"y\": 2.174}, {\"title\": \"Precision Empowers, Excess Distracts: Visual Question Answering With  Dynamically Infused Knowledge In Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.197, \"y\": 8.021}, {\"title\": \"CNVSRC 2023: The First Chinese Continuous Visual Speech Recognition  Challenge\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.945, \"y\": 5.64}, {\"title\": \"HIRO: Hierarchical Information Retrieval Optimization\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.047, \"y\": 4.659}, {\"title\": \"Disentangling Dialect from Social Bias via Multitask Learning to Improve  Fairness\", \"topic\": \"Bias in Language Models\", \"x\": 3.364, \"y\": 4.403}, {\"title\": \"In-depth analysis of recall initiators of medical devices with a Machine  Learning-Natural language Processing workflow\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.669, \"y\": 7.976}, {\"title\": \"A Better LLM Evaluator for Text Generation: The Impact of Prompt Output  Sequencing and Optimization\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 6.99, \"y\": 3.422}, {\"title\": \"ChartMimic: Evaluating LMM's Cross-Modal Reasoning Capability via  Chart-to-Code Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 7.868, \"y\": 7.605}, {\"title\": \"BiVLC: Extending Vision-Language Compositionality Evaluation with  Text-to-Image Retrieval\", \"topic\": \"Multimodal Language Models\", \"x\": 8.751, \"y\": 7.409}, {\"title\": \"An efficient text augmentation approach for contextualized Mandarin  speech recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.101, \"y\": 5.258}, {\"title\": \"Experiments in News Bias Detection with Pre-Trained Neural Transformers\", \"topic\": \"Fake News Detection\", \"x\": 3.941, \"y\": 5.584}, {\"title\": \"CliBench: Multifaceted Evaluation of Large Language Models in Clinical  Decisions on Diagnoses, Procedures, Lab Tests Orders and Prescriptions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.671, \"y\": 8.09}, {\"title\": \"Enhancing Fake News Detection in Social Media via Label Propagation on  Cross-modal Tweet Graph\", \"topic\": \"Fake News Detection\", \"x\": 4.029, \"y\": 5.887}, {\"title\": \"A Unified Data Augmentation Framework for Low-Resource Multi-Domain  Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.671, \"y\": 3.98}, {\"title\": \"LUMA: A Benchmark Dataset for Learning from Uncertain and Multimodal  Data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.065, \"y\": 7.435}, {\"title\": \"Rapport-Driven Virtual Agent: Rapport Building Dialogue Strategy for  Improving User Experience at First Meeting\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.092, \"y\": 3.682}, {\"title\": \"RadEx: A Framework for Structured Information Extraction from Radiology  Reports based on Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.206, \"y\": 8.635}, {\"title\": \"OSPC: Detecting Harmful Memes with Large Language Model as a Catalyst\", \"topic\": \"Hate Speech Detection\", \"x\": 2.902, \"y\": 5.519}, {\"title\": \"Application of Natural Language Processing in Financial Risk Detection\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.98, \"y\": 6.613}, {\"title\": \"Bootstrapping Language Models with DPO Implicit Rewards\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.345, \"y\": 1.296}, {\"title\": \"Self-Knowledge Distillation for Learning Ambiguity\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.508, \"y\": 3.867}, {\"title\": \"UniBridge: A Unified Approach to Cross-Lingual Transfer Learning for  Low-Resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.394, \"y\": 4.778}, {\"title\": \"What is the best model? Application-driven Evaluation for Large Language  Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.283, \"y\": 3.764}, {\"title\": \"Unraveling the Mechanics of Learning-Based Demonstration Selection for  In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.311, \"y\": 3.381}, {\"title\": \"Enhancing Voice Wake-Up for Dysarthria: Mandarin Dysarthria Speech  Corpus Release and Customized System Design\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.243, \"y\": 5.592}, {\"title\": \"Optimizing Byte-level Representation for End-to-end ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.967, \"y\": 5.234}, {\"title\": \"A Survey on Large Language Models from General Purpose to Medical  Applications: Datasets, Methodologies, and Evaluations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.795, \"y\": 8.005}, {\"title\": \"Multimodal Large Language Models with Fusion Low Rank Adaptation for  Device Directed Speech Detection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.626, \"y\": 5.087}, {\"title\": \"Large Language Models as Software Components: A Taxonomy for  LLM-Integrated Applications\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.256, \"y\": 3.982}, {\"title\": \"Speech ReaLLM -- Real-time Streaming Speech Recognition with Multimodal  LLMs by Teaching the Flow of Time\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.013, \"y\": 5.229}, {\"title\": \"A Systematic Review of Generative AI for Teaching and Learning Practice\", \"topic\": \"Bias in Language Models\", \"x\": 4.876, \"y\": 4.541}, {\"title\": \"Talking Heads: Understanding Inter-layer Communication in Transformer  Language Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.421, \"y\": 3.495}, {\"title\": \"MuirBench: A Comprehensive Benchmark for Robust Multi-image  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 7.975, \"y\": 7.579}, {\"title\": \"Visual Sketchpad: Sketching as a Visual Chain of Thought for Multimodal  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.023, \"y\": 7.713}, {\"title\": \"DiscreteSLU: A Large Language Model with Self-Supervised Discrete Speech  Units for Spoken Language Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.632, \"y\": 5.064}, {\"title\": \"ProxyLM: Predicting Language Model Performance on Multilingual Tasks via  Proxy Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.412, \"y\": 4.301}, {\"title\": \"Transformers meet Neural Algorithmic Reasoners\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.239, \"y\": 3.57}, {\"title\": \"AlignMMBench: Evaluating Chinese Multimodal Alignment in Large  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.085, \"y\": 7.665}, {\"title\": \"Exploring Spoken Language Identification Strategies for Automatic  Transcription of Multilingual Broadcast and Institutional Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.671, \"y\": 5.298}, {\"title\": \"On the Effects of Heterogeneous Data Sources on Speech-to-Text  Foundation Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.105, \"y\": 5.266}, {\"title\": \"Unpacking DPO and PPO: Disentangling Best Practices for Learning from  Preference Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.305, \"y\": 1.211}, {\"title\": \"End-to-end Streaming model for Low-Latency Speech Anonymization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.955, \"y\": 5.167}, {\"title\": \"Language Complexity and Speech Recognition Accuracy: Orthographic  Complexity Hurts, Phonological Complexity Doesn't\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.975, \"y\": 5.461}, {\"title\": \"Orthogonality and isotropy of speaker and phonetic information in  self-supervised speech representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.609, \"y\": 5.024}, {\"title\": \"ReMI: A Dataset for Reasoning with Multiple Images\", \"topic\": \"Multimodal Language Models\", \"x\": 8.075, \"y\": 7.567}, {\"title\": \"DefAn: Definitive Answer Dataset for LLMs Hallucination Evaluation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.177, \"y\": 1.056}, {\"title\": \"Diffusion Gaussian Mixture Audio Denoise\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.317, \"y\": 6.054}, {\"title\": \"LASER: Learning by Aligning Self-supervised Representations of Speech  for Improving Content-related Tasks\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.993, \"y\": 4.98}, {\"title\": \"Investigating the translation capabilities of Large Language Models  trained on parallel data only\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.487, \"y\": 4.381}, {\"title\": \"Chain of Preference Optimization: Improving Chain-of-Thought Reasoning  in LLMs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.594, \"y\": 2.157}, {\"title\": \"INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance  in Insurance\", \"topic\": \"Multimodal Language Models\", \"x\": 7.86, \"y\": 7.552}, {\"title\": \"Chain-of-Though (CoT) prompting strategies for medical error detection  and correction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.595, \"y\": 8.148}, {\"title\": \"CUDRT: Benchmarking the Detection of Human vs. Large Language Models  Generated Texts\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.121, \"y\": 4.746}, {\"title\": \"SememeLM: A Sememe Knowledge Enhanced Method for Long-tail Relation  Representation\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.066, \"y\": 6.597}, {\"title\": \"MiLoRA: Harnessing Minor Singular Components for Parameter-Efficient LLM  Finetuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.163, \"y\": 2.066}, {\"title\": \"Multi-Agent Software Development through Cross-Team Collaboration\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.527, \"y\": 2.776}, {\"title\": \"Word Order in English-Japanese Simultaneous Interpretation: Analyses and  Evaluation using Chunk-wise Monotonic Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.798, \"y\": 4.845}, {\"title\": \"Exploring Multilingual Unseen Speaker Emotion Recognition: Leveraging  Co-Attention Cues in Multitask Learning\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.199, \"y\": 7.821}, {\"title\": \"Advanced Multimodal Deep Learning Architecture for Image-Text Matching\", \"topic\": \"Multimodal Language Models\", \"x\": 8.416, \"y\": 6.986}, {\"title\": \"An Initial Investigation of Language Adaptation for TTS Systems under  Low-resource Scenarios\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.606, \"y\": 5.078}, {\"title\": \"Delta-CoMe: Training-Free Delta-Compression with Mixed-Precision for  Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.641, \"y\": 2.198}, {\"title\": \"Plan, Generate and Complicate: Improving Low-resource Dialogue State  Tracking via Easy-to-Difficult Zero-shot Data Augmentation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.582, \"y\": 3.833}, {\"title\": \"An Approach to Build Zero-Shot Slot-Filling System for Industry-Grade  Conversational Assistants\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.787, \"y\": 3.967}, {\"title\": \"ContraSolver: Self-Alignment of Language Models by Resolving Internal  Preference Contradictions\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.325, \"y\": 1.426}, {\"title\": \"Research on Optimization of Natural Language Processing Model Based on  Multimodal Deep Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.359, \"y\": 6.908}, {\"title\": \"DisfluencySpeech -- Single-Speaker Conversational Speech Dataset with  Paralanguage\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.897, \"y\": 5.796}, {\"title\": \"Linguistic Bias in ChatGPT: Language Models Reinforce Dialect  Discrimination\", \"topic\": \"Bias in Language Models\", \"x\": 3.707, \"y\": 4.584}, {\"title\": \"Mixture-of-Skills: Learning to Optimize Data Usage for Fine-Tuning Large  Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.531, \"y\": 2.651}, {\"title\": \"Automatically Labeling $200B Life-Saving Datasets: A Large Clinical  Trial Outcome Benchmark\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.794, \"y\": 7.858}, {\"title\": \"MMFakeBench: A Mixed-Source Multimodal Misinformation Detection  Benchmark for LVLMs\", \"topic\": \"Fake News Detection\", \"x\": 4.219, \"y\": 5.852}, {\"title\": \"Standard Language Ideology in AI-Generated Language\", \"topic\": \"Bias in Language Models\", \"x\": 4.128, \"y\": 4.175}, {\"title\": \"VLind-Bench: Measuring Language Priors in Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.428, \"y\": 7.489}, {\"title\": \"HelpSteer2: Open-source dataset for training top-performing reward  models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.18, \"y\": 1.424}, {\"title\": \"Ad Auctions for LLMs via Retrieval Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.061, \"y\": 4.516}, {\"title\": \"TC-Bench: Benchmarking Temporal Compositionality in Text-to-Video and  Image-to-Video Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.852, \"y\": 7.834}, {\"title\": \"VeraCT Scan: Retrieval-Augmented Fake News Detection with Justifiable  Reasoning\", \"topic\": \"Fake News Detection\", \"x\": 4.089, \"y\": 5.743}, {\"title\": \"ML-SUPERB 2.0: Benchmarking Multilingual Speech Models Across Modeling  Constraints, Languages, and Datasets\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.84, \"y\": 5.087}, {\"title\": \"Updating CLIP to Prefer Descriptions Over Captions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.991, \"y\": 7.346}, {\"title\": \"Pandora: Towards General World Model with Natural Language Actions and  Video States\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.73, \"y\": 2.486}, {\"title\": \"Advancing High Resolution Vision-Language Models in Biomedicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.443, \"y\": 8.296}, {\"title\": \"What If We Recaption Billions of Web Images with LLaMA-3?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.974, \"y\": 7.474}, {\"title\": \"OLMES: A Standard for Language Model Evaluations\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.515, \"y\": 3.778}, {\"title\": \"MMWorld: Towards Multi-discipline Multi-faceted World Model Evaluation  in Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.129, \"y\": 7.598}, {\"title\": \"Understanding Sounds, Missing the Questions: The Challenge of Object  Hallucination in Large Audio-Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.17, \"y\": 1.064}, {\"title\": \"Towards Unsupervised Speech Recognition Without Pronunciation Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.152, \"y\": 5.303}, {\"title\": \"Speech Emotion Recognition with ASR Transcripts: A Comprehensive Study  on Word Error Rate and Fusion Techniques\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.183, \"y\": 7.872}, {\"title\": \"M3T: A New Benchmark Dataset for Multi-Modal Document-Level Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.811, \"y\": 4.674}, {\"title\": \"SumHiS: Extractive Summarization Exploiting Hidden Structure\", \"topic\": \"Text Summarization\", \"x\": 5.681, \"y\": 6.414}, {\"title\": \"Transformer-based Model for ASR N-Best Rescoring and Rewriting\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.199, \"y\": 5.228}, {\"title\": \"A Dialogue Game for Eliciting Balanced Collaboration\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.26, \"y\": 3.061}, {\"title\": \"Underneath the Numbers: Quantitative and Qualitative Gender Fairness in  LLMs for Depression Prediction\", \"topic\": \"Bias in Language Models\", \"x\": 3.466, \"y\": 4.279}, {\"title\": \"Supportiveness-based Knowledge Rewriting for Retrieval-augmented  Language Modeling\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.079, \"y\": 4.596}, {\"title\": \"Multimodal Table Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.001, \"y\": 7.427}, {\"title\": \"Languages Transferred Within the Encoder: On Representation Transfer in  Zero-Shot Multilingual Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.627, \"y\": 4.843}, {\"title\": \"AustroTox: A Dataset for Target-Based Austrian German Offensive Language  Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.735, \"y\": 5.329}, {\"title\": \"A Concept-Based Explainability Framework for Large Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.25, \"y\": 7.122}, {\"title\": \"Adversarial Evasion Attack Efficiency against Large Language Models\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.269, \"y\": 2.936}, {\"title\": \"Improving child speech recognition with augmented child-like speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.202, \"y\": 5.35}, {\"title\": \"Attentive Merging of Hidden Embeddings from Pre-trained Speech Model for  Anti-spoofing Detection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.085, \"y\": 5.288}, {\"title\": \"It Takes Two: On the Seamlessness between Reward and Policy Model in  RLHF\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.132, \"y\": 1.55}, {\"title\": \"Guiding In-Context Learning of LLMs through Quality Estimation for  Machine Translation\", \"topic\": \"In-Context Learning\", \"x\": 8.883, \"y\": 3.649}, {\"title\": \"LibriTTS-P: A Corpus with Speaking Style and Speaker Identity Prompts  for Text-to-Speech and Style Captioning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.346, \"y\": 6.035}, {\"title\": \"Political Leaning Inference through Plurinational Scenarios\", \"topic\": \"Fake News Detection\", \"x\": 3.603, \"y\": 5.509}, {\"title\": \"Automated Information Extraction from Thyroid Operation Narrative: A  Comparative Study of GPT-4 and Fine-tuned KoELECTRA\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.792, \"y\": 7.984}, {\"title\": \"Analyzing Multi-Head Attention on Trojan BERT Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.539, \"y\": 3.406}, {\"title\": \"Exploring Self-Supervised Multi-view Contrastive Learning for Speech  Emotion Recognition with Limited Annotations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.206, \"y\": 7.833}, {\"title\": \"Exploring Speech Foundation Models for Speaker Diarization in  Child-Adult Dyadic Interactions\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.004, \"y\": 5.4}, {\"title\": \"Label-aware Hard Negative Sampling Strategies with Momentum Contrastive  Learning for Implicit Hate Speech Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.637, \"y\": 5.276}, {\"title\": \"Designing a Dashboard for Transparency and Control of Conversational AI\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.909, \"y\": 3.621}, {\"title\": \"BookSQL: A Large Scale Text-to-SQL Dataset for Accounting Domain\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.057, \"y\": 6.768}, {\"title\": \"VALL-E R: Robust and Efficient Zero-Shot Text-to-Speech Synthesis via  Monotonic Alignment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.559, \"y\": 5.583}, {\"title\": \"Dynamic Stochastic Decoding Strategy for Open-Domain Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.499, \"y\": 3.963}, {\"title\": \"Dual-Pipeline with Low-Rank Adaptation for New Language Integration in  Multilingual ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.907, \"y\": 5.151}, {\"title\": \"Labeling Comic Mischief Content in Online Videos with a Multimodal  Hierarchical-Cross-Attention Model\", \"topic\": \"Hate Speech Detection\", \"x\": 3.063, \"y\": 5.806}, {\"title\": \"PRoDeliberation: Parallel Robust Deliberation for End-to-End Spoken  Language Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.003, \"y\": 5.146}, {\"title\": \"Tell Me What's Next: Textual Foresight for Generic UI Representations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.339, \"y\": 7.335}, {\"title\": \"Spoof Diarization: \\\"What Spoofed When\\\" in Partially Spoofed Audio\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.036, \"y\": 5.559}, {\"title\": \"Prompt-Based Length Controlled Generation with Multiple Control Types\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.344, \"y\": 3.458}, {\"title\": \"PolySpeech: Exploring Unified Multitask Speech Models for  Competitiveness with Single-task Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.713, \"y\": 5.395}, {\"title\": \"Making Task-Oriented Dialogue Datasets More Natural by Synthetically  Generating Indirect User Requests\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.476, \"y\": 3.688}, {\"title\": \"A Critical Look At Tokenwise Reward-Guided Text Generation\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.272, \"y\": 1.691}, {\"title\": \"Soft Language Identification for Language-Agnostic Many-to-One  End-to-End Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.508, \"y\": 5.342}, {\"title\": \"LT4SG@SMM4H24: Tweets Classification for Digital Epidemiology of  Childhood Health Outcomes Using Pre-Trained Language Models\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.133, \"y\": 7.033}, {\"title\": \"The MuSe 2024 Multimodal Sentiment Analysis Challenge: Social Perception  and Humor Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.336, \"y\": 7.359}, {\"title\": \"UICoder: Finetuning Large Language Models to Generate User Interface  Code through Automated Feedback\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.335, \"y\": 2.371}, {\"title\": \"REAL Sampling: Boosting Factuality and Diversity of Open-Ended  Generation via Asymptotic Entropy\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.503, \"y\": 1.281}, {\"title\": \"ExHuBERT: Enhancing HuBERT Through Block Extension and Fine-Tuning on 37  Emotion Datasets\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.217, \"y\": 7.82}, {\"title\": \"Automated Question Generation for Science Tests in Arabic Language Using  NLP Techniques\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.169, \"y\": 4.902}, {\"title\": \"Question-Answering (QA) Model for a Personalized Learning Assistant for  Arabic Language\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.196, \"y\": 4.995}, {\"title\": \"Sustainable self-supervised learning for speech representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.845, \"y\": 4.859}, {\"title\": \"Transformer Models in Education: Summarizing Science Textbooks with  AraBART, MT5, AraT5, and mBART\", \"topic\": \"Text Summarization\", \"x\": 5.646, \"y\": 6.357}, {\"title\": \"OPTune: Efficient Online Preference Tuning\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.249, \"y\": 1.362}, {\"title\": \"Situational Awareness Matters in 3D Vision Language Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.605, \"y\": 7.458}, {\"title\": \"Samba: Simple Hybrid State Space Models for Efficient Unlimited Context  Language Modeling\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.706, \"y\": 3.104}, {\"title\": \"THaLLE: Text Hyperlocally Augmented Large Language Extension --  Technical Report\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.901, \"y\": 6.866}, {\"title\": \"Just Because We Camp, Doesn't Mean We Should: The Ethics of Modelling  Queer Voices\", \"topic\": \"Bias in Language Models\", \"x\": 3.351, \"y\": 4.635}, {\"title\": \"Image Textualization: An Automatic Framework for Creating Accurate and  Detailed Image Descriptions\", \"topic\": \"Multimodal Language Models\", \"x\": 9.02, \"y\": 7.322}, {\"title\": \"Advancing Annotation of Stance in Social Media Posts: A Comparative  Analysis of Large Language Models and Crowd Sourcing\", \"topic\": \"Fake News Detection\", \"x\": 3.706, \"y\": 5.78}, {\"title\": \"VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio  Understanding in Video-LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.832, \"y\": 7.903}, {\"title\": \"On the Robustness of Document-Level Relation Extraction Models to Entity  Name Variations\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.894, \"y\": 6.81}, {\"title\": \"Textual Similarity as a Key Metric in Machine Translation Quality  Estimation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.687, \"y\": 4.835}, {\"title\": \"Learning Domain-Invariant Features for Out-of-Context News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.057, \"y\": 5.869}, {\"title\": \"VersiCode: Towards Version-controllable Code Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.436, \"y\": 2.37}, {\"title\": \"BvSP: Broad-view Soft Prompting for Few-Shot Aspect Sentiment Quad  Prediction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.155, \"y\": 6.842}, {\"title\": \"Autograding Mathematical Induction Proofs with Natural Language  Processing\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.122, \"y\": 2.885}, {\"title\": \"GLIMPSE: Pragmatically Informative Multi-Document Summarization for  Scholarly Reviews\", \"topic\": \"Text Summarization\", \"x\": 5.446, \"y\": 6.376}, {\"title\": \"Toxic Memes: A Survey of Computational Perspectives on the Detection and  Explanation of Meme Toxicities\", \"topic\": \"Hate Speech Detection\", \"x\": 2.875, \"y\": 5.043}, {\"title\": \"DR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented  Generation for Question-Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.945, \"y\": 4.714}, {\"title\": \"CTC-based Non-autoregressive Textless Speech-to-Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.517, \"y\": 5.035}, {\"title\": \"3D-Properties: Identifying Challenges in DPO and Charting a Path Forward\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.307, \"y\": 1.159}, {\"title\": \"MM-KWS: Multi-modal Prompts for Multilingual User-defined Keyword  Spotting\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.801, \"y\": 5.16}, {\"title\": \"Instruct Large Language Models to Drive like Humans\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.616, \"y\": 2.664}, {\"title\": \"Can We Achieve High-quality Direct Speech-to-Speech Translation without  Parallel Speech Data?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.503, \"y\": 5.274}, {\"title\": \"Bilingual Sexism Classification: Fine-Tuned XLM-RoBERTa and GPT-3.5  Few-Shot Learning\", \"topic\": \"Hate Speech Detection\", \"x\": 2.958, \"y\": 5.565}, {\"title\": \"MBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in  Generative LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.627, \"y\": 4.274}, {\"title\": \"On the Hallucination in Simultaneous Machine Translation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.19, \"y\": 1.031}, {\"title\": \"Decipherment-Aware Multilingual Learning in Jointly Trained Language  Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.576, \"y\": 4.708}, {\"title\": \"Improving Commonsense Bias Classification by Mitigating the Influence of  Demographic Terms\", \"topic\": \"Bias in Language Models\", \"x\": 3.184, \"y\": 4.786}, {\"title\": \"Improving Autoformalization using Type Checking\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.176, \"y\": 2.785}, {\"title\": \"Towards Human-AI Collaboration in Healthcare: Guided Deferral Systems  with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.45, \"y\": 8.072}, {\"title\": \"EmoBox: Multilingual Multi-corpus Speech Emotion Recognition Toolkit and  Benchmark\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.213, \"y\": 7.862}, {\"title\": \"Scaling Large-Language-Model-based Multi-Agent Collaboration\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.437, \"y\": 2.843}, {\"title\": \"Translating speech with just images\", \"topic\": \"Multimodal Language Models\", \"x\": 8.969, \"y\": 7.005}, {\"title\": \"Tag and correct: high precision post-editing approach to correction of  speech recognition errors\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.14, \"y\": 5.497}, {\"title\": \"Fast Context-Biasing for CTC and Transducer ASR models with CTC-based  Word Spotter\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.425, \"y\": 5.011}, {\"title\": \"DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for  Question Answering over Knowledge Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.722, \"y\": 5.46}, {\"title\": \"HalluDial: A Large-Scale Benchmark for Automatic Dialogue-Level  Hallucination Evaluation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.184, \"y\": 1.116}, {\"title\": \"Reading Miscue Detection in Primary School through Automatic Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.198, \"y\": 5.511}, {\"title\": \"AIM: Let Any Multi-modal Large Language Models Embrace Efficient  In-Context Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.252, \"y\": 7.285}, {\"title\": \"Paying More Attention to Source Context: Mitigating Unfaithful  Translations from Large Language Model\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.568, \"y\": 4.322}, {\"title\": \"Improving Multi-hop Logical Reasoning in Knowledge Graphs with  Context-Aware Query Representation Learning\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.804, \"y\": 5.612}, {\"title\": \"Improving Language Models for Emotion Analysis: Insights from Cognitive  Science\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.518, \"y\": 7.501}, {\"title\": \"MoreauPruner: Robust Pruning of Large Language Models against Weight  Perturbations\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.549, \"y\": 2.491}, {\"title\": \"Bridging Language Gaps in Audio-Text Retrieval\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.564, \"y\": 5.289}, {\"title\": \"A Probabilistic Framework for LLM Hallucination Detection via Belief  Tree Propagation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.234, \"y\": 1.104}, {\"title\": \"A Non-autoregressive Generation Framework for End-to-End Simultaneous  Speech-to-Any Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.451, \"y\": 5.188}, {\"title\": \"Agent-SiMT: Agent-assisted Simultaneous Machine Translation with Large  Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.071, \"y\": 4.604}, {\"title\": \"Silent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded  Dog Whistles\", \"topic\": \"Hate Speech Detection\", \"x\": 2.822, \"y\": 5.32}, {\"title\": \"AGB-DE: A Corpus for the Automated Legal Assessment of Clauses in German  Consumer Contracts\", \"topic\": \"Legal NLP\", \"x\": 5.087, \"y\": 5.787}, {\"title\": \"Raccoon: Prompt Extraction Benchmark of LLM-Integrated Applications\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.384, \"y\": 2.522}, {\"title\": \"Leveraging Large Language Models for Knowledge-free Weak Supervision in  Clinical Natural Language Processing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.941, \"y\": 7.95}, {\"title\": \"Direct Preference Optimization for Suppressing Hallucinated Prior Exams  in Radiology Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.483, \"y\": 1.094}, {\"title\": \"Parallelizing Linear Transformers with the Delta Rule over Sequence  Length\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.773, \"y\": 3.215}, {\"title\": \"Towards a Personal Health Large Language Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.382, \"y\": 7.969}, {\"title\": \"AID: Adapting Image2Video Diffusion Models for Instruction-guided Video  Prediction\", \"topic\": \"Multimodal Language Models\", \"x\": 8.817, \"y\": 7.771}, {\"title\": \"Transforming Wearable Data into Health Insights using Large Language  Model Agents\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.291, \"y\": 7.866}, {\"title\": \"Evaluating the Retrieval Component in LLM-Based Question Answering  Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.808, \"y\": 4.556}, {\"title\": \"A Large Language Model Pipeline for Breast Cancer Oncology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.85, \"y\": 7.95}, {\"title\": \"Multimodal Contextualized Semantic Parsing from Speech\", \"topic\": \"Multimodal Language Models\", \"x\": 8.246, \"y\": 7.466}, {\"title\": \"Enrolment-based personalisation for improving individual-level fairness  in speech emotion recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.168, \"y\": 7.84}, {\"title\": \"Controlling Emotion in Text-to-Speech with Natural Language Prompts\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.324, \"y\": 7.759}, {\"title\": \"Meta Learning Text-to-Speech Synthesis in over 7000 Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.507, \"y\": 5.588}, {\"title\": \"INTERSPEECH 2009 Emotion Challenge Revisited: Benchmarking 15 Years of  Progress in Speech Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.16, \"y\": 7.857}, {\"title\": \"Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt  LLMs for Dialogue\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 5.897, \"y\": 3.698}, {\"title\": \"STimage-1K4M: A histopathology image-gene expression dataset for spatial  transcriptomics\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.257, \"y\": 8.389}, {\"title\": \"Low-Rank Quantization-Aware Training for LLMs\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.64, \"y\": 2.153}, {\"title\": \"Diffusion-RPO: Aligning Diffusion Models through Relative Preference  Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.431, \"y\": 1.207}, {\"title\": \"mHuBERT-147: A Compact Multilingual HuBERT Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.311, \"y\": 5.027}, {\"title\": \"Symmetric Dot-Product Attention for Efficient Training of BERT Language  Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.835, \"y\": 3.251}, {\"title\": \"MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific  Workflows\", \"topic\": \"Text Summarization\", \"x\": 5.639, \"y\": 6.311}, {\"title\": \"Sustained Vowels for Pre- vs Post-Treatment COPD Classification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.07, \"y\": 5.512}, {\"title\": \"MedExQA: Medical Question Answering Benchmark with Multiple Explanations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.803, \"y\": 7.893}, {\"title\": \"A Parameter-efficient Language Extension Framework for Multilingual ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.795, \"y\": 4.895}, {\"title\": \"Tx-LLM: A Large Language Model for Therapeutics\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.085, \"y\": 7.9}, {\"title\": \"Multi-Prompting Decoder Helps Better Language Understanding\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.917, \"y\": 3.398}, {\"title\": \"LINGOLY: A Benchmark of Olympiad-Level Linguistic Reasoning Puzzles in  Low-Resource and Extinct Languages\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.647, \"y\": 3.412}, {\"title\": \"Thunder : Unified Regression-Diffusion Speech Enhancement with a Single  Reverse Step using Brownian Bridge\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.699, \"y\": 5.799}, {\"title\": \"Building Bridges: A Dataset for Evaluating Gender-Fair Machine  Translation into German\", \"topic\": \"Bias in Language Models\", \"x\": 3.013, \"y\": 4.399}, {\"title\": \"Comparing Data Augmentation Methods for End-to-End Task-Oriented Dialog  Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.457, \"y\": 3.742}, {\"title\": \"StreamAtt: Direct Streaming Speech-to-Text Translation with  Attention-based Audio History Selection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.522, \"y\": 5.182}, {\"title\": \"The Impact of Quantization on Retrieval-Augmented Generation: An  Analysis of Small LLMs\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.616, \"y\": 2.211}, {\"title\": \"Efficient k-Nearest-Neighbor Machine Translation with Dynamic Retrieval\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.941, \"y\": 4.308}, {\"title\": \"Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of  Health for Clinical Text\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.35, \"y\": 7.912}, {\"title\": \"HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question  Answering using LLMs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.686, \"y\": 5.432}, {\"title\": \"CARES: A Comprehensive Benchmark of Trustworthiness in Medical Vision  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.318, \"y\": 8.157}, {\"title\": \"FLEUR: An Explainable Reference-Free Evaluation Metric for Image  Captioning Using a Large Multimodal Model\", \"topic\": \"Multimodal Language Models\", \"x\": 9.058, \"y\": 7.42}, {\"title\": \"A Dual-View Approach to Classifying Radiology Reports by Co-Training\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.23, \"y\": 8.586}, {\"title\": \"ShiftAddLLM: Accelerating Pretrained LLMs via Post-Training  Multiplication-Less Reparameterization\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.7, \"y\": 2.267}, {\"title\": \"Prompting Large Language Models with Audio for General-Purpose Speech  Summarization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.468, \"y\": 5.412}, {\"title\": \"CVQA: Culturally-diverse Multilingual Visual Question Answering  Benchmark\", \"topic\": \"Multimodal Language Models\", \"x\": 8.123, \"y\": 8.005}, {\"title\": \"Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated  Parameters\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.437, \"y\": 2.451}, {\"title\": \"Hello Again! LLM-powered Personalized Agent for Long-term Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.208, \"y\": 3.35}, {\"title\": \"Why Don't Prompt-Based Fairness Metrics Correlate?\", \"topic\": \"Bias in Language Models\", \"x\": 3.43, \"y\": 4.302}, {\"title\": \"TTM-RE: Memory-Augmented Document-Level Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.902, \"y\": 6.891}, {\"title\": \"Whose Preferences? Differences in Fairness Preferences and Their Impact  on the Fairness of AI Utilizing Human Feedback\", \"topic\": \"Bias in Language Models\", \"x\": 3.627, \"y\": 4.31}, {\"title\": \"Feriji: A French-Zarma Parallel Corpus, Glossary & Translator\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.514, \"y\": 5.132}, {\"title\": \"Zero-Shot End-To-End Spoken Question Answering In Medical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.051, \"y\": 7.504}, {\"title\": \"II-Bench: An Image Implication Understanding Benchmark for Multimodal  Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.107, \"y\": 7.629}, {\"title\": \"MedREQAL: Examining Medical Knowledge Recall of Large Language Models  via Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.785, \"y\": 7.657}, {\"title\": \"Unified Text-to-Image Generation and Retrieval\", \"topic\": \"Multimodal Language Models\", \"x\": 8.35, \"y\": 7.124}, {\"title\": \"Do Prompts Really Prompt? Exploring the Prompt Understanding Capability  of Whisper\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.191, \"y\": 3.237}, {\"title\": \"RE-RAG: Improving Open-Domain QA Performance and Interpretability with  Relevance Estimator in Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.937, \"y\": 4.899}, {\"title\": \"Gentle-CLIP: Exploring Aligned Semantic In Low-Quality Multimodal Data  With Soft Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.448, \"y\": 7.03}, {\"title\": \"EmbSpatial-Bench: Benchmarking Spatial Understanding for Embodied Tasks  with Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.391, \"y\": 7.586}, {\"title\": \"QGEval: A Benchmark for Question Generation Evaluation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.231, \"y\": 4.967}, {\"title\": \"SinkLoRA: Enhanced Efficiency and Chat Capabilities for Long-Context  Large Language Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.558, \"y\": 2.992}, {\"title\": \"Flow of Reasoning: Efficient Training of LLM Policy with Divergent  Thinking\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.424, \"y\": 2.601}, {\"title\": \"MS-HuBERT: Mitigating Pre-training and Inference Mismatch in Masked  Language Modelling methods for learning Speech Representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.82, \"y\": 4.82}, {\"title\": \"DomainRAG: A Chinese Benchmark for Evaluating Domain-specific  Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.95, \"y\": 4.618}, {\"title\": \"How Alignment and Jailbreak Work: Explain LLM Safety through  Intermediate Hidden States\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.322, \"y\": 2.26}, {\"title\": \"ATLAS: Improving Lay Summarisation with Attribute-based Control\", \"topic\": \"Text Summarization\", \"x\": 5.619, \"y\": 6.541}, {\"title\": \"Video-Language Understanding: A Survey from Model Architecture, Model  Training, and Data Perspectives\", \"topic\": \"Multimodal Language Models\", \"x\": 8.769, \"y\": 7.898}, {\"title\": \"Can Prompt Modifiers Control Bias? A Comparative Analysis of  Text-to-Image Generative Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.399, \"y\": 4.522}, {\"title\": \"Automata Extraction from Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.128, \"y\": 3.65}, {\"title\": \"Autoregressive Diffusion Transformer for Text-to-Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.421, \"y\": 5.988}, {\"title\": \"Exploring the Benefits of Tokenization of Discrete Acoustic Units\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.576, \"y\": 5.168}, {\"title\": \"Online DPO: Online Direct Preference Optimization with Fast-Slow Chasing\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.328, \"y\": 1.258}, {\"title\": \"Generalist Multimodal AI: A Review of Architectures, Challenges and  Opportunities\", \"topic\": \"Multimodal Language Models\", \"x\": 8.054, \"y\": 7.346}, {\"title\": \"Investigating and Addressing Hallucinations of LLMs in Tasks Involving  Negation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.189, \"y\": 1.166}, {\"title\": \"MLLM-SR: Conversational Symbolic Regression base Multi-Modal Large  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.107, \"y\": 7.127}, {\"title\": \"VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text  to Speech Synthesizers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.529, \"y\": 5.546}, {\"title\": \"Write Summary Step-by-Step: A Pilot Study of Stepwise Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.566, \"y\": 6.187}, {\"title\": \"Flexible and Adaptable Summarization via Expertise Separation\", \"topic\": \"Text Summarization\", \"x\": 5.566, \"y\": 6.387}, {\"title\": \"MemeGuard: An LLM and VLM-based Framework for Advancing Content  Moderation via Meme Intervention\", \"topic\": \"Hate Speech Detection\", \"x\": 2.984, \"y\": 5.618}, {\"title\": \"Teaching-Assistant-in-the-Loop: Improving Knowledge Distillation from  Imperfect Teacher Models in Low-Budget Scenarios\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.382, \"y\": 3.7}, {\"title\": \"LoCoCo: Dropping In Convolutions for Long Context Compression\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.587, \"y\": 2.859}, {\"title\": \"DeviceBERT: Applied Transfer Learning With Targeted Annotations and  Vocabulary Enrichment to Identify Medical Device and Component Terminology in  FDA Recall Summaries\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.304, \"y\": 7.398}, {\"title\": \"SuperPos-Prompt: Enhancing Soft Prompt Tuning of Language Models with  Superposition of Multi Token Embeddings\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.733, \"y\": 3.379}, {\"title\": \"Generative Explore-Exploit: Training-free Optimization of Generative  Recommender Systems using LLM Optimizers\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.925, \"y\": 2.889}, {\"title\": \"Improving Logits-based Detector without Logits from Black-box LLMs\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.081, \"y\": 4.668}, {\"title\": \"CPLIP: Zero-Shot Learning for Histopathology with Comprehensive  Vision-Language Alignment\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.606, \"y\": 8.32}, {\"title\": \"LLMs Are Not Intelligent Thinkers: Introducing Mathematical Topic Tree  Benchmark for Comprehensive Evaluation of LLMs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.663, \"y\": 3.088}, {\"title\": \"Evaluating the Effectiveness of Data Augmentation for Emotion  Classification in Low-Resource Settings\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.293, \"y\": 7.669}, {\"title\": \"3D-GRAND: A Million-Scale Dataset for 3D-LLMs with Better Grounding and  Less Hallucination\", \"topic\": \"Multimodal Language Models\", \"x\": 8.787, \"y\": 7.209}, {\"title\": \"An Empirical Study on Parameter-Efficient Fine-Tuning for MultiModal  Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.895, \"y\": 2.394}, {\"title\": \"Multi-Head RAG: Solving Multi-Aspect Problems with LLMs\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.004, \"y\": 4.616}, {\"title\": \"On Ambiguity and the Expressive Function of Law: The Role of Pragmatics  in Smart Legal Ecosystems\", \"topic\": \"Legal NLP\", \"x\": 5.118, \"y\": 5.538}, {\"title\": \"SUMIE: A Synthetic Benchmark for Incremental Entity Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.607, \"y\": 6.177}, {\"title\": \"Are Large Language Models More Empathetic than Humans?\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.633, \"y\": 7.753}, {\"title\": \"Bootstrapping Referring Multi-Object Tracking\", \"topic\": \"Multimodal Language Models\", \"x\": 8.134, \"y\": 6.815}, {\"title\": \"Scenarios and Approaches for Situated Natural Language Explanations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.979, \"y\": 3.66}, {\"title\": \"Adversarial Tuning: Defending Against Jailbreak Attacks for LLMs\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.352, \"y\": 2.586}, {\"title\": \"LinkQ: An LLM-Assisted Visual Interface for Knowledge Graph  Question-Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.817, \"y\": 5.506}, {\"title\": \"MEFT: Memory-Efficient Fine-Tuning through Sparse Adapter\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.059, \"y\": 2.332}, {\"title\": \"TCMD: A Traditional Chinese Medicine QA Dataset for Evaluating Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.785, \"y\": 7.878}, {\"title\": \"LLM-based speaker diarization correction: A generalizable approach\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.025, \"y\": 5.385}, {\"title\": \"Through the Thicket: A Study of Number-Oriented LLMs derived from Random  Forest Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.28, \"y\": 2.767}, {\"title\": \"XTTS: a Massively Multilingual Zero-Shot Text-to-Speech Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.496, \"y\": 5.555}, {\"title\": \"Sexism Detection on a Data Diet\", \"topic\": \"Hate Speech Detection\", \"x\": 2.94, \"y\": 5.259}, {\"title\": \"Seeing the Unseen: Visual Metaphor Captioning for Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.71, \"y\": 7.536}, {\"title\": \"A Deep Dive into the Trade-Offs of Parameter-Efficient Preference  Alignment Techniques\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.404, \"y\": 1.342}, {\"title\": \"HateDebias: On the Diversity and Variability of Hate Speech Debiasing\", \"topic\": \"Hate Speech Detection\", \"x\": 2.728, \"y\": 5.35}, {\"title\": \"ComplexTempQA: A Large-Scale Dataset for Complex Temporal Question  Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.45, \"y\": 5.331}, {\"title\": \"Digital assistant in a point of sales\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.112, \"y\": 3.929}, {\"title\": \"BERTs are Generative In-Context Learners\", \"topic\": \"In-Context Learning\", \"x\": 8.668, \"y\": 3.471}, {\"title\": \"SelfGoal: Your Language Agents Already Know How to Achieve High-level  Goals\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.871, \"y\": 2.378}, {\"title\": \"Think out Loud: Emotion Deducing Explanation in Dialogues\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.427, \"y\": 7.682}, {\"title\": \"CRAG -- Comprehensive RAG Benchmark\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.766, \"y\": 4.87}, {\"title\": \"LoRA-Whisper: Parameter-Efficient and Extensible Multilingual ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.025, \"y\": 5.182}, {\"title\": \"AICoderEval: Improving AI Domain Code Generation of Large Language  Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.439, \"y\": 2.423}, {\"title\": \"Transforming Dental Diagnostics with Artificial Intelligence: Advanced  Integration of ChatGPT and Large Language Models for Patient Care\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.578, \"y\": 8.158}, {\"title\": \"More Victories, Less Cooperation: Assessing Cicero's Diplomacy Play\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.251, \"y\": 3.001}, {\"title\": \"Low-Resource Cross-Lingual Summarization through Few-Shot Learning with  Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.312, \"y\": 4.652}, {\"title\": \"Key-Element-Informed sLLM Tuning for Document Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.58, \"y\": 6.266}, {\"title\": \"What do MLLMs hear? Examining reasoning with text and sound components  in Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.094, \"y\": 7.493}, {\"title\": \"LawGPT: A Chinese Legal Knowledge-Enhanced Large Language Model\", \"topic\": \"Legal NLP\", \"x\": 5.283, \"y\": 5.548}, {\"title\": \"Pitch-Aware RNN-T for Mandarin Chinese Mispronunciation Detection and  Diagnosis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.903, \"y\": 5.523}, {\"title\": \"Creating an AI Observer: Generative Semantic Workspaces\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.595, \"y\": 2.972}, {\"title\": \"Label-Synchronous Neural Transducer for E2E Simultaneous Speech  Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.502, \"y\": 5.257}, {\"title\": \"llmNER: (Zero|Few)-Shot Named Entity Recognition, Exploiting the Power  of Large Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 7.39, \"y\": 6.719}, {\"title\": \"NATURAL PLAN: Benchmarking LLMs on Natural Language Planning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.967, \"y\": 2.721}, {\"title\": \"To Distill or Not to Distill? On the Robustness of Robust Knowledge  Distillation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.879, \"y\": 4.781}, {\"title\": \"Reinterpreting 'the Company a Word Keeps': Towards Explainable and  Ontologically Grounded Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.021, \"y\": 3.671}, {\"title\": \"Small-E: Small Language Model with Linear Attention for Efficient Speech  Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.551, \"y\": 5.506}, {\"title\": \"MAIRA-2: Grounded Radiology Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.217, \"y\": 8.626}, {\"title\": \"LipGER: Visually-Conditioned Generative Error Correction for Robust  Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.101, \"y\": 5.344}, {\"title\": \"The Prompt Report: A Systematic Survey of Prompting Techniques\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.093, \"y\": 3.31}, {\"title\": \"Aligning Large Language Models with Self-generated Preference Data\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.358, \"y\": 1.401}, {\"title\": \"VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval\", \"topic\": \"Multimodal Language Models\", \"x\": 8.367, \"y\": 7.123}, {\"title\": \"Self-Play with Adversarial Critic: Provable and Scalable Offline  Alignment for Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.285, \"y\": 1.395}, {\"title\": \"Buffer of Thoughts: Thought-Augmented Reasoning with Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.451, \"y\": 2.551}, {\"title\": \"Transformers need glasses! Information over-squashing in language tasks\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.323, \"y\": 3.576}, {\"title\": \"MLVU: A Comprehensive Benchmark for Multi-Task Long Video Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.743, \"y\": 7.903}, {\"title\": \"Hypernetworks for Personalizing ASR to Atypical Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.189, \"y\": 5.224}, {\"title\": \"FairytaleQA Translated: Enabling Educational Question and Answer  Generation in Less-Resourced Languages\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.276, \"y\": 5.01}, {\"title\": \"The CLRS-Text Algorithmic Reasoning Language Benchmark\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.744, \"y\": 2.828}, {\"title\": \"BEADs: Bias Evaluation Across Domains\", \"topic\": \"Bias in Language Models\", \"x\": 3.371, \"y\": 4.357}, {\"title\": \"What Do Language Models Learn in Context? The Structured Task Hypothesis\", \"topic\": \"In-Context Learning\", \"x\": 8.385, \"y\": 3.432}, {\"title\": \"Legal Documents Drafting with Fine-Tuned Pre-Trained Large Language  Model\", \"topic\": \"Legal NLP\", \"x\": 5.231, \"y\": 5.618}, {\"title\": \"Confabulation: The Surprising Value of Large Language Model  Hallucinations\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.145, \"y\": 1.141}, {\"title\": \"Prototypical Reward Network for Data-Efficient RLHF\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.21, \"y\": 1.536}, {\"title\": \"AgentGym: Evolving Large Language Model-based Agents across Diverse  Environments\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.792, \"y\": 2.557}, {\"title\": \"Towards Understanding Task-agnostic Debiasing Through the Lenses of  Intrinsic Bias and Forgetfulness\", \"topic\": \"Bias in Language Models\", \"x\": 3.345, \"y\": 4.207}, {\"title\": \"Legal Judgment Reimagined: PredEx and the Rise of Intelligent AI  Interpretation in Indian Courts\", \"topic\": \"Legal NLP\", \"x\": 5.09, \"y\": 5.706}, {\"title\": \"Explainability and Hate Speech: Structured Explanations Make Social  Media Moderators Faster\", \"topic\": \"Hate Speech Detection\", \"x\": 2.896, \"y\": 5.17}, {\"title\": \"A Human-in-the-Loop Approach to Improving Cross-Text Prosody Transfer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.612, \"y\": 5.598}, {\"title\": \"Ask LLMs Directly, \\\"What shapes your bias?\\\": Measuring Social Bias in  Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.506, \"y\": 4.369}, {\"title\": \"On The Persona-based Summarization of Domain-Specific Documents\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.599, \"y\": 7.294}, {\"title\": \"A + B: A General Generator-Reader Framework for Optimizing LLMs to  Unleash Synergy Potential\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.048, \"y\": 4.578}, {\"title\": \"Tox-BART: Leveraging Toxicity Attributes for Explanation Generation of  Implicit Hate Speech\", \"topic\": \"Hate Speech Detection\", \"x\": 2.83, \"y\": 4.999}, {\"title\": \"UltraMedical: Building Specialized Generalists in Biomedicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.862, \"y\": 8.04}, {\"title\": \"HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew\", \"topic\": \"Text Summarization\", \"x\": 5.556, \"y\": 6.038}, {\"title\": \"How Good is Zero-Shot MT Evaluation for Low Resource Indian Languages?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.624, \"y\": 4.83}, {\"title\": \"Spontaneous Speech-Based Suicide Risk Detection Using Whisper and Large  Language Models\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.332, \"y\": 7.501}, {\"title\": \"Evaluating the IWSLT2023 Speech Translation Tasks: Human Annotations,  Automatic Metrics, and Segmentation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.981, \"y\": 4.973}, {\"title\": \"BLSP-Emo: Towards Empathetic Large Speech-Language Models\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.371, \"y\": 7.871}, {\"title\": \"Recovering document annotations for sentence-level bitext\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.781, \"y\": 4.436}, {\"title\": \"MuJo: Multimodal Joint Feature Space Learning for Human Activity  Recognition\", \"topic\": \"Multimodal Language Models\", \"x\": 8.21, \"y\": 7.145}, {\"title\": \"Performance of large language models in numerical vs. semantic medical  knowledge: Benchmarking on evidence-based Q&As\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.749, \"y\": 7.924}, {\"title\": \"Lean Workbook: A large-scale Lean problem set formalized from natural  language math problems\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.055, \"y\": 2.88}, {\"title\": \"Are Large Language Models the New Interface for Data Pipelines?\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.488, \"y\": 4.081}, {\"title\": \"Chaos with Keywords: Exposing Large Language Models Sycophancy to  Misleading Keywords and Evaluating Defense Strategies\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.158, \"y\": 1.261}, {\"title\": \"Improving Zero-Shot Chinese-English Code-Switching ASR with kNN-CTC and  Gated Monolingual Datastores\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.688, \"y\": 5.343}, {\"title\": \"Light-PEFT: Lightening Parameter-Efficient Fine-Tuning via Early Pruning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.012, \"y\": 2.361}, {\"title\": \"End-to-End Trainable Soft Retriever for Low-resource Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.872, \"y\": 6.824}, {\"title\": \"A Survey on Medical Large Language Models: Technology, Application,  Trustworthiness, and Future Directions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.595, \"y\": 7.907}, {\"title\": \"Improving Audio Codec-based Zero-Shot Text-to-Speech Synthesis with  Multi-Modal Context and Large Language Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.562, \"y\": 5.751}, {\"title\": \"Synthesizing Conversations from Unlabeled Documents using Automatic  Response Segmentation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.55, \"y\": 4.152}, {\"title\": \"M-QALM: A Benchmark to Assess Clinical Reading Comprehension and  Knowledge Recall in Large Language Models via Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.851, \"y\": 7.86}, {\"title\": \"VHDL-Eval: A Framework for Evaluating Large Language Models in VHDL Code  Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.443, \"y\": 2.473}, {\"title\": \"Is Free Self-Alignment Possible?\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.458, \"y\": 1.422}, {\"title\": \"Advancing Anomaly Detection: Non-Semantic Financial Data Encoding with  LLMs\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.872, \"y\": 6.829}, {\"title\": \"Knowledge-Infused Legal Wisdom: Navigating LLM Consultation through the  Lens of Diagnostics and Positive-Unlabeled Reinforcement Learning\", \"topic\": \"Legal NLP\", \"x\": 5.244, \"y\": 5.426}, {\"title\": \"Measuring Retrieval Complexity in Question Answering Systems\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.637, \"y\": 4.972}, {\"title\": \"Wings: Learning Multimodal LLMs without Text-only Forgetting\", \"topic\": \"Multimodal Language Models\", \"x\": 8.357, \"y\": 7.264}, {\"title\": \"Analyzing LLM Behavior in Dialogue Summarization: Unveiling  Circumstantial Hallucination Trends\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.163, \"y\": 1.193}, {\"title\": \"QJL: 1-Bit Quantized JL Transform for KV Cache Quantization with Zero  Overhead\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.771, \"y\": 2.306}, {\"title\": \"MODABS: Multi-Objective Learning for Dynamic Aspect-Based Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.396, \"y\": 6.394}, {\"title\": \"Exploring Multilingual Large Language Models for Enhanced TNM  classification of Radiology Report in lung cancer staging\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.042, \"y\": 8.385}, {\"title\": \"Are LLMs classical or nonmonotonic reasoners? Lessons from generics\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.536, \"y\": 3.195}, {\"title\": \"IrokoBench: A New Benchmark for African Languages in the Age of Large  Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.066, \"y\": 4.956}, {\"title\": \"Error-preserving Automatic Speech Recognition of Young English Learners'  Language\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.15, \"y\": 5.375}, {\"title\": \"Assessing the Emergent Symbolic Reasoning Abilities of Llama Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.737, \"y\": 3.065}, {\"title\": \"Towards Detecting LLMs Hallucination via Markov Chain-based Multi-agent  Debate Framework\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.227, \"y\": 1.179}, {\"title\": \"RadBARTsum: Domain Specific Adaption of Denoising Sequence-to-Sequence  Models for Abstractive Radiology Report Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.164, \"y\": 8.578}, {\"title\": \"StreamSpeech: Simultaneous Speech-to-Speech Translation with Multi-task  Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.444, \"y\": 5.255}, {\"title\": \"Bi-Chainer: Automated Large Language Models Reasoning with Bidirectional  Chaining\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.64, \"y\": 2.645}, {\"title\": \"BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.456, \"y\": 2.536}, {\"title\": \"Adversarial Moment-Matching Distillation of Large Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.529, \"y\": 3.783}, {\"title\": \"4D ASR: Joint Beam Search Integrating CTC, Attention, Transducer, and  Mask Predict Decoders\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.132, \"y\": 5.103}, {\"title\": \"The Task-oriented Queries Benchmark (ToQB)\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.594, \"y\": 3.802}, {\"title\": \"Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.15, \"y\": 5.442}, {\"title\": \"Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large  Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.571, \"y\": 2.468}, {\"title\": \"Text Injection for Neural Contextual Biasing\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.271, \"y\": 5.169}, {\"title\": \"MultifacetEval: Multifaceted Evaluation to Probe LLMs in Mastering  Medical Knowledge\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.913, \"y\": 7.871}, {\"title\": \"Improving In-Context Learning with Prediction Feedback for Sentiment  Analysis\", \"topic\": \"In-Context Learning\", \"x\": 8.144, \"y\": 3.438}, {\"title\": \"S$^2$GSL: Incorporating Segment to Syntactic Enhanced Graph Structure  Learning for Aspect-based Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.069, \"y\": 6.867}, {\"title\": \"Scaling Laws for Reward Model Overoptimization in Direct Alignment  Algorithms\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.157, \"y\": 1.444}, {\"title\": \"HYDRA: Model Factorization Framework for Black-Box LLM Personalization\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.101, \"y\": 3.059}, {\"title\": \"PLaD: Preference-based Large Language Model Distillation with  Pseudo-Preference Pairs\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.479, \"y\": 3.767}, {\"title\": \"Evaluating the Efficacy of Large Language Models in Detecting Fake News:  A Comparative Analysis\", \"topic\": \"Fake News Detection\", \"x\": 4.053, \"y\": 5.625}, {\"title\": \"LCS: A Language Converter Strategy for Zero-Shot Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.761, \"y\": 4.532}, {\"title\": \"NUMCoT: Numerals and Units of Measurement in Chain-of-Thought Reasoning  using Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.147, \"y\": 2.939}, {\"title\": \"Item-Language Model for Conversational Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.878, \"y\": 2.934}, {\"title\": \"Too Big to Fail: Larger Language Models are Disproportionately Resilient  to Induction of Dementia-Related Linguistic Anomalies\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.29, \"y\": 3.455}, {\"title\": \"Exploring Robustness in Doctor-Patient Conversation Summarization: An  Analysis of Out-of-Domain SOAP Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.595, \"y\": 7.946}, {\"title\": \"Language Models can Infer Action Semantics for Classical Planners from  Environment Feedback\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.884, \"y\": 2.549}, {\"title\": \"Disentangling Logic: The Role of Context in Large Language Model  Reasoning Capabilities\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.765, \"y\": 3.242}, {\"title\": \"Aligning Large Language Models via Fine-grained Supervision\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.374, \"y\": 1.472}, {\"title\": \"RATT: A Thought Structure for Coherent and Correct LLM Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.506, \"y\": 2.533}, {\"title\": \"Textless Acoustic Model with Self-Supervised Distillation for  Noise-Robust Expressive Speech-to-Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.518, \"y\": 5.578}, {\"title\": \"Parrot: Multilingual Visual Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.376, \"y\": 7.383}, {\"title\": \"TopViewRS: Vision-Language Models as Top-View Spatial Reasoners\", \"topic\": \"Multimodal Language Models\", \"x\": 8.346, \"y\": 7.552}, {\"title\": \"Block Transformer: Global-to-Local Language Modeling for Fast Inference\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.781, \"y\": 3.19}, {\"title\": \"Deterministic Reversible Data Augmentation for Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.734, \"y\": 4.677}, {\"title\": \"Language-Universal Speech Attributes Modeling for Zero-Shot Multilingual  Spoken Keyword Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.904, \"y\": 5.307}, {\"title\": \"Landscape-Aware Growing: The Power of a Little LAG\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.517, \"y\": 3.142}, {\"title\": \"Set-Based Prompting: Provably Solving the Language Model Order  Dependency Problem\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.232, \"y\": 3.162}, {\"title\": \"Multiple Choice Questions and Large Languages Models: A Case Study with  Fictional Medical Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.762, \"y\": 7.856}, {\"title\": \"XRec: Large Language Models for Explainable Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.946, \"y\": 2.942}, {\"title\": \"Large Language Models Make Sample-Efficient Recommender Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.009, \"y\": 2.866}, {\"title\": \"LlamaCare: A Large Medical Language Model for Enhancing Healthcare  Knowledge Sharing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.851, \"y\": 8.033}, {\"title\": \"Linguistic Fingerprint in Transformer Models: How Language Variation  Influences Parameter Selection in Irony Detection\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.504, \"y\": 6.696}, {\"title\": \"Break the Chain: Large Language Models Can be Shortcut Reasoners\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.678, \"y\": 2.307}, {\"title\": \"Translation Deserves Better: Analyzing Translation Artifacts in  Cross-lingual Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.269, \"y\": 7.954}, {\"title\": \"Technical Language Processing for Telecommunications Specifications\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.379, \"y\": 4.061}, {\"title\": \"From Redundancy to Relevance: Enhancing Explainability in Multimodal  Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.318, \"y\": 7.474}, {\"title\": \"SMS Spam Detection and Classification to Combat Abuse in Telephone  Networks Using Natural Language Processing\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.137, \"y\": 4.962}, {\"title\": \"Enhancing Retrieval-Augmented LMs with a Two-stage Consistency Learning  Compressor\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.95, \"y\": 4.632}, {\"title\": \"Understanding Retrieval Robustness for Retrieval-Augmented Image  Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.907, \"y\": 7.378}, {\"title\": \"Modeling Emotional Trajectories in Written Stories Utilizing  Transformers and Weakly-Supervised Learning\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.528, \"y\": 7.515}, {\"title\": \"Why Only Text: Empowering Vision-and-Language Navigation with  Multi-modal Prompts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.437, \"y\": 7.348}, {\"title\": \"A multilingual dataset for offensive language and hate speech detection  for hausa, yoruba and igbo languages\", \"topic\": \"Hate Speech Detection\", \"x\": 2.811, \"y\": 5.363}, {\"title\": \"Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition  via Weakly Phonetic Supervision\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.831, \"y\": 5.306}, {\"title\": \"The current status of large language models in summarizing radiology  report impressions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.029, \"y\": 8.476}, {\"title\": \"SimulTron: On-Device Simultaneous Speech to Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.491, \"y\": 5.273}, {\"title\": \"Iteration Head: A Mechanistic Study of Chain-of-Thought\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.797, \"y\": 2.248}, {\"title\": \"UniOQA: A Unified Framework for Knowledge Graph Question Answering with  Large Language Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.721, \"y\": 5.417}, {\"title\": \"MARS: Benchmarking the Metaphysical Reasoning Abilities of Language  Models with a Multi-task Evaluation Dataset\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.477, \"y\": 3.035}, {\"title\": \"Exploring Mathematical Extrapolation of Large Language Models with  Synthetic Data\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.173, \"y\": 2.805}, {\"title\": \"Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown  in State-Of-the-Art Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.556, \"y\": 3.184}, {\"title\": \"Analyzing Social Biases in Japanese Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.66, \"y\": 4.2}, {\"title\": \"QROA: A Black-Box Query-Response Optimization Attack on LLMs\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.362, \"y\": 2.439}, {\"title\": \"Multimodal Reasoning with Multimodal Knowledge Graph\", \"topic\": \"Multimodal Language Models\", \"x\": 8.046, \"y\": 7.462}, {\"title\": \"Phonetic Enhanced Language Modeling for Text-to-Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.702, \"y\": 5.653}, {\"title\": \"Efficiently Train ASR Models that Memorize Less and Perform Better with  Per-core Clipping\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.307, \"y\": 5.064}, {\"title\": \"Personalized Topic Selection Model for Topic-Grounded Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.297, \"y\": 3.862}, {\"title\": \"OccamLLM: Fast and Exact Language Model Arithmetic in a Single Step\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.55, \"y\": 2.793}, {\"title\": \"Process-Driven Autoformalization in Lean 4\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.164, \"y\": 2.814}, {\"title\": \"OTTAWA: Optimal TransporT Adaptive Word Aligner for Hallucination and  Omission Translation Errors Detection\", \"topic\": \"Hallucination in Language Models\", \"x\": 9.567, \"y\": 4.883}, {\"title\": \"HPE-CogVLM: New Head Pose Grounding Task Exploration on Vision Language  Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.728, \"y\": 7.392}, {\"title\": \"Explicitly Encoding Structural Symmetry is Key to Length Generalization  in Arithmetic Tasks\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.542, \"y\": 3.568}, {\"title\": \"CR-UTP: Certified Robustness against Universal Text Perturbations on  Large Language Models\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.266, \"y\": 2.963}, {\"title\": \"OLoRA: Orthonormal Low-Rank Adaptation of Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.25, \"y\": 2.127}, {\"title\": \"LLMs Beyond English: Scaling the Multilingual Capability of LLMs with  Cross-Lingual Feedback\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.1, \"y\": 4.38}, {\"title\": \"MedFuzz: Exploring the Robustness of Large Language Models in Medical  Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.798, \"y\": 7.906}, {\"title\": \"Text-guided Controllable Mesh Refinement for Interactive 3D Modeling\", \"topic\": \"Multimodal Language Models\", \"x\": 8.916, \"y\": 6.999}, {\"title\": \"Graph Neural Network Enhanced Retrieval for Question Answering of LLMs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.898, \"y\": 5.527}, {\"title\": \"Understanding Preference Fine-Tuning Through the Lens of Coverage\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.251, \"y\": 1.358}, {\"title\": \"Enhancing Clinical Documentation with Synthetic Data: Leveraging  Generative Models for Improved Accuracy\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.752, \"y\": 8.127}, {\"title\": \"Enabling ASR for Low-Resource Languages: A Comprehensive Dataset  Creation Approach\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.922, \"y\": 5.392}, {\"title\": \"Superhuman performance in urology board questions by an explainable  large language model enabled for context integration of the European  Association of Urology guidelines: the UroBot study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.65, \"y\": 7.994}, {\"title\": \"Universal In-Context Approximation By Prompting Fully Recurrent Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.183, \"y\": 3.417}, {\"title\": \"How to Understand Whole Software Repository?\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.323, \"y\": 2.451}, {\"title\": \"Sparsity-Accelerated Training for Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.355, \"y\": 2.62}, {\"title\": \"R2C2-Coder: Enhancing and Benchmarking Real-world Repository-level Code  Completion Abilities of Code Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.619, \"y\": 2.51}, {\"title\": \"DHA: Learning Decoupled-Head Attention from Transformer Checkpoints via  Adaptive Heads Fusion\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.714, \"y\": 3.05}, {\"title\": \"CodeR: Issue Resolving with Multi-Agent and Task Graphs\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.225, \"y\": 2.441}, {\"title\": \"Improved Few-Shot Jailbreaking Can Circumvent Aligned Language Models  and Their Defenses\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.336, \"y\": 2.297}, {\"title\": \"Focus on the Core: Efficient Attention via Pruned Token Compression for  Document Classification\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.681, \"y\": 3.405}, {\"title\": \"EffiQA: Efficient Question-Answering with Strategic Multi-Model  Collaboration on Knowledge Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.72, \"y\": 5.373}, {\"title\": \"Demonstration Augmentation for Zero-shot In-context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.239, \"y\": 3.437}, {\"title\": \"Explore then Determine: A GNN-LLM Synergy Framework for Reasoning over  Knowledge Graph\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.798, \"y\": 5.515}, {\"title\": \"TCMBench: A Comprehensive Benchmark for Evaluating Large Language Models  in Traditional Chinese Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.85, \"y\": 7.887}, {\"title\": \"RAG Enabled Conversations about Household Electricity Monitoring\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.944, \"y\": 4.654}, {\"title\": \"Guiding ChatGPT to Generate Salient Domain Summaries\", \"topic\": \"Text Summarization\", \"x\": 5.686, \"y\": 6.104}, {\"title\": \"MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.127, \"y\": 3.661}, {\"title\": \"Scalable Ensembling For Mitigating Reward Overoptimisation\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.203, \"y\": 1.519}, {\"title\": \"Revolutionizing Large Language Model Training through Dynamic Parameter  Adjustment\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.008, \"y\": 2.392}, {\"title\": \"SemCoder: Training Code Language Models with Comprehensive Semantics\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.321, \"y\": 2.336}, {\"title\": \"Predicting Drug-Gene Relations via Analogy Tasks with Word Embeddings\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.385, \"y\": 7.463}, {\"title\": \"Selectively Answering Visual Questions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.196, \"y\": 7.944}, {\"title\": \"Generative Pre-trained Speech Language Model with Efficient Hierarchical  Transformer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.402, \"y\": 5.462}, {\"title\": \"Luna: An Evaluation Foundation Model to Catch Language Model  Hallucinations with High Accuracy and Low Cost\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.174, \"y\": 1.17}, {\"title\": \"Unveil the Duality of Retrieval-Augmented Generation: Theoretical  Analysis and Practical Solution\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.966, \"y\": 4.525}, {\"title\": \"MEDIQ: Question-Asking LLMs for Adaptive and Reliable Clinical Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.738, \"y\": 7.887}, {\"title\": \"YODAS: Youtube-Oriented Dataset for Audio and Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.562, \"y\": 5.577}, {\"title\": \"Phonetic Error Analysis of Raw Waveform Acoustic Models with Parametric  and Non-Parametric CNNs\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.968, \"y\": 5.5}, {\"title\": \"Show, Don't Tell: Aligning Language Models with Demonstrated Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.618, \"y\": 1.677}, {\"title\": \"The Power of Summary-Source Alignments\", \"topic\": \"Text Summarization\", \"x\": 5.619, \"y\": 6.285}, {\"title\": \"BoNBoN Alignment for Large Language Models and the Sweetness of  Best-of-n Sampling\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.349, \"y\": 1.349}, {\"title\": \"Towards a copilot in BIM authoring tool using a large language  model-based agent for intelligent human-machine interaction\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.681, \"y\": 2.86}, {\"title\": \"Towards commands recommender system in BIM authoring tool using  transformers\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.051, \"y\": 2.968}, {\"title\": \"Developing an efficient corpus using Ensemble Data cleaning approach\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.899, \"y\": 7.614}, {\"title\": \"Applying Intrinsic Debiasing on Downstream Tasks: Challenges and  Considerations for Machine Translation\", \"topic\": \"Bias in Language Models\", \"x\": 3.056, \"y\": 4.354}, {\"title\": \"Automatic Instruction Evolving for Large Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 7.988, \"y\": 2.269}, {\"title\": \"Evaluating Mathematical Reasoning of Large Language Models: A Focus on  Error Identification and Correction\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.847, \"y\": 2.972}, {\"title\": \"An Early Investigation into the Utility of Multimodal Large Language  Models in Medical Imaging\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.4, \"y\": 8.306}, {\"title\": \"Enhancing Zero-shot Text-to-Speech Synthesis with Human Feedback\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.645, \"y\": 5.834}, {\"title\": \"Harnessing Business and Media Insights with Large Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.942, \"y\": 6.602}, {\"title\": \"SPAGHETTI: Open-Domain Question Answering from Heterogeneous Data  Sources with Retrieval and Semantic Parsing\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.584, \"y\": 5.266}, {\"title\": \"LIDAO: Towards Limited Interventions for Debiasing (Large) Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.425, \"y\": 4.186}, {\"title\": \"Recent Advances in End-to-End Simultaneous Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.375, \"y\": 5.153}, {\"title\": \"On Overcoming Miscalibrated Conversational Priors in LLM-based Chatbots\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.946, \"y\": 3.027}, {\"title\": \"Mix-of-Granularity: Optimize the Chunking Granularity for  Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.972, \"y\": 4.811}, {\"title\": \"Gender Bias Detection in Court Decisions: A Brazilian Case Study\", \"topic\": \"Bias in Language Models\", \"x\": 3.375, \"y\": 4.498}, {\"title\": \"Enhancing Text Authenticity: A Novel Hybrid Approach for AI-Generated  Text Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.168, \"y\": 4.733}, {\"title\": \"RoBERTa-BiLSTM: A Context-Aware Hybrid Model for Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.515, \"y\": 6.722}, {\"title\": \"KGLink: A column type annotation method that combines knowledge graph  and pre-trained language model\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.023, \"y\": 5.917}, {\"title\": \"CASE: Efficient Curricular Data Pre-training for Building Assistive  Psychology Expert Models\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.396, \"y\": 7.557}, {\"title\": \"Multi-Dimensional Optimization for Text Summarization via Reinforcement  Learning\", \"topic\": \"Text Summarization\", \"x\": 5.561, \"y\": 6.269}, {\"title\": \"Phased Instruction Fine-Tuning for Large Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.08, \"y\": 2.281}, {\"title\": \"A Closer Look at Logical Reasoning with LLMs: The Choice of Tool Matters\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.601, \"y\": 3.066}, {\"title\": \"Are Large Vision Language Models up to the Challenge of Chart  Comprehension and Reasoning? An Extensive Investigation into the Capabilities  and Limitations of LVLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.01, \"y\": 7.691}, {\"title\": \"Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech  Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.212, \"y\": 7.83}, {\"title\": \"Exfiltration of personal information from ChatGPT via prompt injection\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.484, \"y\": 2.786}, {\"title\": \"How In-Context Learning Emerges from Training on Unstructured Data: On  the Role of Co-Occurrence, Positional Information, and Noise Structures\", \"topic\": \"In-Context Learning\", \"x\": 8.567, \"y\": 3.333}, {\"title\": \"Video-MME: The First-Ever Comprehensive Evaluation Benchmark of  Multi-modal LLMs in Video Analysis\", \"topic\": \"Multimodal Language Models\", \"x\": 8.53, \"y\": 7.796}, {\"title\": \"Generalization Beyond Data Imbalance: A Controlled Study on CLIP for  Transferable Insights\", \"topic\": \"Multimodal Language Models\", \"x\": 8.929, \"y\": 7.196}, {\"title\": \"Exploratory Preference Optimization: Harnessing Implicit  Q*-Approximation for Sample-Efficient RLHF\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.206, \"y\": 1.47}, {\"title\": \"Direct Alignment of Language Models via Quality-Aware Self-Refinement\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.404, \"y\": 1.541}, {\"title\": \"You Only Scan Once: Efficient Multi-dimension Sequential Modeling with  LightNet\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.818, \"y\": 3.24}, {\"title\": \"Improved Techniques for Optimization-Based Jailbreaking on Large  Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.304, \"y\": 2.298}, {\"title\": \"LCQ: Low-Rank Codebook based Quantization for Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.685, \"y\": 2.185}, {\"title\": \"Enhancing Vision Models for Text-Heavy Content Understanding and  Interaction\", \"topic\": \"Multimodal Language Models\", \"x\": 8.388, \"y\": 7.204}, {\"title\": \"Preemptive Answer \\\"Attacks\\\" on Chain-of-Thought Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.525, \"y\": 2.296}, {\"title\": \"Improving Reward Models with Synthetic Critiques\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.221, \"y\": 1.571}, {\"title\": \"Don't Buy it! Reassessing the Ad Understanding Abilities of Contrastive  Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.272, \"y\": 7.639}, {\"title\": \"Outliers and Calibration Sets have Diminishing Effect on Quantization of  Modern LLMs\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.743, \"y\": 2.092}, {\"title\": \"Self-Augmented Preference Optimization: Off-Policy Paradigms for  Language Model Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.372, \"y\": 1.342}, {\"title\": \"Ovis: Structural Embedding Alignment for Multimodal Large Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.293, \"y\": 7.253}, {\"title\": \"Improving code-mixed hate detection by native sample mixing: A case  study for Hindi-English code-mixed scenario\", \"topic\": \"Hate Speech Detection\", \"x\": 2.772, \"y\": 5.407}, {\"title\": \"FinGen: A Dataset for Argument Generation in Finance\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.883, \"y\": 6.873}, {\"title\": \"It is Simple Sometimes: A Study On Improving Aspect-Based Sentiment  Analysis Performance\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.117, \"y\": 6.818}, {\"title\": \"Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization  for Prompt Enhancement\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.424, \"y\": 3.158}, {\"title\": \"Unraveling and Mitigating Retriever Inconsistencies in  Retrieval-Augmented Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.169, \"y\": 4.365}, {\"title\": \"Position Coupling: Leveraging Task Structure for Improved Length  Generalization of Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.648, \"y\": 3.455}, {\"title\": \"Reward-based Input Construction for Cross-document Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.828, \"y\": 6.943}, {\"title\": \"Shotluck Holmes: A Family of Efficient Small-Scale Large Language Vision  Models For Video Captioning and Summarization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.911, \"y\": 7.885}, {\"title\": \"Large Language Models Enhanced Sequential Recommendation for Long-tail  User and Item\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.928, \"y\": 2.869}, {\"title\": \"FineRadScore: A Radiology Report Line-by-Line Evaluation Technique  Generating Corrections with Severity Scores\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.142, \"y\": 8.543}, {\"title\": \"GAMedX: Generative AI-based Medical Entity Data Extractor Using Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.114, \"y\": 7.77}, {\"title\": \"Unveiling the Impact of Coding Data Instruction Fine-Tuning on Large  Language Models Reasoning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.111, \"y\": 2.478}, {\"title\": \"An Automatic Question Usability Evaluation Toolkit\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.184, \"y\": 5.043}, {\"title\": \"Towards Ontology-Enhanced Representation Learning for Large Language  Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.243, \"y\": 7.647}, {\"title\": \"How Multilingual Are Large Language Models Fine-Tuned for Translation?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.5, \"y\": 4.402}, {\"title\": \"Deep Learning Approaches for Detecting Adversarial Cyberbullying and  Hate Speech in Social Networks\", \"topic\": \"Hate Speech Detection\", \"x\": 2.807, \"y\": 5.378}, {\"title\": \"Transfer Q Star: Principled Decoding for LLM Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.373, \"y\": 1.397}, {\"title\": \"Enhancing Antibiotic Stewardship using a Natural Language Approach for  Better Feature Representation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.829, \"y\": 8.176}, {\"title\": \"Jailbreaking Large Language Models Against Moderation Guardrails via  Cipher Characters\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.297, \"y\": 2.271}, {\"title\": \"SeamlessExpressiveLM: Speech Language Model for Expressive  Speech-to-Speech Translation with Chain-of-Thought\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.425, \"y\": 5.409}, {\"title\": \"Investigating the Robustness of LLMs on Math Word Problems\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.629, \"y\": 2.792}, {\"title\": \"Xwin-LM: Strong and Scalable Alignment Practice for LLMs\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.383, \"y\": 1.481}, {\"title\": \"CoSy: Evaluating Textual Explanations of Neurons\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.201, \"y\": 4.055}, {\"title\": \"Hallucination-Free? Assessing the Reliability of Leading AI Legal  Research Tools\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.094, \"y\": 1.226}, {\"title\": \"ANAH: Analytical Annotation of Hallucinations in Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.159, \"y\": 1.089}, {\"title\": \"Large Language Models Can Self-Improve At Web Agent Tasks\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.665, \"y\": 2.579}, {\"title\": \"Group Robust Preference Optimization in Reward-free RLHF\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.308, \"y\": 1.287}, {\"title\": \"Who Writes the Review, Human or AI?\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.342, \"y\": 4.845}, {\"title\": \"ROAST: Review-level Opinion Aspect Sentiment Target Joint Detection\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.136, \"y\": 6.787}, {\"title\": \"ETHER: Efficient Finetuning of Large-Scale Models with Hyperplane  Reflections\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.052, \"y\": 2.205}, {\"title\": \"Towards Hierarchical Multi-Agent Workflows for Zero-Shot Prompt  Optimization\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.18, \"y\": 3.065}, {\"title\": \"TS-Align: A Teacher-Student Collaborative Framework for Scalable  Iterative Finetuning of Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.399, \"y\": 1.382}, {\"title\": \"PostDoc: Generating Poster from a Long Multimodal Document Using Deep  Submodular Optimization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.023, \"y\": 7.032}, {\"title\": \"Jina CLIP: Your CLIP Model Is Also Your Text Retriever\", \"topic\": \"Multimodal Language Models\", \"x\": 8.746, \"y\": 7.102}, {\"title\": \"Robo-Instruct: Simulator-Augmented Instruction Alignment For Finetuning  CodeLLMs\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 7.93, \"y\": 2.241}, {\"title\": \"Iterative Feature Boosting for Explainable Speech Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.224, \"y\": 7.808}, {\"title\": \"GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.879, \"y\": 5.445}, {\"title\": \"Language Models Need Inductive Biases to Count Inductively\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.199, \"y\": 3.414}, {\"title\": \"Fill in the Gap! Combining Self-supervised Representation Learning with  Neural Audio Synthesis for Speech Inpainting\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.928, \"y\": 5.173}, {\"title\": \"Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in  Code Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.404, \"y\": 2.344}, {\"title\": \"Would I Lie To You? Inference Time Alignment of Language Models using  Direct Preference Heads\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.244, \"y\": 1.383}, {\"title\": \"Efficient LLM-Jailbreaking by Introducing Visual Modality\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.29, \"y\": 2.302}, {\"title\": \"GenKubeSec: LLM-Based Kubernetes Misconfiguration Detection,  Localization, Reasoning, and Remediation\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.397, \"y\": 2.332}, {\"title\": \"ExU: AI Models for Examining Multilingual Disinformation Narratives and  Understanding their Spread\", \"topic\": \"Fake News Detection\", \"x\": 4.162, \"y\": 5.72}, {\"title\": \"Similarity is Not All You Need: Endowing Retrieval Augmented Generation  with Multi Layered Thoughts\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.017, \"y\": 4.659}, {\"title\": \"From Words to Actions: Unveiling the Theoretical Underpinnings of  LLM-Driven Autonomous Systems\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.855, \"y\": 2.448}, {\"title\": \"Is In-Context Learning Sufficient for Instruction Following in LLMs?\", \"topic\": \"In-Context Learning\", \"x\": 8.292, \"y\": 3.197}, {\"title\": \"DevEval: A Manually-Annotated Code Generation Benchmark Aligned with  Real-World Code Repositories\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.442, \"y\": 2.418}, {\"title\": \"Improve Student's Reasoning Generalizability through Cascading  Decomposed CoTs Distillation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.853, \"y\": 2.253}, {\"title\": \"From Symbolic Tasks to Code Generation: Diversification Yields Better  Task Performers\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.237, \"y\": 2.406}, {\"title\": \"Dataflow-Guided Retrieval Augmentation for Repository-Level Code  Completion\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.535, \"y\": 2.424}, {\"title\": \"Enhancing Consistency and Role-Specific Knowledge Capturing by  Rebuilding Fictional Character's Persona\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.978, \"y\": 3.629}, {\"title\": \"Enhancing Reinforcement Learning with Label-Sensitive Reward for Natural  Language Understanding\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.144, \"y\": 1.656}, {\"title\": \"Beyond Imitation: Learning Key Reasoning Steps from Dual  Chain-of-Thoughts in Reasoning Distillation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.774, \"y\": 2.284}, {\"title\": \"Two Optimizers Are Better Than One: LLM Catalyst Empowers Gradient-Based  Optimization for Prompt Tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.467, \"y\": 3.069}, {\"title\": \"Enhancing Large Vision Language Models with Self-Training on Image  Comprehension\", \"topic\": \"Multimodal Language Models\", \"x\": 8.525, \"y\": 7.584}, {\"title\": \"Significance of Chain of Thought in Gender Bias Mitigation for  English-Dravidian Machine Translation\", \"topic\": \"Bias in Language Models\", \"x\": 3.03, \"y\": 4.4}, {\"title\": \"One Token Can Help! Learning Scalable and Pluggable Virtual Tokens for  Retrieval-Augmented Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.04, \"y\": 4.538}, {\"title\": \"SysCaps: Language Interfaces for Simulation Surrogates of Complex  Systems\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.865, \"y\": 3.146}, {\"title\": \"Detecting Hallucinations in Large Language Model Generation: A Token  Probability Approach\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.183, \"y\": 1.087}, {\"title\": \"Easy Problems That LLMs Get Wrong\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.572, \"y\": 3.327}, {\"title\": \"SVFT: Parameter-Efficient Fine-Tuning with Singular Vectors\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.058, \"y\": 2.197}, {\"title\": \"Why Larger Language Models Do In-context Learning Differently?\", \"topic\": \"In-Context Learning\", \"x\": 8.594, \"y\": 3.367}, {\"title\": \"A Deep Convolutional Neural Network-based Model for Aspect and Polarity  Classification in Hausa Movie Reviews\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.221, \"y\": 6.776}, {\"title\": \"Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.516, \"y\": 8.314}, {\"title\": \"Selective Explanations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.923, \"y\": 3.682}, {\"title\": \"Unlocking the Potential of Large Language Models for Clinical Text  Anonymization: A Comparative Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.615, \"y\": 7.845}, {\"title\": \"One-Shot Safety Alignment for Large Language Models via Optimal  Dualization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.243, \"y\": 1.403}, {\"title\": \"CheXpert Plus: Augmenting a Large Chest X-ray Dataset with Text  Radiology Reports, Patient Demographics and Additional Image Formats\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.261, \"y\": 8.621}, {\"title\": \"Preference Learning Algorithms Do Not Learn Preference Rankings\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.275, \"y\": 1.342}, {\"title\": \"A Full-duplex Speech Dialogue Scheme Based On Large Language Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.412, \"y\": 3.581}, {\"title\": \"Deep Learning for Assessment of Oral Reading Fluency\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.081, \"y\": 5.573}, {\"title\": \"Adaptive In-conversation Team Building for Language Model Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.416, \"y\": 2.847}, {\"title\": \"X-VILA: Cross-Modality Alignment for Large Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.394, \"y\": 7.283}, {\"title\": \"LLMs Meet Multimodal Generation and Editing: A Survey\", \"topic\": \"Multimodal Language Models\", \"x\": 8.126, \"y\": 7.294}, {\"title\": \"Robust Preference Optimization through Reward Model Distillation\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.306, \"y\": 1.253}, {\"title\": \"Matryoshka Query Transformer for Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.559, \"y\": 7.567}, {\"title\": \"Integrating Multi-scale Contextualized Information for Byte-based Neural  Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.808, \"y\": 4.454}, {\"title\": \"MASSIVE Multilingual Abstract Meaning Representation: A Dataset and  Baselines for Hallucination Detection\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.185, \"y\": 1.128}, {\"title\": \"PediatricsGPT: Large Language Models as Chinese Medical Assistants for  Pediatric Applications\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.746, \"y\": 8.113}, {\"title\": \"AlchemistCoder: Harmonizing and Eliciting Code Capability by Hindsight  Tuning on Multi-source Data\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.682, \"y\": 2.388}, {\"title\": \"Weak-to-Strong Search: Align Large Language Models via Searching over  Small Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.526, \"y\": 1.579}, {\"title\": \"VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on  Long Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.793, \"y\": 7.902}, {\"title\": \"MetaToken: Detecting Hallucination in Image Descriptions by Meta  Classification\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.269, \"y\": 1.026}, {\"title\": \"DGRC: An Effective Fine-tuning Framework for Distractor Generation in  Chinese Multi-choice Reading Comprehension\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.29, \"y\": 4.78}, {\"title\": \"PathReasoner: Modeling Reasoning Path with Equivalent Extension for  Logical Question Answering\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.619, \"y\": 2.881}, {\"title\": \"Multi-stage Retrieve and Re-rank Model for Automatic Medical Coding  Recommendation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.891, \"y\": 8.414}, {\"title\": \"Auxiliary Knowledge-Induced Learning for Automatic Multi-Label Medical  Document Classification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.946, \"y\": 8.328}, {\"title\": \"EasyAnimate: A High-Performance Long Video Generation Method based on  Transformer Architecture\", \"topic\": \"Multimodal Language Models\", \"x\": 8.94, \"y\": 7.792}, {\"title\": \"Encoding Hierarchical Schema via Concept Flow for Multifaceted Ideology  Detection\", \"topic\": \"Fake News Detection\", \"x\": 3.618, \"y\": 5.628}, {\"title\": \"Are You Sure? Rank Them Again: Repeated Ranking For Better Preference  Datasets\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.217, \"y\": 1.498}, {\"title\": \"Kestrel: Point Grounding Multimodal LLM for Part-Aware 3D  Vision-Language Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.757, \"y\": 7.379}, {\"title\": \"Understanding and Addressing the Under-Translation Problem from the  Perspective of Decoding Objective\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.806, \"y\": 4.331}, {\"title\": \"Towards Faithful Chain-of-Thought: Large Language Models are Bridging  Reasoners\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.555, \"y\": 2.393}, {\"title\": \"Are queries and keys always relevant? A case study on Transformer wave  functions\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.774, \"y\": 3.299}, {\"title\": \"Simulation, Modelling and Classification of Wiki Contributors: Spotting  The Good, The Bad, and The Ugly\", \"topic\": \"Fake News Detection\", \"x\": 3.953, \"y\": 5.666}, {\"title\": \"Reverse Image Retrieval Cues Parametric Memory in Multimodal LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.267, \"y\": 7.579}, {\"title\": \"CtrlA: Adaptive Retrieval-Augmented Generation via Probe-Guided Control\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.971, \"y\": 4.354}, {\"title\": \"Correctable Landmark Discovery via Large Models for Vision-Language  Navigation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.782, \"y\": 7.2}, {\"title\": \"Efficient Model-agnostic Alignment via Bayesian Persuasion\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.431, \"y\": 1.431}, {\"title\": \"Efficient Preference-based Reinforcement Learning via Aligned Experience  Estimation\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.221, \"y\": 1.473}, {\"title\": \"Can GPT Redefine Medical Understanding? Evaluating GPT on Biomedical  Machine Reading Comprehension\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.941, \"y\": 7.719}, {\"title\": \"LLM-based Hierarchical Concept Decomposition for Interpretable  Fine-Grained Image Classification\", \"topic\": \"Multimodal Language Models\", \"x\": 8.665, \"y\": 7.323}, {\"title\": \"Zipper: A Multi-Tower Decoder Architecture for Fusing Modalities\", \"topic\": \"Multimodal Language Models\", \"x\": 8.436, \"y\": 7.096}, {\"title\": \"Understanding Intrinsic Socioeconomic Biases in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.505, \"y\": 4.281}, {\"title\": \"Are PPO-ed Language Models Hackable?\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.15, \"y\": 1.46}, {\"title\": \"JADS: A Framework for Self-supervised Joint Aspect Discovery and  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.402, \"y\": 6.477}, {\"title\": \"Improving Speech Decoding from ECoG with Self-Supervised Pretraining\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.747, \"y\": 5.134}, {\"title\": \"BioBERT-based Deep Learning and Merged ChemProt-DrugProt for Enhanced  Biomedical Relation Extraction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.42, \"y\": 7.39}, {\"title\": \"It's Not a Modality Gap: Characterizing and Addressing the Contrastive  Gap\", \"topic\": \"Multimodal Language Models\", \"x\": 8.753, \"y\": 7.22}, {\"title\": \"Why are Visually-Grounded Language Models Bad at Image Classification?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.683, \"y\": 7.394}, {\"title\": \"Don't Forget to Connect! Improving RAG with Graph-based Reranking\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.962, \"y\": 4.902}, {\"title\": \"RACCooN: Remove, Add, and Change Video Content with Auto-Generated  Narratives\", \"topic\": \"Multimodal Language Models\", \"x\": 8.975, \"y\": 7.816}, {\"title\": \"OwLore: Outlier-weighed Layerwise Sampled Low-Rank Projection for  Memory-Efficient LLM Fine-tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.144, \"y\": 2.152}, {\"title\": \"PromptWizard: Task-Aware Agent-driven Prompt Optimization Framework\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.198, \"y\": 3.133}, {\"title\": \"MMCTAgent: Multi-modal Critical Thinking Agent Framework for Complex  Visual Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.086, \"y\": 7.702}, {\"title\": \"Faithful Logical Reasoning via Symbolic Chain-of-Thought\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.707, \"y\": 2.601}, {\"title\": \"Text-only Synthesis for Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.981, \"y\": 7.36}, {\"title\": \"IAPT: Instruction-Aware Prompt Tuning for Large Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.69, \"y\": 3.257}, {\"title\": \"Hate Speech Detection with Generalizable Target-aware Fairness\", \"topic\": \"Hate Speech Detection\", \"x\": 2.733, \"y\": 5.355}, {\"title\": \"ATM: Adversarial Tuning Multi-agent System Makes a Robust  Retrieval-Augmented Generator\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.897, \"y\": 4.656}, {\"title\": \"Context is Important in Depressive Language: A Study of the Interaction  Between the Sentiments and Linguistic Markers in Reddit Discussions\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.084, \"y\": 7.408}, {\"title\": \"PRFashion24: A Dataset for Sentiment Analysis of Fashion Products  Reviews in Persian\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.717, \"y\": 6.584}, {\"title\": \"Spanish and LLM Benchmarks: is MMLU Lost in Translation?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.121, \"y\": 4.346}, {\"title\": \"Instruction Tuning with Retrieval-based Examples Ranking for  Aspect-based Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.132, \"y\": 6.811}, {\"title\": \"Edinburgh Clinical NLP at MEDIQA-CORR 2024: Guiding Large Language  Models with Hints\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.641, \"y\": 8.046}, {\"title\": \"TimeChara: Evaluating Point-in-Time Character Hallucination of  Role-Playing Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.125, \"y\": 1.27}, {\"title\": \"MultiADE: A Multi-domain Benchmark for Adverse Drug Event Extraction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.64, \"y\": 7.701}, {\"title\": \"Aligning to Thousands of Preferences via System Message Generalization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.321, \"y\": 1.485}, {\"title\": \"Recent Trends in Personalized Dialogue Generation: A Review of Datasets,  Methodologies, and Evaluations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.172, \"y\": 3.723}, {\"title\": \"Knowledge Circuits in Pretrained Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.407, \"y\": 3.471}, {\"title\": \"Transformer and Hybrid Deep Learning Based Models for Machine-Generated  Text Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 3.862, \"y\": 5.184}, {\"title\": \"Online Merging Optimizers for Boosting Rewards and Mitigating Tax in  Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.31, \"y\": 1.391}, {\"title\": \"The Evolution of Multimodal Model Architectures\", \"topic\": \"Multimodal Language Models\", \"x\": 8.137, \"y\": 7.265}, {\"title\": \"Enhancing Emotion Recognition in Conversation through Emotional  Cross-Modal Fusion and Inter-class Contrastive Learning\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.281, \"y\": 7.784}, {\"title\": \"Arithmetic Reasoning with LLM: Prolog Generation & Permutation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.011, \"y\": 2.724}, {\"title\": \"SLMRec: Empowering Small Language Models for Sequential Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.955, \"y\": 2.845}, {\"title\": \"Seeing the Image: Prioritizing Visual Correlation by Contrastive  Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.683, \"y\": 7.132}, {\"title\": \"Benchmarks Underestimate the Readiness of Multi-lingual Dialogue Agents\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.702, \"y\": 3.773}, {\"title\": \"Personalized Steering of Large Language Models: Versatile Steering  Vectors Through Bi-directional Preference Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.213, \"y\": 1.341}, {\"title\": \"The Impossibility of Fair LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.532, \"y\": 4.136}, {\"title\": \"Judgement Citation Retrieval using Contextual Similarity\", \"topic\": \"Legal NLP\", \"x\": 5.207, \"y\": 5.835}, {\"title\": \"TransVIP: Speech to Speech Translation System with Voice and Isochrony  Preservation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.568, \"y\": 5.434}, {\"title\": \"MobileConvRec: A Conversational Dataset for Mobile Apps Recommendations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.946, \"y\": 3.094}, {\"title\": \"Multi-objective Representation for Numbers in Clinical Narratives Using  CamemBERT-bio\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.879, \"y\": 7.969}, {\"title\": \"Does Geo-co-location Matter? A Case Study of Public Health Conversations  during COVID-19\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.086, \"y\": 6.859}, {\"title\": \"InversionView: A General-Purpose Method for Reading Information from  Neural Activations\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.43, \"y\": 3.491}, {\"title\": \"Cross-Modal Safety Alignment: Is textual unlearning all you need?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.257, \"y\": 7.093}, {\"title\": \"HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal  Stories with LLMs\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.694, \"y\": 7.828}, {\"title\": \"A Framework for Multi-modal Learning: Jointly Modeling Inter- &  Intra-Modality Dependencies\", \"topic\": \"Multimodal Language Models\", \"x\": 8.032, \"y\": 7.275}, {\"title\": \"Explainable machine learning multi-label classification of Spanish legal  judgements\", \"topic\": \"Legal NLP\", \"x\": 5.058, \"y\": 5.77}, {\"title\": \"LoRA-XS: Low-Rank Adaptation with Extremely Small Number of Parameters\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.203, \"y\": 2.082}, {\"title\": \"RAGSys: Item-Cold-Start Recommender as RAG System\", \"topic\": \"In-Context Learning\", \"x\": 8.216, \"y\": 3.35}, {\"title\": \"Matryoshka Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.225, \"y\": 7.55}, {\"title\": \"BIOSCAN-CLIP: Bridging Vision and Genomics for Biodiversity Monitoring  at Scale\", \"topic\": \"Multimodal Language Models\", \"x\": 8.294, \"y\": 7.054}, {\"title\": \"QUB-Cirdan at \\\"Discharge Me!\\\": Zero shot discharge letter generation by  open-source LLM\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.692, \"y\": 8.117}, {\"title\": \"THREAD: Thinking Deeper with Recursive Spawning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.372, \"y\": 2.658}, {\"title\": \"ReMoDetect: Reward Models Recognize Aligned LLM's Generations\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.288, \"y\": 1.379}, {\"title\": \"A One-Layer Decoder-Only Transformer is a Two-Layer RNN: With an  Application to Certified Robustness\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.676, \"y\": 3.351}, {\"title\": \"DoRA: Enhancing Parameter-Efficient Fine-Tuning with Dynamic Rank  Distribution\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.133, \"y\": 2.171}, {\"title\": \"Cost-efficient Knowledge-based Question Answering with Large Language  Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.733, \"y\": 5.445}, {\"title\": \"Unveiling Themes in Judicial Proceedings: A Cross-Country Study Using  Topic Modeling on Legal Documents from India and the UK\", \"topic\": \"Legal NLP\", \"x\": 4.99, \"y\": 5.903}, {\"title\": \"On the Noise Robustness of In-Context Learning for Text Generation\", \"topic\": \"In-Context Learning\", \"x\": 8.195, \"y\": 3.629}, {\"title\": \"ViSpeR: Multilingual Audio-Visual Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.695, \"y\": 5.542}, {\"title\": \"Efficient multi-prompt evaluation of LLMs\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.044, \"y\": 3.383}, {\"title\": \"Aligning LLMs through Multi-perspective User Preference Ranking-based  Feedback for Programming Question Answering\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.348, \"y\": 1.555}, {\"title\": \"Exploiting the Layered Intrinsic Dimensionality of Deep Models for  Practical Adversarial Training\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.196, \"y\": 3.0}, {\"title\": \"TEII: Think, Explain, Interact and Iterate with Large Language Models to  Solve Cross-lingual Emotion Detection\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.334, \"y\": 7.511}, {\"title\": \"LLM-Optic: Unveiling the Capabilities of Large Language Models for  Universal Visual Grounding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.644, \"y\": 7.376}, {\"title\": \"Unifying Demonstration Selection and Compression for In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.245, \"y\": 3.408}, {\"title\": \"ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off  Code Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.514, \"y\": 2.322}, {\"title\": \"EMERGE: Integrating RAG for Improved Multimodal EHR Predictive Modeling\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.908, \"y\": 8.244}, {\"title\": \"The Multi-Range Theory of Translation Quality Measurement: MQM scoring  models and Statistical Quality Control\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.748, \"y\": 4.722}, {\"title\": \"Empowering Large Language Models to Set up a Knowledge Retrieval Indexer  via Self-Learning\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.932, \"y\": 5.179}, {\"title\": \"VoCoT: Unleashing Visually Grounded Multi-Step Reasoning in Large  Multi-Modal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.082, \"y\": 7.751}, {\"title\": \"On Mesa-Optimization in Autoregressively Trained Transformers: Emergence  and Capability\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.481, \"y\": 3.295}, {\"title\": \"Performance evaluation of Reddit Comments using Machine Learning and  Natural Language Processing methods in Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.519, \"y\": 6.74}, {\"title\": \"LLM-Based Cooperative Agents using Information Relevance and Plan  Validation\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.439, \"y\": 2.909}, {\"title\": \"Adaptive Activation Steering: A Tuning-Free LLM Truthfulness Improvement  Method for Diverse Hallucinations Categories\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.582, \"y\": 1.414}, {\"title\": \"Accurate and Nuanced Open-QA Evaluation Through Textual Entailment\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.51, \"y\": 5.03}, {\"title\": \"Implicit Multimodal Alignment: On the Generalization of Frozen LLMs to  Multimodal Inputs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.319, \"y\": 7.378}, {\"title\": \"Triple Preference Optimization: Achieving Better Alignment with Less  Data in a Single Step Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.347, \"y\": 1.349}, {\"title\": \"Crossmodal ASR Error Correction with Discrete Speech Units\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.074, \"y\": 5.361}, {\"title\": \"Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal  Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.409, \"y\": 2.477}, {\"title\": \"A Survey of Multimodal Large Language Model from A Data-centric  Perspective\", \"topic\": \"Multimodal Language Models\", \"x\": 7.991, \"y\": 7.191}, {\"title\": \"Let Silence Speak: Enhancing Fake News Detection with Generated Comments  from Large Language Models\", \"topic\": \"Fake News Detection\", \"x\": 3.839, \"y\": 5.631}, {\"title\": \"M$^3$CoT: A Novel Benchmark for Multi-Domain Multi-step Multi-modal  Chain-of-Thought\", \"topic\": \"Multimodal Language Models\", \"x\": 7.989, \"y\": 7.624}, {\"title\": \"Predicting Rental Price of Lane Houses in Shanghai with Machine Learning  Methods and Large Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.705, \"y\": 6.716}, {\"title\": \"The Importance of Directional Feedback for LLM-based Optimizers\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.243, \"y\": 2.983}, {\"title\": \"AI-Generated Text Detection and Classification Based on BERT Deep  Learning Algorithm\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.221, \"y\": 4.993}, {\"title\": \"M-RAG: Reinforcing Large Language Model Performance through  Retrieval-Augmented Generation with Multiple Partitions\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.996, \"y\": 4.59}, {\"title\": \"Code Repair with LLMs gives an Exploration-Exploitation Tradeoff\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.391, \"y\": 2.254}, {\"title\": \"Augmented Risk Prediction for the Onset of Alzheimer's Disease from  Electronic Health Records with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.589, \"y\": 8.268}, {\"title\": \"KG-FIT: Knowledge Graph Fine-Tuning Upon Open-World Knowledge\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.11, \"y\": 6.023}, {\"title\": \"Tensor Attention Training: Provably Efficient Learning of Higher-order  Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.92, \"y\": 3.176}, {\"title\": \"Assessing Empathy in Large Language Models with Real-World  Physician-Patient Interactions\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.814, \"y\": 7.872}, {\"title\": \"Multi-Reference Preference Optimization for Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.289, \"y\": 1.301}, {\"title\": \"STRIDE: A Tool-Assisted LLM Agent Framework for Strategic and  Interactive Decision-Making\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.593, \"y\": 2.86}, {\"title\": \"Comparative Analysis of Open-Source Language Models in Summarizing  Medical Text Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.611, \"y\": 7.471}, {\"title\": \"Retrieval-Augmented Conversational Recommendation with Prompt-based  Semi-Structured Natural Language State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.906, \"y\": 2.928}, {\"title\": \"Picturing Ambiguity: A Visual Twist on the Winograd Schema Challenge\", \"topic\": \"Multimodal Language Models\", \"x\": 8.287, \"y\": 7.567}, {\"title\": \"AutoManual: Generating Instruction Manuals by LLM Agents via Interactive  Environmental Learning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.871, \"y\": 2.443}, {\"title\": \"Towards Unlocking Insights from Logbooks Using AI\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.004, \"y\": 4.715}, {\"title\": \"Accelerating Inference of Retrieval-Augmented Generation via Sparse  Context Selection\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.209, \"y\": 4.644}, {\"title\": \"C3LLM: Conditional Multimodal Content Generation Using Large Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.769, \"y\": 7.16}, {\"title\": \"Prompt Optimization with EASE? Efficient Ordering-aware Automated  Selection of Exemplars\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.536, \"y\": 3.258}, {\"title\": \"SNOBERT: A Benchmark for clinical notes entity linking in the SNOMED CT  clinical terminology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.934, \"y\": 7.928}, {\"title\": \"Keypoint-based Progressive Chain-of-Thought Distillation for LLMs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.943, \"y\": 2.229}, {\"title\": \"SPP: Sparsity-Preserved Parameter-Efficient Fine-Tuning for Large  Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.391, \"y\": 2.388}, {\"title\": \"Evaluating the Adversarial Robustness of Retrieval-Based In-Context  Learning for Large Language Models\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.22, \"y\": 2.976}, {\"title\": \"Enhancing Visual-Language Modality Alignment in Large Vision Language  Models via Self-Improvement\", \"topic\": \"Multimodal Language Models\", \"x\": 8.464, \"y\": 7.501}, {\"title\": \"Transformers represent belief state geometry in their residual stream\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.282, \"y\": 3.702}, {\"title\": \"Zero-Shot Spam Email Classification Using Pre-trained Large Language  Models\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.161, \"y\": 4.805}, {\"title\": \"SLIDE: A Framework Integrating Small and Large Language Models for  Open-Domain Dialogues Evaluation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.633, \"y\": 3.791}, {\"title\": \"Hacc-Man: An Arcade Game for Jailbreaking LLMs\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.29, \"y\": 2.248}, {\"title\": \"Basis Selection: Low-Rank Decomposition of Pretrained Large Language  Models for Target Applications\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.525, \"y\": 2.366}, {\"title\": \"Large Language Model Pruning\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.519, \"y\": 2.534}, {\"title\": \"Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus  Creation and Model Development\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.596, \"y\": 7.79}, {\"title\": \"GPT is Not an Annotator: The Necessity of Human Annotation in Fairness  Benchmark Construction\", \"topic\": \"Bias in Language Models\", \"x\": 3.461, \"y\": 4.451}, {\"title\": \"Optimizing Large Language Models for OpenAPI Code Completion\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.548, \"y\": 2.406}, {\"title\": \"EmpathicStories++: A Multimodal Dataset for Empathy towards Personal  Experiences\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.711, \"y\": 7.867}, {\"title\": \"Clustered Retrieved Augmented Generation (CRAG)\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.02, \"y\": 4.607}, {\"title\": \"VDGD: Mitigating LVLM Hallucinations in Cognitive Prompts by Bridging  the Visual Perception Gap\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.304, \"y\": 1.03}, {\"title\": \"GECKO: Generative Language Model for English, Code and Korean\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.832, \"y\": 4.177}, {\"title\": \"M4U: Evaluating Multilingual Understanding and Reasoning for Large  Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.92, \"y\": 7.608}, {\"title\": \"Synergizing In-context Learning with Hints for End-to-end Task-oriented  Dialog Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.693, \"y\": 3.812}, {\"title\": \"Adapting PromptORE for Modern History: Information Extraction from  Hispanic Monarchy Documents of the XVIth Century\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.902, \"y\": 6.607}, {\"title\": \"Sparse Matrix in Large Language Model Fine-tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.101, \"y\": 2.186}, {\"title\": \"Learning Beyond Pattern Matching? Assaying Mathematical Understanding in  LLMs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.334, \"y\": 2.883}, {\"title\": \"Benchmarking Pre-trained Large Language Models' Potential Across Urdu  NLP tasks\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.756, \"y\": 4.534}, {\"title\": \"Decompose and Aggregate: A Step-by-Step Interpretable Evaluation  Framework\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.354, \"y\": 3.79}, {\"title\": \"Before Generation, Align it! A Novel and Effective Strategy for  Mitigating Hallucinations in Text-to-SQL Generation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.329, \"y\": 1.199}, {\"title\": \"Denoising LM: Pushing the Limits of Error Correction Models for Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.089, \"y\": 5.302}, {\"title\": \"How Culturally Aware are Vision-Language Models?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.71, \"y\": 7.499}, {\"title\": \"SOAP: Enhancing Efficiency of Generated Code via Self-Optimization\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.473, \"y\": 2.4}, {\"title\": \"VB-LoRA: Extreme Parameter Efficient Fine-Tuning with Vector Banks\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.209, \"y\": 2.043}, {\"title\": \"Athena: Efficient Block-Wise Post-Training Quantization for Large  Language Models Using Second-Order Matrix Derivative Information\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.729, \"y\": 2.138}, {\"title\": \"Intelligent Go-Explore: Standing on the Shoulders of Giant Foundation  Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.857, \"y\": 2.473}, {\"title\": \"Efficient Biomedical Entity Linking: Clinical Text Standardization with  Low-Resource Techniques\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.268, \"y\": 7.622}, {\"title\": \"Generalizable and Scalable Multistage Biomedical Concept Normalization  Leveraging Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.922, \"y\": 7.849}, {\"title\": \"CHARP: Conversation History AwaReness Probing for Knowledge-grounded  Dialogue Systems\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.228, \"y\": 1.388}, {\"title\": \"Contrastive and Consistency Learning for Neural Noisy-Channel Model in  Spoken Language Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.991, \"y\": 5.11}, {\"title\": \"Dissociation of Faithful and Unfaithful Reasoning in LLMs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.55, \"y\": 2.535}, {\"title\": \"Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to  the Edge of Generalization\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.28, \"y\": 3.452}, {\"title\": \"Optimizing example selection for retrieval-augmented machine translation  with translation memories\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.748, \"y\": 4.328}, {\"title\": \"Multilingual Prosody Transfer: Comparing Supervised & Transfer Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.521, \"y\": 5.408}, {\"title\": \"CrossVoice: Crosslingual Prosody Preserving Cascade-S2ST using Transfer  Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.502, \"y\": 5.477}, {\"title\": \"Aya 23: Open Weight Releases to Further Multilingual Progress\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.806, \"y\": 4.229}, {\"title\": \"AGRaME: Any-Granularity Ranking with Multi-Vector Embeddings\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.593, \"y\": 5.138}, {\"title\": \"Extracting Prompts by Inverting LLM Outputs\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.41, \"y\": 3.213}, {\"title\": \"RE-Adapt: Reverse Engineered Adaptation of Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.761, \"y\": 2.45}, {\"title\": \"LOVA3: Learning to Visual Question Answering, Asking and Assessment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.169, \"y\": 8.021}, {\"title\": \"A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image  Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.354, \"y\": 8.275}, {\"title\": \"From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by  Step\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.782, \"y\": 2.196}, {\"title\": \"Can LLMs Solve longer Math Word Problems Better?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.119, \"y\": 2.936}, {\"title\": \"Lessons from the Trenches on Reproducible Evaluation of Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.548, \"y\": 3.934}, {\"title\": \"Smart Bilingual Focused Crawling of Parallel Documents\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.517, \"y\": 4.981}, {\"title\": \"Pragmatic Feature Preferences: Learning Reward-Relevant Preferences from  Human Input\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.19, \"y\": 1.463}, {\"title\": \"FinRobot: An Open-Source AI Agent Platform for Financial Applications  using Large Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.837, \"y\": 6.848}, {\"title\": \"SliM-LLM: Salience-Driven Mixed-Precision Quantization for Large  Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.735, \"y\": 2.118}, {\"title\": \"SimPO: Simple Preference Optimization with a Reference-Free Reward\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.34, \"y\": 1.397}, {\"title\": \"CAPE: Context-Adaptive Positional Encoding for Length Extrapolation\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.553, \"y\": 3.347}, {\"title\": \"Implicit In-context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.37, \"y\": 3.361}, {\"title\": \"Efficient Medical Question Answering with Knowledge-Augmented Question  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.925, \"y\": 7.568}, {\"title\": \"Unveiling the Achilles' Heel of NLG Evaluators: A Unified Adversarial  Framework Driven by Large Language Models\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.251, \"y\": 2.981}, {\"title\": \"Calibrated Self-Rewarding Vision Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.663, \"y\": 1.175}, {\"title\": \"Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating  Representative and Affinity Bias in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.574, \"y\": 4.324}, {\"title\": \"Exploring Alignment in Shared Cross-lingual Spaces\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.279, \"y\": 4.879}, {\"title\": \"Synthetic Data Generation for Intersectional Fairness by Leveraging  Hierarchical Group Structure\", \"topic\": \"Bias in Language Models\", \"x\": 3.537, \"y\": 4.316}, {\"title\": \"Impact of Non-Standard Unicode Characters on Security and Comprehension  in Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.371, \"y\": 2.283}, {\"title\": \"RefChecker: Reference-based Fine-grained Hallucination Checker and  Benchmark for Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.179, \"y\": 1.117}, {\"title\": \"Which Information Matters? Dissecting Human-written Multi-document  Summaries with Partial Information Decomposition\", \"topic\": \"Text Summarization\", \"x\": 5.566, \"y\": 6.404}, {\"title\": \"RaFe: Ranking Feedback Improves Query Rewriting for RAG\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.098, \"y\": 4.554}, {\"title\": \"Mitigating Quantization Errors Due to Activation Spikes in GLU-Based  LLMs\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.717, \"y\": 2.124}, {\"title\": \"Instruction Tuning With Loss Over Instructions\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.184, \"y\": 2.413}, {\"title\": \"Emotion Identification for French in Written Texts: Considering their  Modes of Expression as a Step Towards Text Complexity Analysis\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.496, \"y\": 7.353}, {\"title\": \"JiuZhang3.0: Efficiently Improving Mathematical Reasoning by Training  Small Data Synthesis Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.124, \"y\": 2.763}, {\"title\": \"Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.781, \"y\": 2.547}, {\"title\": \"Improving Language Models Trained with Translated Data via Continual  Pre-Training and Dictionary Learning Analysis\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.561, \"y\": 4.448}, {\"title\": \"Let's Fuse Step by Step: A Generative Fusion Decoding Algorithm with  LLMs for Multi-modal Text Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.808, \"y\": 5.41}, {\"title\": \"Text-Based Correlation Matrix in Multi-Asset Allocation\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.836, \"y\": 6.836}, {\"title\": \"EHR-SeqSQL : A Sequential Text-to-SQL Dataset For Interactively  Exploring Electronic Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.897, \"y\": 7.804}, {\"title\": \"Boosting Medical Image-based Cancer Detection via Text-guided  Supervision from Reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.113, \"y\": 8.277}, {\"title\": \"From Text to Pixel: Advancing Long-Context Understanding in MLLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.312, \"y\": 7.282}, {\"title\": \"Agent Planning with World Knowledge Model\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.869, \"y\": 2.527}, {\"title\": \"Self-Taught Recognizer: Toward Unsupervised Adaptation for Speech  Foundation Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.18, \"y\": 5.172}, {\"title\": \"ViHateT5: Enhancing Hate Speech Detection in Vietnamese With A Unified  Text-to-Text Transformer Model\", \"topic\": \"Hate Speech Detection\", \"x\": 2.722, \"y\": 5.445}, {\"title\": \"AlignGPT: Multi-modal Large Language Models with Adaptive Alignment  Capability\", \"topic\": \"Multimodal Language Models\", \"x\": 8.326, \"y\": 7.092}, {\"title\": \"Integrating Medical Imaging and Clinical Reports Using Multimodal Deep  Learning for Advanced Disease Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.179, \"y\": 8.436}, {\"title\": \"Structural Entities Extraction and Patient Indications Incorporation for  Chest X-ray Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.244, \"y\": 8.632}, {\"title\": \"$T^2$ of Thoughts: Temperature Tree Elicits Reasoning in Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.394, \"y\": 2.544}, {\"title\": \"Exploration of Attention Mechanism-Enhanced Deep Learning Models in the  Mining of Medical Textual Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.963, \"y\": 8.022}, {\"title\": \"Your Large Language Models Are Leaving Fingerprints\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.153, \"y\": 4.637}, {\"title\": \"Use of natural language processing to extract and classify papillary  thyroid cancer features from surgical pathology reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.618, \"y\": 8.077}, {\"title\": \"Refining Skewed Perceptions in Vision-Language Models through Visual  Representations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.881, \"y\": 7.298}, {\"title\": \"Evaluating Large Language Models with Human Feedback: Establishing a  Swedish Benchmark\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.148, \"y\": 3.725}, {\"title\": \"Why Not Transform Chat Large Language Models to Non-English?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.292, \"y\": 4.407}, {\"title\": \"TOPA: Extend Large Language Models for Video Understanding via Text-Only  Pre-Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.939, \"y\": 7.841}, {\"title\": \"Image-of-Thought Prompting for Visual Reasoning Refinement in Multimodal  Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.07, \"y\": 7.797}, {\"title\": \"Getting More from Less: Large Language Models are Good Spontaneous  Multilingual Learners\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.25, \"y\": 4.372}, {\"title\": \"DETAIL: Task DEmonsTration Attribution for Interpretable In-context  Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.527, \"y\": 3.297}, {\"title\": \"Grounding Toxicity in Real-World Events across Languages\", \"topic\": \"Hate Speech Detection\", \"x\": 3.117, \"y\": 5.27}, {\"title\": \"CrossCheckGPT: Universal Hallucination Ranking for Multimodal Foundation  Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.241, \"y\": 1.04}, {\"title\": \"Knowledge Graph Reasoning with Self-supervised Reinforcement Learning\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.892, \"y\": 5.586}, {\"title\": \"Automated Evaluation of Retrieval-Augmented Language Models with  Task-Specific Exam Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.807, \"y\": 4.697}, {\"title\": \"COTET: Cross-view Optimal Transport for Knowledge Graph Entity Typing\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.209, \"y\": 6.157}, {\"title\": \"ConTrans: Weak-to-Strong Alignment Engineering via Concept  Transplantation\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.605, \"y\": 1.564}, {\"title\": \"FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation  Research\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.018, \"y\": 4.604}, {\"title\": \"Knowledge-Driven Cross-Document Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.813, \"y\": 6.95}, {\"title\": \"Annotation-Efficient Preference Optimization for Language Model  Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.34, \"y\": 1.29}, {\"title\": \"Attention Mechanisms Don't Learn Additive Models: Rethinking Feature  Importance for Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.533, \"y\": 3.407}, {\"title\": \"LIRE: listwise reward enhancement for preference alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.232, \"y\": 1.363}, {\"title\": \"Joint Optimization of Streaming and Non-Streaming Automatic Speech  Recognition with Multi-Decoder and Knowledge Distillation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.16, \"y\": 5.15}, {\"title\": \"Disperse-Then-Merge: Pushing the Limits of Instruction Tuning via  Alignment Tax Reduction\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.357, \"y\": 2.311}, {\"title\": \"You don't understand me!: Comparing ASR results for L1 and L2 speakers  of Swedish\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.105, \"y\": 5.5}, {\"title\": \"Efficacy of ByT5 in Multilingual Translation of Biblical Texts for  Underrepresented Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.625, \"y\": 4.852}, {\"title\": \"Contextualized Automatic Speech Recognition with Dynamic Vocabulary\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.324, \"y\": 5.08}, {\"title\": \"Mosaic IT: Enhancing Instruction Tuning with Data Mosaics\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.175, \"y\": 2.354}, {\"title\": \"KU-DMIS at EHRSQL 2024:Generating SQL query via question templatization  in EHR\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.924, \"y\": 7.694}, {\"title\": \"MELD-ST: An Emotion-aware Speech Translation Dataset\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.233, \"y\": 7.887}, {\"title\": \"Dataset Decomposition: Faster LLM Training with Variable Sequence Length  Curriculum\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.367, \"y\": 2.878}, {\"title\": \"How Reliable AI Chatbots are for Disease Prediction from Patient  Complaints?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.422, \"y\": 8.144}, {\"title\": \"Equipping Transformer with Random-Access Reading for Long-Context  Understanding\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.696, \"y\": 3.299}, {\"title\": \"Investigating Symbolic Capabilities of Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.755, \"y\": 2.977}, {\"title\": \"Modeling Real-Time Interactive Conversations as Timed Diarized  Transcripts\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.469, \"y\": 3.644}, {\"title\": \"Comparative Analysis of Different Efficient Fine Tuning Methods of Large  Language Models (LLMs) in Low-Resource Setting\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.911, \"y\": 2.486}, {\"title\": \"Towards Retrieval-Augmented Architectures for Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.927, \"y\": 7.52}, {\"title\": \"G-DIG: Towards Gradient-based DIverse and hiGh-quality Instruction Data  Selection for Machine Translation\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.278, \"y\": 2.426}, {\"title\": \"Topic Modelling Case Law Using a Large Language Model and a New Taxonomy  for UK Law: AI Insights into Summary Judgment\", \"topic\": \"Legal NLP\", \"x\": 5.097, \"y\": 5.728}, {\"title\": \"Diffusion-RSCC: Diffusion Probabilistic Model for Change Captioning in  Remote Sensing Images\", \"topic\": \"Multimodal Language Models\", \"x\": 9.111, \"y\": 7.055}, {\"title\": \"Large Language Models Meet NLP: A Survey\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.512, \"y\": 4.19}, {\"title\": \"What Have We Achieved on Non-autoregressive Translation?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.12, \"y\": 4.564}, {\"title\": \"RecGPT: Generative Pre-training for Text-based Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.933, \"y\": 2.874}, {\"title\": \"Multimodal Adaptive Inference for Document Image Classification with  Anytime Early Exiting\", \"topic\": \"Multimodal Language Models\", \"x\": 8.023, \"y\": 7.037}, {\"title\": \"OLAPH: Improving Factuality in Biomedical Long-form Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.719, \"y\": 7.79}, {\"title\": \"A Survey on Multi-modal Machine Translation: Tasks, Methods and  Challenges\", \"topic\": \"Multimodal Language Models\", \"x\": 7.99, \"y\": 7.105}, {\"title\": \"Tagengo: A Multilingual Chat Dataset\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.956, \"y\": 4.324}, {\"title\": \"Multi-domain Knowledge Graph Collaborative Pre-training and Prompt  Tuning for Diverse Downstream Tasks\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.122, \"y\": 5.849}, {\"title\": \"Diverse and Effective Synthetic Data Generation for Adaptable Zero-Shot  Dialogue State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.6, \"y\": 3.989}, {\"title\": \"CoCo Matrix: Taxonomy of Cognitive Contributions in Co-writing with  Intelligent Agents\", \"topic\": \"Bias in Language Models\", \"x\": 5.087, \"y\": 4.518}, {\"title\": \"Targeted Multilingual Adaptation for Low-resource Language Families\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.297, \"y\": 4.484}, {\"title\": \"Thesis: Document Summarization with applications to Keyword extraction  and Image Retrieval\", \"topic\": \"Text Summarization\", \"x\": 5.445, \"y\": 6.418}, {\"title\": \"Question-Based Retrieval using Atomic Units for Enterprise RAG\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.153, \"y\": 4.77}, {\"title\": \"MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.165, \"y\": 2.067}, {\"title\": \"Reindex-Then-Adapt: Improving Large Language Models for Conversational  Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.939, \"y\": 2.938}, {\"title\": \"Imp: Highly Capable Large Multimodal Models for Mobile Devices\", \"topic\": \"Multimodal Language Models\", \"x\": 8.094, \"y\": 7.155}, {\"title\": \"DOP: Diagnostic-Oriented Prompting for Large Language Models in  Mathematical Correction\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.961, \"y\": 2.546}, {\"title\": \"Unveiling factors influencing judgment variation in Sentiment Analysis  with Natural Language Processing and Statistics\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.529, \"y\": 6.569}, {\"title\": \"KG-RAG: Bridging the Gap Between Knowledge and Creativity\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.917, \"y\": 5.577}, {\"title\": \"FAME-MT Dataset: Formality Awareness Made Easy for Machine Translation  Purposes\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.635, \"y\": 4.792}, {\"title\": \"Biomedical Entity Linking for Dutch: Fine-tuning a Self-alignment BERT  Model on an Automatically Generated Wikipedia Corpus\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.418, \"y\": 7.504}, {\"title\": \"A Constraint-Enforcing Reward for Adversarial Attacks on Text  Classifiers\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.175, \"y\": 3.051}, {\"title\": \"CReMa: Crisis Response through Computational Identification and Matching  of Cross-Lingual Requests and Offers Shared on Social Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.126, \"y\": 6.688}, {\"title\": \"Unveiling and Manipulating Prompt Influence in Large Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.094, \"y\": 3.33}, {\"title\": \"Intuitive Fine-Tuning: Towards Simplifying Alignment into a Single  Process\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.483, \"y\": 1.385}, {\"title\": \"CoNLL#: Fine-grained Error Analysis and a Corrected Test Set for  CoNLL-03 English\", \"topic\": \"Named Entity Recognition\", \"x\": 7.335, \"y\": 6.84}, {\"title\": \"Beyond MLE: Investigating SEARNN for Low-Resourced Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.69, \"y\": 4.474}, {\"title\": \"(Perhaps) Beyond Human Translation: Harnessing Multi-Agent Collaboration  for Translating Ultra-Long Literary Texts\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.74, \"y\": 4.777}, {\"title\": \"Large Language Models for Medicine: A Survey\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.513, \"y\": 7.76}, {\"title\": \"OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.147, \"y\": 1.546}, {\"title\": \"Your Transformer is Secretly Linear\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.566, \"y\": 3.454}, {\"title\": \"ColorFoil: Investigating Color Blindness in Large Vision and Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.4, \"y\": 7.62}, {\"title\": \"MeteoRA: Multiple-tasks Embedded LoRA for Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.066, \"y\": 2.039}, {\"title\": \"Inquire, Interact, and Integrate: A Proactive Agent Collaborative  Framework for Zero-Shot Multimodal Medical Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.371, \"y\": 8.232}, {\"title\": \"Continuous Predictive Modeling of Clinical Notes and ICD Codes in  Patient Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.734, \"y\": 8.234}, {\"title\": \"SLAB: Efficient Transformers with Simplified Linear Attention and  Progressive Re-parameterized Batch Normalization\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.786, \"y\": 3.31}, {\"title\": \"MSNER: A Multilingual Speech Dataset for Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.398, \"y\": 6.775}, {\"title\": \"SemEval-2024 Task 3: Multimodal Emotion Cause Analysis in Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.291, \"y\": 7.683}, {\"title\": \"Effective In-Context Example Selection through Data Compression\", \"topic\": \"In-Context Learning\", \"x\": 8.262, \"y\": 3.415}, {\"title\": \"Efficient Prompt Tuning by Multi-Space Projection and Prompt Fusion\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.762, \"y\": 3.292}, {\"title\": \"EmbSum: Leveraging the Summarization Capabilities of Large Language  Models for Content-Based Recommendations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.888, \"y\": 2.927}, {\"title\": \"MHPP: Exploring the Capabilities and Limitations of Language Models  Beyond Basic Code Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.328, \"y\": 2.569}, {\"title\": \"Can Public LLMs be used for Self-Diagnosis of Medical Conditions ?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.602, \"y\": 8.166}, {\"title\": \"LeaPformer: Enabling Linear Transformers for Autoregressive and  Simultaneous Tasks via Learned Proportions\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.855, \"y\": 3.343}, {\"title\": \"MapCoder: Multi-Agent Code Generation for Competitive Problem Solving\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.381, \"y\": 2.389}, {\"title\": \"Large Language Models Lack Understanding of Character Composition of  Words\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.045, \"y\": 3.646}, {\"title\": \"Enhancing Fine-Grained Image Classifications via Cascaded Vision  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.741, \"y\": 7.305}, {\"title\": \"Uni-MoE: Scaling Unified Multimodal LLMs with Mixture of Experts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.18, \"y\": 7.252}, {\"title\": \"EnviroExam: Benchmarking Environmental Science Knowledge of Large  Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.374, \"y\": 4.135}, {\"title\": \"WisPerMed at \\\"Discharge Me!\\\": Advancing Text Generation in Healthcare  with Large Language Models, Dynamic Expert Selection, and Priming Techniques  on MIMIC-IV\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.7, \"y\": 8.072}, {\"title\": \"Case-Based Reasoning Approach for Solving Financial Question Answering\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.01, \"y\": 6.809}, {\"title\": \"Transformer based neural networks for emotion recognition in  conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.314, \"y\": 7.678}, {\"title\": \"Identifying and Aligning Medical Claims Made on Social Media with  Medical Evidence\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.418, \"y\": 7.521}, {\"title\": \"Automated Text Identification Using CNN and Training Dynamics\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.264, \"y\": 5.048}, {\"title\": \"LexGen: Domain-aware Multilingual Lexicon Generation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.258, \"y\": 4.798}, {\"title\": \"BrainStorm @ iREL at SMM4H 2024: Leveraging Translation and Topical  Embeddings for Annotation Detection in Tweets\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.024, \"y\": 6.702}, {\"title\": \"Towards Knowledge-Infused Automated Disease Diagnosis Assistant\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.582, \"y\": 8.289}, {\"title\": \"LG AI Research & KAIST at EHRSQL 2024: Self-Training Large Language  Models with Pseudo-Labeled Unanswerable Questions for a Reliable Text-to-SQL  System on EHRs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.917, \"y\": 7.721}, {\"title\": \"Towards Modular LLMs by Building and Reusing a Library of LoRAs\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.926, \"y\": 2.122}, {\"title\": \"Dynamic Embeddings with Task-Oriented prompting\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.717, \"y\": 3.078}, {\"title\": \"Prompt Exploration with Prompt Regression\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.201, \"y\": 3.271}, {\"title\": \"Leveraging Discourse Structure for Extractive Meeting Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.844, \"y\": 6.099}, {\"title\": \"From Generalist to Specialist: Improving Large Language Models for  Medical Physics Using ARCoT\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.942, \"y\": 8.086}, {\"title\": \"The Unappreciated Role of Intent in Algorithmic Moderation of Social  Media Content\", \"topic\": \"Hate Speech Detection\", \"x\": 3.108, \"y\": 5.397}, {\"title\": \"Generative Artificial Intelligence: A Systematic Review and Applications\", \"topic\": \"Bias in Language Models\", \"x\": 4.901, \"y\": 4.4}, {\"title\": \"COGNET-MD, an evaluation framework and dataset for Large Language Model  benchmarks in the medical domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.743, \"y\": 8.018}, {\"title\": \"ECR-Chain: Advancing Generative Language Models to Better Emotion-Cause  Reasoners through Reasoning Chains\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.489, \"y\": 7.819}, {\"title\": \"Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging  General-Purpose Knowledge Graphs for Enriched Embeddings\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.012, \"y\": 6.005}, {\"title\": \"SBAAM! Eliminating Transcript Dependency in Automatic Subtitling\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.409, \"y\": 5.535}, {\"title\": \"Feature-Adaptive and Data-Scalable In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.429, \"y\": 3.26}, {\"title\": \"Empowering Prior to Court Legal Analysis: A Transparent and Accessible  Dataset for Defensive Statement Classification and Interpretation\", \"topic\": \"Legal NLP\", \"x\": 5.023, \"y\": 5.743}, {\"title\": \"Medical Dialogue: A Survey of Categories, Methods, Evaluation and  Challenges\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.58, \"y\": 7.584}, {\"title\": \"Dynamic data sampler for cross-language transfer learning in large  language models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.217, \"y\": 4.281}, {\"title\": \"Feature-based Low-Rank Compression of Large Language Models via Bayesian  Optimization\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.529, \"y\": 2.392}, {\"title\": \"Surgical Feature-Space Decomposition of LLMs: Why, When and How?\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.465, \"y\": 2.536}, {\"title\": \"RDRec: Rationale Distillation for LLM-based Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.922, \"y\": 2.878}, {\"title\": \"A Hybrid Deep Learning Framework for Stock Price Prediction Considering  the Investor Sentiment of Online Forum Enhanced by Popularity\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.446, \"y\": 6.806}, {\"title\": \"Enhancing Dialogue State Tracking Models through LLM-backed User-Agents  Simulation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.502, \"y\": 3.787}, {\"title\": \"Language Models can Exploit Cross-Task In-context Learning for  Data-Scarce Novel Tasks\", \"topic\": \"In-Context Learning\", \"x\": 8.667, \"y\": 3.433}, {\"title\": \"Benchmarking Large Language Models on CFLUE -- A Chinese Financial  Language Understanding Evaluation Dataset\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.033, \"y\": 6.728}, {\"title\": \"Towards Better Question Generation in QA-based Event Extraction\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.334, \"y\": 5.239}, {\"title\": \"Large Language Models for Tuning Evolution Strategies\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 7.926, \"y\": 2.522}, {\"title\": \"Retrieving and Refining: A Hybrid Framework with Large Language Models  for Rare Disease Identification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.716, \"y\": 8.087}, {\"title\": \"Thinking Fair and Slow: On the Efficacy of Structured Prompts for  Debiasing Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 6.891, \"y\": 3.281}, {\"title\": \"Revisiting OPRO: The Limitations of Small-Scale LLMs as Optimizers\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.262, \"y\": 3.111}, {\"title\": \"Building a Luganda Text-to-Speech Model From Crowdsourced Data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.795, \"y\": 5.593}, {\"title\": \"StyloAI: Distinguishing AI-Generated Content with Stylometric Analysis\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.344, \"y\": 4.821}, {\"title\": \"Faithful Attention Explainer: Verbalizing Decisions Based on  Discriminative Features\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.101, \"y\": 3.876}, {\"title\": \"Listen Again and Choose the Right Answer: A New Paradigm for Automatic  Speech Recognition with Large Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.13, \"y\": 5.368}, {\"title\": \"FinTextQA: A Dataset for Long-form Financial Question Answering\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.978, \"y\": 6.791}, {\"title\": \"SciQAG: A Framework for Auto-Generated Scientific Question Answering  Dataset with Fine-grained Evaluation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.186, \"y\": 5.345}, {\"title\": \"TransMI: A Framework to Create Strong Baselines from Multilingual  Pretrained Language Models for Transliterated Data\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.339, \"y\": 4.586}, {\"title\": \"Crowdsourcing with Enhanced Data Quality Assurance: An Efficient  Approach to Mitigate Resource Scarcity Challenges in Training Large Language  Models for Healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.458, \"y\": 7.654}, {\"title\": \"Enhancing Semantics in Multimodal Chain of Thought via Soft Negative  Sampling\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.476, \"y\": 2.186}, {\"title\": \"DuetSim: Building User Simulator with Dual Large Language Models for  Task-Oriented Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.411, \"y\": 3.624}, {\"title\": \"Chameleon: Mixed-Modal Early-Fusion Foundation Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.239, \"y\": 7.381}, {\"title\": \"MediSyn: Text-Guided Diffusion Models for Broad Medical 2D and 3D Image  Synthesis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.596, \"y\": 8.298}, {\"title\": \"Many-Shot In-Context Learning in Multimodal Foundation Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.299, \"y\": 7.302}, {\"title\": \"Optimization Techniques for Sentiment Analysis Based on LLM (GPT-3)\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.581, \"y\": 6.71}, {\"title\": \"Unsupervised Extractive Dialogue Summarization in Hyperdimensional Space\", \"topic\": \"Text Summarization\", \"x\": 5.434, \"y\": 6.36}, {\"title\": \"Leveraging Human Revisions for Improving Text-to-Layout Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.233, \"y\": 1.524}, {\"title\": \"A survey on fairness of large language models in e-commerce: progress,  application, and challenge\", \"topic\": \"Bias in Language Models\", \"x\": 3.533, \"y\": 4.158}, {\"title\": \"SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World  Knowledge\", \"topic\": \"Multimodal Language Models\", \"x\": 8.579, \"y\": 7.968}, {\"title\": \"STAR: A Benchmark for Situated Reasoning in Real-World Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.568, \"y\": 7.969}, {\"title\": \"LoRA Learns Less and Forgets Less\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.155, \"y\": 2.101}, {\"title\": \"Large Language Model Bias Mitigation from the Perspective of Knowledge  Editing\", \"topic\": \"Bias in Language Models\", \"x\": 3.31, \"y\": 4.177}, {\"title\": \"IM-RAG: Multi-Round Retrieval-Augmented Generation Through Learning  Inner Monologues\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.03, \"y\": 4.481}, {\"title\": \"A Survey on Transformers in NLP with Focus on Efficiency\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.595, \"y\": 3.414}, {\"title\": \"Unveiling Hallucination in Text, Image, Video, and Audio Foundation  Models: A Comprehensive Survey\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.168, \"y\": 1.069}, {\"title\": \"Word Alignment as Preference for Machine Translation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.74, \"y\": 1.215}, {\"title\": \"Bridging the gap in online hate speech detection: a comparative analysis  of BERT and traditional models for homophobic content identification on  X/Twitter\", \"topic\": \"Hate Speech Detection\", \"x\": 2.752, \"y\": 5.388}, {\"title\": \"Adapting Abstract Meaning Representation Parsing to the Clinical  Narrative -- the SPRING THYME parser\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.866, \"y\": 8.147}, {\"title\": \"Continued Pretraining for Domain Adaptation of Wav2vec2.0 in Automatic  Speech Recognition for Elementary Math Classroom Settings\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.224, \"y\": 5.087}, {\"title\": \"A Japanese-Chinese Parallel Corpus Using Crowdsourcing for Web Mining\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.537, \"y\": 4.884}, {\"title\": \"Spatial Semantic Recurrent Mining for Referring Image Segmentation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.793, \"y\": 7.117}, {\"title\": \"LLM-Assisted Rule Based Machine Translation for Low/No-Resource  Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.763, \"y\": 4.501}, {\"title\": \"Challenges in Deploying Long-Context Transformers: A Theoretical Peak  Performance Analysis\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.489, \"y\": 3.061}, {\"title\": \"Self-supervised vision-langage alignment of deep learning  representations for bone X-rays analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.354, \"y\": 8.548}, {\"title\": \"Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation  of Non-Literal Intent Resolution in LLMs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.354, \"y\": 3.191}, {\"title\": \"The Evolution of Darija Open Dataset: Introducing Version 2\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.137, \"y\": 5.353}, {\"title\": \"A Comprehensive Survey of Large Language Models and Multimodal Large  Language Models in Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.561, \"y\": 7.9}, {\"title\": \"The Unseen Targets of Hate -- A Systematic Review of Hateful  Communication Datasets\", \"topic\": \"Hate Speech Detection\", \"x\": 2.853, \"y\": 5.364}, {\"title\": \"Improving Transformers with Dynamically Composable Multi-Head Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.891, \"y\": 3.145}, {\"title\": \"A Prompt-driven Task Planning Method for Multi-drones based on Large  Language Model\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 6.069, \"y\": 2.646}, {\"title\": \"Archimedes-AUEB at SemEval-2024 Task 5: LLM explains Civil Procedure\", \"topic\": \"Legal NLP\", \"x\": 5.165, \"y\": 5.444}, {\"title\": \"When Large Language Models Meet Optical Networks: Paving the Way for  Automation\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.668, \"y\": 2.927}, {\"title\": \"Enhancing Gender-Inclusive Machine Translation with Neomorphemes and  Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 2.952, \"y\": 4.344}, {\"title\": \"Evaluating LLMs at Evaluating Temporal Generalization\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.227, \"y\": 3.842}, {\"title\": \"How Alignment Helps Make the Most of Multimodal Data\", \"topic\": \"Multimodal Language Models\", \"x\": 7.904, \"y\": 7.273}, {\"title\": \"Investigating the 'Autoencoder Behavior' in Speech Self-Supervised  Models: a focus on HuBERT's Pretraining\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.804, \"y\": 4.868}, {\"title\": \"PromptMind Team at EHRSQL-2024: Improving Reliability of SQL Generation  using Ensemble LLMs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.909, \"y\": 7.725}, {\"title\": \"PromptMind Team at MEDIQA-CORR 2024: Improving Clinical Text Correction  with Error Categorization and LLM Ensembles\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.659, \"y\": 8.168}, {\"title\": \"A Decoupling and Aggregating Framework for Joint Extraction of Entities  and Relations\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.918, \"y\": 6.898}, {\"title\": \"SpeechVerse: A Large-scale Generalizable Audio Language Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.614, \"y\": 5.246}, {\"title\": \"Who's in and who's out? A case study of multimodal CLIP-filtering in  DataComp\", \"topic\": \"Multimodal Language Models\", \"x\": 3.654, \"y\": 5.143}, {\"title\": \"CANTONMT: Investigating Back-Translation and Model-Switch Mechanisms for  Cantonese-English Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.836, \"y\": 4.664}, {\"title\": \"Benchmarking Retrieval-Augmented Large Language Models in Biomedical  NLP: Application, Robustness, and Self-Awareness\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.057, \"y\": 7.585}, {\"title\": \"Discursive objection strategies in online comments: Developing a  classification schema and validating its training\", \"topic\": \"Hate Speech Detection\", \"x\": 2.995, \"y\": 5.304}, {\"title\": \"Unveiling Social Media Comments with a Novel Named Entity Recognition  System for Identity Groups\", \"topic\": \"Hate Speech Detection\", \"x\": 2.785, \"y\": 5.46}, {\"title\": \"Many-Shot Regurgitation (MSR) Prompting\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.361, \"y\": 1.377}, {\"title\": \"KET-QA: A Dataset for Knowledge Enhanced Table Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.602, \"y\": 5.315}, {\"title\": \"Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large  Language Models in Code Generation from Scientific Plots\", \"topic\": \"Multimodal Language Models\", \"x\": 8.013, \"y\": 7.532}, {\"title\": \"AgentClinic: a multimodal agent benchmark to evaluate AI in simulated  clinical environments\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.653, \"y\": 8.192}, {\"title\": \"PARDEN, Can You Repeat That? Defending against Jailbreaks via Repetition\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.331, \"y\": 2.306}, {\"title\": \"Zero-Shot Tokenizer Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.574, \"y\": 4.621}, {\"title\": \"RLHF Workflow: From Reward Modeling to Online RLHF\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.24, \"y\": 1.49}, {\"title\": \"TANQ: An open domain dataset of table answered questions\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.547, \"y\": 5.359}, {\"title\": \"LlamaTurk: Adapting Open-Source Generative Large Language Models for  Low-Resource Language\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.127, \"y\": 4.098}, {\"title\": \"Quantifying and Optimizing Global Faithfulness in Persona-driven  Role-playing\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 5.913, \"y\": 1.462}, {\"title\": \"UCCIX: Irish-eXcellence Large Language Model\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.824, \"y\": 4.097}, {\"title\": \"Age-Dependent Analysis and Stochastic Generation of Child-Directed  Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.463, \"y\": 5.485}, {\"title\": \"FastSAG: Towards Fast Non-Autoregressive Singing Accompaniment  Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.336, \"y\": 6.097}, {\"title\": \"An Empirical Study on the Robustness of Massively Multilingual Neural  Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.673, \"y\": 4.577}, {\"title\": \"Control Token with Dense Passage Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.239, \"y\": 4.665}, {\"title\": \"News Recommendation with Category Description by a Large Language Model\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.925, \"y\": 2.909}, {\"title\": \"MuMath-Code: Combining Tool-Use Large Language Models with  Multi-perspective Data Augmentation for Mathematical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.121, \"y\": 2.605}, {\"title\": \"PromptLink: Leveraging Large Language Models for Cross-Source Biomedical  Concept Linking\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.288, \"y\": 7.559}, {\"title\": \"Evaluating large language models in medical applications: a survey\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.482, \"y\": 7.792}, {\"title\": \"Auto FAQ Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.231, \"y\": 5.175}, {\"title\": \"Evaluation of Retrieval-Augmented Generation: A Survey\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.053, \"y\": 4.734}, {\"title\": \"Exploring the Potential of Conversational AI Support for Agent-Based  Social Simulation Model Design\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.148, \"y\": 3.621}, {\"title\": \"Understanding the Rare Inflammatory Disease Using Large Language Models  and Social Media Data\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.323, \"y\": 7.419}, {\"title\": \"MathDivide: Improved mathematical reasoning by large language models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.897, \"y\": 2.834}, {\"title\": \"Bottleneck-Minimal Indexing for Generative Document Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.512, \"y\": 4.972}, {\"title\": \"A Survey on Recent Advances in Conversational Data Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.268, \"y\": 3.874}, {\"title\": \"DuetRAG: Collaborative Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.13, \"y\": 4.682}, {\"title\": \"Designing and Evaluating Dialogue LLMs for Co-Creative Improvised  Theatre\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.03, \"y\": 3.701}, {\"title\": \"Survey on Reasoning Capabilities and Accessibility of Large Language  Models Using Biology-related Questions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.781, \"y\": 7.403}, {\"title\": \"Evaluating Task-based Effectiveness of MLLMs on Charts\", \"topic\": \"Multimodal Language Models\", \"x\": 7.826, \"y\": 7.751}, {\"title\": \"Quite Good, but Not Enough: Nationality Bias in Large Language Models --  A Case Study of ChatGPT\", \"topic\": \"Bias in Language Models\", \"x\": 3.829, \"y\": 4.47}, {\"title\": \"Large Language Model in Financial Regulatory Interpretation\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.91, \"y\": 6.784}, {\"title\": \"Summarizing Radiology Reports Findings into Impressions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.121, \"y\": 8.552}, {\"title\": \"Linearizing Large Language Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.754, \"y\": 3.153}, {\"title\": \"Value Augmented Sampling for Language Model Alignment and  Personalization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.368, \"y\": 1.294}, {\"title\": \"Multimodal LLMs Struggle with Basic Visual Network Analysis: a VNA  Benchmark\", \"topic\": \"Multimodal Language Models\", \"x\": 8.136, \"y\": 7.772}, {\"title\": \"Characterizing the Accuracy - Efficiency Trade-off of Low-rank  Decomposition in Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.543, \"y\": 2.363}, {\"title\": \"Mitigating Hallucinations in Large Language Models via  Self-Refinement-Enhanced Knowledge Retrieval\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.325, \"y\": 1.363}, {\"title\": \"Prompting Large Language Models with Knowledge Graphs for Question  Answering Involving Long-tail Facts\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.807, \"y\": 5.215}, {\"title\": \"Aspect-based Sentiment Evaluation of Chess Moves (ASSESS): an NLP-based  Method for Evaluating Chess Strategies from Textbooks\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.076, \"y\": 6.762}, {\"title\": \"LyS at SemEval-2024 Task 3: An Early Prototype for End-to-End Multimodal  Emotion Linking as Graph-Based Parsing\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.271, \"y\": 7.719}, {\"title\": \"Pseudo-Prompt Generating in Pre-trained Vision-Language Models for  Multi-Label Medical Image Classification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.477, \"y\": 8.186}, {\"title\": \"E2TP: Element to Tuple Prompting Improves Aspect Sentiment Tuple  Prediction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.098, \"y\": 6.837}, {\"title\": \"Improving Instruction Following in Language Models through Proxy-Based  Uncertainty Estimation\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.364, \"y\": 1.731}, {\"title\": \"Akal Badi ya Bias: An Exploratory Study of Gender Bias in Hindi Language  Technology\", \"topic\": \"Bias in Language Models\", \"x\": 3.301, \"y\": 4.534}, {\"title\": \"Decoding Emotions in Abstract Art: Cognitive Plausibility of CLIP in  Recognizing Color-Emotion Associations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.372, \"y\": 7.681}, {\"title\": \"A NLP Approach to \\\"Review Bombing\\\" in Metacritic PC Videogames User  Ratings\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.711, \"y\": 6.478}, {\"title\": \"Pruning as a Domain-specific LLM Extractor\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.561, \"y\": 2.437}, {\"title\": \"XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced  In-Context Learning in Healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.782, \"y\": 8.251}, {\"title\": \"SaudiBERT: A Large Language Model Pretrained on Saudi Dialect Corpora\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.095, \"y\": 5.204}, {\"title\": \"For the Misgendered Chinese in Gender Bias Research: Multi-Task Learning  with Knowledge Distillation for Pinyin Name-Gender Prediction\", \"topic\": \"Bias in Language Models\", \"x\": 3.205, \"y\": 4.403}, {\"title\": \"A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language  Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.957, \"y\": 4.472}, {\"title\": \"VLSM-Adapter: Finetuning Vision-Language Segmentation Efficiently with  Lightweight Blocks\", \"topic\": \"Multimodal Language Models\", \"x\": 8.647, \"y\": 7.229}, {\"title\": \"Lost in Transcription: Identifying and Quantifying the Accuracy Biases  of Automatic Speech Recognition Systems Against Disfluent Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.236, \"y\": 5.559}, {\"title\": \"Reddit-Impacts: A Named Entity Recognition Dataset for Analyzing  Clinical and Social Effects of Substance Use Derived from Social Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.353, \"y\": 7.24}, {\"title\": \"Muting Whisper: A Universal Acoustic Adversarial Attack on Speech  Foundation Models\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 11.255, \"y\": 5.386}, {\"title\": \"LLMs for XAI: Future Directions for Explaining Explanations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.762, \"y\": 3.781}, {\"title\": \"Smurfs: Leveraging Multiple Proficiency Agents with Context-Efficiency  for Tool Planning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.866, \"y\": 2.633}, {\"title\": \"Digital Diagnostics: The Potential Of Large Language Models In  Recognizing Symptoms Of Common Illnesses\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.496, \"y\": 8.131}, {\"title\": \"Towards a More Inclusive AI: Progress and Perspectives in Large Language  Model Training for the S\\u00e1mi Language\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.749, \"y\": 4.314}, {\"title\": \"Can large language models understand uncommon meanings of common words?\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.953, \"y\": 3.835}, {\"title\": \"LLM-QBench: A Benchmark Towards the Best Practice for Post-training  Quantization of Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.684, \"y\": 2.172}, {\"title\": \"Hypothesis Testing Prompting Improves Deductive Reasoning in Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.759, \"y\": 2.724}, {\"title\": \"An Automatic Prompt Generation System for Tabular Data Tasks\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.154, \"y\": 3.529}, {\"title\": \"Memory-Space Visual Prompting for Efficient Vision-Language Fine-Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.575, \"y\": 7.521}, {\"title\": \"Exploring the Capabilities of Large Multimodal Models on Dense Text\", \"topic\": \"Multimodal Language Models\", \"x\": 7.916, \"y\": 7.329}, {\"title\": \"LLMs can Find Mathematical Reasoning Mistakes by Pedagogical  Chain-of-Thought\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.837, \"y\": 2.487}, {\"title\": \"Automatic question generation for propositional logical equivalences\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.206, \"y\": 4.935}, {\"title\": \"Cross-Care: Assessing the Healthcare Implications of Pre-training Data  on Language Model Bias\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.608, \"y\": 7.819}, {\"title\": \"Boosting Large Language Models with Continual Learning for Aspect-based  Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.149, \"y\": 6.789}, {\"title\": \"Parameter-Efficient Fine-Tuning With Adapters\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.009, \"y\": 2.373}, {\"title\": \"Using Machine Translation to Augment Multilingual Classification\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.551, \"y\": 4.731}, {\"title\": \"Interpretability Needs a New Paradigm\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.856, \"y\": 3.931}, {\"title\": \"Interpretable Cross-Examination Technique (ICE-T): Using highly  informative features to boost LLM performance\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.839, \"y\": 8.184}, {\"title\": \"\\\"They are uncultured\\\": Unveiling Covert Harms and Social Threats in LLM  Generated Conversations\", \"topic\": \"Bias in Language Models\", \"x\": 3.479, \"y\": 4.129}, {\"title\": \"Krey\\u00f2l-MT: Building MT for Latin American, Caribbean and Colonial  African Creole Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.556, \"y\": 5.132}, {\"title\": \"The Effect of Model Size on LLM Post-hoc Explainability via LIME\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.939, \"y\": 3.679}, {\"title\": \"Benchmarking Educational Program Repair\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.256, \"y\": 2.428}, {\"title\": \"CARE-SD: Classifier-based analysis for recognizing and eliminating  stigmatizing and doubt marker labels in electronic health records: model  development and validation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.158, \"y\": 7.855}, {\"title\": \"XAMPLER: Learning to Retrieve Cross-Lingual In-Context Examples\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.143, \"y\": 4.888}, {\"title\": \"Seeds of Stereotypes: A Large-Scale Textual Analysis of Race and Gender  Associations with Diseases in Online Sources\", \"topic\": \"Bias in Language Models\", \"x\": 3.361, \"y\": 4.554}, {\"title\": \"Improving Long Text Understanding with Knowledge Distilled from  Summarization Model\", \"topic\": \"Text Summarization\", \"x\": 5.616, \"y\": 6.207}, {\"title\": \"VisionGraph: Leveraging Large Multimodal Models for Graph Theory  Problems in Visual Context\", \"topic\": \"Multimodal Language Models\", \"x\": 8.03, \"y\": 7.529}, {\"title\": \"Fine-tuning Pre-trained Named Entity Recognition Models For Indian  Languages\", \"topic\": \"Named Entity Recognition\", \"x\": 7.432, \"y\": 6.824}, {\"title\": \"APrompt4EM: Augmented Prompt Tuning for Generalized Entity Matching\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.698, \"y\": 3.309}, {\"title\": \"DALK: Dynamic Co-Augmentation of LLMs and KG to answer Alzheimer's  Disease Questions with Scientific Literature\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.27, \"y\": 8.191}, {\"title\": \"Multi-level Shared Knowledge Guided Learning for Knowledge Graph  Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.053, \"y\": 6.011}, {\"title\": \"Utilizing Large Language Models to Generate Synthetic Data to Increase  the Performance of BERT-Based Neural Networks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.376, \"y\": 7.912}, {\"title\": \"CourseGPT-zh: an Educational Large Language Model Based on Knowledge  Distillation Incorporating Prompt Optimization\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.371, \"y\": 3.277}, {\"title\": \"Bridging the Bosphorus: Advancing Turkish Large Language Models through  Strategies for Low-Resource Language Adaptation and Benchmarking\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.996, \"y\": 4.251}, {\"title\": \"SUTRA: Scalable Multilingual Language Model Architecture\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.208, \"y\": 4.352}, {\"title\": \"Folded context condensation in Path Integral formalism for infinite  context transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.844, \"y\": 3.294}, {\"title\": \"NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and  Natural User Prompts\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.45, \"y\": 2.422}, {\"title\": \"A Transformer with Stack Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.749, \"y\": 3.373}, {\"title\": \"Analyzing Language Bias Between French and English in Conventional  Multilingual Sentiment Analysis Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.141, \"y\": 4.69}, {\"title\": \"The Silicon Ceiling: Auditing GPT's Race and Gender Biases in Hiring\", \"topic\": \"Bias in Language Models\", \"x\": 3.472, \"y\": 4.316}, {\"title\": \"Learning To See But Forgetting To Follow: Visual Instruction Tuning  Makes LLMs More Prone To Jailbreak Attacks\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.416, \"y\": 2.436}, {\"title\": \"Revisiting character-level adversarial attacks\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.147, \"y\": 2.997}, {\"title\": \"Granite Code Models: A Family of Open Foundation Models for Code  Intelligence\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.593, \"y\": 2.549}, {\"title\": \"Open Implementation and Study of BEST-RQ for Speech Processing\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.003, \"y\": 5.036}, {\"title\": \"Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is  GECScore\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.087, \"y\": 4.765}, {\"title\": \"Generating Feature Vectors from Phonetic Transcriptions in  Cross-Linguistic Data Formats\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.338, \"y\": 5.401}, {\"title\": \"D-NLP at SemEval-2024 Task 2: Evaluating Clinical Inference Capabilities  of Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.757, \"y\": 7.812}, {\"title\": \"LingML: Linguistic-Informed Machine Learning for Enhanced Fake News  Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.016, \"y\": 5.711}, {\"title\": \"MEDVOC: Vocabulary Adaptation for Fine-tuning Pre-trained Language  Models on Medical Text Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.092, \"y\": 8.15}, {\"title\": \"Fine-grained Speech Sentiment Analysis in Chinese Psychological Support  Hotlines Based on Large-scale Pre-trained Model\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.072, \"y\": 7.494}, {\"title\": \"Utilizing GPT to Enhance Text Summarization: A Strategy to Minimize  Hallucinations\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.116, \"y\": 1.143}, {\"title\": \"ESIHGNN: Event-State Interactions Infused Heterogeneous Graph Neural  Network for Conversational Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.261, \"y\": 7.773}, {\"title\": \"A Roadmap for Multilingual, Multimodal Domain Independent Deception  Detection\", \"topic\": \"Fake News Detection\", \"x\": 3.965, \"y\": 5.603}, {\"title\": \"Guylingo: The Republic of Guyana Creole Corpora\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.254, \"y\": 5.255}, {\"title\": \"Detecting Anti-Semitic Hate Speech using Transformer-based Large  Language Models\", \"topic\": \"Hate Speech Detection\", \"x\": 2.741, \"y\": 5.371}, {\"title\": \"Hire Me or Not? Examining Language Model's Behavior with Occupation  Attributes\", \"topic\": \"Bias in Language Models\", \"x\": 3.377, \"y\": 4.347}, {\"title\": \"GOVERN: Gradient Orientation Vote Ensemble for Multi-Teacher Reinforced  Distillation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.503, \"y\": 3.796}, {\"title\": \"Language-Image Models with 3D Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.769, \"y\": 7.312}, {\"title\": \"SWE-agent: Agent-Computer Interfaces Enable Automated Software  Engineering\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.577, \"y\": 2.757}, {\"title\": \"GREEN: Generative Radiology Report Evaluation and Error Notation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.124, \"y\": 8.58}, {\"title\": \"Enabling High-Sparsity Foundational Llama Models with Efficient  Pretraining and Deployment\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.363, \"y\": 2.404}, {\"title\": \"MAmmoTH2: Scaling Instructions from the Web\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.106, \"y\": 2.322}, {\"title\": \"Gaussian Stochastic Weight Averaging for Bayesian Low-Rank Adaptation of  Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.131, \"y\": 2.213}, {\"title\": \"Explainable Fake News Detection With Large Language Model via Defense  Among Competing Wisdom\", \"topic\": \"Fake News Detection\", \"x\": 3.984, \"y\": 5.742}, {\"title\": \"MedDoc-Bot: A Chat Tool for Comparative Analysis of Large Language  Models in the Context of the Pediatric Hypertension Guideline\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.425, \"y\": 7.919}, {\"title\": \"QuakeBERT: Accurate Classification of Social Media Texts for Rapid  Earthquake Impact Assessment\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.193, \"y\": 6.631}, {\"title\": \"Visual Language Model based Cross-modal Semantic Communication Systems\", \"topic\": \"Multimodal Language Models\", \"x\": 8.332, \"y\": 6.993}, {\"title\": \"Vietnamese AI Generated Text Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.058, \"y\": 4.766}, {\"title\": \"Advancing Multimodal Medical Capabilities of Gemini\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.322, \"y\": 8.502}, {\"title\": \"ERAGent: Enhancing Retrieval-Augmented Language Models with Improved  Accuracy, Efficiency, and Personalization\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.96, \"y\": 4.632}, {\"title\": \"CRAFT: Extracting and Tuning Cultural Instructions from the Wild\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.174, \"y\": 2.348}, {\"title\": \"FairMonitor: A Dual-framework for Detecting Stereotypes and Biases in  Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.41, \"y\": 4.316}, {\"title\": \"Compressing Long Context for Enhancing RAG with AMR-based Concept  Distillation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.064, \"y\": 4.717}, {\"title\": \"Exploring prompts to elicit memorization in masked language model-based  named entity recognition\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.404, \"y\": 3.3}, {\"title\": \"Parameter-Efficient Fine-Tuning with Discrete Fourier Transform\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.198, \"y\": 2.071}, {\"title\": \"MedAdapter: Efficient Test-Time Adaptation of Large Language Models  towards Medical Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.117, \"y\": 7.989}, {\"title\": \"Exploring the Compositional Deficiency of Large Language Models in  Mathematical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.837, \"y\": 2.947}, {\"title\": \"Enabling Patient-side Disease Prediction via the Integration of Patient  Narratives\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.675, \"y\": 8.272}, {\"title\": \"Relay Decoding: Concatenating Large Language Models for Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.766, \"y\": 4.41}, {\"title\": \"Stochastic RAG: End-to-End Retrieval-Augmented Generation through  Expected Utility Maximization\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.001, \"y\": 4.734}, {\"title\": \"NegativePrompt: Leveraging Psychology for Large Language Models  Enhancement via Negative Emotional Stimuli\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.616, \"y\": 7.645}, {\"title\": \"ImageInWords: Unlocking Hyper-Detailed Image Descriptions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.979, \"y\": 7.387}, {\"title\": \"ATG: Benchmarking Automated Theorem Generation for Generative Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.006, \"y\": 2.85}, {\"title\": \"Relations Prediction for Knowledge Graph Completion using Large Language  Models\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.982, \"y\": 5.92}, {\"title\": \"Enhancing News Summarization with ELearnFit through Efficient In-Context  Learning and Efficient Fine-Tuning\", \"topic\": \"Text Summarization\", \"x\": 5.503, \"y\": 6.253}, {\"title\": \"On the Information Redundancy in Non-Autoregressive Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.107, \"y\": 4.66}, {\"title\": \"R4: Reinforced Retriever-Reorder-Responder for Retrieval-Augmented Large  Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.212, \"y\": 4.397}, {\"title\": \"Random Masking Finds Winning Tickets for Parameter Efficient Fine-tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.959, \"y\": 2.426}, {\"title\": \"A Literature Review and Framework for Human Evaluation of Generative  Large Language Models in Healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.436, \"y\": 7.834}, {\"title\": \"Overview of the EHRSQL 2024 Shared Task on Reliable Text-to-SQL Modeling  on Electronic Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.846, \"y\": 7.82}, {\"title\": \"Mothman at SemEval-2024 Task 9: An Iterative System for Chain-of-Thought  Prompt Optimization\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.507, \"y\": 2.83}, {\"title\": \"What is Sentiment Meant to Mean to Language Models?\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.502, \"y\": 6.786}, {\"title\": \"Combining X-Vectors and Bayesian Batch Active Learning: Two-Stage Active  Learning Pipeline for Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.297, \"y\": 4.97}, {\"title\": \"CALRec: Contrastive Alignment of Generative LLMs For Sequential  Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.925, \"y\": 2.906}, {\"title\": \"Parameter-Efficient Instruction Tuning of Large Language Models For  Extreme Financial Numeral Labelling\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.906, \"y\": 6.861}, {\"title\": \"Instruction-Guided Bullet Point Summarization of Long Financial Earnings  Call Transcripts\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.947, \"y\": 6.782}, {\"title\": \"Hoaxpedia: A Unified Wikipedia Hoax Articles Dataset\", \"topic\": \"Fake News Detection\", \"x\": 4.061, \"y\": 5.672}, {\"title\": \"Exposing and Explaining Fake News On-the-Fly\", \"topic\": \"Fake News Detection\", \"x\": 4.075, \"y\": 5.871}, {\"title\": \"MedReadMe: A Systematic Study for Fine-grained Sentence Readability in  Medical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.95, \"y\": 7.578}, {\"title\": \"Unveiling the Potential of LLM-Based ASR on Chinese Open-Source Datasets\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.74, \"y\": 5.231}, {\"title\": \"TIPAA-SSL: Text Independent Phone-to-Audio Alignment based on  Self-Supervised Learning and Knowledge Transfer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.798, \"y\": 5.526}, {\"title\": \"Large Multimodal Model based Standardisation of Pathology Reports with  Confidence and their Prognostic Significance\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.125, \"y\": 8.482}, {\"title\": \"The Trade-off between Performance, Efficiency, and Fairness in Adapter  Modules for Text Classification\", \"topic\": \"Bias in Language Models\", \"x\": 3.397, \"y\": 4.211}, {\"title\": \"Sentiment Polarity Analysis of Bangla Food Reviews Using Machine and  Deep Learning Algorithms\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.579, \"y\": 6.561}, {\"title\": \"Dependency-Aware Semi-Structured Sparsity: Declining Roles of Outliers  in Pruning GLU-based LLMs\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.584, \"y\": 2.41}, {\"title\": \"OARelatedWork: A Large-Scale Dataset of Related Work Sections with  Full-texts from Open Access Sources\", \"topic\": \"Text Summarization\", \"x\": 5.587, \"y\": 6.344}, {\"title\": \"Aloe: A Family of Fine-tuned Open Healthcare LLMs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.877, \"y\": 8.095}, {\"title\": \"Incorporating External Knowledge and Goal Guidance for LLM-based  Conversational Recommender Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.925, \"y\": 3.038}, {\"title\": \"SGHateCheck: Functional Tests for Detecting Hate Speech in Low-Resource  Languages of Singapore\", \"topic\": \"Hate Speech Detection\", \"x\": 2.73, \"y\": 5.355}, {\"title\": \"Understanding Position Bias Effects on Fairness in Social Multi-Document  Summarization\", \"topic\": \"Bias in Language Models\", \"x\": 3.515, \"y\": 4.762}, {\"title\": \"Early Transformers: A study on Efficient Training of Transformer Models  through Early-Bird Lottery Tickets\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.702, \"y\": 3.142}, {\"title\": \"The Psychosocial Impacts of Generative AI Harms\", \"topic\": \"Bias in Language Models\", \"x\": 3.558, \"y\": 4.313}, {\"title\": \"Automatically Extracting Numerical Results from Randomized Controlled  Trials with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.711, \"y\": 7.52}, {\"title\": \"Leveraging Prompt-Learning for Structured Information Extraction from  Crohn's Disease Radiology Reports in a Low-Resource Language\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.098, \"y\": 8.543}, {\"title\": \"Prometheus 2: An Open Source Language Model Specialized in Evaluating  Other Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.205, \"y\": 3.827}, {\"title\": \"D2PO: Discriminator-Guided DPO with Response Evaluation Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.274, \"y\": 1.261}, {\"title\": \"MANTIS: Interleaved Multi-Image Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.41, \"y\": 7.387}, {\"title\": \"NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.484, \"y\": 1.475}, {\"title\": \"V-FLUTE: Visual Figurative Language Understanding with Textual  Explanations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.541, \"y\": 7.576}, {\"title\": \"UQA: Corpus for Urdu Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.486, \"y\": 5.249}, {\"title\": \"MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language  Models using 2D Priors\", \"topic\": \"Multimodal Language Models\", \"x\": 8.738, \"y\": 7.247}, {\"title\": \"Unsupervised Flow Discovery from Task-oriented Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.421, \"y\": 3.928}, {\"title\": \"Topics in the Study of the Pragmatic Functions of Phonetic Reduction in  Dialog\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.756, \"y\": 5.433}, {\"title\": \"Sequence-to-sequence models in peer-to-peer learning: A practical  application\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.068, \"y\": 5.169}, {\"title\": \"Low-resource speech recognition and dialect identification of Irish in a  multi-task framework\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.884, \"y\": 5.398}, {\"title\": \"Reinforcement Learning for Edit-Based Non-Autoregressive Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 6.751, \"y\": 1.712}, {\"title\": \"Prompt engineering paradigms for medical applications: scoping review  and recommendations for better practices\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 5.868, \"y\": 7.559}, {\"title\": \"Boosting Jailbreak Attack with Momentum\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.257, \"y\": 2.387}, {\"title\": \"Few Shot Class Incremental Learning using Vision-Language models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.524, \"y\": 6.868}, {\"title\": \"Bayesian Optimization with LLM-Based Acquisition Functions for Natural  Language Preference Elicitation\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.279, \"y\": 1.386}, {\"title\": \"Language Fairness in Multilingual Information Retrieval\", \"topic\": \"Bias in Language Models\", \"x\": 3.425, \"y\": 4.26}, {\"title\": \"Distillation for Multilingual Information Retrieval\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.458, \"y\": 4.897}, {\"title\": \"Efficient Compression of Multitask Multilingual Speech Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.101, \"y\": 5.082}, {\"title\": \"Modeling Empathetic Alignment in Conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.685, \"y\": 7.912}, {\"title\": \"A Named Entity Recognition and Topic Modeling-based Solution for  Locating and Better Assessment of Natural Disasters in Social Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.156, \"y\": 6.584}, {\"title\": \"Uncovering Agendas: A Novel French & English Dataset for Agenda  Detection on Social Media\", \"topic\": \"Fake News Detection\", \"x\": 3.74, \"y\": 5.828}, {\"title\": \"Self-Play Preference Optimization for Language Model Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.33, \"y\": 1.404}, {\"title\": \"RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document  Abstractive Summarization\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.247, \"y\": 2.01}, {\"title\": \"When Quantization Affects Confidence of Large Language Models?\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.73, \"y\": 2.188}, {\"title\": \"Are Models Biased on Text without Gender-related Language?\", \"topic\": \"Bias in Language Models\", \"x\": 3.208, \"y\": 4.423}, {\"title\": \"The Real, the Better: Aligning Large Language Models with Online Human  Behaviors\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.251, \"y\": 1.49}, {\"title\": \"NumLLM: Numeric-Sensitive Large Language Model for Chinese Finance\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.866, \"y\": 6.838}, {\"title\": \"Mixture of insighTful Experts (MoTE): The Synergy of Thought Chains and  Expert Mixtures in Self-Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.56, \"y\": 1.578}, {\"title\": \"A Legal Framework for Natural Language Processing Model Training in  Portugal\", \"topic\": \"Legal NLP\", \"x\": 5.25, \"y\": 5.551}, {\"title\": \"DAM: A Universal Dual Attention Mechanism for Multimodal Timeseries  Cryptocurrency Trend Forecasting\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.476, \"y\": 6.79}, {\"title\": \"GOLD: Geometry Problem Solver with Natural Language Description\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.086, \"y\": 2.993}, {\"title\": \"Harnessing the Power of Multiple Minds: Lessons Learned from LLM Routing\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.471, \"y\": 2.63}, {\"title\": \"BiomedRAG: A Retrieval Augmented Large Language Model for Biomedicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.107, \"y\": 7.723}, {\"title\": \"Enhancing Surgical Robots with Embodied Intelligence for Autonomous  Ultrasound Scanning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.513, \"y\": 8.341}, {\"title\": \"MetaRM: Shifted Distributions Alignment via Meta-Learning\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.213, \"y\": 1.475}, {\"title\": \"Efficient Sample-Specific Encoder Perturbations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.168, \"y\": 5.02}, {\"title\": \"AdaMoLE: Fine-Tuning Large Language Models with Adaptive Mixture of  Low-Rank Adaptation Experts\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.124, \"y\": 2.077}, {\"title\": \"A Careful Examination of Large Language Model Performance on Grade  School Arithmetic\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.934, \"y\": 2.914}, {\"title\": \"DFKI-NLP at SemEval-2024 Task 2: Towards Robust LLMs Using Data  Perturbations and MinMax Training\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.717, \"y\": 7.689}, {\"title\": \"CodeHalu: Code Hallucinations in LLMs Driven by Execution-based  Verification\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.177, \"y\": 1.058}, {\"title\": \"Graphical Reasoning: LLM-based Semi-Open Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.968, \"y\": 6.741}, {\"title\": \"A Primer on the Inner Workings of Transformer-based Language Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.195, \"y\": 3.671}, {\"title\": \"General Purpose Verification for Chain of Thought Prompting\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.643, \"y\": 2.473}, {\"title\": \"SPAFIT: Stratified Progressive Adaptation Fine-tuning for Pre-trained  Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.968, \"y\": 2.423}, {\"title\": \"In-Context Learning with Long-Context Models: An In-Depth Exploration\", \"topic\": \"In-Context Learning\", \"x\": 8.414, \"y\": 3.402}, {\"title\": \"Towards a Search Engine for Machines: Unified Ranking for Multiple  Retrieval-Augmented Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.17, \"y\": 4.692}, {\"title\": \"Transforming Dutch: Debiasing Dutch Coreference Resolution Systems for  Non-binary Pronouns\", \"topic\": \"Bias in Language Models\", \"x\": 3.074, \"y\": 4.491}, {\"title\": \"Graph Neural Network Approach to Semantic Type Detection in Tables\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.08, \"y\": 5.798}, {\"title\": \"DOCCI: Descriptions of Connected and Contrasting Images\", \"topic\": \"Multimodal Language Models\", \"x\": 8.941, \"y\": 7.326}, {\"title\": \"Iterative Reasoning Preference Optimization\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.592, \"y\": 1.982}, {\"title\": \"ThangDLU at #SMM4H 2024: Encoder-decoder models for classifying text  data on social disorders in children and adolescents\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.147, \"y\": 7.106}, {\"title\": \"Automated Generation of High-Quality Medical Simulation Scenarios  Through Integration of Semi-Structured Data and Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.569, \"y\": 7.973}, {\"title\": \"When to Retrieve: Teaching LLMs to Utilize Information Retrieval  Effectively\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.138, \"y\": 4.528}, {\"title\": \"Naturally Supervised 3D Visual Grounding with Language-Regularized  Concept Learners\", \"topic\": \"Multimodal Language Models\", \"x\": 8.707, \"y\": 7.292}, {\"title\": \"Improving Disease Detection from Social Media Text via Self-Augmentation  and Contrastive Learning\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.344, \"y\": 7.225}, {\"title\": \"Transferring Troubles: Cross-Lingual Transferability of Backdoor Attacks  in LLMs with Instruction Tuning\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.362, \"y\": 2.452}, {\"title\": \"RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural  Language Processing\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.94, \"y\": 4.543}, {\"title\": \"Context-Aware Machine Translation with Source Coreference Explanation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.715, \"y\": 4.332}, {\"title\": \"Safe Training with Sensitive In-domain Data: Leveraging Data  Fragmentation To Mitigate Linkage Attacks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.994, \"y\": 8.131}, {\"title\": \"Which Nigerian-Pidgin does Generative AI speak?: Issues about  Representativeness and Bias for Multilingual and Low Resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.206, \"y\": 5.277}, {\"title\": \"Can Large Language Models put 2 and 2 together? Probing for Entailed  Arithmetical Relationships\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.786, \"y\": 3.087}, {\"title\": \"Countering Reward Over-optimization in LLM with Demonstration-Guided  Reinforcement Learning\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.195, \"y\": 1.686}, {\"title\": \"Evaluating Lexicon Incorporation for Depression Symptom Estimation\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.151, \"y\": 7.497}, {\"title\": \"StablePT: Towards Stable Prompting for Few-shot Learning via Input  Separation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.704, \"y\": 3.528}, {\"title\": \"Knowledge Distillation vs. Pretraining from Scratch under a Fixed  (Computation) Budget\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.209, \"y\": 3.718}, {\"title\": \"QLSC: A Query Latent Semantic Calibrator for Robust Extractive Question  Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.603, \"y\": 5.13}, {\"title\": \"Does Whisper understand Swiss German? An automatic, qualitative, and  human evaluation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.098, \"y\": 5.387}, {\"title\": \"Large Language Model Agent for Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.092, \"y\": 5.702}, {\"title\": \"Exploiting Hatred by Targets for Hate Speech Detection on Vietnamese  Social Media Texts\", \"topic\": \"Hate Speech Detection\", \"x\": 2.831, \"y\": 5.431}, {\"title\": \"HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.144, \"y\": 2.099}, {\"title\": \"Multi-hop Question Answering over Knowledge Graphs using Large Language  Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.786, \"y\": 5.447}, {\"title\": \"GRAMMAR: Grounded and Modular Methodology for Assessment of  Domain-Specific Retrieval-Augmented Language Model\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.909, \"y\": 4.662}, {\"title\": \"Transcrib3D: 3D Referring Expression Resolution through Large Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.846, \"y\": 7.092}, {\"title\": \"Mix of Experts Language Model for Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.331, \"y\": 6.762}, {\"title\": \"Modeling Caption Diversity in Contrastive Vision-Language Pretraining\", \"topic\": \"Multimodal Language Models\", \"x\": 9.021, \"y\": 7.295}, {\"title\": \"Revenge of the Fallen? Recurrent Models Match Transformers at Predicting  Human Language Comprehension Metrics\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.649, \"y\": 3.377}, {\"title\": \"What Drives Performance in Multilingual Language Models?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.086, \"y\": 4.401}, {\"title\": \"Q-GroundCAM: Quantifying Grounding in Vision Language Models via GradCAM\", \"topic\": \"Multimodal Language Models\", \"x\": 8.778, \"y\": 7.552}, {\"title\": \"Blind Spots and Biases: Exploring the Role of Annotator Cognitive Biases  in NLP\", \"topic\": \"Bias in Language Models\", \"x\": 3.47, \"y\": 4.543}, {\"title\": \"SuperCLUE-Fin: Graded Fine-Grained Analysis of Chinese LLMs on Diverse  Financial Tasks and Applications\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.903, \"y\": 6.816}, {\"title\": \"DPO Meets PPO: Reinforced Token Optimization for RLHF\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.191, \"y\": 1.553}, {\"title\": \"Markovian Agents for Informative Language Modeling\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.692, \"y\": 2.311}, {\"title\": \"Truth-value judgment in language models: belief directions are context  sensitive\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.81, \"y\": 3.519}, {\"title\": \"A Comprehensive Rubric for Annotating Pathological Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.111, \"y\": 5.711}, {\"title\": \"Unknown Script: Impact of Script on Cross-Lingual Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.356, \"y\": 4.707}, {\"title\": \"Towards A Structured Overview of Use Cases for Natural Language  Processing in the Legal Domain: A German Perspective\", \"topic\": \"Legal NLP\", \"x\": 5.231, \"y\": 5.662}, {\"title\": \"Foundations of Multisensory Artificial Intelligence\", \"topic\": \"Multimodal Language Models\", \"x\": 8.083, \"y\": 7.181}, {\"title\": \"Towards Dog Bark Decoding: Leveraging Human Speech Processing for  Automated Bark Classification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.824, \"y\": 5.185}, {\"title\": \"The Constant in HATE: Analyzing Toxicity in Reddit across Topics and  Languages\", \"topic\": \"Hate Speech Detection\", \"x\": 2.93, \"y\": 5.257}, {\"title\": \"Simplifying Multimodality: Unimodal Approach to Multimodal Challenges in  Radiology with General-Domain Large Language Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.543, \"y\": 8.301}, {\"title\": \"A cost minimization approach to fix the vocabulary size in a tokenizer  for an End-to-End ASR system\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.948, \"y\": 5.108}, {\"title\": \"Do Vision & Language Decoders use Images and Text equally? How  Self-consistent are their Explanations?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.434, \"y\": 7.533}, {\"title\": \"PoPE: Legendre Orthogonal Polynomials Based Position Encoding for Large  Language Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.644, \"y\": 3.478}, {\"title\": \"Injecting Salesperson's Dialogue Strategies in Large Language Models  with Chain-of-Thought Reasoning\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.362, \"y\": 3.566}, {\"title\": \"MileBench: Benchmarking MLLMs in Long Context\", \"topic\": \"Multimodal Language Models\", \"x\": 7.965, \"y\": 7.404}, {\"title\": \"GPT-4 passes most of the 297 written Polish Board Certification  Examinations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.717, \"y\": 7.978}, {\"title\": \"ECC Analyzer: Extract Trading Signal from Earnings Conference Calls  using Large Language Model for Stock Performance Prediction\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.759, \"y\": 6.797}, {\"title\": \"BMRetriever: Tuning Large Language Models as Better Biomedical Text  Retrievers\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.204, \"y\": 7.645}, {\"title\": \"Capabilities of Gemini Models in Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.384, \"y\": 8.249}, {\"title\": \"LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.144, \"y\": 2.139}, {\"title\": \"Mixture-of-Instructions: Comprehensive Alignment of a Large Language  Model through the Mixture of Diverse System Prompting Instructions\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.382, \"y\": 2.289}, {\"title\": \"LLM-SR: Scientific Equation Discovery via Programming with Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.794, \"y\": 3.308}, {\"title\": \"MM-TTS: A Unified Framework for Multimodal, Prompt-Induced Emotional  Text-to-Speech Synthesis\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.314, \"y\": 7.793}, {\"title\": \"Exploring the Limits of Fine-grained LLM-based Physics Inference via  Premise Removal Interventions\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.801, \"y\": 3.238}, {\"title\": \"Towards Unbiased Evaluation of Detecting Unanswerable Questions in  EHRSQL\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.841, \"y\": 7.652}, {\"title\": \"Comparing LLM prompting with Cross-lingual transfer performance on  Indigenous and Low-resource Brazilian Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.236, \"y\": 4.507}, {\"title\": \"Bias Neutralization Framework: Measuring Fairness in Large Language  Models with Bias Intelligence Quotient (BiQ)\", \"topic\": \"Bias in Language Models\", \"x\": 3.413, \"y\": 4.26}, {\"title\": \"Transfer Learning and Transformer Architecture for Financial Sentiment  Analysis\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.685, \"y\": 6.868}, {\"title\": \"LEGENT: Open Platform for Embodied Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.642, \"y\": 2.843}, {\"title\": \"EkoHate: Abusive Language and Hate Speech Detection for Code-switched  Political Discussions on Nigerian Twitter\", \"topic\": \"Hate Speech Detection\", \"x\": 2.737, \"y\": 5.408}, {\"title\": \"Logic Agent: Enhancing Validity with Logic Rule Invocation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.536, \"y\": 2.532}, {\"title\": \"USAT: A Universal Speaker-Adaptive Text-to-Speech Approach\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.572, \"y\": 5.709}, {\"title\": \"CRE-LLM: A Domain-Specific Chinese Relation Extraction Framework with  Fine-tuned Large Language Model\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.862, \"y\": 6.467}, {\"title\": \"Quality Estimation with $k$-nearest Neighbors and Automatic Evaluation  for Model-specific Quality Estimation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.872, \"y\": 4.594}, {\"title\": \"MediFact at MEDIQA-CORR 2024: Why AI Needs a Human Touch\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.695, \"y\": 8.139}, {\"title\": \"Enhancing Pre-Trained Generative Language Models with Question Attended  Span Extraction on Machine Reading Comprehension\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.535, \"y\": 5.153}, {\"title\": \"Detection of Conspiracy Theories Beyond Keyword Bias in German-Language  Telegram Using Large Language Models\", \"topic\": \"Fake News Detection\", \"x\": 3.975, \"y\": 5.692}, {\"title\": \"TI-ASU: Toward Robust Automatic Speech Understanding through  Text-to-speech Imputation Against Missing Speech Modality\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.026, \"y\": 5.27}, {\"title\": \"Usefulness of Emotional Prosody in Neural Machine Translation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.264, \"y\": 7.812}, {\"title\": \"Transfer Learning Enhanced Single-choice Decision for Multi-choice  Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.544, \"y\": 5.338}, {\"title\": \"Spatio-Temporal Side Tuning Pre-trained Foundation Models for  Video-based Pedestrian Attribute Recognition\", \"topic\": \"Multimodal Language Models\", \"x\": 8.737, \"y\": 7.429}, {\"title\": \"SERPENT-VLM : Self-Refining Radiology Report Generation Using Vision  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.262, \"y\": 8.603}, {\"title\": \"Tool Calling: Enhancing Medication Consultation via Retrieval-Augmented  Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.851, \"y\": 7.759}, {\"title\": \"From Languages to Geographies: Towards Evaluating Cultural Bias in Hate  Speech Datasets\", \"topic\": \"Hate Speech Detection\", \"x\": 2.939, \"y\": 5.206}, {\"title\": \"Revisiting Multimodal Emotion Recognition in Conversation from the  Perspective of Graph Spectrum\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.281, \"y\": 7.755}, {\"title\": \"Revisiting Multi-modal Emotion Learning with Broad State Space Models  and Probability-guidance Fusion\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.259, \"y\": 7.82}, {\"title\": \"VANER: Leveraging Large Language Model for Versatile and Adaptive  Biomedical Named Entity Recognition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.394, \"y\": 7.537}, {\"title\": \"T-CLAP: Temporal-Enhanced Contrastive Language-Audio Pretraining\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.656, \"y\": 5.518}, {\"title\": \"Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing  Japanese Language Capabilities\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.058, \"y\": 4.051}, {\"title\": \"Medical Vision-Language Pre-Training for Brain Abnormalities\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.578, \"y\": 8.319}, {\"title\": \"MRScore: Evaluating Radiology Report Generation with LLM-based Reward  System\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.118, \"y\": 8.563}, {\"title\": \"Evaluating the Application of ChatGPT in Outpatient Triage Guidance: A  Comparative Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.484, \"y\": 8.081}, {\"title\": \"UMass-BioNLP at MEDIQA-M3G 2024: DermPrompt -- A Systematic Exploration  of Prompt Engineering with GPT-4V for Dermatological Diagnosis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.953, \"y\": 8.324}, {\"title\": \"PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction  in Murder Mystery Games\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.276, \"y\": 3.203}, {\"title\": \"A Semi-Automatic Approach to Create Large Gender- and Age-Balanced  Speaker Corpora: Usefulness of Speaker Diarization & Identification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.822, \"y\": 5.621}, {\"title\": \"Language Interaction Network for Clinical Trial Approval Estimation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.707, \"y\": 7.801}, {\"title\": \"Child Speech Recognition in Human-Robot Interaction: Problem Solved?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.197, \"y\": 5.435}, {\"title\": \"Can a Multichoice Dataset be Repurposed for Extractive Question  Answering?\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.384, \"y\": 5.153}, {\"title\": \"Speech Technology Services for Oral History Research\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.906, \"y\": 5.562}, {\"title\": \"Prompting Techniques for Reducing Social Bias in LLMs through System 1  and System 2 Cognitive Processes\", \"topic\": \"Bias in Language Models\", \"x\": 3.666, \"y\": 4.17}, {\"title\": \"Prompting Towards Alleviating Code-Switched Data Scarcity in  Under-Resourced Languages with GPT as a Pivot\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.234, \"y\": 4.824}, {\"title\": \"TIGQA:An Expert Annotated Question Answering Dataset in Tigrinya\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.354, \"y\": 5.142}, {\"title\": \"Prevalent Frequency of Emotional and Physical Symptoms in Social Anxiety  using Zero Shot Classification: An Observational Study\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.139, \"y\": 7.282}, {\"title\": \"HateTinyLLM : Hate Speech Detection Using Tiny Large Language Models\", \"topic\": \"Hate Speech Detection\", \"x\": 2.774, \"y\": 5.424}, {\"title\": \"Text Sentiment Analysis and Classification Based on Bidirectional Gated  Recurrent Units (GRUs) Model\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.58, \"y\": 6.664}, {\"title\": \"CoSD: Collaborative Stance Detection with Contrastive Heterogeneous  Topic Graph Learning\", \"topic\": \"Fake News Detection\", \"x\": 3.502, \"y\": 5.864}, {\"title\": \"Evaluating Class Membership Relations in Knowledge Graphs using Large  Language Models\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.982, \"y\": 5.758}, {\"title\": \"Make-it-Real: Unleashing Large Multimodal Model for Painting 3D Objects  with Realistic Materials\", \"topic\": \"Multimodal Language Models\", \"x\": 8.266, \"y\": 7.426}, {\"title\": \"Weak-to-Strong Extrapolation Expedites Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.395, \"y\": 1.418}, {\"title\": \"Modeling Selective Feature Attention for Representation-based Siamese  Text Matching\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.704, \"y\": 3.356}, {\"title\": \"REBEL: Reinforcement Learning via Regressing Relative Rewards\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.173, \"y\": 1.687}, {\"title\": \"Prefix Text as a Yarn: Eliciting Non-English Alignment in Foundation  Language Model\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.363, \"y\": 4.715}, {\"title\": \"Automatic Speech Recognition System-Independent Word Error Rate  Estimation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.217, \"y\": 5.537}, {\"title\": \"Cooperate or Collapse: Emergence of Sustainability Behaviors in a  Society of LLM Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.079, \"y\": 3.092}, {\"title\": \"Large Language Models in the Clinic: A Comprehensive Benchmark\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.728, \"y\": 8.033}, {\"title\": \"Adapting Open-Source Large Language Models for Cost-Effective,  Expert-Level Clinical Note Generation with On-Policy Reinforcement Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.681, \"y\": 8.041}, {\"title\": \"ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through  Probabilistic Threshold Filtering and Error Handling\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.972, \"y\": 7.67}, {\"title\": \"Incorporating Lexical and Syntactic Knowledge for Unsupervised  Cross-Lingual Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.324, \"y\": 4.849}, {\"title\": \"Hippocrates: An Open-Source Framework for Advancing Large Language  Models in Healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.742, \"y\": 8.038}, {\"title\": \"Samsung Research China-Beijing at SemEval-2024 Task 3: A multi-stage  framework for Emotion-Cause Pair Extraction in Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.301, \"y\": 7.71}, {\"title\": \"Building a Japanese Document-Level Relation Extraction Dataset Assisted  by Cross-Lingual Transfer\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.902, \"y\": 6.85}, {\"title\": \"Instruction Matters, a Simple yet Effective Task Selection Approach in  Instruction Tuning for Specific Tasks\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.353, \"y\": 2.418}, {\"title\": \"List Items One by One: A New Data Source and Learning Paradigm for  Multimodal LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.359, \"y\": 7.578}, {\"title\": \"Don't Say No: Jailbreaking LLM by Suppressing Refusal\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.273, \"y\": 2.27}, {\"title\": \"Learning Syntax Without Planting Trees: Understanding When and Why  Transformers Generalize Hierarchically\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.106, \"y\": 3.814}, {\"title\": \"Digital ASIC Design with Ongoing LLMs: Strategies and Prospects\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.52, \"y\": 2.7}, {\"title\": \"Fake Artificial Intelligence Generated Contents (FAIGC): A Survey of  Theories, Detection Methods, and Opportunities\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.245, \"y\": 4.876}, {\"title\": \"LLM-Based Section Identifiers Excel on Open Source but Stumble in Real  World Applications\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.763, \"y\": 8.102}, {\"title\": \"Translation of Multifaceted Data without Re-Training of Machine  Translation Systems\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.752, \"y\": 4.655}, {\"title\": \"Investigating the prompt leakage effect and black-box defenses for  multi-turn LLM interactions\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.404, \"y\": 2.577}, {\"title\": \"URL: Universal Referential Knowledge Linking via Task-instructed  Representation Compression\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.148, \"y\": 6.177}, {\"title\": \"Knowledge Graph Completion using Structural and Textual Embeddings\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.013, \"y\": 6.062}, {\"title\": \"Towards Efficient Patient Recruitment for Clinical Trials: Application  of a Prompt-Based Learning Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.835, \"y\": 7.879}, {\"title\": \"FairDeDup: Detecting and Mitigating Vision-Language Fairness Disparities  in Semantic Dataset Deduplication\", \"topic\": \"Bias in Language Models\", \"x\": 3.351, \"y\": 4.268}, {\"title\": \"Evolution of Voices in French Audiovisual Media Across Genders and Age  in a Diachronic Perspective\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.642, \"y\": 5.621}, {\"title\": \"Cantor: Inspiring Multimodal Chain-of-Thought of MLLM\", \"topic\": \"Multimodal Language Models\", \"x\": 8.049, \"y\": 7.726}, {\"title\": \"MoDE: CLIP Data Experts via Clustering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.802, \"y\": 7.06}, {\"title\": \"Generalization Measures for Zero-Shot Cross-Lingual Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.432, \"y\": 4.711}, {\"title\": \"Inside the echo chamber: Linguistic underpinnings of misinformation on  Twitter\", \"topic\": \"Fake News Detection\", \"x\": 3.497, \"y\": 5.598}, {\"title\": \"Assessing The Potential Of Mid-Sized Language Models For Clinical QA\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.68, \"y\": 7.926}, {\"title\": \"From Complex to Simple: Enhancing Multi-Constraint Complex Instruction  Following Ability of Large Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.077, \"y\": 2.403}, {\"title\": \"BERT vs GPT for financial engineering\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.776, \"y\": 6.84}, {\"title\": \"One Subgraph for All: Efficient Reasoning on Opening Subgraphs for  Inductive Knowledge Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.986, \"y\": 5.902}, {\"title\": \"A Comprehensive Survey on Evaluating Large Language Model Applications  in the Medical Industry\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.668, \"y\": 7.853}, {\"title\": \"ChEX: Interactive Localization and Region Description in Chest X-rays\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.245, \"y\": 8.595}, {\"title\": \"Let's Think Dot by Dot: Hidden Computation in Transformer Language  Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.346, \"y\": 3.477}, {\"title\": \"No Train but Gain: Language Arithmetic for training-free Language  Adapters enhancement\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.44, \"y\": 4.626}, {\"title\": \"Nyonic Technical Report\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.695, \"y\": 4.043}, {\"title\": \"Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.582, \"y\": 2.339}, {\"title\": \"CatLIP: CLIP-level Visual Recognition Accuracy with 2.7x Faster  Pre-training on Web-scale Image-Text Data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.756, \"y\": 7.115}, {\"title\": \"Semantic Evolvement Enhanced Graph Autoencoder for Rumor Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.046, \"y\": 5.862}, {\"title\": \"ImplicitAVE: An Open-Source Dataset and Multimodal LLMs Benchmark for  Implicit Attribute Value Extraction\", \"topic\": \"Multimodal Language Models\", \"x\": 7.889, \"y\": 7.195}, {\"title\": \"Gated Low-rank Adaptation for personalized Code-Switching Automatic  Speech Recognition on the low-spec devices\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.856, \"y\": 5.109}, {\"title\": \"Can Foundational Large Language Models Assist with Conducting  Pharmaceuticals Manufacturing Investigations?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.835, \"y\": 7.49}, {\"title\": \"CASPR: Automated Evaluation Metric for Contrastive Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.415, \"y\": 6.189}, {\"title\": \"PRISM: Patient Records Interpretation for Semantic Clinical Trial  Matching using Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.759, \"y\": 7.913}, {\"title\": \"BattleAgent: Multi-modal Dynamic Emulation on Historical Battles to  Complement Historical Analysis\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.227, \"y\": 3.118}, {\"title\": \"LogicBench: Towards Systematic Evaluation of Logical Reasoning Ability  of Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.556, \"y\": 3.093}, {\"title\": \"Killkan: The Automatic Speech Recognition Dataset for Kichwa with  Morphosyntactic Information\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.465, \"y\": 5.582}, {\"title\": \"IryoNLP at MEDIQA-CORR 2024: Tackling the Medical Error Detection &  Correction Task On the Shoulders of Medical Agents\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.665, \"y\": 8.082}, {\"title\": \"Evaluating LLMs for Hardware Design and Test\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.53, \"y\": 2.642}, {\"title\": \"Wiki-LLaVA: Hierarchical Retrieval-Augmented Generation for Multimodal  LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.059, \"y\": 7.758}, {\"title\": \"CT-GLIP: 3D Grounded Language-Image Pretraining with CT Scans and  Radiology Reports for Full-Body Scenarios\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.55, \"y\": 8.39}, {\"title\": \"Automatic Layout Planning for Visually-Rich Documents with  Instruction-Following Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.191, \"y\": 7.079}, {\"title\": \"Aligning LLM Agents by Learning Latent Preference from User Edits\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.286, \"y\": 1.464}, {\"title\": \"Re-Thinking Inverse Graphics With Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.617, \"y\": 7.424}, {\"title\": \"The Power of the Noisy Channel: Unsupervised End-to-End Task-Oriented  Dialogue with LLMs\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.517, \"y\": 3.662}, {\"title\": \"Does Instruction Tuning Make LLMs More Consistent?\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.193, \"y\": 2.457}, {\"title\": \"Setting up the Data Printer with Improved English to Ukrainian Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.38, \"y\": 4.385}, {\"title\": \"Regressive Side Effects of Training Language Models to Mimic Student  Misconceptions\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.434, \"y\": 1.38}, {\"title\": \"Bias patterns in the application of LLMs for clinical decision support:  A comprehensive study\", \"topic\": \"Bias in Language Models\", \"x\": 3.725, \"y\": 4.434}, {\"title\": \"MedDr: Diagnosis-Guided Bootstrapping for Large-Scale Medical  Vision-Language Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.339, \"y\": 8.414}, {\"title\": \"Identifying Fairness Issues in Automatically Generated Testing Content\", \"topic\": \"Bias in Language Models\", \"x\": 3.469, \"y\": 4.182}, {\"title\": \"Transformers Can Represent $n$-gram Language Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.153, \"y\": 3.732}, {\"title\": \"A Reproducibility Study of PLAID\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.706, \"y\": 4.969}, {\"title\": \"Achieving >97% on GSM8K: Deeply Understanding the Problems Makes LLMs  Better Solvers for Math Word Problems\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.991, \"y\": 2.697}, {\"title\": \"StoryTTS: A Highly Expressive Text-to-Speech Dataset with Rich Textual  Expressiveness Annotations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.468, \"y\": 5.855}, {\"title\": \"Does It Make Sense to Explain a Black Box With Another Black Box?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.773, \"y\": 3.86}, {\"title\": \"Beyond Code Generation: An Observational Study of ChatGPT Usage in  Software Engineering Practice\", \"topic\": \"Bias in Language Models\", \"x\": 5.239, \"y\": 4.313}, {\"title\": \"Sentence-Level or Token-Level? A Comprehensive Study on Knowledge  Distillation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.5, \"y\": 3.854}, {\"title\": \"Pattern-Aware Chain-of-Thought Prompting in Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.667, \"y\": 2.356}, {\"title\": \"Talk Too Much: Poisoning Large Language Models under Token Limit\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.461, \"y\": 2.601}, {\"title\": \"Med42 -- Evaluating Fine-Tuning Strategies for Medical LLMs:  Full-Parameter vs. Parameter-Efficient Approaches\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.963, \"y\": 7.918}, {\"title\": \"CT-Agent: Clinical Trial Multi-Agent with Large Language Model-based  Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.652, \"y\": 8.193}, {\"title\": \"Simulating Task-Oriented Dialogues with State Transition Graphs and  Large Language Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.45, \"y\": 3.666}, {\"title\": \"SHED: Shapley-Based Automated Dataset Refinement for Instruction  Fine-Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.217, \"y\": 2.303}, {\"title\": \"Generate-on-Graph: Treat LLM as both Agent and KG in Incomplete  Knowledge Graph Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.721, \"y\": 5.529}, {\"title\": \"Insights into Alignment: Evaluating DPO and its Variants Across Multiple  Tasks\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.448, \"y\": 1.418}, {\"title\": \"Bayesian Example Selection Improves In-Context Learning for Speech,  Text, and Visual Modalities\", \"topic\": \"In-Context Learning\", \"x\": 8.293, \"y\": 3.427}, {\"title\": \"FINEMATCH: Aspect-based Fine-grained Image and Text Mismatch Detection  and Correction\", \"topic\": \"Multimodal Language Models\", \"x\": 8.697, \"y\": 7.228}, {\"title\": \"FlashSpeech: Efficient Zero-Shot Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.58, \"y\": 5.946}, {\"title\": \"MisgenderMender: A Community-Informed Approach to Interventions for  Misgendering\", \"topic\": \"Bias in Language Models\", \"x\": 3.046, \"y\": 4.551}, {\"title\": \"Pegasus-v1 Technical Report\", \"topic\": \"Multimodal Language Models\", \"x\": 8.769, \"y\": 7.904}, {\"title\": \"Automated Multi-Language to English Machine Translation Using Generative  Pre-Trained Transformers\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.68, \"y\": 4.68}, {\"title\": \"A Survey on the Real Power of ChatGPT\", \"topic\": \"Bias in Language Models\", \"x\": 5.055, \"y\": 4.522}, {\"title\": \"Q-Tuning: Queue-based Prompt Tuning for Lifelong Few-shot Language  Learning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.815, \"y\": 3.273}, {\"title\": \"Describe-then-Reason: Improving Multimodal Mathematical Reasoning  through Visual Comprehension Training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.174, \"y\": 7.707}, {\"title\": \"WangLab at MEDIQA-M3G 2024: Multimodal Medical Answer Generation using  Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.519, \"y\": 8.167}, {\"title\": \"WangLab at MEDIQA-CORR 2024: Optimized LLM-based Programs for Medical  Error Detection and Correction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.669, \"y\": 8.097}, {\"title\": \"PARAMANU-GANITA: Language Model with Mathematical Capabilities\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.256, \"y\": 2.889}, {\"title\": \"A Multimodal Automated Interpretability Agent\", \"topic\": \"Multimodal Language Models\", \"x\": 8.383, \"y\": 7.47}, {\"title\": \"Less Peaky and More Accurate CTC Forced Alignment by Label Priors\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.135, \"y\": 5.06}, {\"title\": \"Zero-shot Cross-lingual Stance Detection via Adversarial Language  Adaptation\", \"topic\": \"Fake News Detection\", \"x\": 3.38, \"y\": 5.914}, {\"title\": \"Self-Supervised Alignment with Mutual Information: Learning to Follow  Principles without Preference Labels\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.51, \"y\": 1.476}, {\"title\": \"Detecting and Mitigating Hallucination in Large Vision Language Models  via Fine-Grained AI Feedback\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.283, \"y\": 1.021}, {\"title\": \"Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy  Data in Misaligned Languages Suffice?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.51, \"y\": 4.273}, {\"title\": \"Bored to Death: Artificial Intelligence Research Reveals the Role of  Boredom in Suicide Behavior\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.185, \"y\": 7.381}, {\"title\": \"LLMs Know What They Need: Leveraging a Missing Information Guided  Framework to Empower Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.023, \"y\": 4.721}, {\"title\": \"Tree of Reviews: A Tree-based Dynamic Iterative Retrieval Framework for  Multi-hop Question Answering\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.517, \"y\": 2.616}, {\"title\": \"DAIC-WOZ: On the Validity of Using the Therapist's prompts in Automatic  Depression Detection from Clinical Interviews\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.202, \"y\": 7.604}, {\"title\": \"Information Re-Organization Improves Reasoning in Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.732, \"y\": 2.881}, {\"title\": \"Do not think pink elephant!\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.562, \"y\": 2.623}, {\"title\": \"Protecting Your LLMs with Information Bottleneck\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.345, \"y\": 2.351}, {\"title\": \"A User-Centric Benchmark for Evaluating Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.175, \"y\": 3.858}, {\"title\": \"MARIO Eval: Evaluate Your Math LLM with your Math LLM--A mathematical  dataset evaluation toolkit\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.899, \"y\": 2.882}, {\"title\": \"Adaptive Collaboration Strategy for LLMs in Medical Decision Making\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.775, \"y\": 8.234}, {\"title\": \"Competition Report: Finding Universal Jailbreak Backdoors in Aligned  LLMs\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.332, \"y\": 2.384}, {\"title\": \"VALOR-EVAL: Holistic Coverage and Faithfulness Evaluation of Large  Vision-Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.095, \"y\": 0.976}, {\"title\": \"EventLens: Leveraging Event-Aware Pretraining and Cross-modal Linking  Enhances Visual Commonsense Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.359, \"y\": 7.599}, {\"title\": \"Filtered Direct Preference Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.288, \"y\": 1.319}, {\"title\": \"MixLoRA: Enhancing Large Language Models Fine-Tuning with LoRA-based  Mixture of Experts\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.052, \"y\": 2.115}, {\"title\": \"From LLM to NMT: Advancing Low-Resource Machine Translation with Claude\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.82, \"y\": 4.48}, {\"title\": \"Counterfactual Reasoning Using Predicted Latent Personality Dimensions  for Optimizing Persuasion Outcome\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.084, \"y\": 3.733}, {\"title\": \"AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.353, \"y\": 2.637}, {\"title\": \"Iteratively Prompting Multimodal LLMs to Reproduce Natural and  AI-Generated Images\", \"topic\": \"Multimodal Language Models\", \"x\": 3.308, \"y\": 2.805}, {\"title\": \"Evaluating Retrieval Quality in Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.019, \"y\": 4.694}, {\"title\": \"Automated Text Mining of Experimental Methodologies from Biomedical  Literature\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.136, \"y\": 7.483}, {\"title\": \"Using Adaptive Empathetic Responses for Teaching English\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.64, \"y\": 7.824}, {\"title\": \"Embarrassingly Simple Unsupervised Aspect Based Sentiment Tuple  Extraction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.205, \"y\": 6.78}, {\"title\": \"Trojan Detection in Large Language Models: Insights from The Trojan  Detection Challenge\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.471, \"y\": 2.591}, {\"title\": \"PEACH: Pretrained-embedding Explanation Across Contextual and  Hierarchical Structure\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.976, \"y\": 3.962}, {\"title\": \"Utilizing Deep Learning to Optimize Software Development Processes\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.605, \"y\": 2.552}, {\"title\": \"Mixture of LoRA Experts\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.029, \"y\": 2.086}, {\"title\": \"Video sentence grounding with temporally global textual knowledge\", \"topic\": \"Multimodal Language Models\", \"x\": 8.87, \"y\": 7.818}, {\"title\": \"\\\"A good pun is its own reword\\\": Can Large Language Models Understand  Puns?\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.343, \"y\": 3.783}, {\"title\": \"Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast  Cancer Self-Screening Rules into AI Responses\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.538, \"y\": 7.743}, {\"title\": \"Exploring Diverse Methods in Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.184, \"y\": 8.045}, {\"title\": \"Listen Then See: Video Alignment with Speaker Attention\", \"topic\": \"Multimodal Language Models\", \"x\": 8.73, \"y\": 7.797}, {\"title\": \"Parameter Efficient Fine Tuning: A Comprehensive Analysis Across  Applications\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.96, \"y\": 2.286}, {\"title\": \"Do \\\"English\\\" Named Entity Recognizers Work Well on Global Englishes?\", \"topic\": \"Named Entity Recognition\", \"x\": 7.396, \"y\": 6.844}, {\"title\": \"Predicting Question Quality on StackOverflow with Neural Networks\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.156, \"y\": 5.102}, {\"title\": \"Retrieval-Augmented Generation-based Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.898, \"y\": 6.743}, {\"title\": \"Explanation based Bias Decoupling Regularization for Natural Language  Inference\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.9, \"y\": 4.016}, {\"title\": \"Movie101v2: Improved Movie Narration Benchmark\", \"topic\": \"Multimodal Language Models\", \"x\": 8.904, \"y\": 7.824}, {\"title\": \"MahaSQuAD: Bridging Linguistic Divides in Marathi Question-Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.475, \"y\": 5.227}, {\"title\": \"Semantically Corrected Amharic Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.122, \"y\": 5.497}, {\"title\": \"UnibucLLM: Harnessing LLMs for Automated Prediction of Item Difficulty  and Response Time for Multiple-Choice Questions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.924, \"y\": 7.818}, {\"title\": \"Beyond Accuracy: Investigating Error Types in GPT-4 Responses to USMLE  Questions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.73, \"y\": 8.049}, {\"title\": \"Double Mixture: Towards Continual Event Detection from Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.165, \"y\": 5.327}, {\"title\": \"Evaluation of Machine Translation Based on Semantic Dependencies and  Keywords\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.693, \"y\": 4.854}, {\"title\": \"The Instruction Hierarchy: Training LLMs to Prioritize Privileged  Instructions\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.475, \"y\": 2.621}, {\"title\": \"Heterogeneous Subgraph Transformer for Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 3.986, \"y\": 5.853}, {\"title\": \"Beyond Self-Consistency: Ensemble Reasoning Boosts Consistency and  Accuracy of LLMs in Cancer Staging\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.781, \"y\": 8.161}, {\"title\": \"Data Alignment for Zero-Shot Concept Generation in Dermatology AI\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.455, \"y\": 8.286}, {\"title\": \"Stronger Random Baselines for In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.155, \"y\": 3.591}, {\"title\": \"Groma: Localized Visual Tokenization for Grounding Multimodal Large  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.55, \"y\": 7.303}, {\"title\": \"Rethinking the Evaluation of Dialogue Systems: Effects of User Feedback  on Crowdworkers and LLMs\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.252, \"y\": 3.81}, {\"title\": \"MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel  Reviews\", \"topic\": \"Fake News Detection\", \"x\": 3.844, \"y\": 5.98}, {\"title\": \"Unlocking Multi-View Insights in Knowledge-Dense Retrieval-Augmented  Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.999, \"y\": 4.76}, {\"title\": \"How Does the Textual Information Affect the Retrieval of Multimodal  In-Context Learning?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.196, \"y\": 7.082}, {\"title\": \"Multi Class Depression Detection Through Tweets using Artificial  Intelligence\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.106, \"y\": 7.205}, {\"title\": \"CT-ADE: An Evaluation Benchmark for Adverse Drug Event Prediction from  Clinical Trial Results\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.689, \"y\": 7.857}, {\"title\": \"REXEL: An End-to-end Model for Document-Level Relation Extraction and  Entity Linking\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.797, \"y\": 6.774}, {\"title\": \"AutoCrawler: A Progressive Understanding Web Agent for Web Crawler  Generation\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.649, \"y\": 2.535}, {\"title\": \"PDF-MVQA: A Dataset for Multimodal Information Retrieval in PDF-based  Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 7.911, \"y\": 7.739}, {\"title\": \"Mathify: Evaluating Large Language Models on Mathematical Problem  Solving Tasks\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.012, \"y\": 2.92}, {\"title\": \"SOS-1K: A Fine-grained Suicide Risk Classification Dataset for Chinese  Social Media Analysis\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.188, \"y\": 7.403}, {\"title\": \"Pre-trained Vision-Language Models Learn Discoverable Visual Concepts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.582, \"y\": 7.431}, {\"title\": \"Efficient infusion of self-supervised representations in Automatic  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.116, \"y\": 5.076}, {\"title\": \"CORI: CJKV Benchmark with Romanization Integration -- A step towards  Cross-lingual Transfer Beyond Textual Scripts\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.483, \"y\": 4.952}, {\"title\": \"HalluciBot: Is There No Such Thing as a Bad Question?\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.116, \"y\": 1.121}, {\"title\": \"UIClip: A Data-driven Model for Assessing User Interface Design\", \"topic\": \"Multimodal Language Models\", \"x\": 8.438, \"y\": 7.311}, {\"title\": \"BIRD: A Trustworthy Bayesian Inference Framework for Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.513, \"y\": 3.091}, {\"title\": \"EnriCo: Enriched Representation and Globally Constrained Inference for  Entity and Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.969, \"y\": 6.795}, {\"title\": \"GraphER: A Structure-aware Text-to-Graph Model for Entity and Relation  Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.917, \"y\": 6.76}, {\"title\": \"RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.098, \"y\": 4.605}, {\"title\": \"mOthello: When Do Cross-Lingual Representation Alignment and  Cross-Lingual Transfer Emerge in Multilingual Models?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.276, \"y\": 4.689}, {\"title\": \"BLINK: Multimodal Large Language Models Can See but Not Perceive\", \"topic\": \"Multimodal Language Models\", \"x\": 8.191, \"y\": 7.62}, {\"title\": \"Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.971, \"y\": 7.403}, {\"title\": \"Large Language Models in Targeted Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.564, \"y\": 6.561}, {\"title\": \"Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual  Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.355, \"y\": 1.458}, {\"title\": \"Simultaneous Interpretation Corpus Construction by Large Language Models  in Distant Language Pair\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.021, \"y\": 4.869}, {\"title\": \"Augmenting emotion features in irony detection with Large language  modeling\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.383, \"y\": 7.296}, {\"title\": \"Resilience through Scene Context in Visual Referring Expression  Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.713, \"y\": 7.263}, {\"title\": \"Length Generalization of Causal Transformers without Position Encoding\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.743, \"y\": 3.31}, {\"title\": \"EuSQuAD: Automatically Translated and Aligned SQuAD2.0 for Basque\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.385, \"y\": 5.189}, {\"title\": \"Aligning language models with human preferences\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.315, \"y\": 1.411}, {\"title\": \"TIMIT Speaker Profiling: A Comparison of Multi-task learning and  Single-task learning Approaches\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.63, \"y\": 5.236}, {\"title\": \"Exploring Boundaries and Intensities in Offensive and Hate Speech:  Unveiling the Complex Spectrum of Social Media Discourse\", \"topic\": \"Hate Speech Detection\", \"x\": 2.798, \"y\": 5.414}, {\"title\": \"Can We Catch the Elephant? A Survey of the Evolvement of Hallucination  Evaluation on Natural Language Generation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.117, \"y\": 1.09}, {\"title\": \"Enhance Robustness of Language Models Against Variation Attack through  Graph Integration\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.132, \"y\": 3.013}, {\"title\": \"Sequential Compositional Generalization in Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.353, \"y\": 7.112}, {\"title\": \"Token-level Direct Preference Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.347, \"y\": 1.297}, {\"title\": \"CrossIn: An Efficient Instruction Tuning Approach for Cross-Lingual  Knowledge Alignment\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.3, \"y\": 4.58}, {\"title\": \"SKIP: Skill-Localized Prompt Tuning for Inference Speed Boost-Up\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.854, \"y\": 3.212}, {\"title\": \"Enhancing Length Extrapolation in Sequential Models with  Pointer-Augmented Neural Memory\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.498, \"y\": 3.392}, {\"title\": \"Challenging Negative Gender Stereotypes: A Study on the Effectiveness of  Automated Counter-Stereotypes\", \"topic\": \"Bias in Language Models\", \"x\": 3.227, \"y\": 4.482}, {\"title\": \"Sharing Parameter by Conjugation for Knowledge Graph Embeddings in  Complex Space\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.144, \"y\": 6.03}, {\"title\": \"REQUAL-LM: Reliability and Equity through Aggregation in Large Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.524, \"y\": 4.185}, {\"title\": \"Mapping Violence: Developing an Extensive Framework to Build a Bangla  Sectarian Expression Dataset from Social Media Interactions\", \"topic\": \"Hate Speech Detection\", \"x\": 2.909, \"y\": 5.543}, {\"title\": \"Missed Connections: Lateral Thinking Puzzles for Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.407, \"y\": 2.986}, {\"title\": \"Investigating Gender Bias in Turkish Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.242, \"y\": 4.367}, {\"title\": \"Demystifying Legalese: An Automated Approach for Summarizing and  Analyzing Overlaps in Privacy Policies and Terms of Service\", \"topic\": \"Legal NLP\", \"x\": 4.984, \"y\": 5.647}, {\"title\": \"The Landscape of Emerging AI Agent Architectures for Reasoning,  Planning, and Tool Calling: A Survey\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.312, \"y\": 3.106}, {\"title\": \"Quantifying Multilingual Performance of Large Language Models Across  Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.943, \"y\": 4.478}, {\"title\": \"Evaluating Span Extraction in Generative Paradigm: A Reflection on  Aspect-Based Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.155, \"y\": 6.801}, {\"title\": \"GenFighter: A Generative and Evolutive Textual Attack Removal\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.137, \"y\": 3.021}, {\"title\": \"Pack of LLMs: Model Fusion at Test-Time via Perplexity Optimization\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 7.927, \"y\": 2.682}, {\"title\": \"Paraphrase and Solve: Exploring and Exploiting the Impact of Surface  Form on Mathematical Reasoning in Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.001, \"y\": 2.967}, {\"title\": \"Unifying Bias and Unfairness in Information Retrieval: A Survey of  Challenges and Opportunities with Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.556, \"y\": 4.179}, {\"title\": \"Research on emotionally intelligent dialogue generation based on  automatic dialogue system\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.623, \"y\": 7.819}, {\"title\": \"Open-Ended Wargames with Large Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.309, \"y\": 3.092}, {\"title\": \"In-Context Learning State Vector with Inner and Momentum Optimization\", \"topic\": \"In-Context Learning\", \"x\": 8.655, \"y\": 3.431}, {\"title\": \"Position Engineering: Boosting Large Language Models through Positional  Information Manipulation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.356, \"y\": 3.275}, {\"title\": \"Context-Aware Siamese Networks for Efficient Emotion Recognition in  Conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.264, \"y\": 7.805}, {\"title\": \"A Novel ICD Coding Framework Based on Associated and Hierarchical Code  Description Distillation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.948, \"y\": 8.442}, {\"title\": \"What's under the hood: Investigating Automatic Metrics on Meeting  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.475, \"y\": 6.267}, {\"title\": \"Consistency Training by Synthetic Question Generation for Conversational  Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.377, \"y\": 4.884}, {\"title\": \"ViLLM-Eval: A Comprehensive Evaluation Suite for Vietnamese Large  Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.583, \"y\": 4.084}, {\"title\": \"TREACLE: Thrifty Reasoning via Context-Aware LLM and Prompt Selection\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 6.848, \"y\": 2.945}, {\"title\": \"Stepwise Alignment for Constrained Language Model Policy Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.271, \"y\": 1.353}, {\"title\": \"Cross-Platform Hate Speech Detection with Weakly Supervised Causal  Disentanglement\", \"topic\": \"Hate Speech Detection\", \"x\": 2.708, \"y\": 5.357}, {\"title\": \"Many-Shot In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.322, \"y\": 3.439}, {\"title\": \"A Survey on Retrieval-Augmented Text Generation for Large Language  Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.044, \"y\": 4.544}, {\"title\": \"SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA  of LLMs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.577, \"y\": 5.058}, {\"title\": \"Can Language Models Solve Olympiad Programming?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.351, \"y\": 3.603}, {\"title\": \"Shears: Unstructured Sparsity with Neural Low-rank Adapter Search\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.188, \"y\": 2.144}, {\"title\": \"Teaching a Multilingual Large Language Model to Understand Multilingual  Speech via Multi-Instructional Training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.268, \"y\": 5.15}, {\"title\": \"Which questions should I answer? Salience Prediction of Inquisitive  Questions\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.218, \"y\": 5.17}, {\"title\": \"Dynamic Self-adaptive Multiscale Distillation from Pre-trained  Multimodal Large Model for Efficient Cross-modal Representation Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.493, \"y\": 7.018}, {\"title\": \"Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.264, \"y\": 1.328}, {\"title\": \"Dual Modalities of Text: Visual and Textual Generative Pre-training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.689, \"y\": 6.876}, {\"title\": \"Cross-Language Evolution of Divergent Collective Memory Around the Arab  Spring\", \"topic\": \"Fake News Detection\", \"x\": 3.728, \"y\": 5.812}, {\"title\": \"Question Difficulty Ranking for Multiple-Choice Reading Comprehension\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.318, \"y\": 4.893}, {\"title\": \"ViTextVQA: A Large-Scale Visual Question Answering Dataset for  Evaluating Vietnamese Text Comprehension in Images\", \"topic\": \"Multimodal Language Models\", \"x\": 8.206, \"y\": 7.995}, {\"title\": \"The application of Augmented Reality (AR) in Remote Work and Education\", \"topic\": \"Multimodal Language Models\", \"x\": 8.549, \"y\": 6.96}, {\"title\": \"Construction of Domain-specified Japanese Large Language Model for  Finance through Continual Pre-training\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.923, \"y\": 6.864}, {\"title\": \"CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level  Granularity\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.594, \"y\": 2.328}, {\"title\": \"White Men Lead, Black Women Help? Benchmarking Language Agency Social  Biases in LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.43, \"y\": 4.291}, {\"title\": \"Self-Supervised Visual Preference Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 5.791, \"y\": 1.307}, {\"title\": \"When Emotional Stimuli meet Prompt Designing: An Auto-Prompt Graphical  Paradigm\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.112, \"y\": 3.159}, {\"title\": \"Reasoning on Efficient Knowledge Paths:Knowledge Graph Guides Large  Language Model for Domain Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.821, \"y\": 5.512}, {\"title\": \"Relational Graph Convolutional Networks for Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.474, \"y\": 6.775}, {\"title\": \"Balancing Speciality and Versatility: a Coarse to Fine Framework for  Supervised Fine-tuning Large Language Model\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.809, \"y\": 2.298}, {\"title\": \"Exploring Social Media Posts for Depression Identification: A Study on  Reddit Dataset\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.143, \"y\": 7.358}, {\"title\": \"Uncovering Latent Arguments in Social Media Messaging by Employing  LLMs-in-the-Loop Strategy\", \"topic\": \"Fake News Detection\", \"x\": 3.857, \"y\": 5.64}, {\"title\": \"Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical  Vision-Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.495, \"y\": 8.223}, {\"title\": \"Two-Stage Stance Labeling: User-Hashtag Heuristics with Graph Neural  Networks\", \"topic\": \"Fake News Detection\", \"x\": 3.545, \"y\": 5.853}, {\"title\": \"Find The Gap: Knowledge Base Reasoning For Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.105, \"y\": 7.916}, {\"title\": \"Deferred NAM: Low-latency Top-K Context Injection via Deferred Context  Encoding for Non-Streaming ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.29, \"y\": 5.098}, {\"title\": \"ANCHOR: LLM-driven News Subject Conditioning for Text-to-Image Synthesis\", \"topic\": \"Multimodal Language Models\", \"x\": 9.028, \"y\": 7.362}, {\"title\": \"Memory Sharing for Large Language Model based Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.752, \"y\": 2.661}, {\"title\": \"Context Does Matter: Implications for Crowdsourced Evaluation Labels in  Task-Oriented Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.225, \"y\": 3.995}, {\"title\": \"Constructing Benchmarks and Interventions for Combating Hallucinations  in LLMs\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.196, \"y\": 1.104}, {\"title\": \"Detecting AI Generated Text Based on NLP and Machine Learning Approaches\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.222, \"y\": 4.842}, {\"title\": \"Progressive Knowledge Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.008, \"y\": 6.016}, {\"title\": \"Software Engineering Methods For AI-Driven Deductive Legal Reasoning\", \"topic\": \"Legal NLP\", \"x\": 5.09, \"y\": 5.489}, {\"title\": \"Anatomy of Industrial Scale Multilingual ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.116, \"y\": 5.322}, {\"title\": \"Negation Triplet Extraction with Syntactic Dependency and Semantic  Consistency\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.106, \"y\": 6.767}, {\"title\": \"Impact of Preference Noise on the Alignment Performance of Generative  Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.311, \"y\": 1.227}, {\"title\": \"Benchmarking Llama2, Mistral, Gemma and GPT for Factuality, Toxicity,  Bias and Propensity for Hallucinations\", \"topic\": \"Hallucination in Language Models\", \"x\": 4.831, \"y\": 1.479}, {\"title\": \"Quantization of Large Language Models with an Overdetermined Basis\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.746, \"y\": 2.216}, {\"title\": \"Unveiling Imitation Learning: Exploring the Impact of Data Falsity to  Large Language Model\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.067, \"y\": 2.468}, {\"title\": \"Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration\", \"topic\": \"Multimodal Language Models\", \"x\": 7.786, \"y\": 7.755}, {\"title\": \"Learn Your Reference Model for Real Good Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.294, \"y\": 1.387}, {\"title\": \"Real-world Instance-specific Image Goal Navigation for Service Robots:  Bridging the Domain Gap with Contrastive Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.824, \"y\": 7.071}, {\"title\": \"Improving Recall of Large Language Models: A Model Collaboration  Approach for Relational Triple Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.91, \"y\": 6.716}, {\"title\": \"Transformers, Contextualism, and Polysemy\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.366, \"y\": 3.666}, {\"title\": \"Reliability Estimation of News Media Sources: Birds of a Feather Flock  Together\", \"topic\": \"Fake News Detection\", \"x\": 4.201, \"y\": 5.862}, {\"title\": \"State Space Model for New-Generation Network Alternative to  Transformers: A Survey\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.596, \"y\": 3.219}, {\"title\": \"MMCode: Evaluating Multi-Modal Code Large Language Models with Visually  Rich Programming Problems\", \"topic\": \"Multimodal Language Models\", \"x\": 8.008, \"y\": 7.562}, {\"title\": \"Automatic Knowledge Graph Construction for Judicial Cases\", \"topic\": \"Legal NLP\", \"x\": 5.122, \"y\": 5.759}, {\"title\": \"A Large-Scale Evaluation of Speech Foundation Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.635, \"y\": 5.065}, {\"title\": \"Tasks People Prompt: A Taxonomy of LLM Downstream Tasks in Software  Verification and Falsification Approaches\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.107, \"y\": 3.162}, {\"title\": \"Low-Resource Named Entity Recognition with Cross-Lingual,  Character-Level Neural Conditional Random Fields\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.341, \"y\": 5.147}, {\"title\": \"Cross-Data Knowledge Graph Construction for LLM-enabled Educational  Question-Answering System: A~Case~Study~at~HCMUT\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.718, \"y\": 5.581}, {\"title\": \"TrafficVLM: A Controllable Visual Language Model for Traffic Video  Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.82, \"y\": 7.747}, {\"title\": \"JaFIn: Japanese Financial Instruction Dataset\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.915, \"y\": 6.869}, {\"title\": \"Test Code Generation for Telecom Software Systems using Two-Stage  Generative Model\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.311, \"y\": 2.472}, {\"title\": \"Compass: Large Multilingual Language Model for South-east Asia\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.837, \"y\": 4.292}, {\"title\": \"DKE-Research at SemEval-2024 Task 2: Incorporating Data Augmentation  with Generative Models and Biomedical Knowledge to Enhance Inference  Robustness\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.777, \"y\": 7.697}, {\"title\": \"TransformerFAM: Feedback attention is working memory\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.778, \"y\": 3.304}, {\"title\": \"Post-Semantic-Thinking: A Robust Strategy to Distill Reasoning Capacity  from Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.723, \"y\": 2.336}, {\"title\": \"GeMQuAD : Generating Multilingual Question Answering Datasets from Large  Language Models using Few Shot Learning\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.523, \"y\": 5.029}, {\"title\": \"Mitigating Heterogeneity among Factor Tensors via Lie Group Manifolds  for Tensor Decomposition Based Temporal Knowledge Graph Embedding\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.983, \"y\": 6.039}, {\"title\": \"ToNER: Type-oriented Named Entity Recognition with Generative Language  Model\", \"topic\": \"Named Entity Recognition\", \"x\": 7.36, \"y\": 6.763}, {\"title\": \"TLDR at SemEval-2024 Task 2: T5-generated clinical-Language summaries  for DeBERTa Report Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.705, \"y\": 7.645}, {\"title\": \"CuriousLLM: Elevating Multi-Document QA with Reasoning-Infused Knowledge  Graph Prompting\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.736, \"y\": 5.428}, {\"title\": \"Adapting Mental Health Prediction Tasks for Cross-lingual Learning via  Meta-Training and In-context Learning with Large Language Model\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.314, \"y\": 7.579}, {\"title\": \"Introducing Super RAGs in Mistral 8x7B-v1\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.102, \"y\": 4.545}, {\"title\": \"Leveraging Large Language Model as Simulated Patients for Clinical  Education\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.602, \"y\": 8.132}, {\"title\": \"Experimental Design for Active Transductive Inference in Large Language  Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.597, \"y\": 3.261}, {\"title\": \"BERT-LSH: Reducing Absolute Compute For Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.723, \"y\": 3.061}, {\"title\": \"Revisiting Code Similarity Evaluation with Abstract Syntax Tree Edit  Distance\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.629, \"y\": 2.631}, {\"title\": \"Megalodon: Efficient LLM Pretraining and Inference with Unlimited  Context Length\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.59, \"y\": 3.0}, {\"title\": \"JailbreakLens: Visual Analysis of Jailbreak Attacks Against Large  Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.3, \"y\": 2.27}, {\"title\": \"CATS: Contextually-Aware Thresholding for Sparsity in Large Language  Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.376, \"y\": 2.547}, {\"title\": \"The Generation Gap:Exploring Age Bias in the Underlying Value Systems of  Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.779, \"y\": 4.088}, {\"title\": \"Synthetic Dataset Creation and Fine-Tuning of Transformer Models for  Question Answering in Serbian\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.407, \"y\": 5.158}, {\"title\": \"MoPE: Mixture of Prefix Experts for Zero-Shot Dialogue State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.762, \"y\": 3.932}, {\"title\": \"RLHF Deciphered: A Critical Analysis of Reinforcement Learning from  Human Feedback for LLMs\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.132, \"y\": 1.637}, {\"title\": \"Dataset Reset Policy Optimization for RLHF\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.236, \"y\": 1.386}, {\"title\": \"Mitigating Language-Level Performance Disparity in mPLMs via Teacher  Language Selection and Cross-lingual Self-Distillation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.622, \"y\": 4.548}, {\"title\": \"Decoding AI: The inside story of data analysis in ChatGPT\", \"topic\": \"Bias in Language Models\", \"x\": 5.076, \"y\": 4.623}, {\"title\": \"AIMDiT: Modality Augmentation and Interaction via Multimodal Dimension  Transformation for Emotion Recognition in Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.282, \"y\": 7.732}, {\"title\": \"ASR advancements for indigenous languages: Quechua, Guarani, Bribri,  Kotiria, and Wa'ikhana\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.039, \"y\": 5.521}, {\"title\": \"The Integration of Semantic and Structural Knowledge in Knowledge Graph  Entity Typing\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.099, \"y\": 6.085}, {\"title\": \"Subtoxic Questions: Dive Into Attitude Change of LLM's Response in  Jailbreak Attempts\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.33, \"y\": 2.235}, {\"title\": \"Investigating Neural Machine Translation for Low-Resource Languages:  Using Bavarian as a Case Study\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.791, \"y\": 4.613}, {\"title\": \"Measuring Cross-lingual Transfer in Bytes\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.359, \"y\": 4.736}, {\"title\": \"Reducing hallucination in structured outputs via Retrieval-Augmented  Generation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.318, \"y\": 1.314}, {\"title\": \"Language Model Prompt Selection via Simulation Optimization\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.234, \"y\": 3.261}, {\"title\": \"Graph Integrated Language Transformers for Next Action Prediction in  Complex Phone Calls\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.305, \"y\": 3.789}, {\"title\": \"Distilling Algorithmic Reasoning from LLMs via Explaining Solution  Programs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.778, \"y\": 2.592}, {\"title\": \"Extending Translate-Train for ColBERT-X to African Language CLIR\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.71, \"y\": 5.019}, {\"title\": \"Human Latency Conversational Turns for Spoken Avatar Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.399, \"y\": 3.793}, {\"title\": \"Rumour Evaluation with Very Large Language Models\", \"topic\": \"Fake News Detection\", \"x\": 4.162, \"y\": 5.573}, {\"title\": \"Data-Augmentation-Based Dialectal Adaptation for LLMs\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.192, \"y\": 4.347}, {\"title\": \"Variance-reduced Zeroth-Order Methods for Fine-Tuning Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.089, \"y\": 2.302}, {\"title\": \"SQBC: Active Learning using LLM-Generated Synthetic Data for Stance  Detection in Online Political Discussions\", \"topic\": \"Fake News Detection\", \"x\": 3.566, \"y\": 5.755}, {\"title\": \"Any2Point: Empowering Any-modality Large Models for Efficient 3D  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.762, \"y\": 7.267}, {\"title\": \"Language Imbalance Can Boost Cross-lingual Generalisation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.266, \"y\": 4.661}, {\"title\": \"Manipulating Large Language Models to Increase Product Visibility\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.891, \"y\": 2.871}, {\"title\": \"AmpleGCG: Learning a Universal and Transferable Generative Model of  Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.296, \"y\": 2.512}, {\"title\": \"DesignQA: A Multimodal Benchmark for Evaluating Large Language Models'  Understanding of Engineering Documentation\", \"topic\": \"Multimodal Language Models\", \"x\": 7.851, \"y\": 7.587}, {\"title\": \"HGRN2: Gated Linear RNNs with State Expansion\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.666, \"y\": 3.245}, {\"title\": \"Analyzing Toxicity in Deep Conversations: A Reddit Case Study\", \"topic\": \"Hate Speech Detection\", \"x\": 3.019, \"y\": 5.152}, {\"title\": \"Question Generation in Knowledge-Driven Dialog: Explainability and  Evaluation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.233, \"y\": 5.054}, {\"title\": \"Heron-Bench: A Benchmark for Evaluating Vision Language Models in  Japanese\", \"topic\": \"Multimodal Language Models\", \"x\": 8.274, \"y\": 7.752}, {\"title\": \"Curated Datasets and Neural Models for Machine Translation of Informal  Registers between Mayan and Spanish Vernaculars\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.576, \"y\": 4.818}, {\"title\": \"Multi-Image Visual Question Answering for Unsupervised Anomaly Detection\", \"topic\": \"Multimodal Language Models\", \"x\": 7.822, \"y\": 8.027}, {\"title\": \"Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The  Medical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.095, \"y\": 7.942}, {\"title\": \"UltraEval: A Lightweight Platform for Flexible and Comprehensive  Evaluation for LLMs\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.286, \"y\": 3.66}, {\"title\": \"Comments as Natural Logic Pivots: Improve Code Generation via Comment  Perspective\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.448, \"y\": 2.391}, {\"title\": \"Decomposing Label Space, Format and Discrimination: Rethinking How LLMs  Respond and Solve Tasks via In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.372, \"y\": 3.4}, {\"title\": \"Introducing L2M3, A Multilingual Medical Large Language Model to Advance  Health Equity in Low-Resource Regions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.633, \"y\": 7.902}, {\"title\": \"MM-PhyQA: Multimodal Physics Question-Answering With Multi-Image CoT  Prompting\", \"topic\": \"Multimodal Language Models\", \"x\": 7.89, \"y\": 7.723}, {\"title\": \"Interactive Prompt Debugging with Sequence Salience\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.283, \"y\": 3.377}, {\"title\": \"Augmenting Knowledge Graph Hierarchies Using Neural Transformers\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.078, \"y\": 6.01}, {\"title\": \"Laissez-Faire Harms: Algorithmic Biases in Generative Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.451, \"y\": 4.326}, {\"title\": \"\\\"Confidently Nonsensical?'': A Critical Survey on the Perspectives and  Challenges of 'Hallucinations' in NLP\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.11, \"y\": 1.09}, {\"title\": \"Transferable and Principled Efficiency for Open-Vocabulary Segmentation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.754, \"y\": 7.044}, {\"title\": \"Behavior Trees Enable Structured Programming of Language Model Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.806, \"y\": 2.739}, {\"title\": \"LLMs in Biomedicine: A study on clinical Named Entity Recognition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.107, \"y\": 7.847}, {\"title\": \"Conformer-1: Robust ASR via Large-Scale Semisupervised Bootstrapping\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.25, \"y\": 5.171}, {\"title\": \"Leave No Context Behind: Efficient Infinite Context Transformers with  Infini-attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.561, \"y\": 2.954}, {\"title\": \"Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on  Graphs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.543, \"y\": 2.483}, {\"title\": \"A Computational Analysis of the Dehumanisation of Migrants from Syria  and Ukraine in Slovene News Media\", \"topic\": \"Fake News Detection\", \"x\": 3.464, \"y\": 6.02}, {\"title\": \"LM Transparency Tool: Interactive Tool for Analyzing Transformer  Language Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.455, \"y\": 3.52}, {\"title\": \"Event Grounded Criminal Court View Generation with Cooperative (Large)  Language Models\", \"topic\": \"Legal NLP\", \"x\": 5.22, \"y\": 5.944}, {\"title\": \"XNLIeu: a dataset for cross-lingual NLI in Basque\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.175, \"y\": 4.853}, {\"title\": \"Charles Translator: A Machine Translation System between Ukrainian and  Czech\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.651, \"y\": 5.058}, {\"title\": \"MetaCheckGPT -- A Multi-task Hallucination Detector Using LLM  Uncertainty and Meta-models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.111, \"y\": 1.002}, {\"title\": \"Superposition Prompting: Improving and Accelerating Retrieval-Augmented  Generation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.14, \"y\": 3.217}, {\"title\": \"Emotion-cause pair extraction method based on multi-granularity  information and multi-module interaction\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.422, \"y\": 7.712}, {\"title\": \"DiffusionDialog: A Diffusion Model for Diverse Dialog Generation with  Latent Space\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.648, \"y\": 4.039}, {\"title\": \"Global Contrastive Training for Multimodal Electronic Health Records  with Language Supervision\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.965, \"y\": 8.371}, {\"title\": \"Llama-VITS: Enhancing TTS Synthesis with Semantic Awareness\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.386, \"y\": 5.798}, {\"title\": \"MathVC: An LLM-Simulated Multi-Character Virtual Classroom for  Mathematics Education\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.907, \"y\": 2.963}, {\"title\": \"Apollonion: Profile-centric Dialog Agent\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.155, \"y\": 3.528}, {\"title\": \"CoVoMix: Advancing Zero-Shot Speech Generation for Human-like  Multi-talker Conversations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 10.355, \"y\": 5.842}, {\"title\": \"Onco-Retriever: Generative Classifier for Retrieval of EHR Records in  Oncology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.993, \"y\": 7.764}, {\"title\": \"Sample-Efficient Human Evaluation of Large Language Models via Maximum  Discrepancy Competition\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.201, \"y\": 3.677}, {\"title\": \"Leveraging Interesting Facts to Enhance User Engagement with  Conversational Interfaces\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.153, \"y\": 3.847}, {\"title\": \"What is Your Favorite Gender, MLM? Gender Bias Evaluation in  Multilingual Masked Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.181, \"y\": 4.419}, {\"title\": \"FairPair: A Robust Evaluation of Biases in Language Models through  Paired Perturbations\", \"topic\": \"Bias in Language Models\", \"x\": 3.281, \"y\": 4.321}, {\"title\": \"Sandwich attack: Multi-language Mixture Adaptive Attack on LLMs\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.47, \"y\": 2.564}, {\"title\": \"InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model  Handling Resolutions from 336 Pixels to 4K HD\", \"topic\": \"Multimodal Language Models\", \"x\": 8.447, \"y\": 7.498}, {\"title\": \"Comparing Two Model Designs for Clinical Note Generation; Is an LLM a  Useful Evaluator of Consistency?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.615, \"y\": 7.965}, {\"title\": \"Text-Based Reasoning About Vector Graphics\", \"topic\": \"Multimodal Language Models\", \"x\": 8.508, \"y\": 7.522}, {\"title\": \"Large Language Models to the Rescue: Deadlock Resolution in Multi-Robot  Systems\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.872, \"y\": 2.712}, {\"title\": \"Wu's Method can Boost Symbolic AI to Rival Silver Medalists and  AlphaGeometry to Outperform Gold Medalists at IMO Geometry\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.724, \"y\": 2.907}, {\"title\": \"Event Extraction in Basque: Typologically motivated Cross-Lingual  Transfer-Learning Analysis\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.298, \"y\": 4.887}, {\"title\": \"Latent Distance Guided Alignment Training for Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.482, \"y\": 1.421}, {\"title\": \"ClinLinker: Medical Entity Linking of Clinical Concept Mentions in  Spanish\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.135, \"y\": 7.762}, {\"title\": \"nEMO: Dataset of Emotional Speech in Polish\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.246, \"y\": 7.813}, {\"title\": \"Understanding Cross-Lingual Alignment -- A Survey\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.24, \"y\": 4.877}, {\"title\": \"Characterizing Multimodal Long-form Summarization: A Case Study on  Financial Reports\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.25, \"y\": 6.666}, {\"title\": \"Cendol: Open Instruction-tuned Generative Large Language Models for  Indonesian Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.965, \"y\": 4.034}, {\"title\": \"SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for  Hallucination Detection\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.146, \"y\": 1.049}, {\"title\": \"Detection of fields of applications in biomedical abstracts with the  support of argumentation elements\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.985, \"y\": 7.254}, {\"title\": \"Exploring the Necessity of Visual Modality in Multimodal Machine  Translation using Authentic Datasets\", \"topic\": \"Multimodal Language Models\", \"x\": 8.49, \"y\": 7.015}, {\"title\": \"All in One: An Empirical Study of GPT for Few-Shot Aspect-Based  Sentiment Anlaysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.139, \"y\": 6.799}, {\"title\": \"Does Transformer Interpretability Transfer to RNNs?\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.486, \"y\": 3.411}, {\"title\": \"JSTR: Judgment Improves Scene Text Recognition\", \"topic\": \"Multimodal Language Models\", \"x\": 8.795, \"y\": 6.962}, {\"title\": \"THOUGHTSCULPT: Reasoning with Intermediate Revision and Search\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.581, \"y\": 2.433}, {\"title\": \"VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page  Understanding and Grounding?\", \"topic\": \"Multimodal Language Models\", \"x\": 7.927, \"y\": 7.441}, {\"title\": \"Interplay of Machine Translation, Diacritics, and Diacritization\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.691, \"y\": 4.565}, {\"title\": \"The Hallucinations Leaderboard -- An Open Effort to Measure  Hallucinations in Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.154, \"y\": 1.097}, {\"title\": \"Use of a Structured Knowledge Base Enhances Metadata Curation by Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.847, \"y\": 7.517}, {\"title\": \"Eraser: Jailbreaking Defense in Large Language Models via Unlearning  Harmful Knowledge\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.386, \"y\": 2.274}, {\"title\": \"CodecLM: Aligning Language Models with Tailored Synthetic Data\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.073, \"y\": 2.316}, {\"title\": \"Negative Preference Optimization: From Catastrophic Collapse to  Effective Unlearning\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.211, \"y\": 1.388}, {\"title\": \"GeniL: A Multilingual Dataset on Generalizing Language\", \"topic\": \"Bias in Language Models\", \"x\": 3.418, \"y\": 4.383}, {\"title\": \"Softmax Attention with Constant Cost per Token\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.882, \"y\": 3.22}, {\"title\": \"SambaLingo: Teaching Large Language Models New Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.122, \"y\": 4.133}, {\"title\": \"Neural Sequence-to-Sequence Modeling with Attention by Leveraging Deep  Learning Architectures for Enhanced Contextual Understanding in Abstractive  Text Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.675, \"y\": 6.361}, {\"title\": \"Language-Independent Representations Improve Zero-Shot Summarization\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.478, \"y\": 4.634}, {\"title\": \"Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.261, \"y\": 7.375}, {\"title\": \"Responsible Generative AI: What to Generate and What Not\", \"topic\": \"Bias in Language Models\", \"x\": 4.808, \"y\": 4.407}, {\"title\": \"Comprehensive Study on German Language Models for Clinical and  Biomedical Text Understanding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.084, \"y\": 7.984}, {\"title\": \"Evaluating Mathematical Reasoning Beyond Accuracy\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.9, \"y\": 2.758}, {\"title\": \"VietMed: A Dataset and Benchmark for Automatic Speech Recognition of  Vietnamese in the Medical Domain\", \"topic\": \"Speech Recognition and Translation\", \"x\": 6.387, \"y\": 7.838}, {\"title\": \"Is English the New Programming Language? How About Pseudo-code  Engineering?\", \"topic\": \"Bias in Language Models\", \"x\": 5.164, \"y\": 4.386}, {\"title\": \"LTNER: Large Language Model Tagging for Named Entity Recognition with  Contextualized Entity Marking\", \"topic\": \"Named Entity Recognition\", \"x\": 7.427, \"y\": 6.733}, {\"title\": \"SpeechAlign: Aligning Speech Generation to Human Preferences\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.445, \"y\": 1.39}, {\"title\": \"MedExpQA: Multilingual Benchmarking of Large Language Models for Medical  Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.922, \"y\": 7.912}, {\"title\": \"360$^\\\\circ$REA: Towards A Reusable Experience Accumulation with  360\\u00b0 Assessment for Multi-Agent System\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.71, \"y\": 2.816}, {\"title\": \"OPSD: an Offensive Persian Social media Dataset and its baseline  evaluations\", \"topic\": \"Hate Speech Detection\", \"x\": 2.746, \"y\": 5.426}, {\"title\": \"PetKaz at SemEval-2024 Task 3: Advancing Emotion Classification with an  LLM for Emotion-Cause Pair Extraction in Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.306, \"y\": 7.64}, {\"title\": \"PetKaz at SemEval-2024 Task 8: Can Linguistics Capture the Specifics of  LLM-generated Text?\", \"topic\": \"AI-Generated Text Detection\", \"x\": 3.892, \"y\": 5.157}, {\"title\": \"Language Models on a Diet: Cost-Efficient Development of Encoders for  Closely-Related Languages via Additional Pretraining\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.136, \"y\": 4.188}, {\"title\": \"Relation Extraction Using Large Language Models: A Case Study on  Acupuncture Point Locations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.08, \"y\": 7.804}, {\"title\": \"PerkwE_COQA: Enhanced Persian Conversational Question Answering by  combining contextual keyword extraction with Large Language Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.34, \"y\": 4.879}, {\"title\": \"Towards Objectively Benchmarking Social Intelligence for Language Agents  at Action Level\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.236, \"y\": 3.188}, {\"title\": \"Multi-Task Learning for Features Extraction in Financial Annual Reports\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.86, \"y\": 6.73}, {\"title\": \"EFSA: Towards Event-Level Financial Sentiment Analysis\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.703, \"y\": 6.838}, {\"title\": \"Interpreting Themes from Educational Stories\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.357, \"y\": 5.311}, {\"title\": \"Supervised Gradual Machine Learning for Aspect Category Detection\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.095, \"y\": 6.916}, {\"title\": \"LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step  Reasoning with Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.623, \"y\": 2.701}, {\"title\": \"Bidirectional Long-Range Parser for Sequential Data Understanding\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.852, \"y\": 3.251}, {\"title\": \"Semantic Stealth: Adversarial Text Attacks on NLP Using Several Methods\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.164, \"y\": 3.024}, {\"title\": \"Enhancing Clinical Efficiency through LLM: Discharge Note Generation for  Cardiac Patients\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.841, \"y\": 8.131}, {\"title\": \"Plug and Play with Prompts: A Prompt Tuning Approach for Controlling  Text Generation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.346, \"y\": 3.533}, {\"title\": \"MM-MATH: Advancing Multimodal Math Evaluation with Process Evaluation  and Fine-grained Classification\", \"topic\": \"Multimodal Language Models\", \"x\": 7.996, \"y\": 7.644}, {\"title\": \"HaVTR: Improving Video-Text Retrieval Through Augmentation Using Large  Foundation Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.928, \"y\": 7.777}, {\"title\": \"FGAIF: Aligning Large Vision-Language Models with Fine-grained AI  Feedback\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.812, \"y\": 1.247}, {\"title\": \"SemEval-2024 Task 2: Safe Biomedical Natural Language Inference for  Clinical Trials\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.703, \"y\": 7.652}, {\"title\": \"A Two Dimensional Feature Engineering Method for Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.959, \"y\": 6.833}, {\"title\": \"SilverSight: A Multi-Task Chinese Financial Large Language Model Based  on Adaptive Semantic Space Learning\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.832, \"y\": 6.835}, {\"title\": \"Towards Understanding the Influence of Reward Margin on Preference Model  Performance\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.19, \"y\": 1.437}, {\"title\": \"Radial Networks: Dynamic Layer Routing for High-Performance Large  Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.44, \"y\": 2.542}, {\"title\": \"SLPL SHROOM at SemEval2024 Task 06: A comprehensive study on models  ability to detect hallucination\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.151, \"y\": 1.067}, {\"title\": \"Data Bias According to Bipol: Men are Naturally Right and It is the Role  of Women to Follow Their Lead\", \"topic\": \"Bias in Language Models\", \"x\": 3.287, \"y\": 4.495}, {\"title\": \"Low-Resource Machine Translation through Retrieval-Augmented LLM  Prompting: A Study on the Mambai Language\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.319, \"y\": 4.294}, {\"title\": \"A Multi-Level Framework for Accelerating Training Transformer Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.703, \"y\": 3.238}, {\"title\": \"MACM: Utilizing a Multi-Agent System for Condition Mining in Solving  Complex Mathematical Problems\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.788, \"y\": 2.46}, {\"title\": \"PoLLMgraph: Unraveling Hallucinations in Large Language Models via State  Transition Dynamics\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.2, \"y\": 1.17}, {\"title\": \"Multilingual Pretraining and Instruction Tuning Improve Cross-Lingual  Knowledge Alignment, But Only Shallowly\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.219, \"y\": 4.554}, {\"title\": \"Binary Classifier Optimization for Large Language Model Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.326, \"y\": 1.305}, {\"title\": \"HyperTTS: Parameter Efficient Adaptation in Text to Speech using  Hypernetworks\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.667, \"y\": 5.399}, {\"title\": \"On the Limitations of Large Language Models (LLMs): False Attribution\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.191, \"y\": 1.157}, {\"title\": \"Towards Analyzing and Understanding the Limitations of DPO: A  Theoretical Perspective\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.351, \"y\": 1.095}, {\"title\": \"RecGPT: Generative Personalized Prompts for Sequential Recommendation  via ChatGPT Training Paradigm\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.922, \"y\": 2.982}, {\"title\": \"IITK at SemEval-2024 Task 10: Who is the speaker? Improving Emotion  Recognition and Flip Reasoning in Conversations via Speaker Embeddings\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.274, \"y\": 7.753}, {\"title\": \"Large Language Model (LLM) AI text generation detection based on  transformer deep learning algorithm\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.158, \"y\": 4.779}, {\"title\": \"Goal-guided Generative Prompt Injection Attack on Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.395, \"y\": 2.57}, {\"title\": \"Joint Visual and Text Prompting for Improved Object-Centric Perception  with Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.182, \"y\": 7.733}, {\"title\": \"IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe  Biomedical Natural Language Inference for Clinical Trials\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.725, \"y\": 7.678}, {\"title\": \"KazQAD: Kazakh Open-Domain Question Answering Dataset\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.482, \"y\": 5.33}, {\"title\": \"Towards Realistic Few-Shot Relation Extraction: A New Meta Dataset and  Evaluation\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.164, \"y\": 6.653}, {\"title\": \"Counting Like Transformers: Compiling Temporal Counting Logic Into  Softmax Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.604, \"y\": 3.396}, {\"title\": \"Effects of Different Prompts on the Quality of GPT-4 Responses to  Dementia Care Questions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.273, \"y\": 7.964}, {\"title\": \"Deciphering Political Entity Sentiment in News with Large Language  Models: Zero-Shot and Few-Shot Strategies\", \"topic\": \"Fake News Detection\", \"x\": 3.571, \"y\": 5.906}, {\"title\": \"Assisting humans in complex comparisons: automated information  comparison at scale\", \"topic\": \"Text Summarization\", \"x\": 5.509, \"y\": 6.069}, {\"title\": \"Who Evaluates the Evaluations? Objectively Scoring Text-to-Image Prompt  Coherence Metrics with T2IScoreScore (TS2)\", \"topic\": \"Multimodal Language Models\", \"x\": 8.834, \"y\": 6.805}, {\"title\": \"Physical Property Understanding from Language-Embedded Feature Fields\", \"topic\": \"Multimodal Language Models\", \"x\": 8.715, \"y\": 7.19}, {\"title\": \"How Lexical is Bilingual Lexicon Induction?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.433, \"y\": 4.762}, {\"title\": \"Unlocking Parameter-Efficient Fine-Tuning for Low-Resource Language  Translation\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.897, \"y\": 2.476}, {\"title\": \"Parameter Efficient Quasi-Orthogonal Fine-Tuning via Givens Rotation\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.049, \"y\": 2.168}, {\"title\": \"Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.778, \"y\": 3.95}, {\"title\": \"ROPO: Robust Preference Optimization for Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.354, \"y\": 1.259}, {\"title\": \"CLUE: A Clinical Language Understanding Evaluation for LLMs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.763, \"y\": 8.034}, {\"title\": \"Teaching Llama a New Language Through Cross-Lingual Knowledge Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.202, \"y\": 4.295}, {\"title\": \"SEME at SemEval-2024 Task 2: Comparing Masked and Generative Language  Models on Natural Language Inference for Clinical Trials\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.689, \"y\": 7.612}, {\"title\": \"Data Augmentation with In-Context Learning and Comparative Evaluation in  Math Word Problem Solving\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.078, \"y\": 2.757}, {\"title\": \"SAAS: Solving Ability Amplification Strategy for Enhanced Mathematical  Reasoning in Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.92, \"y\": 2.427}, {\"title\": \"A Bi-consolidating Model for Joint Relational Triple Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.885, \"y\": 6.855}, {\"title\": \"Extract, Define, Canonicalize: An LLM-based Framework for Knowledge  Graph Construction\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.968, \"y\": 5.937}, {\"title\": \"Fakes of Varying Shades: How Warning Affects Human Perception and  Engagement Regarding LLM Hallucinations\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.153, \"y\": 1.17}, {\"title\": \"SHROOM-INDElab at SemEval-2024 Task 6: Zero- and Few-Shot LLM-Based  Classification for Hallucination Detection\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.094, \"y\": 0.98}, {\"title\": \"No \\\"Zero-Shot\\\" Without Exponential Data: Pretraining Concept Frequency  Determines Multimodal Model Performance\", \"topic\": \"Multimodal Language Models\", \"x\": 8.457, \"y\": 7.273}, {\"title\": \"Direct Nash Optimization: Teaching Language Models to Self-Improve with  General Preferences\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.294, \"y\": 1.478}, {\"title\": \"WorDepth: Variational Language Prior for Monocular Depth Estimation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.836, \"y\": 7.314}, {\"title\": \"Mind's Eye of LLMs: Visualization-of-Thought Elicits Spatial Reasoning  in Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.282, \"y\": 7.741}, {\"title\": \"Sailor: Open Language Models for South-East Asia\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.821, \"y\": 4.194}, {\"title\": \"Mitigating the Impact of Outlier Channels for Language Model  Quantization with Activation Regularization\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.775, \"y\": 2.184}, {\"title\": \"Intent Detection and Entity Extraction from BioMedical Literature\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.147, \"y\": 7.604}, {\"title\": \"Transducers with Pronunciation-aware Embeddings for Automatic Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.089, \"y\": 5.398}, {\"title\": \"ReFT: Representation Finetuning for Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.861, \"y\": 2.322}, {\"title\": \"From News to Summaries: Building a Hungarian Corpus for Extractive and  Abstractive Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.6, \"y\": 6.349}, {\"title\": \"CodeEditorBench: Evaluating Code Editing Capability of Large Language  Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.358, \"y\": 2.453}, {\"title\": \"BanglaAutoKG: Automatic Bangla Knowledge Graph Construction with  Semantic Neural Graph Filtering\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.932, \"y\": 5.873}, {\"title\": \"A Cause-Effect Look at Alleviating Hallucination of Knowledge-grounded  Dialogue Generation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.314, \"y\": 1.293}, {\"title\": \"Generative AI and Teachers -- For Us or Against Us? A Case Study\", \"topic\": \"Bias in Language Models\", \"x\": 4.941, \"y\": 4.435}, {\"title\": \"The Impact of Unstated Norms in Bias Analysis of Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.445, \"y\": 4.411}, {\"title\": \"Knowledge Graph Representation for Political Information Sources\", \"topic\": \"Fake News Detection\", \"x\": 3.68, \"y\": 5.61}, {\"title\": \"Can Small Language Models Help Large Language Models Reason Better?:  LM-Guided Chain-of-Thought\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.684, \"y\": 2.446}, {\"title\": \"Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak  Attacks?\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.413, \"y\": 2.298}, {\"title\": \"Mitigating LLM Hallucinations via Conformal Abstention\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.26, \"y\": 1.325}, {\"title\": \"nicolay-r at SemEval-2024 Task 3: Using Flan-T5 for Reasoning Emotion  Cause in Conversations with Chain-of-Thought on Emotion States\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.331, \"y\": 7.766}, {\"title\": \"Reason from Fallacy: Enhancing Large Language Models' Logical Reasoning  through Logical Fallacy Understanding\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.494, \"y\": 3.074}, {\"title\": \"Enhancing the Performance of Aspect-Based Sentiment Analysis Systems\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.114, \"y\": 6.865}, {\"title\": \"Conversational Disease Diagnosis via External Planner-Controlled Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.624, \"y\": 8.275}, {\"title\": \"RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting  for Text-to-Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.559, \"y\": 5.627}, {\"title\": \"Do Large Language Models Rank Fairly? An Empirical Study on the Fairness  of LLMs as Rankers\", \"topic\": \"Bias in Language Models\", \"x\": 3.444, \"y\": 4.266}, {\"title\": \"NLP at UC Santa Cruz at SemEval-2024 Task 5: Legal Answer Validation  using Few-Shot Multi-Choice QA\", \"topic\": \"Legal NLP\", \"x\": 5.115, \"y\": 5.703}, {\"title\": \"Exploring the Trade-off Between Model Performance and Explanation  Plausibility of Text Classifiers Using Human Rationales\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.918, \"y\": 3.864}, {\"title\": \"Auditing the Use of Language Models to Guide Hiring Decisions\", \"topic\": \"Bias in Language Models\", \"x\": 3.488, \"y\": 4.277}, {\"title\": \"Mai Ho'om\\u0101una i ka 'Ai: Language Models Improve Automatic Speech  Recognition in Hawaiian\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.128, \"y\": 5.432}, {\"title\": \"Assessing ML Classification Algorithms and NLP Techniques for Depression  Detection: An Experimental Case Study\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.165, \"y\": 7.513}, {\"title\": \"An Incomplete Loop: Deductive, Inductive, and Abductive Learning in  Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.954, \"y\": 3.371}, {\"title\": \"Blessing or curse? A survey on the Impact of Generative AI on Fake News\", \"topic\": \"Fake News Detection\", \"x\": 4.065, \"y\": 5.591}, {\"title\": \"ALOHa: A New Measure for Hallucination in Captioning Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.244, \"y\": 1.002}, {\"title\": \"ChatGLM-Math: Improving Math Problem-Solving in Large Language Models  with a Self-Critique Pipeline\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.845, \"y\": 2.775}, {\"title\": \"Linear Attention Sequence Parallelism\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.853, \"y\": 3.112}, {\"title\": \"Conifer: Improving Complex Constrained Instruction-Following Ability of  Large Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.116, \"y\": 2.339}, {\"title\": \"Identifying Climate Targets in National Laws and Policies using Machine  Learning\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.779, \"y\": 5.889}, {\"title\": \"On Few-Shot Prompting for Controllable Question-Answer Generation in  Narrative Comprehension\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.324, \"y\": 4.913}, {\"title\": \"FPT: Feature Prompt Tuning for Few-shot Readability Assessment\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.666, \"y\": 3.464}, {\"title\": \"Automatic Prompt Selection for Large Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.344, \"y\": 3.241}, {\"title\": \"Attention is Naturally Sparse with Gaussian Distributed Input\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.798, \"y\": 2.996}, {\"title\": \"Cross-Architecture Transfer Learning for Linear-Cost Inference  Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.787, \"y\": 3.303}, {\"title\": \"The VoicePrivacy 2024 Challenge Evaluation Plan\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.859, \"y\": 5.777}, {\"title\": \"Rethinking Kullback-Leibler Divergence in Knowledge Distillation for  Large Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.478, \"y\": 3.714}, {\"title\": \"Towards detecting unanticipated bias in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.4, \"y\": 4.212}, {\"title\": \"Leveraging the Interplay Between Syntactic and Acoustic Cues for  Optimizing Korean TTS Pause Formation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.633, \"y\": 5.701}, {\"title\": \"Affective-NLI: Towards Accurate and Interpretable Personality  Recognition in Conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.454, \"y\": 7.652}, {\"title\": \"Large Language Models for Expansion of Spoken Language Understanding  Systems to New Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.376, \"y\": 4.92}, {\"title\": \"Multi-Granularity Guided Fusion-in-Decoder\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.749, \"y\": 5.257}, {\"title\": \"Language Models as Compilers: Simulating Pseudocode Execution Improves  Algorithmic Reasoning in Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.941, \"y\": 2.559}, {\"title\": \"Personality-affected Emotion Generation in Dialog Systems\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.577, \"y\": 7.803}, {\"title\": \"Learn to Disguise: Avoid Refusal Responses in LLM's Defense via a  Multi-agent Attacker-Disguiser Game\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.511, \"y\": 2.676}, {\"title\": \"Dynamic Demonstration Retrieval and Cognitive Understanding for  Emotional Support Conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.55, \"y\": 7.878}, {\"title\": \"Enhancing Cross-lingual Sentence Embedding for Low-resource Languages  with Word Alignment\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.31, \"y\": 4.874}, {\"title\": \"uTeBC-NLP at SemEval-2024 Task 9: Can LLMs be Lateral Thinkers?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.437, \"y\": 2.666}, {\"title\": \"Prompting for Numerical Sequences: A Case Study on Market Comment  Generation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 6.866, \"y\": 3.347}, {\"title\": \"Adaptive Cross-lingual Text Classification through In-Context One-Shot  Demonstrations\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.363, \"y\": 4.653}, {\"title\": \"From Narratives to Numbers: Valid Inference Using Language Model  Predictions from Verbal Autopsy Narratives\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.346, \"y\": 7.57}, {\"title\": \"KnowHalu: Hallucination Detection via Multi-Form Knowledge Based Factual  Checking\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.222, \"y\": 1.146}, {\"title\": \"Token Trails: Navigating Contextual Depths in Conversational AI with  ChatLLM\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.415, \"y\": 3.588}, {\"title\": \"Backdoor Attack on Multilingual Machine Translation\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.335, \"y\": 2.521}, {\"title\": \"Low-resource neural machine translation with morphological modeling\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.921, \"y\": 4.326}, {\"title\": \"Enhancing Human-Computer Interaction in Chest X-ray Analysis using  Vision and Language Model with Eye Gaze Patterns\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.297, \"y\": 8.585}, {\"title\": \"Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient  Compile-Time Prompt Optimization\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.336, \"y\": 3.179}, {\"title\": \"Mixture-of-Depths: Dynamically allocating compute in transformer-based  language models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.786, \"y\": 3.273}, {\"title\": \"$\\\\texttt{LM}^\\\\texttt{2}$: A Simple Society of Language Models Solves  Complex Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.787, \"y\": 2.777}, {\"title\": \"FLawN-T5: An Empirical Examination of Effective Instruction-Tuning Data  Mixtures for Legal Reasoning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.257, \"y\": 2.272}, {\"title\": \"CLAPNQ: Cohesive Long-form Answers from Passages in Natural Questions  for RAG systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.829, \"y\": 4.769}, {\"title\": \"READ: Improving Relation Extraction from an ADversarial Perspective\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.832, \"y\": 6.76}, {\"title\": \"LastResort at SemEval-2024 Task 3: Exploring Multimodal Emotion Cause  Pair Extraction as Sequence Labelling Task\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.29, \"y\": 7.707}, {\"title\": \"Using Interpretation Methods for Model Enhancement\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.81, \"y\": 3.816}, {\"title\": \"BERTopic-Driven Stock Market Predictions: Unraveling Sentiment Insights\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.597, \"y\": 6.855}, {\"title\": \"Breaking the Silence Detecting and Mitigating Gendered Abuse in Hindi,  Tamil, and Indian English Online Spaces\", \"topic\": \"Hate Speech Detection\", \"x\": 2.82, \"y\": 5.369}, {\"title\": \"Preuve de concept d'un bot vocal dialoguant en wolof\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.772, \"y\": 5.6}, {\"title\": \"Africa-Centric Self-Supervised Pre-Training for Multilingual Speech  Representation in a Sub-Saharan Context\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.685, \"y\": 5.116}, {\"title\": \"DELAN: Dual-Level Alignment for Vision-and-Language Navigation by  Cross-Modal Contrastive Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.85, \"y\": 7.086}, {\"title\": \"Team UTSA-NLP at SemEval 2024 Task 5: Prompt Ensembling for Argument  Reasoning in Civil Procedures with GPT4\", \"topic\": \"Legal NLP\", \"x\": 5.032, \"y\": 5.642}, {\"title\": \"HyperCLOVA X Technical Report\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.599, \"y\": 4.138}, {\"title\": \"SGSH: Stimulate Large Language Models with Skeleton Heuristics for  Knowledge Base Question Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.761, \"y\": 5.366}, {\"title\": \"SCANNER: Knowledge-Enhanced Approach for Robust Multi-modal Named Entity  Recognition of Unseen Entities\", \"topic\": \"Named Entity Recognition\", \"x\": 7.361, \"y\": 6.698}, {\"title\": \"Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language  Models -- A Survey\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.607, \"y\": 3.358}, {\"title\": \"Detecting Gender Bias in Course Evaluations\", \"topic\": \"Bias in Language Models\", \"x\": 3.246, \"y\": 4.431}, {\"title\": \"Poro 34B and the Blessing of Multilinguality\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.002, \"y\": 4.263}, {\"title\": \"A (More) Realistic Evaluation Setup for Generalisation of Community  Models on Malicious Content Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.927, \"y\": 5.469}, {\"title\": \"Using Large Language Models to Understand Telecom Standards\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.423, \"y\": 4.022}, {\"title\": \"Auditing Large Language Models for Enhanced Text-Based Stereotype  Detection and Probing-Based Bias Evaluation\", \"topic\": \"Bias in Language Models\", \"x\": 3.32, \"y\": 4.487}, {\"title\": \"M2SA: Multimodal and Multilingual Model for Sentiment Analysis of Tweets\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.468, \"y\": 6.712}, {\"title\": \"Transfer Learning from Whisper for Microscopic Intelligibility  Prediction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.206, \"y\": 5.244}, {\"title\": \"Self-Improvement Programming for Temporal Knowledge Graph Question  Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.602, \"y\": 5.58}, {\"title\": \"Effective internal language model training and fusion for factorized  transducer model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.889, \"y\": 4.945}, {\"title\": \"On the Role of Summary Content Units in Text Summarization Evaluation\", \"topic\": \"Text Summarization\", \"x\": 5.536, \"y\": 6.184}, {\"title\": \"Event Detection from Social Media for Epidemic Prediction\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.165, \"y\": 6.862}, {\"title\": \"Towards Generalizable and Faithful Logic Reasoning over Natural Language  via Resolution Refutation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.696, \"y\": 2.931}, {\"title\": \"NLP Systems That Can't Tell Use from Mention Censor Counterspeech, but  Teaching the Distinction Helps\", \"topic\": \"Hate Speech Detection\", \"x\": 2.791, \"y\": 5.239}, {\"title\": \"CATP: Cross-Attention Token Pruning for Accuracy Preserved Multimodal  Model Inference\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.897, \"y\": 3.127}, {\"title\": \"Classifying Cancer Stage with Open-Source Clinical Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.905, \"y\": 8.083}, {\"title\": \"Hallucination Diversity-Aware Active Learning for Text Summarization\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.16, \"y\": 1.15}, {\"title\": \"TraveLER: A Multi-LMM Agent Framework for Video Question-Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.649, \"y\": 7.973}, {\"title\": \"CausalChaos! Dataset for Comprehensive Causal Action Question Answering  Over Longer Causal Chains Grounded in Dynamic Visual Scenes\", \"topic\": \"Multimodal Language Models\", \"x\": 8.156, \"y\": 7.866}, {\"title\": \"Evaluating Text-to-Visual Generation with Image-to-Text Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.818, \"y\": 7.489}, {\"title\": \"TWIN-GPT: Digital Twins for Clinical Trials via Large Language Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.581, \"y\": 8.048}, {\"title\": \"IsoBench: Benchmarking Multimodal Foundation Models on Isomorphic  Representations\", \"topic\": \"Multimodal Language Models\", \"x\": 7.898, \"y\": 7.453}, {\"title\": \"Effectively Prompting Small-sized Language Models for Cross-lingual  Tasks via Winning Tickets\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.738, \"y\": 3.409}, {\"title\": \"GFLean: An Autoformalisation Framework for Lean via GF\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.432, \"y\": 3.093}, {\"title\": \"Stable Code Technical Report\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.755, \"y\": 2.558}, {\"title\": \"AILS-NTUA at SemEval-2024 Task 6: Efficient model tuning for  hallucination detection and analysis\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.059, \"y\": 0.978}, {\"title\": \"Generating Faithful and Complete Hospital-Course Summaries from the  Electronic Health Record\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.627, \"y\": 7.93}, {\"title\": \"Exploring LLM Multi-Agents for ICD Coding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.861, \"y\": 8.351}, {\"title\": \"Dialogue with Robots: Proposals for Broadening Participation and  Research in the SLIVAR Community\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.076, \"y\": 3.788}, {\"title\": \"Structured Information Matters: Incorporating Abstract Meaning  Representation into LLMs for Improved Open-Domain Dialogue Evaluation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.635, \"y\": 3.867}, {\"title\": \"Efficient Prompting Methods for Large Language Models: A Survey\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.218, \"y\": 3.139}, {\"title\": \"Exploring the Mystery of Influential Data for Mathematical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.197, \"y\": 2.836}, {\"title\": \"Regularized Best-of-N Sampling to Mitigate Reward Hacking for Language  Model Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.277, \"y\": 1.329}, {\"title\": \"ARAGOG: Advanced RAG Output Grading\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.009, \"y\": 4.588}, {\"title\": \"Utilizing AI and Social Media Analytics to Discover Adverse Side Effects  of GLP-1 Receptor Agonists\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.052, \"y\": 7.713}, {\"title\": \"PairEval: Open-domain Dialogue Evaluation with Pairwise Comparison\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.389, \"y\": 3.856}, {\"title\": \"Constructing and Expanding Low-Resource and Underrepresented Parallel  Datasets for Indonesian Local Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.262, \"y\": 5.078}, {\"title\": \"LLM-RadJudge: Achieving Radiologist-Level Evaluation for X-Ray Report  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.046, \"y\": 8.565}, {\"title\": \"Exploring the Nexus of Large Language Models and Legal Systems: A Short  Survey\", \"topic\": \"Legal NLP\", \"x\": 5.178, \"y\": 5.446}, {\"title\": \"Prior Constraints-based Reward Model Training for Aligning Large  Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.266, \"y\": 1.422}, {\"title\": \"AISPACE at SemEval-2024 task 8: A Class-balanced Soft-voting System for  Detecting Multi-generator Machine-generated Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 3.949, \"y\": 5.127}, {\"title\": \"ChatGLM-RLHF: Practices of Aligning Large Language Models with Human  Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.193, \"y\": 1.518}, {\"title\": \"PSYDIAL: Personality-based Synthetic Dialogue Generation using Large  Language Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.026, \"y\": 3.708}, {\"title\": \"Diverse Perspectives, Divergent Models: Cross-Cultural Evaluation of  Depression Detection on Twitter\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.107, \"y\": 7.406}, {\"title\": \"TM-TREK at SemEval-2024 Task 8: Towards LLM-Based Automatic Boundary  Detection for Human-Machine Mixed Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.046, \"y\": 4.815}, {\"title\": \"Self-Demos: Eliciting Out-of-Demonstration Generalizability in Large  Language Models\", \"topic\": \"In-Context Learning\", \"x\": 8.177, \"y\": 3.365}, {\"title\": \"Do language models plan ahead for future tokens?\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.258, \"y\": 3.646}, {\"title\": \"Extracting Social Determinants of Health from Pediatric Patient Notes  Using Large Language Models: Novel Corpus and Methods\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.369, \"y\": 7.834}, {\"title\": \"Fairness in Large Language Models: A Taxonomic Survey\", \"topic\": \"Bias in Language Models\", \"x\": 3.485, \"y\": 4.16}, {\"title\": \"Opera Graeca Adnotata: Building a 34M+ Token Multilayer Corpus for  Ancient Greek\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.904, \"y\": 5.223}, {\"title\": \"A General and Efficient Training for Transformer via Token Expansion\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.815, \"y\": 3.215}, {\"title\": \"Observations on Building RAG Systems for Technical Documents\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.819, \"y\": 4.781}, {\"title\": \"WavLLM: Towards Robust and Adaptive Speech Large Language Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.544, \"y\": 5.122}, {\"title\": \"Enhancing Bangla Fake News Detection Using Bidirectional Gated Recurrent  Units and Deep Learning Techniques\", \"topic\": \"Fake News Detection\", \"x\": 4.04, \"y\": 5.838}, {\"title\": \"RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.99, \"y\": 4.633}, {\"title\": \"Extensive Self-Contrast Enables Feedback-Free Language Model Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.584, \"y\": 1.594}, {\"title\": \"EvoCodeBench: An Evolving Code Generation Benchmark Aligned with  Real-World Code Repositories\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.402, \"y\": 2.377}, {\"title\": \"Mind Your Neighbours: Leveraging Analogous Instances for Rhetorical Role  Labeling for Legal Documents\", \"topic\": \"Legal NLP\", \"x\": 5.099, \"y\": 5.792}, {\"title\": \"ECtHR-PCR: A Dataset for Precedent Understanding and Prior Case  Retrieval in the European Court of Human Rights\", \"topic\": \"Legal NLP\", \"x\": 5.056, \"y\": 5.872}, {\"title\": \"Query-driven Relevant Paragraph Extraction from Legal Judgments\", \"topic\": \"Legal NLP\", \"x\": 5.196, \"y\": 5.759}, {\"title\": \"LexAbSumm: Aspect-based Summarization of Legal Decisions\", \"topic\": \"Legal NLP\", \"x\": 5.089, \"y\": 5.871}, {\"title\": \"Explainable Multi-hop Question Generation: An End-to-End Approach  without Intermediate Question Labeling\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.544, \"y\": 5.234}, {\"title\": \"ParaICL: Towards Robust Parallel In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.32, \"y\": 3.409}, {\"title\": \"CM-TTS: Enhancing Real Time Text-to-Speech Synthesis Efficiency through  Weighted Samplers and Consistency Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.505, \"y\": 5.908}, {\"title\": \"CodeBenchGen: Creating Scalable Execution-based Code Generation  Benchmarks\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.425, \"y\": 2.386}, {\"title\": \"DivTOD: Unleashing the Power of LLMs for Diversifying Task-Oriented  Dialogue Representations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.671, \"y\": 3.914}, {\"title\": \"Comparing Bad Apples to Good Oranges: Aligning Large Language Models via  Joint Preference Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.295, \"y\": 1.29}, {\"title\": \"MIPS at SemEval-2024 Task 3: Multimodal Emotion-Cause Pair Extraction in  Conversations with Multimodal Language Models\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.32, \"y\": 7.634}, {\"title\": \"Humane Speech Synthesis through Zero-Shot Emotion and Disfluency  Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.594, \"y\": 5.969}, {\"title\": \"Multi-hop Question Answering under Temporal Knowledge Editing\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.449, \"y\": 5.381}, {\"title\": \"PROMPT-SAW: Leveraging Relation-Aware Graphs for Textual Prompt  Compression\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.585, \"y\": 3.141}, {\"title\": \"Edinburgh Clinical NLP at SemEval-2024 Task 2: Fine-tune your model  unless you have access to GPT-4\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.812, \"y\": 7.676}, {\"title\": \"Addressing Both Statistical and Causal Gender Fairness in NLP Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.286, \"y\": 4.24}, {\"title\": \"Automatic explanation of the classification of Spanish legal judgments  in jurisdiction-dependent law categories with tree estimators\", \"topic\": \"Legal NLP\", \"x\": 5.17, \"y\": 5.805}, {\"title\": \"Automatic detection of relevant information, predictions and forecasts  in financial news through topic modelling with Latent Dirichlet Allocation\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.755, \"y\": 6.778}, {\"title\": \"Do Vision-Language Models Understand Compound Nouns?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.893, \"y\": 7.355}, {\"title\": \"Targeted aspect-based emotion analysis to detect opportunities and  precaution in financial Twitter messages\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.469, \"y\": 6.862}, {\"title\": \"Detection of Temporality at Discourse Level on Financial News by  Combining Natural Language Processing and Machine Learning\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.837, \"y\": 6.715}, {\"title\": \"UniMEEC: Towards Unified Multimodal Emotion Recognition and Emotion  Cause\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.299, \"y\": 7.666}, {\"title\": \"Aurora-M: The First Open Source Multilingual Language Model Red-teamed  according to the U.S. Executive Order\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.929, \"y\": 4.298}, {\"title\": \"FineFake: A Knowledge-Enriched Dataset for Fine-Grained Multi-Domain  Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.04, \"y\": 5.825}, {\"title\": \"Small Language Models Learn Enhanced Reasoning Skills from Medical  Textbooks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.78, \"y\": 7.96}, {\"title\": \"Controllable and Diverse Data Augmentation with Large Language Model for  Low-Resource Open-Domain Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.534, \"y\": 3.891}, {\"title\": \"Can LLMs Master Math? Investigating Large Language Models on Math Stack  Exchange\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.831, \"y\": 2.997}, {\"title\": \"Augmenting NER Datasets with LLMs: Towards Automated and Refined  Annotation\", \"topic\": \"Named Entity Recognition\", \"x\": 7.369, \"y\": 6.795}, {\"title\": \"A Comprehensive Study on NLP Data Augmentation for Hate Speech  Detection: Legacy Methods, BERT, and LLMs\", \"topic\": \"Hate Speech Detection\", \"x\": 2.743, \"y\": 5.363}, {\"title\": \"TRABSA: Interpretable Sentiment Analysis of Tweets using Attention-based  BiLSTM and Twitter-RoBERTa\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.637, \"y\": 6.707}, {\"title\": \"Survey on Large Language Model-Enhanced Reinforcement Learning: Concept,  Taxonomy, and Methods\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.939, \"y\": 2.38}, {\"title\": \"DiLM: Distilling Dataset into Language Model for Text-level Dataset  Distillation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.37, \"y\": 3.842}, {\"title\": \"Your Co-Workers Matter: Evaluating Collaborative Capabilities of  Language Models in Blocks World\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.31, \"y\": 2.933}, {\"title\": \"Enhancing Content-based Recommendation via Large Language Model\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.865, \"y\": 2.812}, {\"title\": \"Conceptual and Unbiased Reasoning in Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.786, \"y\": 3.242}, {\"title\": \"GPTA: Generative Prompt Tuning Assistant for Synergistic Downstream  Neural Network Enhancement with LLMs\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.513, \"y\": 3.228}, {\"title\": \"LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact  Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.42, \"y\": 7.413}, {\"title\": \"On-the-fly Definition Augmentation of LLMs for Biomedical NER\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.232, \"y\": 7.564}, {\"title\": \"Unsolvable Problem Detection: Evaluating Trustworthiness of Vision  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.279, \"y\": 7.87}, {\"title\": \"Towards a Framework for Evaluating Explanations in Automated Fact  Verification\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.818, \"y\": 3.767}, {\"title\": \"Emotion-Anchored Contrastive Learning Framework for Emotion Recognition  in Conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.261, \"y\": 7.802}, {\"title\": \"Can LLMs Correct Physicians, Yet? Investigating Effective Interaction  Methods in the Medical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.579, \"y\": 7.957}, {\"title\": \"Exploring Pathological Speech Quality Assessment with ASR-Powered  Wav2Vec2 in Data-Scarce Context\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.215, \"y\": 5.671}, {\"title\": \"Identifying Banking Transaction Descriptions via Support Vector Machine  Short-Text Classification Based on a Specialized Labelled Corpus\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.018, \"y\": 6.737}, {\"title\": \"A Systematic Analysis of Subwords and Cross-Lingual Transfer in  Multilingual Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.272, \"y\": 4.843}, {\"title\": \"IndiBias: A Benchmark Dataset to Measure Social Biases in Language  Models for Indian Context\", \"topic\": \"Bias in Language Models\", \"x\": 3.526, \"y\": 4.506}, {\"title\": \"User Modeling Challenges in Interactive AI Assistant Systems\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.154, \"y\": 3.472}, {\"title\": \"Constructing Multilingual Visual-Text Datasets Revealing Visual  Multilingual Ability of Vision Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.512, \"y\": 7.609}, {\"title\": \"NLP for Counterspeech against Hate: A Survey and How-To Guide\", \"topic\": \"Hate Speech Detection\", \"x\": 2.77, \"y\": 5.303}, {\"title\": \"An Efficient Approach for Studying Cross-Lingual Transfer in  Multilingual Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.332, \"y\": 4.746}, {\"title\": \"Cross-Lingual Transfer Robustness to Lower-Resource Languages on  Adversarial Datasets\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.37, \"y\": 4.872}, {\"title\": \"Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to  Boost for Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.717, \"y\": 2.296}, {\"title\": \"FSMR: A Feature Swapping Multi-modal Reasoning Approach with Joint  Textual and Visual Clues\", \"topic\": \"Multimodal Language Models\", \"x\": 8.266, \"y\": 7.208}, {\"title\": \"On Large Language Models' Hallucination with Regard to Known Facts\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.195, \"y\": 1.159}, {\"title\": \"Large Language Model based Situational Dialogues for Second Language  Learning\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.575, \"y\": 3.502}, {\"title\": \"Enhancing the General Agent Capabilities of Low-Parameter LLMs through  Tuning and Multi-Branch Reasoning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 6.001, \"y\": 2.423}, {\"title\": \"Concept-based Analysis of Neural Networks via Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.507, \"y\": 7.565}, {\"title\": \"Target Span Detection for Implicit Harmful Content\", \"topic\": \"Hate Speech Detection\", \"x\": 2.757, \"y\": 5.405}, {\"title\": \"Multi-Stage Multi-Modal Pre-Training for Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.073, \"y\": 5.11}, {\"title\": \"Developing Healthcare Language Model Embedding Spaces\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.072, \"y\": 8.019}, {\"title\": \"GOLD: Generalized Knowledge Distillation via Out-of-Distribution-Guided  Language Data Generation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.46, \"y\": 3.749}, {\"title\": \"MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.397, \"y\": 7.184}, {\"title\": \"Asymmetric and trial-dependent modeling: the contribution of LIA to SdSV  Challenge Task 2\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.118, \"y\": 5.616}, {\"title\": \"Improving Adversarial Data Collection by Supporting Annotators: Lessons  from GAHD, a German Hate Speech Dataset\", \"topic\": \"Hate Speech Detection\", \"x\": 2.751, \"y\": 5.36}, {\"title\": \"A Review of Multi-Modal Large Language and Vision Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.061, \"y\": 7.274}, {\"title\": \"Improving Clinical NLP Performance through Language Model-Generated  Synthetic Clinical Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.616, \"y\": 7.96}, {\"title\": \"Phonetic Segmentation of the UCLA Phonetics Lab Archive\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.387, \"y\": 5.421}, {\"title\": \"JDocQA: Japanese Document Question Answering Dataset for Generative  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.871, \"y\": 7.978}, {\"title\": \"Mixed Preference Optimization: Reinforcement Learning with Data  Selection and Better Reference Model\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.279, \"y\": 1.297}, {\"title\": \"BP4ER: Bootstrap Prompting for Explicit Reasoning in Medical Dialogue  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.656, \"y\": 7.987}, {\"title\": \"KazParC: Kazakh Parallel Corpus for Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.523, \"y\": 5.163}, {\"title\": \"EthioMT: Parallel Corpus for Low-resource Ethiopian Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.357, \"y\": 5.164}, {\"title\": \"Risk prediction of pathological gambling on social media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.109, \"y\": 7.158}, {\"title\": \"AIpom at SemEval-2024 Task 8: Detecting AI-produced Outputs in M4\", \"topic\": \"AI-Generated Text Detection\", \"x\": 3.904, \"y\": 5.115}, {\"title\": \"Large Language Models Are Unconscious of Unreasonability in Math  Problems\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.747, \"y\": 3.037}, {\"title\": \"Dataverse: Open-Source ETL (Extract, Transform, Load) Pipeline for Large  Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.529, \"y\": 4.051}, {\"title\": \"KazSAnDRA: Kazakh Sentiment Analysis Dataset of Reviews and Attitudes\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.579, \"y\": 6.506}, {\"title\": \"Plug-and-Play Grounding of Reasoning in Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.478, \"y\": 7.438}, {\"title\": \"Beyond Borders: Investigating Cross-Jurisdiction Transfer in Legal Case  Summarization\", \"topic\": \"Legal NLP\", \"x\": 5.067, \"y\": 5.843}, {\"title\": \"EmoScan: Automatic Screening of Depression Symptoms in Romanized Sinhala  Tweets\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.149, \"y\": 7.445}, {\"title\": \"Going Beyond Word Matching: Syntax Improves In-context Example Selection  for Machine Translation\", \"topic\": \"In-Context Learning\", \"x\": 8.496, \"y\": 3.605}, {\"title\": \"Fine-Tuning Language Models with Reward Learning on Policy\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.207, \"y\": 1.476}, {\"title\": \"sDPO: Don't Use Your Data All at Once\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.31, \"y\": 1.234}, {\"title\": \"NaijaHate: Evaluating Hate Speech Detection on Nigerian Twitter Using  Representative Data\", \"topic\": \"Hate Speech Detection\", \"x\": 2.774, \"y\": 5.372}, {\"title\": \"A Benchmark Evaluation of Clinical Named Entity Recognition in French\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.213, \"y\": 7.748}, {\"title\": \"MUGC: Machine Generated versus User Generated Content Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.231, \"y\": 4.714}, {\"title\": \"Mitigating Misleading Chain-of-Thought Reasoning with Selective  Filtering\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.686, \"y\": 2.306}, {\"title\": \"Improving Vietnamese-English Medical Machine Translation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.231, \"y\": 7.877}, {\"title\": \"Disentangling Length from Quality in Direct Preference Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.266, \"y\": 1.332}, {\"title\": \"A Tulu Resource for Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.65, \"y\": 5.042}, {\"title\": \"Streamlining Redundant Layers to Compress Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.533, \"y\": 2.443}, {\"title\": \"Code Comparison Tuning for Code Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.715, \"y\": 2.367}, {\"title\": \"MFORT-QA: Multi-hop Few-shot Open Rich Table Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.638, \"y\": 5.334}, {\"title\": \"Top Leaderboard Ranking = Top Coding Proficiency, Always? EvoEval:  Evolving Coding Benchmarks via LLM\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.44, \"y\": 2.352}, {\"title\": \"FACTOID: FACtual enTailment fOr hallucInation Detection\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.123, \"y\": 1.093}, {\"title\": \"CAUSE: Counterfactual Assessment of User Satisfaction Estimation in  Task-Oriented Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.4, \"y\": 3.769}, {\"title\": \"IDGenRec: LLM-RecSys Alignment with Textual ID Learning\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.892, \"y\": 2.866}, {\"title\": \"ReflectSumm: A Benchmark for Course Reflection Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.42, \"y\": 6.31}, {\"title\": \"\\\"Sorry, Come Again?\\\" Prompting -- Enhancing Comprehension and  Diminishing Hallucination with [PAUSE]-injected Optimal Paraphrasing\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.262, \"y\": 1.18}, {\"title\": \"A Novel Corpus of Annotated Medical Imaging Reports and Information  Extraction Results Using BERT-based Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.198, \"y\": 8.488}, {\"title\": \"The Comparison of Translationese in Machine Translation and Human  Transation in terms of Translation Relations\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.777, \"y\": 4.722}, {\"title\": \"Reshaping Free-Text Radiology Notes Into Structured Reports With  Generative Transformers\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.089, \"y\": 8.515}, {\"title\": \"Mini-Gemini: Mining the Potential of Multi-modality Vision Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.213, \"y\": 7.602}, {\"title\": \"Projective Methods for Mitigating Gender Bias in Pre-trained Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.11, \"y\": 4.369}, {\"title\": \"CYCLE: Learning to Self-Refine the Code Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.419, \"y\": 2.229}, {\"title\": \"Mitigating Hallucinations in Large Vision-Language Models with  Instruction Contrastive Decoding\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.346, \"y\": 1.074}, {\"title\": \"Improving Content Recommendation: Knowledge Graph-Based Semantic  Contrastive Learning for Diversity and Cold-Start Users\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.845, \"y\": 2.93}, {\"title\": \"A Path Towards Legal Autonomy: An interoperable and explainable approach  to extracting, transforming, loading and computing legal information using  large language models, expert systems and Bayesian networks\", \"topic\": \"Legal NLP\", \"x\": 4.991, \"y\": 5.291}, {\"title\": \"PhoWhisper: Automatic Speech Recognition for Vietnamese\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.159, \"y\": 5.494}, {\"title\": \"Language Plays a Pivotal Role in the Object-Attribute Compositional  Generalization of CLIP\", \"topic\": \"Multimodal Language Models\", \"x\": 8.993, \"y\": 7.216}, {\"title\": \"Can Language Beat Numerical Regression? Language-Based Multimodal  Trajectory Prediction\", \"topic\": \"Multimodal Language Models\", \"x\": 8.109, \"y\": 7.326}, {\"title\": \"DELTA: Pre-train a Discriminative Encoder for Legal Case Retrieval via  Structural Word Alignment\", \"topic\": \"Legal NLP\", \"x\": 5.16, \"y\": 5.733}, {\"title\": \"TriviaHG: A Dataset for Automatic Hint Generation from Factoid Questions\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.084, \"y\": 4.872}, {\"title\": \"SemRoDe: Macro Adversarial Training to Learn Representations That are  Robust to Word-Level Attacks\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.207, \"y\": 2.979}, {\"title\": \"BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.97, \"y\": 7.698}, {\"title\": \"An Image Grid Can Be Worth a Video: Zero-shot Video Question Answering  Using a VLM\", \"topic\": \"Multimodal Language Models\", \"x\": 8.534, \"y\": 7.98}, {\"title\": \"Quantifying and Mitigating Unimodal Biases in Multimodal Large Language  Models: A Causal Perspective\", \"topic\": \"Multimodal Language Models\", \"x\": 8.1, \"y\": 7.818}, {\"title\": \"IterAlign: Iterative Constitutional Alignment of Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.463, \"y\": 1.389}, {\"title\": \"A Dataset for Pharmacovigilance in German, French, and Japanese:  Annotating Adverse Drug Reactions across Languages\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.818, \"y\": 7.818}, {\"title\": \"Chinese Offensive Language Detection:Current Status and Future  Directions\", \"topic\": \"Hate Speech Detection\", \"x\": 2.782, \"y\": 5.326}, {\"title\": \"Toward Interactive Regional Understanding in Vision-Large Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.62, \"y\": 7.597}, {\"title\": \"Beyond Embeddings: The Promise of Visual Table in Visual Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.308, \"y\": 7.56}, {\"title\": \"Exploring the Deceptive Power of LLM-Generated Fake News: A Study of  Real-World Detection Challenges\", \"topic\": \"Fake News Detection\", \"x\": 4.078, \"y\": 5.707}, {\"title\": \"Mechanistic Understanding and Mitigation of Language Model Non-Factual  Hallucinations\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.184, \"y\": 1.127}, {\"title\": \"Large Language Models as Financial Data Annotators: A Study on  Effectiveness and Efficiency\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.916, \"y\": 6.783}, {\"title\": \"Large Language Models Produce Responses Perceived to be Empathic\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.773, \"y\": 7.878}, {\"title\": \"Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with  Autoformalization\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.87, \"y\": 2.737}, {\"title\": \"GPTs and Language Barrier: A Cross-Lingual Legal QA Examination\", \"topic\": \"Legal NLP\", \"x\": 5.483, \"y\": 5.489}, {\"title\": \"Enhancing Legal Document Retrieval: A Multi-Phase Approach with Large  Language Models\", \"topic\": \"Legal NLP\", \"x\": 5.192, \"y\": 5.597}, {\"title\": \"Heracles: A Hybrid SSM-Transformer Model for High-Resolution Image and  Time-Series Analysis\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.681, \"y\": 3.207}, {\"title\": \"COIG-CQIA: Quality is All You Need for Chinese Instruction Fine-tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.192, \"y\": 2.312}, {\"title\": \"Supervisory Prompt Training\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.37, \"y\": 3.186}, {\"title\": \"The Impact of Syntactic and Semantic Proximity on Machine Translation  with Back-Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.641, \"y\": 4.62}, {\"title\": \"DORE: A Dataset For Portuguese Definition Generation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.837, \"y\": 4.422}, {\"title\": \"LISA: Layerwise Importance Sampling for Memory-Efficient Large Language  Model Fine-Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.194, \"y\": 2.112}, {\"title\": \"The Unreasonable Ineffectiveness of the Deeper Layers\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.448, \"y\": 2.443}, {\"title\": \"ChroniclingAmericaQA: A Large-scale Question Answering Dataset based on  Historical American Newspaper Pages\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.43, \"y\": 5.284}, {\"title\": \"Using Domain Knowledge to Guide Dialog Structure Induction via Neural  Probabilistic Soft Logic\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.597, \"y\": 3.873}, {\"title\": \"ArabicaQA: A Comprehensive Dataset for Arabic Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.834, \"y\": 5.264}, {\"title\": \"Graph Language Model (GLM): A new graph-based approach to detect social  instabilities\", \"topic\": \"Fake News Detection\", \"x\": 3.784, \"y\": 5.907}, {\"title\": \"FastPerson: Enhancing Video Learning through Effective Video  Summarization that Preserves Linguistic and Visual Contexts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.945, \"y\": 7.895}, {\"title\": \"NJUST-KMG at TRAC-2024 Tasks 1 and 2: Offline Harm Potential  Identification\", \"topic\": \"Hate Speech Detection\", \"x\": 3.22, \"y\": 5.564}, {\"title\": \"Intrinsic Subgraph Generation for Interpretable Graph based Visual  Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.086, \"y\": 7.886}, {\"title\": \"DANCER: Entity Description Augmented Named Entity Corrector for  Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.172, \"y\": 5.325}, {\"title\": \"Mix-Initiative Response Generation with Dynamic Prefix Tuning\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.546, \"y\": 3.765}, {\"title\": \"\\\"You are an expert annotator\\\": Automatic Best-Worst-Scaling Annotations  for Emotion Intensity Modeling\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.464, \"y\": 7.296}, {\"title\": \"Towards a Zero-Data, Controllable, Adaptive Dialog System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.384, \"y\": 3.731}, {\"title\": \"m3P: Towards Multimodal Multilingual Translation with Multimodal Prompt\", \"topic\": \"Multimodal Language Models\", \"x\": 8.479, \"y\": 7.04}, {\"title\": \"RuBia: A Russian Language Bias Detection Dataset\", \"topic\": \"Bias in Language Models\", \"x\": 3.314, \"y\": 4.417}, {\"title\": \"Naive Bayes-based Context Extension for Large Language Models\", \"topic\": \"In-Context Learning\", \"x\": 8.887, \"y\": 3.128}, {\"title\": \"A Gaze-grounded Visual Question Answering Dataset for Clarifying  Ambiguous Japanese Questions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.228, \"y\": 7.971}, {\"title\": \"ILLUMINER: Instruction-tuned Large Language Models as Few-shot Intent  Classifier and Slot Filler\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.259, \"y\": 2.354}, {\"title\": \"Multilingual Sentence-T5: Scalable Sentence Encoders for Multilingual  Applications\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.259, \"y\": 4.985}, {\"title\": \"Sharing the Cost of Success: A Game for Evaluating and Learning  Collaborative Multi-Agent Instruction Giving and Following Policies\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.251, \"y\": 2.799}, {\"title\": \"DGoT: Dynamic Graph of Thoughts for Scientific Abstract Generation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.525, \"y\": 2.609}, {\"title\": \"PCToolkit: A Unified Plug-and-Play Prompt Compression Toolkit of Large  Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.85, \"y\": 3.226}, {\"title\": \"ELLEN: Extremely Lightly Supervised Learning For Efficient Named Entity  Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.401, \"y\": 6.788}, {\"title\": \"Extracting Biomedical Entities from Noisy Audio Transcripts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.079, \"y\": 7.735}, {\"title\": \"Residual-based Language Models are Free Boosters for Biomedical Imaging\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.572, \"y\": 8.231}, {\"title\": \"Don't Listen To Me: Understanding and Exploring Jailbreak Prompts of  Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.261, \"y\": 2.249}, {\"title\": \"JMultiWOZ: A Large-Scale Japanese Multi-Domain Task-Oriented Dialogue  Dataset\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.567, \"y\": 3.695}, {\"title\": \"Common Ground Tracking in Multimodal Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.58, \"y\": 3.681}, {\"title\": \"Automate Knowledge Concept Tagging on Math Questions with LLMs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.073, \"y\": 3.23}, {\"title\": \"A Hybrid Approach To Aspect Based Sentiment Analysis Using Transfer  Learning\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.092, \"y\": 6.85}, {\"title\": \"Extracting Social Support and Social Isolation Information from Clinical  Psychiatry Notes: Comparing a Rule-based NLP System and a Large Language  Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.219, \"y\": 7.776}, {\"title\": \"Advancing Speech Translation: A Corpus of Mandarin-English  Conversational Telephone Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.368, \"y\": 5.308}, {\"title\": \"Reflecting the Male Gaze: Quantifying Female Objectification in 19th and  20th Century Novels\", \"topic\": \"Bias in Language Models\", \"x\": 3.122, \"y\": 4.544}, {\"title\": \"Outcome-Constrained Large Language Models for Countering Hate Speech\", \"topic\": \"Hate Speech Detection\", \"x\": 2.753, \"y\": 5.293}, {\"title\": \"Guided Distant Supervision for Multilingual Relation Extraction Data:  Adapting to a New Language\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.95, \"y\": 6.827}, {\"title\": \"MetaAligner: Towards Generalizable Multi-Objective Alignment of Language  Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.321, \"y\": 1.34}, {\"title\": \"Exploring the Generalization of Cancer Clinical Trial Eligibility  Classifiers Across Diseases\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.815, \"y\": 7.819}, {\"title\": \"The Strong Pull of Prior Knowledge in Large Language Models and Its  Impact on Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.328, \"y\": 7.618}, {\"title\": \"STRUM-LLM: Attributed and Structured Contrastive Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.589, \"y\": 6.337}, {\"title\": \"VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.675, \"y\": 5.883}, {\"title\": \"AIOS: LLM Agent Operating System\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.637, \"y\": 2.831}, {\"title\": \"Hierarchical Recurrent Adapters for Efficient Multi-Task Adaptation of  Large Speech Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.016, \"y\": 4.866}, {\"title\": \"Towards Algorithmic Fidelity: Mental Health Representation across  Demographics in Synthetic vs. Human-generated Data\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.439, \"y\": 7.587}, {\"title\": \"Encoding of lexical tone in self-supervised models of spoken language\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.553, \"y\": 5.064}, {\"title\": \"Towards Explainability in Legal Outcome Prediction Models\", \"topic\": \"Legal NLP\", \"x\": 5.039, \"y\": 5.682}, {\"title\": \"Cross-lingual Contextualized Phrase Retrieval\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.26, \"y\": 5.043}, {\"title\": \"Iterative Refinement of Project-Level Code Context for Precise Code  Generation with Compiler Feedback\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.517, \"y\": 2.321}, {\"title\": \"Can Machine Translation Bridge Multilingual Pretraining and  Cross-lingual Transfer Learning?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.53, \"y\": 4.83}, {\"title\": \"Synthetic Data Generation and Joint Learning for Robust Code-Mixed  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.767, \"y\": 4.69}, {\"title\": \"TrustAI at SemEval-2024 Task 8: A Comprehensive Analysis of Multi-domain  Machine Generated Text Detection Techniques\", \"topic\": \"AI-Generated Text Detection\", \"x\": 3.912, \"y\": 5.095}, {\"title\": \"Hallucination Detection in Foundation Models for Decision-Making: A  Flexible Definition and Review of the State of the Art\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.156, \"y\": 1.093}, {\"title\": \"A Study on How Attention Scores in the BERT Model are Aware of Lexical  Categories in Syntactic and Semantic Tasks on the GLUE Benchmark\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.372, \"y\": 3.301}, {\"title\": \"Towards Automatic Evaluation for LLMs' Clinical Capabilities: Metric,  Data, and Algorithm\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.535, \"y\": 8.237}, {\"title\": \"CodeS: Natural Language to Code Repository via Multi-Layer Sketch\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.452, \"y\": 2.445}, {\"title\": \"If CLIP Could Talk: Understanding Vision-Language Model Representations  Through Their Preferred Concept Descriptions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.7, \"y\": 7.481}, {\"title\": \"Reasoning Runtime Behavior of a Program with LLM: How Far Are We?\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.203, \"y\": 2.49}, {\"title\": \"Synthesize Step-by-Step: Tools, Templates and LLMs as Data Generators  for Reasoning-Based Chart VQA\", \"topic\": \"Multimodal Language Models\", \"x\": 7.87, \"y\": 7.907}, {\"title\": \"Large Language Models in Biomedical and Health Informatics: A  Bibliometric Review\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.674, \"y\": 7.682}, {\"title\": \"LexDrafter: Terminology Drafting for Legislative Documents using  Retrieval Augmented Generation\", \"topic\": \"Legal NLP\", \"x\": 5.339, \"y\": 5.857}, {\"title\": \"Improving Sequence-to-Sequence Models for Abstractive Text Summarization  Using Meta Heuristic Approaches\", \"topic\": \"Text Summarization\", \"x\": 5.62, \"y\": 6.446}, {\"title\": \"ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language  Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.159, \"y\": 2.072}, {\"title\": \"Subspace Defense: Discarding Adversarial Perturbations by Learning a  Subspace for Clean Signals\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.118, \"y\": 2.961}, {\"title\": \"Exploiting Semantic Reconstruction to Mitigate Hallucinations in  Vision-Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.265, \"y\": 1.007}, {\"title\": \"Korean Bio-Medical Corpus (KBMC) for Medical Named Entity Recognition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.315, \"y\": 7.693}, {\"title\": \"A Multi-Label Dataset of French Fake News: Human and Machine Insights\", \"topic\": \"Fake News Detection\", \"x\": 4.065, \"y\": 5.814}, {\"title\": \"LLMs as Compiler for Arabic Programming Language\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.453, \"y\": 2.633}, {\"title\": \"Qibo: A Large Language Model for Traditional Chinese Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.947, \"y\": 8.054}, {\"title\": \"BIMCV-R: A Landmark Dataset for 3D CT Text-Image Retrieval\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.42, \"y\": 8.43}, {\"title\": \"IllusionVQA: A Challenging Optical Illusion Dataset for Vision Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.315, \"y\": 7.827}, {\"title\": \"STEntConv: Predicting Disagreement with Stance Detection and a Signed  Graph Convolutional Network\", \"topic\": \"Fake News Detection\", \"x\": 3.531, \"y\": 5.864}, {\"title\": \"Centered Masking for Language-Image Pre-Training\", \"topic\": \"Multimodal Language Models\", \"x\": 9.045, \"y\": 6.976}, {\"title\": \"MRC-based Nested Medical NER with Co-prediction and Adaptive  Pre-training\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.278, \"y\": 7.813}, {\"title\": \"User-Side Realization\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.185, \"y\": 3.936}, {\"title\": \"Towards a RAG-based Summarization Agent for the Electron-Ion Collider\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.858, \"y\": 4.832}, {\"title\": \"FEEL: A Framework for Evaluating Emotional Support Capability with Large  Language Models\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.563, \"y\": 7.773}, {\"title\": \"EAGLE: A Domain Generalization Framework for AI-generated Text Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.064, \"y\": 4.825}, {\"title\": \"AC4: Algebraic Computation Checker for Circuit Constraints in ZKPs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.321, \"y\": 2.801}, {\"title\": \"AI for Biomedicine in the Era of Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.7, \"y\": 7.702}, {\"title\": \"Improving Retrieval for RAG based Question Answering Models on Financial  Documents\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.947, \"y\": 4.689}, {\"title\": \"NaturalTurn: A Method to Segment Transcripts into Naturalistic  Conversational Turns\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.156, \"y\": 3.93}, {\"title\": \"LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.695, \"y\": 7.515}, {\"title\": \"Can large language models explore in-context?\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.874, \"y\": 2.479}, {\"title\": \"Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy  with Semantic Search and Hybrid Query-Based Retrievers\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.016, \"y\": 4.757}, {\"title\": \"Multi-Review Fusion-in-Context\", \"topic\": \"Text Summarization\", \"x\": 5.658, \"y\": 6.24}, {\"title\": \"Comprehensive Reassessment of Large-Scale Evaluation Outcomes in LLMs: A  Multifaceted Statistical Approach\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.167, \"y\": 3.946}, {\"title\": \"Not All Attention is Needed: Parameter and Computation Efficient  Transfer Learning for Multi-modal Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.967, \"y\": 2.413}, {\"title\": \"Investigating the Performance of Language Models for Completing Code in  Functional Programming Languages: a Haskell Case Study\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.521, \"y\": 2.465}, {\"title\": \"CACA Agent: Capability Collaboration based AI Agent\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.453, \"y\": 2.943}, {\"title\": \"CTSM: Combining Trait and State Emotions for Empathetic Response Model\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.656, \"y\": 7.878}, {\"title\": \"Construction of a Japanese Financial Benchmark for Large Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.062, \"y\": 6.642}, {\"title\": \"ESG Classification by Implicit Rule Learning via GPT-4\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.772, \"y\": 6.495}, {\"title\": \"MasonTigers at SemEval-2024 Task 8: Performance Analysis of  Transformer-based Models on Machine-Generated Text Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 3.908, \"y\": 5.18}, {\"title\": \"MasonTigers at SemEval-2024 Task 9: Solving Puzzles with an Ensemble of  Chain-of-Thoughts\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.588, \"y\": 2.576}, {\"title\": \"KnowLA: Enhancing Parameter-efficient Finetuning with Knowledgeable  Adaptation\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.961, \"y\": 2.158}, {\"title\": \"A Single Linear Layer Yields Task-Adapted Low-Rank Matrices\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.193, \"y\": 2.072}, {\"title\": \"Extending Token Computation for LLM Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.687, \"y\": 2.37}, {\"title\": \"Optimal path for Biomedical Text Summarization Using Pointer GPT\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.857, \"y\": 7.759}, {\"title\": \"Stance Reasoner: Zero-Shot Stance Detection on Social Media with  Explicit Reasoning\", \"topic\": \"Fake News Detection\", \"x\": 3.509, \"y\": 5.815}, {\"title\": \"AutoRE: Document-Level Relation Extraction with Large Language Models\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.809, \"y\": 6.821}, {\"title\": \"Evaluating the Performance of LLMs on Technical Language Processing  tasks\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.186, \"y\": 3.943}, {\"title\": \"VidLA: Video-Language Alignment at Scale\", \"topic\": \"Multimodal Language Models\", \"x\": 8.892, \"y\": 7.815}, {\"title\": \"Enhancing Medical Support in the Arabic Language Through Personalized  ChatGPT Assistance\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.645, \"y\": 8.098}, {\"title\": \"Multi-Agent VQA: Exploring Multi-Agent Foundation Models in Zero-Shot  Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.223, \"y\": 8.005}, {\"title\": \"Emergent World Models and Latent Variable Estimation in Chess-Playing  Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.59, \"y\": 3.045}, {\"title\": \"StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation  from Text\", \"topic\": \"Multimodal Language Models\", \"x\": 9.037, \"y\": 7.717}, {\"title\": \"MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual  Math Problems?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.004, \"y\": 7.587}, {\"title\": \"ReAct Meets ActRe: When Language Agents Enjoy Training Data Autonomy\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.955, \"y\": 2.315}, {\"title\": \"Large Language Models for Multi-Choice Question Classification of  Medical Subjects\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.89, \"y\": 7.767}, {\"title\": \"Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling\", \"topic\": \"Multimodal Language Models\", \"x\": 8.665, \"y\": 7.075}, {\"title\": \"Multi-Level Explanations for Generative Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.085, \"y\": 3.667}, {\"title\": \"Prediction of Translation Techniques for the Translation Process\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.852, \"y\": 4.66}, {\"title\": \"A Multimodal Approach to Device-Directed Speech Detection with Large  Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.922, \"y\": 5.364}, {\"title\": \"Locating and Mitigating Gender Bias in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.312, \"y\": 4.323}, {\"title\": \"Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language  Models through Question Complexity\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.921, \"y\": 4.609}, {\"title\": \"XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for  Noise-Robust Speech Perception\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.573, \"y\": 5.542}, {\"title\": \"Building Accurate Translation-Tailored LLMs with Language Aware  Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.264, \"y\": 2.478}, {\"title\": \"From Large to Tiny: Distilling and Refining Mathematical Expertise for  Math Word Problems with Weakly Supervision\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.15, \"y\": 2.739}, {\"title\": \"Editing Knowledge Representation of Language Model via Rephrased Prefix  Prompts\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.709, \"y\": 3.102}, {\"title\": \"FIT-RAG: Black-Box RAG with Factual Information and Token Reduction\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.967, \"y\": 4.623}, {\"title\": \"Beyond Surface Similarity: Detecting Subtle Semantic Shifts in Financial  Narratives\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.873, \"y\": 6.817}, {\"title\": \"ChainLM: Empowering Large Language Models with Improved Chain-of-Thought  Prompting\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.664, \"y\": 2.372}, {\"title\": \"Scene-Graph ViT: End-to-End Open-Vocabulary Visual Relationship  Detection\", \"topic\": \"Multimodal Language Models\", \"x\": 8.425, \"y\": 7.419}, {\"title\": \"Semantically Aligned Question and Code Generation for Automated Insight  Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.486, \"y\": 5.179}, {\"title\": \"K-Act2Emo: Korean Commonsense Knowledge Graph for Indirect Emotional  Expression\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.41, \"y\": 7.645}, {\"title\": \"Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large  Language Models with Machine Learning in tele-dermatology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.793, \"y\": 8.282}, {\"title\": \"Reinforcement Learning from Reflective Feedback (RLRF): Aligning and  Improving LLMs via Fine-Grained Self-Reflection\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.135, \"y\": 1.711}, {\"title\": \"Sequence-to-Sequence Language Models for Character and Emotion Detection  in Dream Narratives\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.424, \"y\": 7.598}, {\"title\": \"Open Knowledge Base Canonicalization with Multi-task Learning\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.321, \"y\": 6.253}, {\"title\": \"MOGAM: A Multimodal Object-oriented Graph Attention Model for Depression  Detection\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.026, \"y\": 7.438}, {\"title\": \"MMIDR: Teaching Large Language Model to Interpret Multimodal  Misinformation via Knowledge Distillation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.076, \"y\": 7.396}, {\"title\": \"M$^3$AV: A Multimodal, Multigenre, and Multipurpose Audio-Visual  Academic Lecture Dataset\", \"topic\": \"Multimodal Language Models\", \"x\": 8.822, \"y\": 7.546}, {\"title\": \"Reversible Jump Attack to Textual Classifiers with Modification  Reduction\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.159, \"y\": 2.974}, {\"title\": \"C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via  Text Feature Dispersion\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.809, \"y\": 3.491}, {\"title\": \"From Handcrafted Features to LLMs: A Brief Survey for Machine  Translation Quality Estimation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.839, \"y\": 4.591}, {\"title\": \"Benchmarking Chinese Commonsense Reasoning of LLMs: From  Chinese-Specifics to Reasoning-Memorization Correlations\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.5, \"y\": 4.065}, {\"title\": \"Protected group bias and stereotypes in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.453, \"y\": 4.234}, {\"title\": \"Extracting Emotion Phrases from Tweets using BART\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.653, \"y\": 6.731}, {\"title\": \"The NeurIPS 2023 Machine Learning for Audio Workshop: Affective Audio  Benchmarks and Novel Data\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.182, \"y\": 7.818}, {\"title\": \"Ax-to-Grind Urdu: Benchmark Dataset for Urdu Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.037, \"y\": 5.843}, {\"title\": \"A New Massive Multilingual Dataset for High-Performance Language  Technologies\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.157, \"y\": 4.859}, {\"title\": \"Multi-Modal Hallucination Control by Visual Information Grounding\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.332, \"y\": 1.055}, {\"title\": \"Testing the Limits of Jailbreaking Defenses with the Purple Problem\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.299, \"y\": 2.257}, {\"title\": \"Integrating Supervised Extractive and Generative Language Models for  Suicide Risk Evidence Summarization\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.486, \"y\": 7.529}, {\"title\": \"Reducing Large Language Model Bias with Emphasis on 'Restricted  Industries': Automated Dataset Augmentation and Prejudice Quantification\", \"topic\": \"Bias in Language Models\", \"x\": 3.321, \"y\": 4.363}, {\"title\": \"Visually Grounded Speech Models have a Mutual Exclusivity Bias\", \"topic\": \"Multimodal Language Models\", \"x\": 8.826, \"y\": 7.01}, {\"title\": \"Leveraging Linguistically Enhanced Embeddings for Open Information  Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.932, \"y\": 6.582}, {\"title\": \"Learning from Models and Data for Visual Grounding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.705, \"y\": 7.315}, {\"title\": \"Natural Language as Policies: Reasoning for Coordinate-Level Embodied  Control with LLMs\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.959, \"y\": 2.697}, {\"title\": \"Information-Theoretic Distillation for Reference-less Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.6, \"y\": 6.221}, {\"title\": \"PARAMANU-AYN: An Efficient Novel Generative and Instruction-tuned  Language Model for Indian Legal Case Documents\", \"topic\": \"Legal NLP\", \"x\": 5.25, \"y\": 5.603}, {\"title\": \"RoleInteract: Evaluating the Social Interaction of Role-Playing Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.078, \"y\": 3.308}, {\"title\": \"Defending Against Indirect Prompt Injection Attacks With Spotlighting\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.407, \"y\": 2.635}, {\"title\": \"Grounding Spatial Relations in Text-Only Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.527, \"y\": 7.116}, {\"title\": \"Do Not Worry if You Do Not Have Data: Building Pretrained Language  Models Using Translationese\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.429, \"y\": 4.544}, {\"title\": \"Genetic Auto-prompt Learning for Pre-trained Code Intelligence Language  Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.29, \"y\": 3.211}, {\"title\": \"CoCoST: Automatic Complex Code Generation with Online Searching and  Correctness Testing\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.443, \"y\": 2.366}, {\"title\": \"Dynamic Reward Adjustment in Multi-Reward Reinforcement Learning for  Counselor Reflection Generation\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.265, \"y\": 1.708}, {\"title\": \"How Gender Interacts with Political Values: A Case Study on Czech BERT  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.484, \"y\": 4.478}, {\"title\": \"What if...?: Thinking Counterfactual Keywords Helps to Mitigate  Hallucination in Large Multi-modal Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.244, \"y\": 1.412}, {\"title\": \"HyperLLaVA: Dynamic Visual and Language Expert Tuning for Multimodal  Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.208, \"y\": 7.41}, {\"title\": \"AgentGroupChat: An Interactive Group Chat Simulacra For Better Eliciting  Emergent Behavior\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.081, \"y\": 3.325}, {\"title\": \"Inserting Faces inside Captions: Image Captioning with Attention Guided  Merging\", \"topic\": \"Multimodal Language Models\", \"x\": 9.045, \"y\": 7.426}, {\"title\": \"Clinical information extraction for Low-resource languages with Few-shot  learning using Pre-trained language models and Prompting\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.069, \"y\": 8.118}, {\"title\": \"Incentivizing News Consumption on Social Media Platforms Using Large  Language Models and Realistic Bot Accounts\", \"topic\": \"Fake News Detection\", \"x\": 3.74, \"y\": 5.688}, {\"title\": \"USE: Dynamic User Modeling with Stateful Sequence Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.926, \"y\": 2.861}, {\"title\": \"Polaris: A Safety-focused LLM Constellation Architecture for Healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.398, \"y\": 8.07}, {\"title\": \"LeanReasoner: Boosting Complex Logical Reasoning with Lean\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.726, \"y\": 2.886}, {\"title\": \"AFLoRA: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient  Fine-Tuning of Large Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.155, \"y\": 2.096}, {\"title\": \"SumTra: A Differentiable Pipeline for Few-Shot Cross-Lingual  Summarization\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.234, \"y\": 4.811}, {\"title\": \"A Big Data Analytics System for Predicting Suicidal Ideation in  Real-Time Based on Social Media Streaming Data\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.159, \"y\": 7.311}, {\"title\": \"Towards Unsupervised Question Answering System with Multi-level  Summarization for Legal Text\", \"topic\": \"Legal NLP\", \"x\": 5.12, \"y\": 5.719}, {\"title\": \"Automatic Summarization of Doctor-Patient Encounter Dialogues Using  Large Language Model through Prompt Tuning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.674, \"y\": 8.032}, {\"title\": \"LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach  Combining Predictive Agent Reasoning and Critical Agent Instruction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.718, \"y\": 8.144}, {\"title\": \"LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic  Prompt Compression\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.726, \"y\": 3.114}, {\"title\": \"Negative Yields Positive: Unified Dual-Path Adapter for Vision-Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.609, \"y\": 7.185}, {\"title\": \"Automatic Information Extraction From Employment Tribunal Judgements  Using Large Language Models\", \"topic\": \"Legal NLP\", \"x\": 5.16, \"y\": 5.71}, {\"title\": \"Epistemology of Language Models: Do Language Models Have Holistic  Knowledge?\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.961, \"y\": 3.681}, {\"title\": \"Comparing Explanation Faithfulness between Multilingual and Monolingual  Fine-tuned Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.883, \"y\": 3.666}, {\"title\": \"Investigating Text Shortening Strategy in BERT: Truncation vs  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.62, \"y\": 6.369}, {\"title\": \"BiLoRA: A Bi-level Optimization Framework for Overfitting-Resilient  Low-Rank Adaptation of Large Pre-trained Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.151, \"y\": 2.107}, {\"title\": \"Instructing Large Language Models to Identify and Ignore Irrelevant  Conditions\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.807, \"y\": 2.464}, {\"title\": \"Multi-Dimensional Machine Translation Evaluation: Model Evaluation and  Resource for Korean\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.74, \"y\": 4.696}, {\"title\": \"Fine-Tuning Pre-trained Language Models to Detect In-Game Trash Talks\", \"topic\": \"Hate Speech Detection\", \"x\": 2.89, \"y\": 5.067}, {\"title\": \"Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.028, \"y\": 7.765}, {\"title\": \"AlphaFin: Benchmarking Financial Analysis with Retrieval-Augmented  Stock-Chain Framework\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.884, \"y\": 6.799}, {\"title\": \"Simple Hack for Transformers against Heavy Long-Text Classification on a  Time- and Memory-Limited GPU Service\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.667, \"y\": 3.446}, {\"title\": \"A Large Collection of Model-generated Contradictory Responses for  Consistency-aware Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.617, \"y\": 3.937}, {\"title\": \"Embodied LLM Agents Learn to Cooperate in Organized Teams\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.475, \"y\": 2.792}, {\"title\": \"WoLF: Wide-scope Large Language Model Framework for CXR Understanding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.2, \"y\": 8.542}, {\"title\": \"MSLM-S2ST: A Multitask Speech Language Model for Textless  Speech-to-Speech Translation with Speaker Style Preservation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.537, \"y\": 5.402}, {\"title\": \"Cross-Lingual Transfer for Natural Language Inference via Multilingual  Prompt Translator\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.25, \"y\": 4.59}, {\"title\": \"Towards Interpretable Hate Speech Detection using Large Language  Model-extracted Rationales\", \"topic\": \"Hate Speech Detection\", \"x\": 2.801, \"y\": 5.35}, {\"title\": \"An Empirical Study of Speech Language Models for Prompt-Conditioned  Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.448, \"y\": 5.952}, {\"title\": \"Dr3: Ask Large Language Models Not to Give Off-Topic Answers in Open  Domain Multi-Hop Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.519, \"y\": 5.263}, {\"title\": \"Improving Generalizability of Extracting Social Determinants of Health  Using Large Language Models through Prompt-tuning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.825, \"y\": 7.834}, {\"title\": \"Emotion Detection with Transformers: A Comparative Study\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.46, \"y\": 7.387}, {\"title\": \"Leveraging Large Language Models to Extract Information on Substance Use  Disorder Severity from Clinical Notes: A Zero-shot Learning Approach\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.123, \"y\": 7.859}, {\"title\": \"FinLlama: Financial Sentiment Classification for Algorithmic Trading  Applications\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.75, \"y\": 6.863}, {\"title\": \"Zero-Shot Multi-task Hallucination Detection\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.184, \"y\": 1.047}, {\"title\": \"Reference-based Metrics Disprove Themselves in Question Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.184, \"y\": 4.951}, {\"title\": \"EasyJailbreak: A Unified Framework for Jailbreaking Large Language  Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.294, \"y\": 2.26}, {\"title\": \"Syn-QA2: Evaluating False Assumptions in Long-tail Questions with  Synthetic QA Datasets\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.37, \"y\": 5.01}, {\"title\": \"From Pixels to Insights: A Survey on Automatic Chart Understanding in  the Era of Large Foundation Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.823, \"y\": 7.704}, {\"title\": \"FlexCap: Generating Rich, Localized, and Flexible Captions in Images\", \"topic\": \"Multimodal Language Models\", \"x\": 9.007, \"y\": 7.489}, {\"title\": \"A Toolbox for Surfacing Health Equity Harms and Biases in Large Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.561, \"y\": 4.325}, {\"title\": \"Enhancing Taiwanese Hokkien Dual Translation by Exploring and  Standardizing of Four Writing Systems\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.629, \"y\": 4.569}, {\"title\": \"Supervised Fine-Tuning as Inverse Reinforcement Learning\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.419, \"y\": 1.439}, {\"title\": \"EnvGen: Generating and Adapting Environments via LLMs for Training  Embodied Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.873, \"y\": 2.351}, {\"title\": \"Towards Enabling FAIR Dataspaces Using Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.62, \"y\": 4.09}, {\"title\": \"Adaptative Bilingual Aligning Using Multilingual Sentence Embedding\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.5, \"y\": 4.913}, {\"title\": \"Investigating Markers and Drivers of Gender Bias in Machine Translations\", \"topic\": \"Bias in Language Models\", \"x\": 3.12, \"y\": 4.376}, {\"title\": \"From Explainable to Interpretable Deep Learning for Natural Language  Processing in Healthcare: How Far from Reality?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.375, \"y\": 7.736}, {\"title\": \"QueryAgent: A Reliable and Efficient Reasoning Framework with  Environmental Feedback-based Self-Correction\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.657, \"y\": 2.565}, {\"title\": \"Loops On Retrieval Augmented Generation (LoRAG)\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.117, \"y\": 4.586}, {\"title\": \"SSCAE -- Semantic, Syntactic, and Context-aware natural language  Adversarial Examples generator\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.16, \"y\": 3.031}, {\"title\": \"How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming  Ability in Multi-Agent Environments\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.59, \"y\": 2.959}, {\"title\": \"Reasoning Abilities of Large Language Models: In-Depth Analysis on the  Abstraction and Reasoning Corpus\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.632, \"y\": 3.259}, {\"title\": \"Modality-Agnostic fMRI Decoding of Vision and Language\", \"topic\": \"Multimodal Language Models\", \"x\": 8.552, \"y\": 7.033}, {\"title\": \"Revisiting The Classics: A Study on Identifying and Rectifying Gender  Stereotypes in Rhymes and Poems\", \"topic\": \"Bias in Language Models\", \"x\": 3.249, \"y\": 4.416}, {\"title\": \"Embedded Named Entity Recognition using Probing Classifiers\", \"topic\": \"Named Entity Recognition\", \"x\": 7.314, \"y\": 6.749}, {\"title\": \"Hatred Stems from Ignorance! Distillation of the Persuasion Modes in  Countering Conversational Hate Speech\", \"topic\": \"Hate Speech Detection\", \"x\": 2.84, \"y\": 5.258}, {\"title\": \"A Disease Labeler for Chinese Chest X-Ray Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.187, \"y\": 8.572}, {\"title\": \"HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive  Speech Detection via Large Language Models\", \"topic\": \"Hate Speech Detection\", \"x\": 2.737, \"y\": 5.336}, {\"title\": \"StyleChat: Learning Recitation-Augmented Memory in LLMs for Stylized  Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.494, \"y\": 3.569}, {\"title\": \"A Novel Paradigm Boosting Translation Capabilities of Large Language  Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.541, \"y\": 4.333}, {\"title\": \"Narrative Feature or Structured Feature? A Study of Large Language  Models to Identify Cancer Patients at Risk of Heart Failure\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.791, \"y\": 8.21}, {\"title\": \"Can LLM-Augmented autonomous agents cooperate?, An evaluation of their  cooperative capabilities through Melting Pot\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.406, \"y\": 2.941}, {\"title\": \"Decoding Multilingual Topic Dynamics and Trend Identification through  ARIMA Time Series Analysis on Social Networks: A Novel Data Translation  Framework Enhanced by LDA/HDP Models\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.144, \"y\": 6.622}, {\"title\": \"What Makes Math Word Problems Challenging for LLMs?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.855, \"y\": 2.968}, {\"title\": \"CantonMT: Cantonese to English NMT Platform with Fine-Tuned Models Using  Synthetic Back-Translation Data\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.78, \"y\": 4.623}, {\"title\": \"Few-Shot VQA with Frozen LLMs: A Tale of Two Approaches\", \"topic\": \"Multimodal Language Models\", \"x\": 8.364, \"y\": 7.867}, {\"title\": \"Mixture-of-Prompt-Experts for Multi-modal Semantic Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 7.952, \"y\": 7.21}, {\"title\": \"SQ-LLaVA: Self-Questioning for Large Vision-Language Assistant\", \"topic\": \"Multimodal Language Models\", \"x\": 8.301, \"y\": 7.883}, {\"title\": \"A Modified Word Saliency-Based Adversarial Attack on Text Classification  Models\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.083, \"y\": 3.092}, {\"title\": \"Cheap Ways of Extracting Clinical Markers from Texts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.589, \"y\": 7.863}, {\"title\": \"Quality-Aware Image-Text Alignment for Real-World Image Quality  Assessment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.974, \"y\": 7.297}, {\"title\": \"Evaluation Ethics of LLMs in Legal Domain\", \"topic\": \"Legal NLP\", \"x\": 5.165, \"y\": 5.363}, {\"title\": \"Granular Change Accuracy: A More Accurate Performance Metric for  Dialogue State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.684, \"y\": 3.928}, {\"title\": \"HarmPot: An Annotation Framework for Evaluating Offline Harm Potential  of Social Media Text\", \"topic\": \"Hate Speech Detection\", \"x\": 3.047, \"y\": 5.427}, {\"title\": \"ProgGen: Generating Named Entity Recognition Datasets Step-by-step with  Self-Reflexive Large Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 7.358, \"y\": 6.728}, {\"title\": \"Customizing Visual-Language Foundation Models for Multi-modal Anomaly  Detection and Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.839, \"y\": 7.503}, {\"title\": \"Deep Learning-based Sentiment Analysis in Persian Language\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.627, \"y\": 6.622}, {\"title\": \"FlowMind: Automatic Workflow Generation with LLMs\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.842, \"y\": 3.043}, {\"title\": \"Pointer-Generator Networks for Low-Resource Machine Translation: Don't  Copy That!\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.823, \"y\": 4.487}, {\"title\": \"Initial Decoding with Minimally Augmented Language Model for Improved  Lattice Rescoring in Low Resource ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.034, \"y\": 5.343}, {\"title\": \"Optimizing Language Augmentation for Multilingual Large Language Models:  A Case Study on Korean\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.134, \"y\": 4.247}, {\"title\": \"RetinaQA: A Robust Knowledge Base Question Answering Model for both  Answerable and Unanswerable Questions\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.563, \"y\": 5.355}, {\"title\": \"Two-step Automated Cybercrime Coded Word Detection using Multi-level  Representation Learning\", \"topic\": \"Hate Speech Detection\", \"x\": 3.1, \"y\": 5.398}, {\"title\": \"Deciphering Hate: Identifying Hateful Memes and Their Targets\", \"topic\": \"Hate Speech Detection\", \"x\": 2.818, \"y\": 5.598}, {\"title\": \"Can Large Language Models abstract Medical Coded Language?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.714, \"y\": 8.114}, {\"title\": \"Efficient Pruning of Large Language Model with Adaptive Estimation  Fusion\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.493, \"y\": 2.504}, {\"title\": \"From Words to Routes: Applying Large Language Models to Vehicle Routing\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 6.154, \"y\": 2.925}, {\"title\": \"Detecting Bias in Large Language Models: Fine-tuned KcBERT\", \"topic\": \"Bias in Language Models\", \"x\": 3.387, \"y\": 4.396}, {\"title\": \"ECRC: Emotion-Causality Recognition in Korean Conversation for GCN\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.282, \"y\": 7.787}, {\"title\": \"Depression Detection on Social Media with Large Language Models\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.219, \"y\": 7.476}, {\"title\": \"PERL: Parameter Efficient Reinforcement Learning from Human Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.223, \"y\": 1.491}, {\"title\": \"A Multilingual Perspective on Probing Gender Bias\", \"topic\": \"Bias in Language Models\", \"x\": 3.228, \"y\": 4.491}, {\"title\": \"MYTE: Morphology-Driven Byte Encoding for Better and Fairer Multilingual  Language Modeling\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.237, \"y\": 4.867}, {\"title\": \"Towards Unified Multi-Modal Personalization: Large Vision-Language  Models for Generative Recommendation and Beyond\", \"topic\": \"Multimodal Language Models\", \"x\": 8.187, \"y\": 7.099}, {\"title\": \"VideoAgent: Long-form Video Understanding with Large Language Model as  Agent\", \"topic\": \"Multimodal Language Models\", \"x\": 8.737, \"y\": 7.952}, {\"title\": \"Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A  Pilot Study\", \"topic\": \"Multimodal Language Models\", \"x\": 8.772, \"y\": 7.199}, {\"title\": \"EXAMS-V: A Multi-Discipline Multilingual Multimodal Exam Benchmark for  Evaluating Vision Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.007, \"y\": 7.872}, {\"title\": \"TriSum: Learning Summarization Ability from Large Language Models with  Structured Rationale\", \"topic\": \"Text Summarization\", \"x\": 5.516, \"y\": 6.231}, {\"title\": \"Application of GPT Language Models for Innovation in Activities in  University Teaching\", \"topic\": \"Bias in Language Models\", \"x\": 5.23, \"y\": 4.484}, {\"title\": \"Large Language Model-informed ECG Dual Attention Network for Heart  Failure Risk Prediction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.794, \"y\": 8.321}, {\"title\": \"A Question on the Explainability of Large Language Models and the  Word-Level Univariate First-Order Plausibility Assumption\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.135, \"y\": 3.756}, {\"title\": \"Is Translation All You Need? A Study on Solving Multilingual Tasks with  Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.284, \"y\": 4.399}, {\"title\": \"HawkEye: Training Video-Text LLMs for Grounding Text in Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.886, \"y\": 7.84}, {\"title\": \"Enhanced Coherence-Aware Network with Hierarchical Disentanglement for  Aspect-Category Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.149, \"y\": 6.954}, {\"title\": \"Read between the lines -- Functionality Extraction From READMEs\", \"topic\": \"Text Summarization\", \"x\": 5.631, \"y\": 6.148}, {\"title\": \"The Whole is Better than the Sum: Using Aggregated Demonstrations in  In-Context Learning for Sequential Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.036, \"y\": 2.871}, {\"title\": \"Intent-conditioned and Non-toxic Counterspeech Generation using  Multi-Task Instruction Tuning with RLAIF\", \"topic\": \"Hate Speech Detection\", \"x\": 2.708, \"y\": 5.252}, {\"title\": \"DRAGIN: Dynamic Retrieval Augmented Generation based on the Information  Needs of Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.018, \"y\": 4.587}, {\"title\": \"Triple GNNs: Introducing Syntactic and Semantic Information for  Conversational Aspect-Based Quadruple Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.142, \"y\": 6.883}, {\"title\": \"Repoformer: Selective Retrieval for Repository-Level Code Completion\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.55, \"y\": 2.519}, {\"title\": \"Are LLMs Good Cryptic Crossword Solvers?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.666, \"y\": 3.598}, {\"title\": \"Identifying Health Risks from Family History: A Survey of Natural  Language Processing Techniques\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.363, \"y\": 7.782}, {\"title\": \"GET: Unlocking the Multi-modal Potential of CLIP for Generalized  Category Discovery\", \"topic\": \"Multimodal Language Models\", \"x\": 8.677, \"y\": 7.185}, {\"title\": \"FakeWatch: A Framework for Detecting Fake News to Ensure Credible  Elections\", \"topic\": \"Fake News Detection\", \"x\": 3.985, \"y\": 5.753}, {\"title\": \"Scaling Behavior of Machine Translation with Large Language Models under  Prompt Injection Attacks\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.421, \"y\": 2.584}, {\"title\": \"Images are Achilles' Heel of Alignment: Exploiting Visual  Vulnerabilities for Jailbreaking Multimodal Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.278, \"y\": 2.511}, {\"title\": \"Transformers Get Stable: An End-to-End Signal Propagation Theory for  Language Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.766, \"y\": 3.335}, {\"title\": \"3D-VLA: A 3D Vision-Language-Action Generative World Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.768, \"y\": 7.197}, {\"title\": \"Quiet-STaR: Language Models Can Teach Themselves to Think Before  Speaking\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.79, \"y\": 2.415}, {\"title\": \"MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.305, \"y\": 7.296}, {\"title\": \"Less is More: Data Value Estimation for Visual Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.526, \"y\": 7.448}, {\"title\": \"VisionGPT-3D: A Generalized Multimodal Agent for Enhanced 3D Vision  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.269, \"y\": 7.47}, {\"title\": \"MT-PATCHER: Selective and Extendable Knowledge Distillation from Large  Language Models for Machine Translation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.165, \"y\": 4.09}, {\"title\": \"Leveraging Prototypical Representations for Mitigating Social Bias  without Demographic Information\", \"topic\": \"Bias in Language Models\", \"x\": 3.332, \"y\": 4.343}, {\"title\": \"From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward  Fake News\", \"topic\": \"Fake News Detection\", \"x\": 4.035, \"y\": 5.585}, {\"title\": \"Rectifying Demonstration Shortcut in In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.298, \"y\": 3.388}, {\"title\": \"Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.439, \"y\": 1.643}, {\"title\": \"Komodo: A Linguistic Expedition into Indonesia's Regional Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.882, \"y\": 4.398}, {\"title\": \"More than words: Advancements and challenges in speech recognition for  singing\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.068, \"y\": 5.5}, {\"title\": \"Anatomical Structure-Guided Medical Vision-Language Pre-training\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.465, \"y\": 8.439}, {\"title\": \"Retrieval augmented text-to-SQL generation for epidemiological question  answering using electronic health records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.901, \"y\": 7.765}, {\"title\": \"What Was Your Prompt? A Remote Keylogging Attack on AI Assistants\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.421, \"y\": 2.612}, {\"title\": \"Exploring the Comprehension of ChatGPT in Traditional Chinese Medicine  Knowledge\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.742, \"y\": 7.763}, {\"title\": \"Caveat Lector: Large Language Models in Legal Practice\", \"topic\": \"Legal NLP\", \"x\": 5.205, \"y\": 5.29}, {\"title\": \"Basque and Spanish Counter Narrative Generation: Data Creation and  Evaluation\", \"topic\": \"Hate Speech Detection\", \"x\": 2.767, \"y\": 5.258}, {\"title\": \"Evaluating LLMs for Gender Disparities in Notable Persons\", \"topic\": \"Bias in Language Models\", \"x\": 3.363, \"y\": 4.34}, {\"title\": \"AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based  on Meta Learning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.16, \"y\": 2.122}, {\"title\": \"MCFEND: A Multi-source Benchmark Dataset for Chinese Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.052, \"y\": 5.85}, {\"title\": \"Meaningful Learning: Advancing Abstract Reasoning in Large Language  Models via Generic Fact Guidance\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.732, \"y\": 3.2}, {\"title\": \"UniCode: Learning a Unified Codebook for Multimodal Large Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.484, \"y\": 7.206}, {\"title\": \"A Continued Pretrained LLM Approach for Automatic Medical Note  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.68, \"y\": 8.026}, {\"title\": \"RAGGED: Towards Informed Design of Retrieval Augmented Generation  Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.045, \"y\": 4.758}, {\"title\": \"CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language  Models to Coding Preferences\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.505, \"y\": 1.58}, {\"title\": \"ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.936, \"y\": 7.553}, {\"title\": \"Re-Search for The Truth: Multi-round Retrieval-augmented Large Language  Models are Strong Fake News Detectors\", \"topic\": \"Fake News Detection\", \"x\": 4.147, \"y\": 5.636}, {\"title\": \"AutoGuide: Automated Generation and Selection of State-Aware Guidelines  for Large Language Model Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.961, \"y\": 2.418}, {\"title\": \"Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM  Era\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.522, \"y\": 4.022}, {\"title\": \"Detecting Hallucination and Coverage Errors in Retrieval Augmented  Generation for Controversial Topics\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.166, \"y\": 1.196}, {\"title\": \"Evaluating Large Language Models as Generative User Simulators for  Conversational Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.131, \"y\": 3.532}, {\"title\": \"DAM: Dynamic Adapter Merging for Continual Video QA Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.706, \"y\": 7.932}, {\"title\": \"Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing  Framework\", \"topic\": \"Bias in Language Models\", \"x\": 3.556, \"y\": 4.121}, {\"title\": \"The Garden of Forking Paths: Observing Dynamic Parameters Distribution  in Large Language Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.083, \"y\": 3.803}, {\"title\": \"Improving Acoustic Word Embeddings through Correspondence Training of  Self-supervised Speech Representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.687, \"y\": 5.121}, {\"title\": \"Strengthening Multimodal Large Language Model with Bootstrapped  Preference Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.053, \"y\": 1.263}, {\"title\": \"SOTOPIA-$\\u03c0$: Interactive Learning of Socially Intelligent Language  Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.086, \"y\": 3.189}, {\"title\": \"Zero-shot and Few-shot Generation Strategies for Artificial Clinical  Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.632, \"y\": 8.111}, {\"title\": \"Distilling Named Entity Recognition Models for Endangered Species from  Large Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 7.224, \"y\": 6.715}, {\"title\": \"MedInsight: A Multi-Source Context Augmentation Framework for Generating  Patient-Centric Medical Responses using Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.02, \"y\": 7.939}, {\"title\": \"DevBench: A Comprehensive Benchmark for Software Development\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.327, \"y\": 2.526}, {\"title\": \"Non-discrimination Criteria for Generative Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.32, \"y\": 4.393}, {\"title\": \"Automatic Interactive Evaluation for Large Language Models with State  Aware Patient Simulator\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.576, \"y\": 8.051}, {\"title\": \"Data-oriented Dynamic Fine-tuning Parameter Selection Strategy for FISH  Mask based Efficient Fine-tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.926, \"y\": 2.262}, {\"title\": \"Tastle: Distract Large Language Models for Automatic Jailbreak Attack\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.335, \"y\": 2.29}, {\"title\": \"Misinformation is not about Bad Facts: An Analysis of the Production and  Consumption of Fringe Content\", \"topic\": \"Fake News Detection\", \"x\": 3.966, \"y\": 5.891}, {\"title\": \"Learning to Describe for Predicting Zero-shot Drug-Drug Interactions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.64, \"y\": 7.799}, {\"title\": \"Is Context Helpful for Chat Translation Evaluation?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.681, \"y\": 4.54}, {\"title\": \"Towards Personalized Evaluation of Large Language Models with An  Anonymous Crowd-Sourcing Platform\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.248, \"y\": 3.745}, {\"title\": \"Skipformer: A Skip-and-Recover Strategy for Efficient Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.21, \"y\": 5.029}, {\"title\": \"Research on the Application of Deep Learning-based BERT Model in  Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.665, \"y\": 6.679}, {\"title\": \"SpeechColab Leaderboard: An Open-Source Platform for Automatic Speech  Recognition Evaluation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.167, \"y\": 5.436}, {\"title\": \"Embedded Translations for Low-resource Automated Glossing\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.451, \"y\": 4.496}, {\"title\": \"Automatic Speech Recognition (ASR) for the Diagnosis of pronunciation of  Speech Sound Disorders in Korean children\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.192, \"y\": 5.587}, {\"title\": \"Legally Binding but Unfair? Towards Assessing Fairness of Privacy  Policies\", \"topic\": \"Bias in Language Models\", \"x\": 3.709, \"y\": 4.117}, {\"title\": \"Simulating Weighted Automata over Sequences and Trees with Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.201, \"y\": 3.585}, {\"title\": \"Mechanics of Next Token Prediction with Self-Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.575, \"y\": 3.423}, {\"title\": \"FluoroSAM: A Language-aligned Foundation Model for X-ray Image  Segmentation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.311, \"y\": 8.607}, {\"title\": \"Generating Clarification Questions for Disambiguating Contracts\", \"topic\": \"Legal NLP\", \"x\": 5.223, \"y\": 5.621}, {\"title\": \"Big City Bias: Evaluating the Impact of Metropolitan Size on  Computational Job Market Abilities of Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.524, \"y\": 4.263}, {\"title\": \"Harnessing Artificial Intelligence to Combat Online Hate: Exploring the  Challenges and Opportunities of Large Language Models in Hate Speech  Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.833, \"y\": 5.314}, {\"title\": \"Gujarati-English Code-Switching Speech Recognition using ensemble  prediction of spoken language\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.802, \"y\": 5.157}, {\"title\": \"Pix2Pix-OnTheFly: Leveraging LLMs for Instruction-Guided Image Editing\", \"topic\": \"Multimodal Language Models\", \"x\": 9.015, \"y\": 6.848}, {\"title\": \"Towards a clinically accessible radiology foundation model: open-access  and lightweight, with automated evaluation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.28, \"y\": 8.499}, {\"title\": \"LiveCodeBench: Holistic and Contamination Free Evaluation of Large  Language Models for Code\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.344, \"y\": 2.507}, {\"title\": \"RAD-PHI2: Instruction Tuning PHI-2 for Radiology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.065, \"y\": 8.525}, {\"title\": \"Fine-tuning Large Language Models with Sequential Instructions\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.152, \"y\": 2.385}, {\"title\": \"Transforming Competition into Collaboration: The Revolutionary Role of  Multi-Agent Systems and Language Models in Modern Organizations\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.349, \"y\": 2.91}, {\"title\": \"FineMath: A Fine-Grained Mathematical Evaluation Benchmark for Chinese  Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.867, \"y\": 3.15}, {\"title\": \"SemEval-2024 Shared Task 6: SHROOM, a Shared-task on Hallucinations and  Related Observable Overgeneration Mistakes\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.098, \"y\": 0.978}, {\"title\": \"Improving Reinforcement Learning from Human Feedback Using Contrastive  Rewards\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.176, \"y\": 1.549}, {\"title\": \"ORPO: Monolithic Preference Optimization without Reference Model\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.364, \"y\": 1.239}, {\"title\": \"Triples-to-isiXhosa (T2X): Addressing the Challenges of Low-Resource  Agglutinative Data-to-Text Generation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.72, \"y\": 4.924}, {\"title\": \"Truth-Aware Context Selection: Mitigating Hallucinations of Large  Language Models Being Misled by Untruthful Contexts\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.494, \"y\": 1.392}, {\"title\": \"MAMMOTH: Massively Multilingual Modular Open Translation @ Helsinki\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.448, \"y\": 4.337}, {\"title\": \"Matrix-Transformation Based Low-Rank Adaptation (MTLoRA): A  Brain-Inspired Method for Parameter-Efficient Fine-Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.177, \"y\": 2.039}, {\"title\": \"Enhancing Readmission Prediction with Deep Learning: Extracting  Biomedical Concepts from Clinical Texts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.604, \"y\": 8.155}, {\"title\": \"Stress index strategy enhanced with financial news sentiment analysis  for the equity markets\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.592, \"y\": 6.821}, {\"title\": \"Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.594, \"y\": 5.385}, {\"title\": \"SVD-LLM: Truncation-aware Singular Value Decomposition for Large  Language Model Compression\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.678, \"y\": 2.341}, {\"title\": \"Rethinking ASTE: A Minimalist Tagging Scheme Alongside Contrastive  Learning\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.122, \"y\": 6.839}, {\"title\": \"IM-Unpack: Training and Inference with Arbitrarily Low Precision  Integers\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.72, \"y\": 2.482}, {\"title\": \"GPT-generated Text Detection: Benchmark Dataset and Tensor-based  Detection Method\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.272, \"y\": 4.768}, {\"title\": \"Knowledge Graph Large Language Model (KG-LLM) for Link Prediction\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.956, \"y\": 5.747}, {\"title\": \"A Survey of Explainable Knowledge Tracing\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.946, \"y\": 3.879}, {\"title\": \"A novel interface for adversarial trivia question-writing\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 5.956, \"y\": 4.819}, {\"title\": \"CKERC : Joint Large Language Models with Commonsense Knowledge for  Emotion Recognition in Conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.273, \"y\": 7.792}, {\"title\": \"Curry-DPO: Enhancing Alignment using Curriculum Learning & Ranked  Preferences\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.366, \"y\": 1.269}, {\"title\": \"TMU at TREC Clinical Trials Track 2023\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.696, \"y\": 7.567}, {\"title\": \"CuentosIE: can a chatbot about \\\"tales with a message\\\" help to teach  emotional intelligence?\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.586, \"y\": 7.693}, {\"title\": \"Textual analysis of End User License Agreement for red-flagging  potentially malicious software\", \"topic\": \"Legal NLP\", \"x\": 5.024, \"y\": 5.779}, {\"title\": \"One Category One Prompt: Dataset Distillation using Diffusion Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.512, \"y\": 3.888}, {\"title\": \"Counterfactual Reasoning with Knowledge Graph Embeddings\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.869, \"y\": 5.884}, {\"title\": \"Naming, Describing, and Quantifying Visual Objects in Humans and LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.578, \"y\": 7.405}, {\"title\": \"ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.665, \"y\": 2.364}, {\"title\": \"Simplicity Bias of Transformers to Learn Low Sensitivity Functions\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.588, \"y\": 3.373}, {\"title\": \"Real-time Transformer-based Open-Vocabulary Detection with Efficient  Fusion Head\", \"topic\": \"Multimodal Language Models\", \"x\": 8.659, \"y\": 7.088}, {\"title\": \"Exploring Large Language Models and Hierarchical Frameworks for  Classification of Large Unstructured Legal Documents\", \"topic\": \"Legal NLP\", \"x\": 5.11, \"y\": 5.733}, {\"title\": \"Development of a Reliable and Accessible Caregiving Language Model  (CaLM)\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.44, \"y\": 7.756}, {\"title\": \"RA-ISF: Learning to Answer and Understand from Retrieval Augmentation  via Iterative Self-Feedback\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.034, \"y\": 4.54}, {\"title\": \"Medical Image Synthesis via Fine-Grained Image-Text Alignment and  Anatomy-Pathology Prompting\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.319, \"y\": 8.602}, {\"title\": \"The evaluation of a code-switched Sepedi-English automatic speech  recognition system\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.778, \"y\": 5.425}, {\"title\": \"An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference  Acceleration for Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.713, \"y\": 7.548}, {\"title\": \"ALaRM: Align Language Models via Hierarchical Rewards Modeling\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.306, \"y\": 1.361}, {\"title\": \"ACT-MNMT Auto-Constriction Turning for Multilingual Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.803, \"y\": 4.403}, {\"title\": \"Restoring Ancient Ideograph: A Multimodal Multitask Neural Network  Approach\", \"topic\": \"Multimodal Language Models\", \"x\": 8.503, \"y\": 7.111}, {\"title\": \"TRAWL: External Knowledge-Enhanced Recommendation with LLM Assistance\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.891, \"y\": 2.938}, {\"title\": \"MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway  Encoding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.722, \"y\": 8.209}, {\"title\": \"Guiding Clinical Reasoning with Large Language Models via Knowledge  Seeds\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.666, \"y\": 8.102}, {\"title\": \"Improving Speaker Assignment in Speaker-Attributed ASR for Real Meeting  Applications\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.007, \"y\": 5.399}, {\"title\": \"How to Understand Named Entities: Using Common Sense for News Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.821, \"y\": 7.589}, {\"title\": \"Automatic Generation of Python Programs Using Context-Free Grammars\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.382, \"y\": 2.516}, {\"title\": \"Multilingual Turn-taking Prediction Using Voice Activity Projection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.492, \"y\": 5.533}, {\"title\": \"Unsupervised Real-Time Hallucination Detection based on the Internal  States of Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.161, \"y\": 1.148}, {\"title\": \"A Knowledge-Injected Curriculum Pretraining Framework for Question  Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.727, \"y\": 5.429}, {\"title\": \"GlossLM: Multilingual Pretraining for Low-Resource Interlinear Glossing\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.256, \"y\": 4.591}, {\"title\": \"Multi-modal Semantic Understanding with Contrastive Cross-modal Feature  Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.247, \"y\": 7.195}, {\"title\": \"Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.097, \"y\": 4.317}, {\"title\": \"Transformer based Multitask Learning for Image Captioning and Object  Detection\", \"topic\": \"Multimodal Language Models\", \"x\": 8.661, \"y\": 7.215}, {\"title\": \"SCORE: Self-supervised Correspondence Fine-tuning for Improved Content  Representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.979, \"y\": 4.931}, {\"title\": \"No Language is an Island: Unifying Chinese and English in Financial  Large Language Models, Instruction Data, and Benchmarks\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.863, \"y\": 6.871}, {\"title\": \"Mipha: A Comprehensive Overhaul of Multimodal Assistant with Small  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.322, \"y\": 7.437}, {\"title\": \"FMPAF: How Do Fed Chairs Affect the Financial Market? A Fine-grained  Monetary Policy Analysis Framework on Their Language\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.748, \"y\": 6.815}, {\"title\": \"Large Language Models on Fine-grained Emotion Detection Dataset with  Data Augmentation and Transfer Learning\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.434, \"y\": 7.417}, {\"title\": \"Automatic design optimization of preference-based subjective evaluation  with online learning in crowdsourcing environment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.239, \"y\": 1.299}, {\"title\": \"Can LLM Substitute Human Labeling? A Case Study of Fine-grained Chinese  Address Entity Recognition Dataset for UAV Delivery\", \"topic\": \"Named Entity Recognition\", \"x\": 7.382, \"y\": 6.754}, {\"title\": \"Target-constrained Bidirectional Planning for Generation of  Target-oriented Proactive Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.455, \"y\": 3.506}, {\"title\": \"Understanding Social Perception, Interactions, and Safety Aspects of  Sidewalk Delivery Robots Using Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.78, \"y\": 6.514}, {\"title\": \"Exploratory Data Analysis on Code-mixed Misogynistic Comments\", \"topic\": \"Hate Speech Detection\", \"x\": 2.814, \"y\": 5.452}, {\"title\": \"Persian Slang Text Conversion to Formal and Deep Learning of Persian  Short Texts on Social Media for Sentiment Classification\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.66, \"y\": 6.619}, {\"title\": \"Institutional-Level Monitoring of Immune Checkpoint Inhibitor IrAEs  Using a Novel Natural Language Processing Algorithmic Pipeline\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.638, \"y\": 8.036}, {\"title\": \"Enhanced Auto Language Prediction with Dictionary Capsule -- A Novel  Approach\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.741, \"y\": 5.139}, {\"title\": \"Measuring Bias in a Ranked List using Term-based Representations\", \"topic\": \"Bias in Language Models\", \"x\": 3.371, \"y\": 4.291}, {\"title\": \"Thread Detection and Response Generation using Transformers with Prompt  Optimisation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.415, \"y\": 3.743}, {\"title\": \"High Throughput Phenotyping of Physician Notes with Large Language and  Hybrid NLP Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.701, \"y\": 7.984}, {\"title\": \"An Audio-textual Diffusion Model For Converting Speech Signals Into  Ultrasound Tongue Imaging Data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.346, \"y\": 5.957}, {\"title\": \"MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging  Knowledge Graphs\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.536, \"y\": 4.051}, {\"title\": \"ClinicalMamba: A Generative Clinical Language Model on Longitudinal  Clinical Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.809, \"y\": 8.114}, {\"title\": \"ItD: Large Language Models Can Teach Themselves Induction through  Deduction\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.739, \"y\": 2.991}, {\"title\": \"On the Benefits of Fine-Grained Loss Truncation: A Case Study on  Factuality in Summarization\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.203, \"y\": 1.269}, {\"title\": \"FLAP: Flow-Adhering Planning with Constrained Decoding in LLMs\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.893, \"y\": 2.517}, {\"title\": \"Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated  Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.221, \"y\": 4.665}, {\"title\": \"A Benchmark of Domain-Adapted Large Language Models for Generating Brief  Hospital Course Summaries\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.657, \"y\": 8.053}, {\"title\": \"SeeGULL Multilingual: a Dataset of Geo-Culturally Situated Stereotypes\", \"topic\": \"Bias in Language Models\", \"x\": 3.631, \"y\": 4.286}, {\"title\": \"How Well Do Multi-modal LLMs Interpret CT Scans? An Auto-Evaluation  Framework for Analyses\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.157, \"y\": 8.488}, {\"title\": \"PipeRAG: Fast Retrieval-Augmented Generation via Algorithm-System  Co-design\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.096, \"y\": 4.655}, {\"title\": \"Concept-aware Data Construction Improves In-context Learning of Language  Models\", \"topic\": \"In-Context Learning\", \"x\": 8.375, \"y\": 3.344}, {\"title\": \"Tell, Don't Show!: Language Guidance Eases Transfer Across Domains in  Images and Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.945, \"y\": 7.428}, {\"title\": \"Bayesian Preference Elicitation with Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.253, \"y\": 1.464}, {\"title\": \"Gemini 1.5: Unlocking multimodal understanding across millions of tokens  of context\", \"topic\": \"Multimodal Language Models\", \"x\": 7.986, \"y\": 7.564}, {\"title\": \"Bias-Augmented Consistency Training Reduces Biased Reasoning in  Chain-of-Thought\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.669, \"y\": 2.261}, {\"title\": \"Unfamiliar Finetuning Examples Control How Language Models Hallucinate\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.387, \"y\": 1.162}, {\"title\": \"FFSTC: Fongbe to French Speech Translation Corpus\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.349, \"y\": 5.319}, {\"title\": \"HistGen: Histopathology Report Generation via Local-Global Feature  Encoding and Cross-modal Context Interaction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.238, \"y\": 8.508}, {\"title\": \"The Impact of Quantization on the Robustness of Transformer-based Text  Classifiers\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.172, \"y\": 3.032}, {\"title\": \"ChatASU: Evoking LLM's Reflexion to Truly Understand Aspect Sentiment in  Dialogues\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.111, \"y\": 6.818}, {\"title\": \"RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in  Long-Horizon Generation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.612, \"y\": 2.454}, {\"title\": \"ACLSum: A New Dataset for Aspect-based Summarization of Scientific  Publications\", \"topic\": \"Text Summarization\", \"x\": 5.515, \"y\": 6.442}, {\"title\": \"PEEB: Part-based Image Classifiers with an Explainable and Editable  Language Bottleneck\", \"topic\": \"Multimodal Language Models\", \"x\": 8.789, \"y\": 7.195}, {\"title\": \"LLM4Decompile: Decompiling Binary Code with Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.734, \"y\": 2.388}, {\"title\": \"Deep Prompt Multi-task Network for Abuse Language Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.789, \"y\": 5.362}, {\"title\": \"ERBench: An Entity-Relationship based Automatically Verifiable  Hallucination Benchmark for Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.242, \"y\": 1.311}, {\"title\": \"Cross-lingual Transfer or Machine Translation? On Data Augmentation for  Monolingual Semantic Textual Similarity\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.424, \"y\": 4.942}, {\"title\": \"Harnessing Multi-Role Capabilities of Large Language Models for  Open-Domain Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.573, \"y\": 5.024}, {\"title\": \"SocialPET: Socially Informed Pattern Exploiting Training for Few-Shot  Stance Detection in Social Media\", \"topic\": \"Fake News Detection\", \"x\": 3.477, \"y\": 5.853}, {\"title\": \"CommitBench: A Benchmark for Commit Message Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.382, \"y\": 2.441}, {\"title\": \"ROUGE-K: Do Your Summaries Have Keywords?\", \"topic\": \"Text Summarization\", \"x\": 5.482, \"y\": 6.201}, {\"title\": \"Speech Robust Bench: A Robustness Benchmark For Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.188, \"y\": 5.539}, {\"title\": \"A Concept-based Interpretable Model for the Diagnosis of Choroid  Neoplasias using Multimodal Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.169, \"y\": 8.439}, {\"title\": \"Rule-driven News Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.958, \"y\": 7.536}, {\"title\": \"MEIT: Multi-Modal Electrocardiogram Instruction Tuning on Large Language  Models for Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.192, \"y\": 8.234}, {\"title\": \"ConstitutionalExperts: Training a Mixture of Principle-based Prompts\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.461, \"y\": 3.127}, {\"title\": \"Few shot chain-of-thought driven reasoning to prompt LLMs for open ended  medical question answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.667, \"y\": 7.843}, {\"title\": \"Code-Mixed Probes Show How Pre-Trained Models Generalise On  Code-Switched Text\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.506, \"y\": 4.767}, {\"title\": \"How Far Are We from Intelligent Visual Deductive Reasoning?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.341, \"y\": 7.729}, {\"title\": \"Common 7B Language Models Already Possess Strong Math Capabilities\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.228, \"y\": 2.842}, {\"title\": \"Chain of Thought Explanation for Dialogue State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.818, \"y\": 3.336}, {\"title\": \"MedFLIP: Medical Vision-and-Language Self-supervised Fast Pre-Training  with Masked Autoencoder\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.564, \"y\": 8.403}, {\"title\": \"Uncertainty-Aware Relational Graph Neural Network for Few-Shot Knowledge  Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.101, \"y\": 6.086}, {\"title\": \"Pearl: A Review-driven Persona-Knowledge Grounded Conversational  Recommendation Dataset\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.97, \"y\": 3.189}, {\"title\": \"Low-Resource Court Judgment Summarization for Common Law Systems\", \"topic\": \"Legal NLP\", \"x\": 5.04, \"y\": 5.863}, {\"title\": \"Classist Tools: Social Class Correlates with Performance in NLP\", \"topic\": \"Bias in Language Models\", \"x\": 3.594, \"y\": 4.499}, {\"title\": \"From Graph to Word Bag: Introducing Domain Knowledge to Confusing Charge  Prediction\", \"topic\": \"Legal NLP\", \"x\": 5.132, \"y\": 5.78}, {\"title\": \"Discriminative Probing and Tuning for Text-to-Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.992, \"y\": 6.806}, {\"title\": \"HaluEval-Wild: Evaluating Hallucinations of Language Models in the Wild\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.136, \"y\": 1.108}, {\"title\": \"Proxy-RLHF: Decoupling Generation and Alignment in Large Language Model  with Proxy\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.249, \"y\": 1.479}, {\"title\": \"A New Benchmark for Evaluating Automatic Speech Recognition in the  Arabic Call Domain\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.854, \"y\": 5.488}, {\"title\": \"Advancing Biomedical Text Mining with Community Challenges\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.741, \"y\": 7.541}, {\"title\": \"Can Small Language Models be Good Reasoners for Sequential  Recommendation?\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.931, \"y\": 2.827}, {\"title\": \"DEEP-ICL: Definition-Enriched Experts for Language Model In-Context  Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.329, \"y\": 3.355}, {\"title\": \"Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.461, \"y\": 2.472}, {\"title\": \"Aligners: Decoupling LLMs and Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.506, \"y\": 1.573}, {\"title\": \"Self-Evaluation of Large Language Model based on Glass-box Features\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.07, \"y\": 3.487}, {\"title\": \"DA-Net: A Disentangled and Adaptive Network for Multi-Source  Cross-Lingual Transfer Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.75, \"y\": 4.783}, {\"title\": \"Levels of AI Agents: from Rules to Large Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.318, \"y\": 2.978}, {\"title\": \"Did Translation Models Get More Robust Without Anyone Even Noticing?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.7, \"y\": 4.364}, {\"title\": \"SaulLM-7B: A pioneering Large Language Model for Law\", \"topic\": \"Legal NLP\", \"x\": 5.204, \"y\": 5.557}, {\"title\": \"ShortGPT: Layers in Large Language Models are More Redundant Than You  Expect\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.498, \"y\": 2.499}, {\"title\": \"A Modular Approach for Multimodal Summarization of TV Shows\", \"topic\": \"Multimodal Language Models\", \"x\": 8.664, \"y\": 7.937}, {\"title\": \"German also Hallucinates! Inconsistency Detection in News Summaries with  the Absinth Dataset\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.128, \"y\": 1.106}, {\"title\": \"Rapidly Developing High-quality Instruction Data and Evaluation  Benchmark for Large Language Models with Minimal Human Effort: A Case Study  on Japanese\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 7.906, \"y\": 2.343}, {\"title\": \"Apollo: A Lightweight Multilingual Medical LLM towards Democratizing  Medical AI to 6B People\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.017, \"y\": 7.984}, {\"title\": \"Design of an Open-Source Architecture for Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.8, \"y\": 4.373}, {\"title\": \"gaHealth: An English-Irish Bilingual Corpus of Health Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.143, \"y\": 7.676}, {\"title\": \"Benchmarking Hallucination in Large Language Models based on  Unanswerable Math Word Problem\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.188, \"y\": 1.139}, {\"title\": \"Prompt Mining for Language-based Human Mobility Forecasting\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.128, \"y\": 3.357}, {\"title\": \"Non-verbal information in spontaneous speech -- towards a new framework  of analysis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.716, \"y\": 5.548}, {\"title\": \"BiVert: Bidirectional Vocabulary Evaluation using Relations for Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.73, \"y\": 4.836}, {\"title\": \"Detecting AI-Generated Sentences in Human-AI Collaborative Hybrid Texts:  Challenges, Strategies, and Insights\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.433, \"y\": 4.809}, {\"title\": \"A Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.63, \"y\": 4.08}, {\"title\": \"VLSP 2023 -- LTER: A Summary of the Challenge on Legal Textual  Entailment Recognition\", \"topic\": \"Legal NLP\", \"x\": 5.216, \"y\": 5.6}, {\"title\": \"Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language  Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.007, \"y\": 2.262}, {\"title\": \"Negating Negatives: Alignment without Human Positive Samples via  Distributional Dispreference Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.282, \"y\": 1.29}, {\"title\": \"Japanese-English Sentence Translation Exercises Dataset for Automatic  Grading\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.659, \"y\": 4.759}, {\"title\": \"Learning to Maximize Mutual Information for Chain-of-Thought  Distillation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.489, \"y\": 3.804}, {\"title\": \"AttentionStitch: How Attention Solves the Speech Editing Problem\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.686, \"y\": 5.639}, {\"title\": \"DIVERSE: Deciphering Internet Views on the U.S. Military Through Video  Comment Stance Analysis, A Novel Benchmark Dataset for Stance Classification\", \"topic\": \"Fake News Detection\", \"x\": 3.455, \"y\": 5.871}, {\"title\": \"Best of Both Worlds: A Pliable and Generalizable Neuro-Symbolic Approach  for Relation Classification\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.109, \"y\": 6.685}, {\"title\": \"SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context  Misinformation Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.224, \"y\": 5.956}, {\"title\": \"Design2Code: How Far Are We From Automating Front-End Engineering?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.206, \"y\": 7.599}, {\"title\": \"\\\"In Dialogues We Learn\\\": Towards Personalized Dialogue Without  Pre-defined Profiles through In-Dialogue Learning\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.315, \"y\": 3.719}, {\"title\": \"KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.827, \"y\": 2.585}, {\"title\": \"NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and  Diffusion Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.582, \"y\": 5.846}, {\"title\": \"Detecting Concrete Visual Tokens for Multimodal Machine Translation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.52, \"y\": 7.011}, {\"title\": \"Adding Multimodal Capabilities to a Text-only Translation Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.603, \"y\": 6.954}, {\"title\": \"SimuCourt: Building Judicial Decision-Making Agents with Real-world  Judgement Documents\", \"topic\": \"Legal NLP\", \"x\": 5.086, \"y\": 5.719}, {\"title\": \"AIx Speed: Playback Speed Optimization Using Listening Comprehension of  Speech Recognition Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.083, \"y\": 5.452}, {\"title\": \"A Second Look on BASS -- Boosting Abstractive Summarization with Unified  Semantic Graphs -- A Replication Study\", \"topic\": \"Text Summarization\", \"x\": 5.591, \"y\": 6.298}, {\"title\": \"JMI at SemEval 2024 Task 3: Two-step approach for multimodal ECAC using  in-context learning with GPT and instruction-tuned Llama models\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.263, \"y\": 7.701}, {\"title\": \"Zero-Shot Cross-Lingual Document-Level Event Causality Identification  with Heterogeneous Graph Contrastive Transfer Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.227, \"y\": 5.157}, {\"title\": \"In Search of Truth: An Interrogation Approach to Hallucination Detection\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.185, \"y\": 1.128}, {\"title\": \"MathScale: Scaling Instruction Tuning for Mathematical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.062, \"y\": 2.814}, {\"title\": \"Enhancing Conceptual Understanding in Multimodal Contrastive Learning  through Hard Negative Samples\", \"topic\": \"Multimodal Language Models\", \"x\": 8.65, \"y\": 6.978}, {\"title\": \"On the Limitations of Fine-tuned Judge Models for LLM Evaluation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.356, \"y\": 3.667}, {\"title\": \"DPPA: Pruning Method for Large Language Model to Model Merging\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.517, \"y\": 2.482}, {\"title\": \"CURATRON: Complete Robust Preference Data for Robust Alignment of Large  Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.24, \"y\": 1.393}, {\"title\": \"Towards Training A Chinese Large Language Model for Anesthesiology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.808, \"y\": 8.047}, {\"title\": \"Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of  Vietnamese Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.473, \"y\": 4.02}, {\"title\": \"InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated  Large Language Model Agents\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.422, \"y\": 2.617}, {\"title\": \"Finetuned Multimodal Language Models Are High-Quality Image-Text Data  Filters\", \"topic\": \"Multimodal Language Models\", \"x\": 8.6, \"y\": 7.107}, {\"title\": \"FinReport: Explainable Stock Earnings Forecasting via News Factor  Analyzing Model\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.757, \"y\": 6.807}, {\"title\": \"Updating the Minimum Information about CLinical Artificial Intelligence  (MI-CLAIM) checklist for generative modeling research\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.675, \"y\": 8.039}, {\"title\": \"DACO: Towards Application-Driven and Comprehensive Data Analysis via  Code Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.364, \"y\": 2.366}, {\"title\": \"Enhancing LLM Safety via Constrained Direct Preference Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.139, \"y\": 1.356}, {\"title\": \"OffensiveLang: A Community Based Implicit Offensive Language Dataset\", \"topic\": \"Hate Speech Detection\", \"x\": 2.744, \"y\": 5.315}, {\"title\": \"How does Architecture Influence the Base Capabilities of Pre-trained  Language Models? A Case Study Based on FFN-Wider Transformer Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.534, \"y\": 3.463}, {\"title\": \"Key-Point-Driven Data Synthesis with its Enhancement on Mathematical  Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.031, \"y\": 2.828}, {\"title\": \"Contrastive Region Guidance: Improving Grounding in Vision-Language  Models without Training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.652, \"y\": 7.503}, {\"title\": \"Emotion Granularity from Text: An Aggregate-Level Indicator of Mental  Health\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.136, \"y\": 7.462}, {\"title\": \"Subjective $\\\\textit{Isms}$? On the Danger of Conflating Hate and Offence  in Abusive Language Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.852, \"y\": 5.439}, {\"title\": \"Distilled ChatGPT Topic & Sentiment Modeling with Applications in  Finance\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.702, \"y\": 6.863}, {\"title\": \"Masked Thought: Simply Masking Partial Reasoning Steps Can Improve  Mathematical Reasoning Learning of Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.97, \"y\": 2.512}, {\"title\": \"EEE-QA: Exploring Effective and Efficient Question-Answer  Representations\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.589, \"y\": 5.064}, {\"title\": \"Large Language Models in Fire Engineering: An Examination of Technical  Questions Against Domain Knowledge\", \"topic\": \"Bias in Language Models\", \"x\": 5.233, \"y\": 4.365}, {\"title\": \"EMOVOME Database: Advancing Emotion Recognition in Speech Beyond Staged  Scenarios\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.217, \"y\": 7.838}, {\"title\": \"Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed  Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language  Models\", \"topic\": \"Hate Speech Detection\", \"x\": 2.781, \"y\": 5.395}, {\"title\": \"adaptMLLM: Fine-Tuning Multilingual Language Models on Low-Resource  Languages with Integrated LLM Playgrounds\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.418, \"y\": 4.477}, {\"title\": \"Breaking the Language Barrier: Can Direct Inference Outperform  Pre-Translation in Multilingual LLM Applications?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.436, \"y\": 4.472}, {\"title\": \"Vanilla Transformers are Transfer Capability Teachers\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.531, \"y\": 3.803}, {\"title\": \"FakeNewsGPT4: Advancing Multimodal Fake News Detection through  Knowledge-Augmented LVLMs\", \"topic\": \"Fake News Detection\", \"x\": 4.047, \"y\": 5.87}, {\"title\": \"Transformers for Low-Resource Languages:Is F\\u00e9idir Linn!\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.981, \"y\": 4.265}, {\"title\": \"Multi-perspective Improvement of Knowledge Graph Completion with Large  Language Models\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.044, \"y\": 5.991}, {\"title\": \"AS-ES Learning: Towards Efficient CoT Learning in Small Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.746, \"y\": 2.233}, {\"title\": \"adaptNMT: an open-source, language-agnostic development environment for  Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.857, \"y\": 4.499}, {\"title\": \"Human Evaluation of English--Irish Transformer-Based NMT\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.806, \"y\": 4.551}, {\"title\": \"To Generate or to Retrieve? On the Effectiveness of Artificial Contexts  for Medical Open-Domain Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.915, \"y\": 7.517}, {\"title\": \"Arabic Text Sentiment Analysis: Reinforcing Human-Performed Surveys with  Wider Topic Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.526, \"y\": 6.615}, {\"title\": \"LLM vs. Lawyers: Identifying a Subset of Summary Judgments in a Large UK  Case Law Dataset\", \"topic\": \"Legal NLP\", \"x\": 5.07, \"y\": 5.723}, {\"title\": \"Fostering the Ecosystem of Open Neural Encoders for Portuguese with  Albertina PT* Family\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.071, \"y\": 4.462}, {\"title\": \"FCDS: Fusing Constituency and Dependency Syntax into Document-Level  Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.87, \"y\": 6.825}, {\"title\": \"CET2: Modelling Topic Transitions for Coherent and Engaging  Knowledge-Grounded Conversations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.449, \"y\": 3.959}, {\"title\": \"TopicDiff: A Topic-enriched Diffusion Approach for Multimodal  Conversational Emotion Detection\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.256, \"y\": 7.753}, {\"title\": \"NPHardEval4V: A Dynamic Reasoning Benchmark of Multimodal Large Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.095, \"y\": 7.677}, {\"title\": \"Derivative-Free Optimization for Low-Rank Adaptation in Large Language  Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.199, \"y\": 2.087}, {\"title\": \"JEP-KD: Joint-Embedding Predictive Architecture Based Knowledge  Distillation for Visual Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.869, \"y\": 5.344}, {\"title\": \"You Need to Pay Better Attention: Rethinking the Mathematics of  Attention Mechanism\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.867, \"y\": 3.186}, {\"title\": \"SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional  Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.949, \"y\": 7.627}, {\"title\": \"Enhancing Neural Machine Translation of Low-Resource Languages: Corpus  Development, Human Evaluation and Explainable AI Architectures\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.848, \"y\": 4.607}, {\"title\": \"SERVAL: Synergy Learning between Vertical Models and LLMs towards  Oracle-Level Zero-shot Medical Prediction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.257, \"y\": 8.226}, {\"title\": \"In-Context Sharpness as Alerts: An Inner Representation Perspective for  Hallucination Mitigation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.244, \"y\": 1.076}, {\"title\": \"Revisiting Dynamic Evaluation: Online Adaptation for Large Language  Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.064, \"y\": 2.377}, {\"title\": \"Align-to-Distill: Trainable Attention Alignment for Knowledge  Distillation in Neural Machine Translation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.499, \"y\": 3.817}, {\"title\": \"Answerability in Retrieval-Augmented Open-Domain Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.678, \"y\": 5.089}, {\"title\": \"Logic Rules as Explanations for Legal Case Retrieval\", \"topic\": \"Legal NLP\", \"x\": 5.133, \"y\": 5.648}, {\"title\": \"What Is Missing in Multilingual Visual Reasoning and How to Fix It\", \"topic\": \"Multimodal Language Models\", \"x\": 8.195, \"y\": 7.644}, {\"title\": \"CR-LT-KGQA: A Knowledge Graph Question Answering Dataset Requiring  Commonsense Reasoning and Long-Tail Knowledge\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.768, \"y\": 5.52}, {\"title\": \"Right for Right Reasons: Large Language Models for Verifiable  Commonsense Knowledge Graph Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.691, \"y\": 5.421}, {\"title\": \"On the Compressibility of Quantized Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.699, \"y\": 2.179}, {\"title\": \"Automatic Question-Answer Generation for Long-Tail Knowledge\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.486, \"y\": 5.179}, {\"title\": \"SyllabusQA: A Course Logistics Question Answering Dataset\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.321, \"y\": 5.203}, {\"title\": \"Quantity Matters: Towards Assessing and Mitigating Number Hallucination  in Large Vision-Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.289, \"y\": 0.971}, {\"title\": \"Improving Cross-lingual Representation for Semantic Retrieval with  Code-switching\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.375, \"y\": 4.858}, {\"title\": \"Large Language Multimodal Models for 5-Year Chronic Disease Cohort  Prediction Using EHR Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.837, \"y\": 8.321}, {\"title\": \"A comprehensive cross-language framework for harmful content detection  with the aid of sentiment analysis\", \"topic\": \"Hate Speech Detection\", \"x\": 2.822, \"y\": 5.308}, {\"title\": \"AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.331, \"y\": 2.31}, {\"title\": \"SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code\", \"topic\": \"Multimodal Language Models\", \"x\": 8.716, \"y\": 7.442}, {\"title\": \"Emotion Analysis in NLP: Trends, Gaps and Roadmap for Future Directions\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.523, \"y\": 7.401}, {\"title\": \"Machine Translation in the Covid domain: an English-Irish case study for  LoResMT 2021\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.01, \"y\": 7.653}, {\"title\": \"RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.154, \"y\": 1.195}, {\"title\": \"DINER: Debiasing Aspect-based Sentiment Analysis with Multi-variable  Causal Inference\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.147, \"y\": 6.79}, {\"title\": \"STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient  Fine-Tuning of Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.909, \"y\": 2.309}, {\"title\": \"BootTOD: Bootstrap Task-oriented Dialogue Representations by Aligning  Diverse Responses\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.624, \"y\": 3.987}, {\"title\": \"A Survey of AI-generated Text Forensic Systems: Detection, Attribution,  and Characterization\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.187, \"y\": 4.793}, {\"title\": \"LLaMoCo: Instruction Tuning of Large Language Models for Optimization  Code Generation\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.015, \"y\": 2.396}, {\"title\": \"FaiMA: Feature-aware In-context Learning for Multi-domain Aspect-based  Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.103, \"y\": 6.841}, {\"title\": \"Peacock: A Family of Arabic Multimodal Large Language Models and  Benchmarks\", \"topic\": \"Multimodal Language Models\", \"x\": 8.003, \"y\": 7.513}, {\"title\": \"LocalRQA: From Generating Data to Locally Training, Testing, and  Deploying Retrieval-Augmented QA Systems\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.479, \"y\": 5.165}, {\"title\": \"MALTO at SemEval-2024 Task 6: Leveraging Synthetic Data for LLM  Hallucination Detection\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.122, \"y\": 1.017}, {\"title\": \"AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge  Graph Construction Based on Ontologies-enhanced Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.872, \"y\": 8.171}, {\"title\": \"MediSwift: Efficient Sparse Pre-trained Biomedical Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.225, \"y\": 7.883}, {\"title\": \"Dialect prejudice predicts AI decisions about people's character,  employability, and criminality\", \"topic\": \"Bias in Language Models\", \"x\": 3.337, \"y\": 4.472}, {\"title\": \"Modeling the Quality of Dialogical Explanations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.649, \"y\": 3.79}, {\"title\": \"DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large  Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.091, \"y\": 1.019}, {\"title\": \"Large Language Models for Simultaneous Named Entity Extraction and  Spelling Correction\", \"topic\": \"Named Entity Recognition\", \"x\": 7.42, \"y\": 6.524}, {\"title\": \"A Regularization-based Transfer Learning Method for Information  Extraction via Instructed Graph Decoder\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.966, \"y\": 6.582}, {\"title\": \"LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.379, \"y\": 3.813}, {\"title\": \"SEGAA: A Unified Approach to Predicting Age, Gender, and Emotion in  Speech\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.271, \"y\": 7.744}, {\"title\": \"Your Model Is Not Predicting Depression Well And That Is Why: A Case  Study of PRIMATE Dataset\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.232, \"y\": 7.416}, {\"title\": \"Hierarchical Indexing for Retrieval-Augmented Opinion Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.215, \"y\": 6.323}, {\"title\": \"Cross-Lingual Learning vs. Low-Resource Fine-Tuning: A Case Study with  Fact-Checking in Turkish\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.241, \"y\": 4.78}, {\"title\": \"Provably Robust DPO: Aligning Language Models with Noisy Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.331, \"y\": 1.232}, {\"title\": \"Post-decoder Biasing for End-to-End Speech Recognition of Multi-turn  Medical Interview\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.214, \"y\": 5.147}, {\"title\": \"Semi-Instruct: Bridging Natural-Instruct and Self-Instruct for Code  Large Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 7.942, \"y\": 2.191}, {\"title\": \"Gender Bias in Large Language Models across Multiple Languages\", \"topic\": \"Bias in Language Models\", \"x\": 3.23, \"y\": 4.387}, {\"title\": \"SoftTiger: A Clinical Foundation Model for Healthcare Workflows\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.596, \"y\": 8.018}, {\"title\": \"EUROPA: A Legal Multilingual Keyphrase Generation Dataset\", \"topic\": \"Legal NLP\", \"x\": 5.307, \"y\": 5.677}, {\"title\": \"Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by  Exploring Refusal Loss Landscapes\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.287, \"y\": 2.325}, {\"title\": \"CASIMIR: A Corpus of Scientific Articles enhanced with Multiple  Author-Integrated Revisions\", \"topic\": \"Text Summarization\", \"x\": 5.777, \"y\": 6.195}, {\"title\": \"Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of  Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.095, \"y\": 7.625}, {\"title\": \"Transcription and translation of videos using fine-tuned XLSR Wav2Vec2  on custom dataset and mBART\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.838, \"y\": 5.504}, {\"title\": \"AXOLOTL: Fairness through Assisted Self-Debiasing of Large Language  Model Outputs\", \"topic\": \"Bias in Language Models\", \"x\": 3.344, \"y\": 4.22}, {\"title\": \"EBBS: An Ensemble with Bi-Level Beam Search for Zero-Shot Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.658, \"y\": 4.578}, {\"title\": \"Prompting ChatGPT for Translation: A Comparative Analysis of Translation  Brief and Persona Prompts\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.422, \"y\": 3.443}, {\"title\": \"LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.404, \"y\": 2.486}, {\"title\": \"TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.575, \"y\": 7.944}, {\"title\": \"$\\\\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization  Evaluation\", \"topic\": \"Text Summarization\", \"x\": 5.519, \"y\": 6.24}, {\"title\": \"Functional Benchmarks for Robust Evaluation of Reasoning Performance,  and the Reasoning Gap\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.972, \"y\": 3.129}, {\"title\": \"Speaker-Independent Dysarthria Severity Classification using  Self-Supervised Transformers and Multi-Task Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.286, \"y\": 5.572}, {\"title\": \"Compositional API Recommendation for Library-Oriented Code Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.387, \"y\": 2.411}, {\"title\": \"Griffin: Mixing Gated Linear Recurrences with Local Attention for  Efficient Language Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.722, \"y\": 3.143}, {\"title\": \"EAMA : Entity-Aware Multimodal Alignment Based Approach for News Image  Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.283, \"y\": 7.134}, {\"title\": \"OpenMedLM: Prompt engineering can out-perform fine-tuning in medical  question-answering with open-source large language models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.875, \"y\": 7.824}, {\"title\": \"Prompting Explicit and Implicit Knowledge for Multi-hop Question  Answering Based on Human Reading Process\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.591, \"y\": 5.324}, {\"title\": \"Compact Speech Translation Models via Discrete Speech Units Pretraining\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.548, \"y\": 5.388}, {\"title\": \"SEED: Customize Large Language Models with Sample-Efficient Adaptation  for Code Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.415, \"y\": 2.364}, {\"title\": \"Robust Guidance for Unsupervised Data Selection: Capturing Perplexing  Named Entities for Domain-Specific Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.765, \"y\": 4.508}, {\"title\": \"GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of  LLMs as Mathematical Problem Solvers\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.83, \"y\": 2.915}, {\"title\": \"Memory-Augmented Generative Adversarial Transformers\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.352, \"y\": 4.315}, {\"title\": \"PeLLE: Encoder-based language models for Brazilian Portuguese based on  open data\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.046, \"y\": 4.414}, {\"title\": \"PRSA: PRompt Stealing Attacks against Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.381, \"y\": 2.535}, {\"title\": \"Improving Legal Judgement Prediction in Romanian with Long Text Encoders\", \"topic\": \"Legal NLP\", \"x\": 5.104, \"y\": 5.762}, {\"title\": \"Teaching Large Language Models an Unseen Language on the Fly\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.292, \"y\": 4.135}, {\"title\": \"Large Language Models are Learnable Planners for Long-Term  Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.08, \"y\": 2.883}, {\"title\": \"VIXEN: Visual Text Comparison Network for Image Difference Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.023, \"y\": 7.269}, {\"title\": \"Whispers that Shake Foundations: Analyzing and Mitigating False Premise  Hallucinations in Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.318, \"y\": 1.076}, {\"title\": \"Controllable Preference Optimization: Toward Controllable  Multi-Objective Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.315, \"y\": 1.307}, {\"title\": \"EyeGPT: Ophthalmic Assistant with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.942, \"y\": 8.257}, {\"title\": \"SemEval 2024 -- Task 10: Emotion Discovery and Reasoning its Flip in  Conversation (EDiReF)\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.26, \"y\": 7.589}, {\"title\": \"Inappropriate Pause Detection In Dysarthric Speech Using Large-Scale  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.269, \"y\": 5.611}, {\"title\": \"AdaMergeX: Cross-Lingual Transfer with Large Language Models via  Adaptive Adapter Merging\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.444, \"y\": 4.774}, {\"title\": \"Evolving to the Future: Unseen Event Adaptive Fake News Detection on  Social Media\", \"topic\": \"Fake News Detection\", \"x\": 4.021, \"y\": 5.856}, {\"title\": \"Reducing Hallucinations in Entity Abstract Summarization with  Facts-Template Decomposition\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.167, \"y\": 1.2}, {\"title\": \"How do Large Language Models Handle Multilingualism?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.177, \"y\": 4.281}, {\"title\": \"ARTiST: Automated Text Simplification for Task Guidance in Augmented  Reality\", \"topic\": \"Multimodal Language Models\", \"x\": 8.749, \"y\": 6.905}, {\"title\": \"MPAT: Building Robust Deep Neural Networks against Textual Adversarial  Attacks\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.196, \"y\": 3.049}, {\"title\": \"Advancing Generative AI for Portuguese with Open Decoder Gerv\\u00e1sio PT*\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.007, \"y\": 4.319}, {\"title\": \"How Much Annotation is Needed to Compare Summarization Models?\", \"topic\": \"Text Summarization\", \"x\": 5.544, \"y\": 6.085}, {\"title\": \"Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.774, \"y\": 4.647}, {\"title\": \"NeuroPrune: A Neuro-inspired Topological Sparse Training Algorithm for  Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.472, \"y\": 2.548}, {\"title\": \"Learning to Compress Prompt in Natural Language Formats\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.73, \"y\": 3.149}, {\"title\": \"Simple linear attention language models balance the recall-throughput  tradeoff\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.712, \"y\": 3.026}, {\"title\": \"FOFO: A Benchmark to Evaluate LLMs' Format-Following Capability\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.51, \"y\": 2.81}, {\"title\": \"Arithmetic Control of LLMs for Diverse User Preferences: Directional  Preference Alignment with Multi-Objective Rewards\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.347, \"y\": 1.449}, {\"title\": \"RNNs are not Transformers (Yet): The Key Bottleneck on In-context  Retrieval\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.505, \"y\": 3.26}, {\"title\": \"Few-Shot Fairness: Unveiling LLM's Potential for Fairness-Aware  Classification\", \"topic\": \"Bias in Language Models\", \"x\": 3.431, \"y\": 4.094}, {\"title\": \"NewsQs: Multi-Source Question Generation for the Inquiring Mind\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.155, \"y\": 5.229}, {\"title\": \"Leveraging Diverse Modeling Contexts with Collaborating Learning for  Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.996, \"y\": 4.509}, {\"title\": \"Emotion Classification in Low and Moderate Resource Languages\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.268, \"y\": 7.551}, {\"title\": \"Can GPT Improve the State of Prior Authorization via Guideline Based  Automated Question Answering?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.72, \"y\": 7.617}, {\"title\": \"A Cognitive Evaluation Benchmark of Image Reasoning and Description for  Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.177, \"y\": 7.757}, {\"title\": \"The First Place Solution of WSDM Cup 2024: Leveraging Large Language  Models for Conversational Multi-Doc QA\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.617, \"y\": 5.201}, {\"title\": \"Focus on Your Question! Interpreting and Mitigating Toxic CoT Problems  in Commonsense Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.518, \"y\": 2.336}, {\"title\": \"How to think step-by-step: A mechanistic understanding of  chain-of-thought reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.649, \"y\": 2.34}, {\"title\": \"Is Crowdsourcing Breaking Your Bank? Cost-Effective Fine-Tuning of  Pre-trained Language Models with Proximal Policy Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.388, \"y\": 1.599}, {\"title\": \"Exploration of Adapter for Noise Robust Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.223, \"y\": 5.112}, {\"title\": \"A Survey on Neural Question Generation: Methods, Applications, and  Prospects\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.237, \"y\": 5.067}, {\"title\": \"Towards Generalist Prompting for Large Language Models by Mental Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.074, \"y\": 3.007}, {\"title\": \"Learning or Self-aligning? Rethinking Instruction Fine-tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.165, \"y\": 2.352}, {\"title\": \"Prospect Personalized Recommendation on Large Language Model-based Agent  Platform\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.921, \"y\": 2.944}, {\"title\": \"DANSK and DaCy 2.6.0: Domain Generalization of Danish Named Entity  Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.319, \"y\": 6.789}, {\"title\": \"Clustering and Ranking: Diversity-preserved Instruction Selection  through Expert-aligned Quality Estimation\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.324, \"y\": 2.227}, {\"title\": \"Challenges in Pre-Training Graph Neural Networks for Context-Based Fake  News Detection: An Evaluation of Current Strategies and Resource Limitations\", \"topic\": \"Fake News Detection\", \"x\": 3.982, \"y\": 5.81}, {\"title\": \"Evaluating Quantized Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.686, \"y\": 2.177}, {\"title\": \"MedAide: Leveraging Large Language Models for On-Premise Medical  Assistance on Edge Devices\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.778, \"y\": 8.03}, {\"title\": \"MMSR: Symbolic Regression is a Multimodal Task\", \"topic\": \"Multimodal Language Models\", \"x\": 8.153, \"y\": 7.243}, {\"title\": \"Unsupervised Information Refinement Training of Large Language Models  for Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.033, \"y\": 4.571}, {\"title\": \"Learning Intrinsic Dimension via Information Bottleneck for Explainable  Aspect-based Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.099, \"y\": 6.832}, {\"title\": \"UniVS: Unified and Universal Video Segmentation with Prompts as Queries\", \"topic\": \"Multimodal Language Models\", \"x\": 8.538, \"y\": 7.359}, {\"title\": \"LoRA-SP: Streamlined Partial Parameter Adaptation for Resource-Efficient  Fine-Tuning of Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.129, \"y\": 2.158}, {\"title\": \"Polos: Multimodal Metric Learning from Human Feedback for Image  Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.059, \"y\": 7.444}, {\"title\": \"Benchmarking Large Language Models on Answering and Explaining  Challenging Medical Questions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.798, \"y\": 7.846}, {\"title\": \"ResLoRA: Identity Residual Mapping in Low-Rank Adaption\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.167, \"y\": 2.064}, {\"title\": \"Hire a Linguist!: Learning Endangered Languages with In-Context  Linguistic Descriptions\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.368, \"y\": 4.379}, {\"title\": \"A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.614, \"y\": 3.837}, {\"title\": \"FlattenQuant: Breaking Through the Inference Compute-bound for Large  Language Models with Per-tensor Quantization\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.713, \"y\": 2.209}, {\"title\": \"M3-VRD: Multimodal Multi-task Multi-teacher Visually-Rich Form Document  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.045, \"y\": 7.071}, {\"title\": \"Collaborative decoding of critical tokens for boosting factuality of  large language models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.554, \"y\": 1.377}, {\"title\": \"All in an Aggregated Image for In-Image Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.315, \"y\": 7.32}, {\"title\": \"An Iterative Associative Memory Model for Empathetic Response Generation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.649, \"y\": 7.919}, {\"title\": \"Twists, Humps, and Pebbles: Multilingual Speech Recognition Models  Exhibit Gender Performance Gaps\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.205, \"y\": 5.525}, {\"title\": \"SparseLLM: Towards Global Pruning for Pre-trained Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.48, \"y\": 2.461}, {\"title\": \"Acquiring Linguistic Knowledge from Multimodal Input\", \"topic\": \"Multimodal Language Models\", \"x\": 8.385, \"y\": 7.131}, {\"title\": \"Multitask Multilingual Model Adaptation with Featurized Low-Rank  Mixtures\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.075, \"y\": 2.252}, {\"title\": \"Pragmatic Instruction Following and Goal Assistance via Cooperative  Language-Guided Inverse Planning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.755, \"y\": 2.447}, {\"title\": \"Adversarial Math Word Problem Generation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.591, \"y\": 2.832}, {\"title\": \"Researchy Questions: A Dataset of Multi-Perspective, Decompositional  Questions for LLM Web Agents\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.411, \"y\": 5.221}, {\"title\": \"JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning  and Professional Question Answering Capability\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.982, \"y\": 7.669}, {\"title\": \"BlendSQL: A Scalable Dialect for Unifying Hybrid Question Answering in  Relational Algebra\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.754, \"y\": 5.268}, {\"title\": \"Deep Learning Detection Method for Large Language Models-Generated  Scientific Content\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.223, \"y\": 4.778}, {\"title\": \"Tower: An Open Multilingual Large Language Model for Translation-Related  Tasks\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.407, \"y\": 4.428}, {\"title\": \"Case-Based or Rule-Based: How Do Transformers Do the Math?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.136, \"y\": 2.733}, {\"title\": \"Agent-Pro: Learning to Evolve via Policy-Level Reflection and  Optimization\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.83, \"y\": 2.28}, {\"title\": \"Unleashing the Potential of Large Language Models as Prompt Optimizers:  An Analogical Analysis with Gradient-based Model Optimizers\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.41, \"y\": 3.066}, {\"title\": \"TruthX: Alleviating Hallucinations by Editing Large Language Models in  Truthful Space\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.544, \"y\": 1.397}, {\"title\": \"Latent Attention for Linear Time Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.802, \"y\": 3.287}, {\"title\": \"Extreme Miscalibration and the Illusion of Adversarial Robustness\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.187, \"y\": 3.053}, {\"title\": \"REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain  Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.985, \"y\": 4.698}, {\"title\": \"Emotional Voice Messages (EMOVOME) database: emotion recognition in  spontaneous voice messages\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.296, \"y\": 7.798}, {\"title\": \"Predicting postoperative risks using large language models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.866, \"y\": 8.248}, {\"title\": \"Can GPT-4 Identify Propaganda? Annotation and Detection of Propaganda  Spans in News Articles\", \"topic\": \"Fake News Detection\", \"x\": 3.972, \"y\": 5.48}, {\"title\": \"Exploiting Emotion-Semantic Correlations for Empathetic Response  Generation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.6, \"y\": 7.879}, {\"title\": \"Spot the bot: Coarse-Grained Partition of Semantic Paths for Bots and  Humans\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.393, \"y\": 4.964}, {\"title\": \"FairBelief -- Assessing Harmful Beliefs in Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.254, \"y\": 4.241}, {\"title\": \"RECOST: External Knowledge Guided Data-efficient Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.255, \"y\": 2.213}, {\"title\": \"Unsupervised multiple choices question answering via universal corpus\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.406, \"y\": 5.349}, {\"title\": \"SKT5SciSumm -- A Hybrid Generative Approach for Multi-Document  Scientific Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.776, \"y\": 6.404}, {\"title\": \"Probing Multimodal Large Language Models for Global and Local Semantic  Representations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.454, \"y\": 7.406}, {\"title\": \"MELoRA: Mini-Ensemble Low-Rank Adapters for Parameter-Efficient  Fine-Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.169, \"y\": 2.051}, {\"title\": \"Image-Text Matching with Multi-View Attention\", \"topic\": \"Multimodal Language Models\", \"x\": 8.498, \"y\": 6.843}, {\"title\": \"MATHSENSEI: A Tool-Augmented Large Language Model for Mathematical  Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.025, \"y\": 2.815}, {\"title\": \"Reasoning in Conversation: Solving Subjective Tasks through Dialogue  Simulation for Large Language Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.431, \"y\": 3.529}, {\"title\": \"Measuring Vision-Language STEM Skills of Neural Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.104, \"y\": 7.772}, {\"title\": \"An Effective Mixture-Of-Experts Approach For Code-Switching Speech  Recognition Leveraging Encoder Disentanglement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.003, \"y\": 5.168}, {\"title\": \"Extreme Encoder Output Frame Rate Reduction: Improving Computational  Latencies of Large End-to-End Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.169, \"y\": 5.004}, {\"title\": \"Clustering Document Parts: Detecting and Characterizing Influence  Campaigns from Documents\", \"topic\": \"Fake News Detection\", \"x\": 3.833, \"y\": 5.879}, {\"title\": \"OSCaR: Object State Captioning and State Change Representation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.538, \"y\": 7.407}, {\"title\": \"Sinkhorn Distance Minimization for Knowledge Distillation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.541, \"y\": 3.779}, {\"title\": \"Leveraging Large Language Models for Learning Complex Legal Concepts  through Storytelling\", \"topic\": \"Legal NLP\", \"x\": 5.181, \"y\": 5.5}, {\"title\": \"Z-AGI Labs at ClimateActivism 2024: Stance and Hate Event Detection on  Social Media\", \"topic\": \"Hate Speech Detection\", \"x\": 3.008, \"y\": 5.593}, {\"title\": \"Towards Explainability and Fairness in Swiss Judgement Prediction:  Benchmarking on a Multilingual Dataset\", \"topic\": \"Legal NLP\", \"x\": 4.966, \"y\": 5.65}, {\"title\": \"GROUNDHOG: Grounding Large Language Models to Holistic Segmentation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.716, \"y\": 7.419}, {\"title\": \"Multi-LoRA Composition for Image Generation\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.227, \"y\": 2.01}, {\"title\": \"Do Large Language Models Latently Perform Multi-Hop Reasoning?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.628, \"y\": 2.931}, {\"title\": \"Mysterious Projections: Multimodal LLMs Gain Domain-Specific Visual  Capabilities Without Richer Cross-Modal Projections\", \"topic\": \"Multimodal Language Models\", \"x\": 8.257, \"y\": 7.542}, {\"title\": \"Nemotron-4 15B Technical Report\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.788, \"y\": 4.285}, {\"title\": \"A Surprising Failure? Multimodal LLMs and the NLVR Challenge\", \"topic\": \"Multimodal Language Models\", \"x\": 8.154, \"y\": 7.671}, {\"title\": \"OncoGPT: A Medical Conversational Model Tailored with Oncology Domain  Expertise on a Large Language Model Meta-AI (LLaMA)\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.634, \"y\": 8.1}, {\"title\": \"A Comprehensive Evaluation of Quantization Strategies for Large Language  Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.684, \"y\": 2.164}, {\"title\": \"CodeChameleon: Personalized Encryption Framework for Jailbreaking Large  Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.296, \"y\": 2.28}, {\"title\": \"SelectIT: Selective Instruction Tuning for Large Language Models via  Uncertainty-Aware Self-Reflection\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.213, \"y\": 2.333}, {\"title\": \"Social Media as a Sensor: Analyzing Twitter Data for Breast Cancer  Medication Effects Using Natural Language Processing\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.437, \"y\": 7.395}, {\"title\": \"Generating Effective Ensembles for Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.459, \"y\": 6.692}, {\"title\": \"HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual  Natural Language Generalization\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.607, \"y\": 2.825}, {\"title\": \"Adaptation of Biomedical and Clinical Pretrained Models to French Long  Documents: A Comparative Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.152, \"y\": 7.92}, {\"title\": \"RepoAgent: An LLM-Powered Open-Source Framework for Repository-level  Code Documentation Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.441, \"y\": 2.417}, {\"title\": \"LangGPT: Rethinking Structured Reusable Prompt Design Framework for LLMs  from the Programming Language\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.227, \"y\": 3.279}, {\"title\": \"PAQA: Toward ProActive Open-Retrieval Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.493, \"y\": 4.972}, {\"title\": \"Rethinking Negative Instances for Generative Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.362, \"y\": 6.821}, {\"title\": \"Two-stage Generative Question Answering on Temporal Knowledge Graph  Using Large Language Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.649, \"y\": 5.499}, {\"title\": \"Retrieval Augmented Generation Systems: Automatic Dataset Creation,  Evaluation and Boolean Agent Setup\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.909, \"y\": 4.686}, {\"title\": \"Integrating Large Language Models with Graphical Session-Based  Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.968, \"y\": 2.9}, {\"title\": \"Pre-training Cross-lingual Open Domain Question Answering with  Large-scale Synthetic Supervision\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.653, \"y\": 5.313}, {\"title\": \"LLMArena: Assessing Capabilities of Large Language Models in Dynamic  Multi-Agent Environments\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.632, \"y\": 3.029}, {\"title\": \"Unveiling Vulnerability of Self-Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.825, \"y\": 3.372}, {\"title\": \"Defending LLMs against Jailbreaking Attacks via Backtranslation\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.326, \"y\": 2.343}, {\"title\": \"ID-XCB: Data-independent Debiasing for Fair and Accurate  Transformer-based Cyberbullying Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.764, \"y\": 5.379}, {\"title\": \"From RAGs to riches: Using large language models to write documents for  clinical trials\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.644, \"y\": 7.792}, {\"title\": \"An Automated End-to-End Open-Source Software for High-Quality  Text-to-Speech Dataset Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.612, \"y\": 5.577}, {\"title\": \"MathGenie: Generating Synthetic Data with Question Back-translation for  Enhancing Mathematical Reasoning of LLMs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.05, \"y\": 2.747}, {\"title\": \"Data-freeWeight Compress and Denoise for Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.604, \"y\": 2.389}, {\"title\": \"Finer: Investigating and Enhancing Fine-Grained Visual Concept  Recognition in Large Vision Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.683, \"y\": 7.484}, {\"title\": \"QASE Enhanced PLMs: Improved Control in Text Generation for MRC\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.474, \"y\": 5.301}, {\"title\": \"RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic  Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.868, \"y\": 8.017}, {\"title\": \"HypoTermQA: Hypothetical Terms Dataset for Benchmarking Hallucination  Tendency of LLMs\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.158, \"y\": 1.101}, {\"title\": \"IR2: Information Regularization for Information Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.22, \"y\": 4.746}, {\"title\": \"ASEM: Enhancing Empathy in Chatbot through Attention-based Sentiment and  Emotion Modeling\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.543, \"y\": 7.743}, {\"title\": \"Defending Large Language Models against Jailbreak Attacks via Semantic  Smoothing\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.299, \"y\": 2.473}, {\"title\": \"DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM  Jailbreakers\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.322, \"y\": 2.228}, {\"title\": \"DistALANER: Distantly Supervised Active Learning Augmented Named Entity  Recognition in the Open Source Software Ecosystem\", \"topic\": \"Named Entity Recognition\", \"x\": 7.315, \"y\": 6.758}, {\"title\": \"From Text to Transformation: A Comprehensive Review of Large Language  Models' Versatility\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.483, \"y\": 4.128}, {\"title\": \"What Generative Artificial Intelligence Means for Terminological  Definitions\", \"topic\": \"Bias in Language Models\", \"x\": 4.917, \"y\": 4.403}, {\"title\": \"Training a Bilingual Language Model by Mapping Tokens onto a Shared  Character Space\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.442, \"y\": 4.854}, {\"title\": \"Citation-Enhanced Generation for LLM-based Chatbots\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.191, \"y\": 1.37}, {\"title\": \"Say More with Less: Understanding Prompt Learning Behaviors through Gist  Compression\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.627, \"y\": 3.221}, {\"title\": \"LSTP: Language-guided Spatial-Temporal Prompt Learning for Long-form  Video-Text Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.949, \"y\": 7.949}, {\"title\": \"LLMs with Chain-of-Thought Are Non-Causal Reasoners\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.65, \"y\": 2.38}, {\"title\": \"Detecting Machine-Generated Texts by Multi-Population Aware Optimization  for Maximum Mean Discrepancy\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.078, \"y\": 4.746}, {\"title\": \"EHRNoteQA: An LLM Benchmark for Real-World Clinical Practice Using  Discharge Summaries\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.7, \"y\": 7.974}, {\"title\": \"Deep Learning Approaches for Improving Question Answering Systems in  Hepatocellular Carcinoma Research\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.721, \"y\": 7.648}, {\"title\": \"Emotion Classification in Short English Texts using Deep Learning  Techniques\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.416, \"y\": 7.414}, {\"title\": \"Don't Forget Your Reward Values: Language Model Alignment via  Value-based Calibration\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.262, \"y\": 1.39}, {\"title\": \"A Machine Learning Approach to Detect Customer Satisfaction From  Multiple Tweet Parameters\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.723, \"y\": 6.672}, {\"title\": \"Phonetic and Lexical Discovery of a Canine Language using HuBERT\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.74, \"y\": 5.141}, {\"title\": \"Direct Punjabi to English speech translation using discrete units\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.353, \"y\": 5.294}, {\"title\": \"Cognitive Bias in High-Stakes Decision-Making with LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.671, \"y\": 4.186}, {\"title\": \"Debug like a Human: A Large Language Model Debugger via Verifying  Runtime Execution Step-by-step\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.29, \"y\": 2.37}, {\"title\": \"Bridging the Gap between 2D and 3D Visual Question Answering: A Fusion  Approach for 3D VQA\", \"topic\": \"Multimodal Language Models\", \"x\": 8.246, \"y\": 7.977}, {\"title\": \"PRP: Propagating Universal Perturbations to Attack Large Language Model  Guard-Rails\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.312, \"y\": 2.532}, {\"title\": \"MATHWELL: Generating Age-Appropriate Educational Math Word Problems\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.053, \"y\": 2.82}, {\"title\": \"Prompt Perturbation Consistency Learning for Robust Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.562, \"y\": 3.122}, {\"title\": \"IPED: An Implicit Perspective for Relational Triple Extraction based on  Diffusion Model\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.008, \"y\": 6.739}, {\"title\": \"Linguistic Intelligence in Large Language Models for Telecommunications\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.515, \"y\": 4.017}, {\"title\": \"Measuring Bargaining Abilities of LLMs: A Benchmark and A  Buyer-Enhancement Method\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.209, \"y\": 3.026}, {\"title\": \"Empowering Large Language Model Agents through Action Learning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.877, \"y\": 2.308}, {\"title\": \"Enhanced User Interaction in Operating Systems through Machine Learning  Language Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.931, \"y\": 2.952}, {\"title\": \"Look Before You Leap: Problem Elaboration Prompting Improves  Mathematical Reasoning in Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.911, \"y\": 2.747}, {\"title\": \"Stepwise Self-Consistent Mathematical Reasoning with Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.759, \"y\": 2.377}, {\"title\": \"Dental Severity Assessment through Few-shot Learning and SBERT  Fine-tuning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.95, \"y\": 8.335}, {\"title\": \"Sparse MeZO: Less Parameters for Better Performance in Zeroth-Order LLM  Fine-Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.209, \"y\": 2.232}, {\"title\": \"GAOKAO-MM: A Chinese Human-Level Benchmark for Multimodal Models  Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 7.99, \"y\": 7.616}, {\"title\": \"How Do Humans Write Code? Large Models Do It the Same Way Too\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.814, \"y\": 2.365}, {\"title\": \"Hal-Eval: A Universal and Fine-grained Hallucination Evaluation  Framework for Large Vision Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.196, \"y\": 1.029}, {\"title\": \"CoRelation: Boosting Automatic ICD Coding Through Contextualized Code  Relation Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.951, \"y\": 8.486}, {\"title\": \"Foot In The Door: Understanding Large Language Model Jailbreaking via  Cognitive Psychology\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.259, \"y\": 2.191}, {\"title\": \"Leveraging ChatGPT in Pharmacovigilance Event Extraction: An Empirical  Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.675, \"y\": 7.752}, {\"title\": \"Exploring Failure Cases in Multimodal Reasoning About Physical Dynamics\", \"topic\": \"Multimodal Language Models\", \"x\": 8.202, \"y\": 7.594}, {\"title\": \"Addressing Order Sensitivity of In-Context Demonstration Examples in  Causal Language Models\", \"topic\": \"In-Context Learning\", \"x\": 8.165, \"y\": 3.284}, {\"title\": \"Fine-Grained Self-Endorsement Improves Factuality and Reasoning\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.673, \"y\": 1.708}, {\"title\": \"Language-Based User Profiles for Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.928, \"y\": 2.92}, {\"title\": \"Selective \\\"Selective Prediction\\\": Reducing Unnecessary Abstention in  Vision-Language Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.379, \"y\": 7.781}, {\"title\": \"Alternating Weak Triphone/BPE Alignment Supervision from Hybrid Model  Improves End-to-End ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.288, \"y\": 5.22}, {\"title\": \"CI w/o TN: Context Injection without Task Name for Procedure Planning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.951, \"y\": 7.503}, {\"title\": \"Social Convos: Capturing Agendas and Emotions on Social Media\", \"topic\": \"Fake News Detection\", \"x\": 3.639, \"y\": 5.911}, {\"title\": \"AgentOhana: Design Unified Data and Training Pipeline for Effective  Agent Learning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.681, \"y\": 2.418}, {\"title\": \"Self-Retrieval: Building an Information Retrieval System with One Large  Language Model\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.261, \"y\": 4.552}, {\"title\": \"API-BLEND: A Comprehensive Corpora for Training and Benchmarking API  LLMs\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.865, \"y\": 2.899}, {\"title\": \"Prejudice and Volatility: A Statistical Framework for Measuring Social  Discrimination in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.401, \"y\": 4.37}, {\"title\": \"Leveraging Domain Knowledge for Efficient Reward Modelling in RLHF: A  Case-Study in E-Commerce Opinion Summarization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.19, \"y\": 1.458}, {\"title\": \"Brain-Inspired Two-Stage Approach: Enhancing Mathematical Reasoning by  Imitating Human Thought Processes\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.837, \"y\": 2.696}, {\"title\": \"An Empirical Study of Data Ability Boundary in LLMs' Math Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.088, \"y\": 2.7}, {\"title\": \"A Data-Centric Approach To Generate Faithful and High Quality Patient  Summaries with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.554, \"y\": 7.892}, {\"title\": \"PREDILECT: Preferences Delineated with Zero-Shot Language-based  Reasoning in Reinforcement Learning\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.021, \"y\": 1.694}, {\"title\": \"Faithful Temporal Question Answering over Heterogeneous Sources\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.384, \"y\": 5.353}, {\"title\": \"Dual Encoder: Exploiting the Potential of Syntactic and Semantic for  Aspect Sentiment Triplet Extraction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.088, \"y\": 6.834}, {\"title\": \"NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data\", \"topic\": \"Named Entity Recognition\", \"x\": 7.326, \"y\": 6.774}, {\"title\": \"GPTVQ: The Blessing of Dimensionality for LLM Quantization\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.797, \"y\": 2.16}, {\"title\": \"Seeing is Believing: Mitigating Hallucination in Large Vision-Language  Models via CLIP-Guided Decoding\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.304, \"y\": 1.035}, {\"title\": \"Let's Rectify Step by Step: Improving Aspect-based Sentiment Analysis  with Diffusion Models\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.055, \"y\": 6.808}, {\"title\": \"Chitchat as Interference: Adding User Backstories to Task-Oriented  Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.29, \"y\": 3.668}, {\"title\": \"GPT-HateCheck: Can LLMs Write Better Functional Tests for Hate Speech  Detection?\", \"topic\": \"Hate Speech Detection\", \"x\": 2.813, \"y\": 5.268}, {\"title\": \"BSPA: Exploring Black-box Stealthy Prompt Attacks against Image  Generators\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.359, \"y\": 2.718}, {\"title\": \"DeMPT: Decoding-enhanced Multi-phase Prompt Tuning for Making LLMs Be  Better Context-aware Translators\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.855, \"y\": 3.358}, {\"title\": \"Biomedical Entity Linking as Multiple Choice Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.429, \"y\": 7.41}, {\"title\": \"Break the Breakout: Reinventing LM Defense Against Jailbreak Attacks  with Self-Refinement\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.331, \"y\": 2.265}, {\"title\": \"Advancing Parameter Efficiency in Fine-tuning via Representation Editing\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.015, \"y\": 2.331}, {\"title\": \"Interactive-KBQA: Multi-Turn Interactions for Knowledge Base Question  Answering with Large Language Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.702, \"y\": 5.378}, {\"title\": \"Evaluating the Performance of ChatGPT for Spam Email Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.115, \"y\": 4.884}, {\"title\": \"Interpreting Context Look-ups in Transformers: Investigating  Attention-MLP Interactions\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.401, \"y\": 3.441}, {\"title\": \"CARBD-Ko: A Contextually Annotated Review Benchmark Dataset for  Aspect-Level Sentiment Classification in Korean\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.13, \"y\": 6.817}, {\"title\": \"CLoVe: Encoding Compositional Language in Contrastive Vision-Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.909, \"y\": 7.246}, {\"title\": \"Unintended Impacts of LLM Alignment on Global Representation\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.092, \"y\": 1.58}, {\"title\": \"CommVQA: Situating Visual Question Answering in Communicative Contexts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.15, \"y\": 7.985}, {\"title\": \"Divide-or-Conquer? Which Part Should You Distill Your LLM?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.936, \"y\": 2.46}, {\"title\": \"Optimizing Language Models for Human Preferences is a Causal Inference  Problem\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.316, \"y\": 1.349}, {\"title\": \"Introducing GenCeption for Multimodal LLM Benchmarking: You May Bypass  Annotations\", \"topic\": \"Multimodal Language Models\", \"x\": 7.946, \"y\": 7.567}, {\"title\": \"Re-Examine Distantly Supervised NER: A New Benchmark and a Simple  Approach\", \"topic\": \"Named Entity Recognition\", \"x\": 7.399, \"y\": 6.747}, {\"title\": \"PALO: A Polyglot Large Multimodal Model for 5B People\", \"topic\": \"Multimodal Language Models\", \"x\": 8.295, \"y\": 7.592}, {\"title\": \"Measuring Multimodal Mathematical Reasoning with MATH-Vision Dataset\", \"topic\": \"Multimodal Language Models\", \"x\": 8.0, \"y\": 7.662}, {\"title\": \"Zero-shot cross-lingual transfer in instruction tuning of large language  models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.249, \"y\": 4.446}, {\"title\": \"Generalizing Reward Modeling for Out-of-Distribution Preference Learning\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.298, \"y\": 1.291}, {\"title\": \"Large Language Models as Urban Residents: An LLM Agent Framework for  Personal Mobility Generation\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.679, \"y\": 2.915}, {\"title\": \"Chain-of-Thought Unfaithfulness as Disguised Accuracy\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.617, \"y\": 2.384}, {\"title\": \"Efficient and Effective Vocabulary Expansion Towards Multilingual Large  Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.084, \"y\": 4.176}, {\"title\": \"Middleware for LLMs: Tools Are Instrumental for Language Agents in  Complex Environments\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.814, \"y\": 2.64}, {\"title\": \"ConceptMath: A Bilingual Concept-wise Benchmark for Measuring  Mathematical Reasoning of Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.985, \"y\": 3.065}, {\"title\": \"OpenCodeInterpreter: Integrating Code Generation with Execution and  Refinement\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.534, \"y\": 2.35}, {\"title\": \"LLM-DA: Data Augmentation via Large Language Models for Few-Shot Named  Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.408, \"y\": 6.689}, {\"title\": \"SIMPLOT: Enhancing Chart Question Answering by Distilling Essentials\", \"topic\": \"Multimodal Language Models\", \"x\": 7.901, \"y\": 7.857}, {\"title\": \"Less is More: Mitigating Multimodal Hallucination from an EOS Decision  Perspective\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.283, \"y\": 1.03}, {\"title\": \"Daisy-TTS: Simulating Wider Spectrum of Emotions via Prosody Embedding  Decomposition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.278, \"y\": 7.85}, {\"title\": \"Malaysian English News Decoded: A Linguistic Resource for Named Entity  and Relation Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 7.34, \"y\": 6.849}, {\"title\": \"LLMBind: A Unified Modality-Task Integration Framework\", \"topic\": \"Multimodal Language Models\", \"x\": 8.189, \"y\": 7.253}, {\"title\": \"Does the Generator Mind its Contexts? An Analysis of Generative Model  Faithfulness under Context Transfer\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.218, \"y\": 1.043}, {\"title\": \"Annotation and Classification of Relevant Clauses in  Terms-and-Conditions Contracts\", \"topic\": \"Legal NLP\", \"x\": 5.174, \"y\": 5.672}, {\"title\": \"COBIAS: Contextual Reliability in Bias Assessment\", \"topic\": \"Bias in Language Models\", \"x\": 3.39, \"y\": 4.339}, {\"title\": \"A Language Model's Guide Through Latent Space\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.861, \"y\": 3.355}, {\"title\": \"Is ChatGPT More Empathetic than Humans?\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.706, \"y\": 7.832}, {\"title\": \"Transferring BERT Capabilities from High-Resource to Low-Resource  Languages Using Vocabulary Matching\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.267, \"y\": 4.513}, {\"title\": \"Efficient data selection employing Semantic Similarity-based Graph  Structures for model training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.214, \"y\": 5.359}, {\"title\": \"Small Language Model Is a Good Guide for Large Language Model in Chinese  Entity Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.055, \"y\": 6.595}, {\"title\": \"Rethinking Scientific Summarization Evaluation: Grounding Explainable  Metrics on Facet-aware Benchmark\", \"topic\": \"Text Summarization\", \"x\": 5.613, \"y\": 6.111}, {\"title\": \"Understanding and Patching Compositional Reasoning in LLMs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.703, \"y\": 2.559}, {\"title\": \"Subobject-level Image Tokenization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.723, \"y\": 7.229}, {\"title\": \"Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve  Knowledge Base Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.653, \"y\": 5.399}, {\"title\": \"Assessing generalization capability of text ranking models in Polish\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.187, \"y\": 4.581}, {\"title\": \"Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize  Encoded Knowledge\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.74, \"y\": 2.643}, {\"title\": \"TinyLLaVA: A Framework of Small-scale Large Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.232, \"y\": 7.447}, {\"title\": \"Mitigating the Linguistic Gap with Phonemic Representations for Robust  Multilingual Language Understanding\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.169, \"y\": 4.841}, {\"title\": \"GATE X-E : A Challenge Set for Gender-Fair Translations from  Weakly-Gendered Languages\", \"topic\": \"Bias in Language Models\", \"x\": 3.028, \"y\": 4.359}, {\"title\": \"Qsnail: A Questionnaire Dataset for Sequential Question Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.145, \"y\": 5.037}, {\"title\": \"LLM-Assisted Content Conditional Debiasing for Fair Text Embedding\", \"topic\": \"Bias in Language Models\", \"x\": 3.291, \"y\": 4.267}, {\"title\": \"Bangla AI: A Framework for Machine Translation Utilizing Large Language  Models for Ethnic Media\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.45, \"y\": 4.688}, {\"title\": \"Combining Language and Graph Models for Semi-structured Information  Extraction on the Web\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.876, \"y\": 6.72}, {\"title\": \"LexC-Gen: Generating Data for Extremely Low-Resource Languages with  Large Language Models and Bilingual Lexicons\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.539, \"y\": 4.689}, {\"title\": \"Improving Language Understanding from Screenshots\", \"topic\": \"Multimodal Language Models\", \"x\": 8.908, \"y\": 7.195}, {\"title\": \"Hallucinations or Attention Misdirection? The Path to Strategic Value  Extraction in Business Using Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.036, \"y\": 0.979}, {\"title\": \"What's in a Name? Auditing Large Language Models for Race and Gender  Bias\", \"topic\": \"Bias in Language Models\", \"x\": 3.529, \"y\": 4.341}, {\"title\": \"Towards Building Multilingual Language Model for Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.08, \"y\": 7.92}, {\"title\": \"Measuring Social Biases in Masked Language Models by Proxy of Prediction  Quality\", \"topic\": \"Bias in Language Models\", \"x\": 3.312, \"y\": 4.444}, {\"title\": \"Making Reasoning Matter: Measuring and Improving Faithfulness of  Chain-of-Thought Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.659, \"y\": 2.467}, {\"title\": \"Technical Report on the Checkfor.ai AI-Generated Text Classifier\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.139, \"y\": 4.911}, {\"title\": \"Distinctive Image Captioning: Leveraging Ground Truth Captions in CLIP  Guided Reinforcement Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.024, \"y\": 7.459}, {\"title\": \"Do Efficient Transformers Really Save Computation?\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.442, \"y\": 3.296}, {\"title\": \"Exploring ChatGPT and its Impact on Society\", \"topic\": \"Bias in Language Models\", \"x\": 4.857, \"y\": 4.42}, {\"title\": \"SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in  Clinical Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.51, \"y\": 7.785}, {\"title\": \"Could We Have Had Better Multilingual LLMs If English Was Not the  Central Language?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.266, \"y\": 4.433}, {\"title\": \"$Se^2$: Sequential Example Selection for In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.144, \"y\": 3.318}, {\"title\": \"Kuaiji: the First Chinese Accounting Large Language Model\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.945, \"y\": 6.803}, {\"title\": \"Beyond Hate Speech: NLP's Challenges and Opportunities in Uncovering  Dehumanizing Language\", \"topic\": \"Hate Speech Detection\", \"x\": 2.716, \"y\": 5.324}, {\"title\": \"The Geography of Information Diffusion in Online Discourse on Europe and  Migration\", \"topic\": \"Fake News Detection\", \"x\": 3.771, \"y\": 5.902}, {\"title\": \"Breaking the Barrier: Utilizing Large Language Models for Industrial  Recommendation Systems through an Inferential Knowledge Graph\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.924, \"y\": 2.95}, {\"title\": \"Exploiting Adaptive Contextual Masking for Aspect-Based Sentiment  Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.065, \"y\": 6.835}, {\"title\": \"Investigating Multilingual Instruction-Tuning: Do Polyglot Models Demand  for Multilingual Instructions?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.219, \"y\": 4.271}, {\"title\": \"A Unified Framework and Dataset for Assessing Societal Bias in  Vision-Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.236, \"y\": 4.434}, {\"title\": \"MORE: Multi-mOdal REtrieval Augmented Generative Commonsense Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.132, \"y\": 7.526}, {\"title\": \"Overview of the VLSP 2023 -- ComOM Shared Task: A Data Challenge for  Comparative Opinion Mining from Vietnamese Product Reviews\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.608, \"y\": 6.538}, {\"title\": \"CODIS: Benchmarking Context-Dependent Visual Comprehension for  Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.172, \"y\": 7.572}, {\"title\": \"APTQ: Attention-aware Post-Training Mixed-Precision Quantization for  Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.759, \"y\": 2.114}, {\"title\": \"A Multimodal In-Context Tuning Approach for E-Commerce Product  Description Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.221, \"y\": 7.051}, {\"title\": \"WinoViz: Probing Visual Properties of Objects Under Different States\", \"topic\": \"Multimodal Language Models\", \"x\": 8.311, \"y\": 7.753}, {\"title\": \"BBA: Bi-Modal Behavioral Alignment for Reasoning with Large  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.115, \"y\": 7.767}, {\"title\": \"PCA-Bench: Evaluating Multimodal Large Language Models in  Perception-Cognition-Action Chain\", \"topic\": \"Multimodal Language Models\", \"x\": 8.027, \"y\": 7.575}, {\"title\": \"Analysis of Multi-Source Language Training in Cross-Lingual Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.349, \"y\": 4.745}, {\"title\": \"Cognitive Visual-Language Mapper: Advancing Multimodal Comprehension  with Enhanced Visual Knowledge Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.312, \"y\": 7.644}, {\"title\": \"ActiveRAG: Revealing the Treasures of Knowledge via Active Learning\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.163, \"y\": 4.557}, {\"title\": \"LLMs Meet Long Video: Advancing Long Video Comprehension with An  Interactive Visual Adapter in LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.813, \"y\": 7.946}, {\"title\": \"ARL2: Aligning Retrievers for Black-box Large Language Models via  Self-guided Adaptive Relevance Labeling\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.27, \"y\": 4.483}, {\"title\": \"Infrastructure Ombudsman: Mining Future Failure Concerns from Structural  Disaster Response\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.219, \"y\": 6.488}, {\"title\": \"RecMind: Japanese Movie Recommendation Dialogue with Seeker's Internal  State\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.92, \"y\": 2.96}, {\"title\": \"Round Trip Translation Defence against Large Language Model Jailbreaking  Attacks\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.254, \"y\": 2.27}, {\"title\": \"ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity  within Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.497, \"y\": 2.451}, {\"title\": \"From Self-Attention to Markov Models: Unveiling the Dynamics of  Generative Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.517, \"y\": 3.434}, {\"title\": \"Evaluation of a semi-autonomous attentive listening system with takeover  prompting\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.02, \"y\": 3.762}, {\"title\": \"GradSafe: Detecting Jailbreak Prompts for LLMs via Safety-Critical  Gradient Analysis\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.29, \"y\": 2.282}, {\"title\": \"How Important is Domain Specificity in Language Models and Instruction  Finetuning for Biomedical Relation Extraction?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.233, \"y\": 7.857}, {\"title\": \"LocalTweets to LocalHealth: A Mental Health Surveillance Framework Based  on Twitter Data\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.167, \"y\": 7.264}, {\"title\": \"ED-Copilot: Reduce Emergency Department Wait Time with Language Model  Diagnostic Assistance\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.701, \"y\": 8.299}, {\"title\": \"DrBenchmark: A Large Language Understanding Evaluation Benchmark for  French Biomedical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.117, \"y\": 7.821}, {\"title\": \"Healthcare Copilot: Eliciting the Power of General LLMs for Medical  Consultation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.425, \"y\": 8.143}, {\"title\": \"Reliable LLM-based User Simulator for Task-Oriented Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.401, \"y\": 3.642}, {\"title\": \"Enhanced Hallucination Detection in Neural Machine Translation through  Simple Detector Aggregation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.174, \"y\": 1.038}, {\"title\": \"CounterCurate: Enhancing Physical and Semantic Visio-Linguistic  Compositional Reasoning via Counterfactual Examples\", \"topic\": \"Multimodal Language Models\", \"x\": 8.24, \"y\": 7.981}, {\"title\": \"BiMediX: Bilingual Medical Mixture of Experts LLM\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.977, \"y\": 8.053}, {\"title\": \"TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue  Summarization\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.141, \"y\": 1.37}, {\"title\": \"Exploring the Frontier of Vision-Language Models: A Survey of Current  Methodologies and Future Directions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.291, \"y\": 7.535}, {\"title\": \"Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.362, \"y\": 1.183}, {\"title\": \"AgentMD: Empowering Language Agents for Risk Prediction with Large-Scale  Clinical Tool Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.566, \"y\": 8.221}, {\"title\": \"RoCode: A Dataset for Measuring Code Intelligence from Problem  Definitions in Romanian\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.499, \"y\": 2.479}, {\"title\": \"Can Large Language Models be Good Emotional Supporter? Mitigating  Preference Bias on Emotional Support Conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.554, \"y\": 7.791}, {\"title\": \"How do Hyenas deal with Human Speech? Speech Recognition and Translation  with ConfHyena\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.101, \"y\": 4.717}, {\"title\": \"Question Calibration and Multi-Hop Modeling for Temporal Question  Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.601, \"y\": 5.448}, {\"title\": \"Benchmarking Retrieval-Augmented Generation for Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.038, \"y\": 7.392}, {\"title\": \"Is the System Message Really Important to Jailbreaks in Large Language  Models?\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.301, \"y\": 2.251}, {\"title\": \"AnnoTheia: A Semi-Automatic Annotation Toolkit for Audio-Visual Speech  Technologies\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.649, \"y\": 5.617}, {\"title\": \"A Survey on Knowledge Distillation of Large Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.524, \"y\": 3.772}, {\"title\": \"When Only Time Will Tell: Interpreting How Transformers Process Local  Ambiguities Through the Lens of Restart-Incrementality\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.279, \"y\": 3.515}, {\"title\": \"Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for  Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.146, \"y\": 2.238}, {\"title\": \"Effective and Efficient Conversation Retrieval for Dialogue State  Tracking with Implicit Text Summaries\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.671, \"y\": 4.132}, {\"title\": \"SiLLM: Large Language Models for Simultaneous Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.971, \"y\": 4.602}, {\"title\": \"Learning to Check: Unleashing Potentials for Self-Correction in Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.66, \"y\": 2.332}, {\"title\": \"SoMeLVLM: A Large Vision Language Model for Social Media Processing\", \"topic\": \"Multimodal Language Models\", \"x\": 8.034, \"y\": 7.547}, {\"title\": \"Understanding the effects of language-specific class imbalance in  multilingual fine-tuning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.448, \"y\": 4.288}, {\"title\": \"Code Needs Comments: Enhancing Code LLMs with Comment Augmentation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.54, \"y\": 2.395}, {\"title\": \"Towards Trustworthy Reranking: A Simple yet Effective Abstention  Mechanism\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.615, \"y\": 4.901}, {\"title\": \"TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box  Identification\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.382, \"y\": 2.579}, {\"title\": \"Comparing Inferential Strategies of Humans and Large Language Models in  Deductive Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.428, \"y\": 3.132}, {\"title\": \"The Impact of Demonstrations on Multilingual In-Context Learning: A  Multidimensional Analysis\", \"topic\": \"In-Context Learning\", \"x\": 8.283, \"y\": 3.446}, {\"title\": \"Gl\\u00f3rIA -- A Generative and Open Large Language Model for Portuguese\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.92, \"y\": 4.388}, {\"title\": \"Prompt Stealing Attacks Against Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.426, \"y\": 2.607}, {\"title\": \"Large Language Model-based Human-Agent Collaboration for Complex Task  Solving\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.429, \"y\": 2.78}, {\"title\": \"OPDAI at SemEval-2024 Task 6: Small LLMs can Accelerate Hallucination  Detection with Weakly Supervised Data\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.149, \"y\": 1.051}, {\"title\": \"GRAFFORD: A Benchmark Dataset for Testing the Knowledge of Object  Affordances of Language and Vision Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.596, \"y\": 7.445}, {\"title\": \"Backward Lens: Projecting Language Model Gradients into the Vocabulary  Space\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.271, \"y\": 3.56}, {\"title\": \"Handling Ambiguity in Emotion: From Out-of-Domain Detection to  Distribution Estimation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.411, \"y\": 7.498}, {\"title\": \"Instruction-tuned Language Models are Better Knowledge Learners\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.132, \"y\": 2.446}, {\"title\": \"ICON: Improving Inter-Report Consistency of Radiology Report Generation  via Lesion-aware Mix-up Augmentation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.237, \"y\": 8.651}, {\"title\": \"PromptKD: Distilling Student-Friendly Knowledge for Generative Language  Models via Prompt Tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.776, \"y\": 3.302}, {\"title\": \"SymBa: Symbolic Backward Chaining for Multi-step Natural Language  Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.674, \"y\": 2.67}, {\"title\": \"Few shot clinical entity recognition in three languages: Masked language  models outperform LLM prompting\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.195, \"y\": 7.859}, {\"title\": \"Acknowledgment of Emotional States: Generating Validating Responses for  Empathetic Dialogue\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.691, \"y\": 7.856}, {\"title\": \"Model Composition for Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.16, \"y\": 7.25}, {\"title\": \"Me LLaMA: Foundation Large Language Models for Medical Applications\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.903, \"y\": 8.093}, {\"title\": \"Modality-Aware Integration with Large Language Models for  Knowledge-based Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.111, \"y\": 7.718}, {\"title\": \"PRECISE Framework: GPT-based Text For Improved Readability, Reliability,  and Understandability of Radiology Reports For Patient-Centered Care\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.208, \"y\": 8.607}, {\"title\": \"Are LLMs Rational Investors? A Study on Detecting and Reducing the  Financial Bias in LLMs\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.803, \"y\": 6.834}, {\"title\": \"HumanEval on Latest GPT Models -- 2024\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.447, \"y\": 2.497}, {\"title\": \"FormulaReasoning: A Dataset for Formula-Based Numerical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.026, \"y\": 2.733}, {\"title\": \"Simpson's Paradox and the Accuracy-Fluency Tradeoff in Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.757, \"y\": 4.767}, {\"title\": \"FinBen: A Holistic Financial Benchmark for Large Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.904, \"y\": 6.854}, {\"title\": \"OWSM-CTC: An Open Encoder-Only Speech Foundation Model for Speech  Recognition, Translation, and Language Identification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.96, \"y\": 5.184}, {\"title\": \"Bias in Language Models: Beyond Trick Tests and Toward RUTEd Evaluation\", \"topic\": \"Bias in Language Models\", \"x\": 3.288, \"y\": 4.392}, {\"title\": \"StyleDubber: Towards Multi-Scale Style Learning for Movie Dubbing\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.472, \"y\": 6.221}, {\"title\": \"Multimodal Fusion of EHR in Structures and Semantics: Integrating  Clinical Records and Notes with Hypergraph and LLM\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.927, \"y\": 8.289}, {\"title\": \"Detecting misinformation through Framing Theory: the Frame Element-based  Model\", \"topic\": \"Fake News Detection\", \"x\": 4.105, \"y\": 5.9}, {\"title\": \"Archer: A Human-Labeled Text-to-SQL Dataset with Arithmetic, Commonsense  and Hypothetical Reasoning\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.677, \"y\": 5.387}, {\"title\": \"Parallel Structures in Pre-training Data Yield In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.537, \"y\": 3.362}, {\"title\": \"Your Vision-Language Model Itself Is a Strong Filter: Towards  High-Quality Instruction Tuning with Data Selection\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.269, \"y\": 2.399}, {\"title\": \"Asynchronous and Segmented Bidirectional Encoding for NMT\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.943, \"y\": 4.314}, {\"title\": \"The Revolution of Multimodal Large Language Models: A Survey\", \"topic\": \"Multimodal Language Models\", \"x\": 8.156, \"y\": 7.375}, {\"title\": \"HunFlair2 in a cross-corpus evaluation of biomedical named entity  recognition and normalization tools\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.383, \"y\": 7.383}, {\"title\": \"A Critical Evaluation of AI Feedback for Aligning Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.159, \"y\": 1.739}, {\"title\": \"LoRA+: Efficient Low Rank Adaptation of Large Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.228, \"y\": 2.057}, {\"title\": \"Graph-Based Retriever Captures the Long Tail of Biomedical Knowledge\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.203, \"y\": 7.329}, {\"title\": \"Triple-Encoders: Representations That Fire Together, Wire Together\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.204, \"y\": 7.845}, {\"title\": \"Shall We Team Up: Exploring Spontaneous Cooperation of Competing LLM  Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.309, \"y\": 2.906}, {\"title\": \"ARKS: Active Retrieval in Knowledge Soup for Code Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.186, \"y\": 4.508}, {\"title\": \"Is Open-Source There Yet? A Comparative Study on Commercial and  Open-Source LLMs in Their Ability to Label Chest X-Ray Reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.161, \"y\": 8.569}, {\"title\": \"Key ingredients for effective zero-shot cross-lingual knowledge transfer  in generative tasks\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.468, \"y\": 4.697}, {\"title\": \"WorldCoder, a Model-Based LLM Agent: Building World Models by Writing  Code and Interacting with the Environment\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.821, \"y\": 2.505}, {\"title\": \"High-quality Data-to-Text Generation for Severely Under-Resourced  Languages with Out-of-the-box Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.083, \"y\": 4.225}, {\"title\": \"On the Semantic Latent Space of Diffusion-Based Text-to-Speech Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.378, \"y\": 6.014}, {\"title\": \"Analysis of Levenshtein Transformer's Decoder and Its Variants\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.77, \"y\": 4.37}, {\"title\": \"Task-Oriented Dialogue with In-Context Learning\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.527, \"y\": 3.674}, {\"title\": \"Empirical Study on Updating Key-Value Memories in Transformer  Feed-forward Layers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.625, \"y\": 3.149}, {\"title\": \"AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling\", \"topic\": \"Multimodal Language Models\", \"x\": 8.336, \"y\": 7.199}, {\"title\": \"Enhancing Multilingual Capabilities of Large Language Models through  Self-Distillation from Resource-Rich Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.495, \"y\": 4.519}, {\"title\": \"Zero shot VLMs for hate meme detection: Are we there yet?\", \"topic\": \"Hate Speech Detection\", \"x\": 2.772, \"y\": 5.523}, {\"title\": \"Browse and Concentrate: Comprehending Multimodal Content via prior-LLM  Context Fusion\", \"topic\": \"Multimodal Language Models\", \"x\": 8.308, \"y\": 7.334}, {\"title\": \"Your Large Language Model is Secretly a Fairness Proponent and You  Should Prompt it Like One\", \"topic\": \"Bias in Language Models\", \"x\": 3.47, \"y\": 4.174}, {\"title\": \"Evaluating Image Review Ability of Vision Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.482, \"y\": 7.464}, {\"title\": \"Is It a Free Lunch for Removing Outliers during Pretraining?\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.702, \"y\": 2.22}, {\"title\": \"Do Large Language Models Understand Logic or Just Mimick Context?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.82, \"y\": 3.332}, {\"title\": \"Can LLMs Compute with Reasons?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.697, \"y\": 2.853}, {\"title\": \"LVCHAT: Facilitating Long Video Comprehension\", \"topic\": \"Multimodal Language Models\", \"x\": 8.854, \"y\": 7.935}, {\"title\": \"EmoBench: Evaluating the Emotional Intelligence of Large Language Models\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.485, \"y\": 7.671}, {\"title\": \"WKVQuant: Quantizing Weight and Key/Value Cache for Large Language  Models Gains More\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.77, \"y\": 2.211}, {\"title\": \"Scaffolding Coordinates to Promote Vision-Language Coordination in Large  Multi-Modal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.303, \"y\": 7.622}, {\"title\": \"Towards Cross-Tokenizer Distillation: the Universal Logit Distillation  Loss for LLMs\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.502, \"y\": 3.785}, {\"title\": \"Speech Translation with Speech Foundation Models and Large Language  Models: What is There and What is Missing?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.256, \"y\": 5.096}, {\"title\": \"What Do Dialect Speakers Want? A Survey of Attitudes Towards Language  Technology for German Dialects\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.171, \"y\": 5.151}, {\"title\": \"Analysis of Multidomain Abstractive Summarization Using Salience  Allocation\", \"topic\": \"Text Summarization\", \"x\": 5.51, \"y\": 6.408}, {\"title\": \"LEMMA: Towards LVLM-Enhanced Multimodal Misinformation Detection with  External Knowledge Augmentation\", \"topic\": \"Fake News Detection\", \"x\": 4.144, \"y\": 5.839}, {\"title\": \"Semantic Textual Similarity Assessment in Chest X-ray Reports Using a  Domain-Specific Cosine-Based Metric\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.264, \"y\": 8.535}, {\"title\": \"Direct Large Language Model Alignment Through Self-Rewarding Contrastive  Prompt Distillation\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.397, \"y\": 1.315}, {\"title\": \"DiLA: Enhancing LLM Tool Learning with Differential Logic Layer\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.72, \"y\": 2.843}, {\"title\": \"SIBO: A Simple Booster for Parameter-Efficient Fine-Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.971, \"y\": 2.296}, {\"title\": \"FeB4RAG: Evaluating Federated Search in the Context of Retrieval  Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.017, \"y\": 4.724}, {\"title\": \"Revisiting Knowledge Distillation for Autoregressive Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.496, \"y\": 3.812}, {\"title\": \"RJUA-MedDQA: A Multimodal Benchmark for Medical Document Question  Answering and Clinical Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.018, \"y\": 7.926}, {\"title\": \"M2K-VDG: Model-Adaptive Multimodal Knowledge Anchor Enhanced  Video-grounded Dialogue Generation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.37, \"y\": 1.226}, {\"title\": \"Modularized Networks for Few-shot Hateful Meme Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.82, \"y\": 5.526}, {\"title\": \"FIPO: Free-form Instruction-oriented Prompt Optimization with Preference  Dataset and Modular Fine-tuning Schema\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.437, \"y\": 3.237}, {\"title\": \"Unveiling the Magic: Investigating Attention Distillation in  Retrieval-augmented Generation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.475, \"y\": 3.762}, {\"title\": \"Structured Chain-of-Thought Prompting for Few-Shot Generation of  Content-Grounded QA Conversations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.688, \"y\": 2.557}, {\"title\": \"ChatGPT Based Data Augmentation for Improved Parameter-Efficient  Debiasing of LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.499, \"y\": 4.067}, {\"title\": \"SPML: A DSL for Defending Language Models Against Prompt Attacks\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.482, \"y\": 2.698}, {\"title\": \"ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.268, \"y\": 2.298}, {\"title\": \"RFBES at SemEval-2024 Task 8: Investigating Syntactic and Semantic  Features for Distinguishing AI-Generated and Human-Written Texts\", \"topic\": \"AI-Generated Text Detection\", \"x\": 3.998, \"y\": 4.975}, {\"title\": \"In-Context Learning Demonstration Selection via Influence Analysis\", \"topic\": \"In-Context Learning\", \"x\": 8.274, \"y\": 3.382}, {\"title\": \"Machine-Generated Text Localization\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.141, \"y\": 4.814}, {\"title\": \"Utilizing BERT for Information Retrieval: Survey, Applications,  Resources, and Challenges\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.383, \"y\": 4.816}, {\"title\": \"An Empirical Categorization of Prompting Techniques for Large Language  Models: A Practitioner's Guide\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.159, \"y\": 3.228}, {\"title\": \"Numerical Claim Detection in Finance: A New Financial Dataset,  Weak-Supervision Model, and Market Analysis\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.81, \"y\": 6.749}, {\"title\": \"Modelling Political Coalition Negotiations Using LLM-based Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.109, \"y\": 3.129}, {\"title\": \"A Note on Bias to Complete\", \"topic\": \"Bias in Language Models\", \"x\": 3.41, \"y\": 4.469}, {\"title\": \"GNNavi: Navigating the Information Flow in Large Language Models by  Graph Neural Network\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.812, \"y\": 3.171}, {\"title\": \"Vision-Flan: Scaling Human-Labeled Tasks in Visual Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.386, \"y\": 7.409}, {\"title\": \"ALLaVA: Harnessing GPT4V-Synthesized Data for Lite Vision-Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.409, \"y\": 7.555}, {\"title\": \"A Multi-Aspect Framework for Counter Narrative Evaluation using Large  Language Models\", \"topic\": \"Hate Speech Detection\", \"x\": 2.754, \"y\": 5.286}, {\"title\": \"Self-seeding and Multi-intent Self-instructing LLMs for Generating  Intent-aware Information-Seeking dialogs\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.859, \"y\": 4.011}, {\"title\": \"Logical Closed Loop: Uncovering Object Hallucinations in Large  Vision-Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.291, \"y\": 1.011}, {\"title\": \"Decoding News Narratives: A Critical Analysis of Large Language Models  in Framing Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.128, \"y\": 5.907}, {\"title\": \"Revisiting Zeroth-Order Optimization for Memory-Efficient LLM  Fine-Tuning: A Benchmark\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.07, \"y\": 2.376}, {\"title\": \"BESA: Pruning Large Language Models with Blockwise Parameter-Efficient  Sparsity Allocation\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.541, \"y\": 2.423}, {\"title\": \"Visual In-Context Learning for Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.407, \"y\": 7.378}, {\"title\": \"Cobra Effect in Reference-Free Image Captioning Metrics\", \"topic\": \"Multimodal Language Models\", \"x\": 8.939, \"y\": 7.453}, {\"title\": \"LongAgent: Scaling Language Models to 128k Context through Multi-Agent  Collaboration\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.627, \"y\": 2.756}, {\"title\": \"Question Answering Over Spatio-Temporal Knowledge Graph\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.605, \"y\": 5.467}, {\"title\": \"Ploutos: Towards interpretable stock movement prediction with financial  large language model\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.751, \"y\": 6.837}, {\"title\": \"PreAct: Predicting Future in ReAct Enhances Agent's Planning Ability\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.764, \"y\": 2.612}, {\"title\": \"Chain-of-Instructions: Compositional Instruction Tuning on Large  Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.116, \"y\": 2.358}, {\"title\": \"Advancing Translation Preference Modeling with RLHF: A Step Towards  Cost-Effective Solution\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.246, \"y\": 1.463}, {\"title\": \"Unveiling the Secrets of Engaging Conversations: Factors that Keep Users  Hooked on Role-Playing Dialog Agents\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.046, \"y\": 3.611}, {\"title\": \"From Prejudice to Parity: A New Approach to Debiasing Large Language  Model Word Embeddings\", \"topic\": \"Bias in Language Models\", \"x\": 3.221, \"y\": 4.337}, {\"title\": \"ChatGPT in Linear Algebra: Strides Forward, Steps to Go\", \"topic\": \"Bias in Language Models\", \"x\": 5.228, \"y\": 4.432}, {\"title\": \"LEIA: Facilitating Cross-lingual Knowledge Transfer in Language Models  with Entity-based Data Augmentation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.212, \"y\": 4.583}, {\"title\": \"MIKE: A New Benchmark for Fine-grained Multimodal Entity Knowledge  Editing\", \"topic\": \"Multimodal Language Models\", \"x\": 8.04, \"y\": 7.237}, {\"title\": \"DictLLM: Harnessing Key-Value Data Structures with Large Language Models  for Enhanced Medical Diagnostics\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.919, \"y\": 8.181}, {\"title\": \"A Curious Case of Searching for the Correlation between Training Data  and Adversarial Robustness of Transformer Textual Models\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.227, \"y\": 3.082}, {\"title\": \"MSynFD: Multi-hop Syntax aware Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.028, \"y\": 5.877}, {\"title\": \"LoRA-Flow: Dynamic LoRA Fusion for Large Language Models in Generative  Tasks\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.125, \"y\": 2.101}, {\"title\": \"In-Context Example Ordering Guided by Label Distributions\", \"topic\": \"In-Context Learning\", \"x\": 8.248, \"y\": 3.38}, {\"title\": \"Can LLMs Reason with Rules? Logic Scaffolding for Stress-Testing and  Improving LLMs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.604, \"y\": 2.99}, {\"title\": \"LoRETTA: Low-Rank Economic Tensor-Train Adaptation for  Ultra-Low-Parameter Fine-Tuning of Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.124, \"y\": 2.215}, {\"title\": \"Aligning Modalities in Vision Large Language Models via Preference  Fine-tuning\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.662, \"y\": 1.166}, {\"title\": \"Multi-dimensional Evaluation of Empathetic Dialog Responses\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.706, \"y\": 7.881}, {\"title\": \"Don't Go To Extremes: Revealing the Excessive Sensitivity and  Calibration Limitations of LLMs in Implicit Hate Speech Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.768, \"y\": 5.326}, {\"title\": \"Reasoning before Comparison: LLM-Enhanced Semantic Similarity Metrics  for Domain Specialized Text Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.972, \"y\": 8.311}, {\"title\": \"Offline Training of Language Model Agents with Functions as Learnable  Weights\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.862, \"y\": 2.325}, {\"title\": \"Understanding the Impact of Long-Term Memory on Self-Disclosure with  Large Language Model-Driven Chatbots for Public Health Intervention\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.406, \"y\": 7.913}, {\"title\": \"PhaseEvo: Towards Unified In-Context Prompt Optimization for Large  Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.412, \"y\": 3.197}, {\"title\": \"MMMModal -- Multi-Images Multi-Audio Multi-turn Multi-Modal\", \"topic\": \"Multimodal Language Models\", \"x\": 8.271, \"y\": 7.395}, {\"title\": \"Dissecting Human and LLM Preferences\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.021, \"y\": 1.695}, {\"title\": \"OneBit: Towards Extremely Low-bit Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.675, \"y\": 2.337}, {\"title\": \"Puzzle Solving using Reasoning of Large Language Models: A Survey\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.516, \"y\": 3.262}, {\"title\": \"Can Large Multimodal Models Uncover Deep Semantics Behind Images?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.191, \"y\": 7.691}, {\"title\": \"MoRAL: MoE Augmented LoRA for LLMs' Lifelong Learning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.991, \"y\": 2.162}, {\"title\": \"C-ICL: Contrastive In-context Learning for Information Extraction\", \"topic\": \"In-Context Learning\", \"x\": 8.239, \"y\": 3.515}, {\"title\": \"Aligning Large Language Models by On-Policy Self-Judgment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.403, \"y\": 1.507}, {\"title\": \"Detecting a Proxy for Potential Comorbid ADHD in People Reporting  Anxiety Symptoms from Social Media Data\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.175, \"y\": 7.413}, {\"title\": \"Asclepius: A Spectrum Evaluation Benchmark for Medical Multi-Modal Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.016, \"y\": 7.834}, {\"title\": \"Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based  Agents\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.528, \"y\": 2.659}, {\"title\": \"Exploring ChatGPT for Next-generation Information Retrieval:  Opportunities and Challenges\", \"topic\": \"Bias in Language Models\", \"x\": 4.987, \"y\": 4.468}, {\"title\": \"Direct Evaluation of Chain-of-Thought in Multi-hop Reasoning with  Knowledge Graphs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.62, \"y\": 2.411}, {\"title\": \"Evaluating LLMs' Mathematical Reasoning in Financial Document Question  Answering\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.957, \"y\": 6.762}, {\"title\": \"Disclosure and Mitigation of Gender Bias in LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.332, \"y\": 4.306}, {\"title\": \"LaCo: Large Language Model Pruning via Layer Collapse\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.513, \"y\": 2.502}, {\"title\": \"A Question Answering Based Pipeline for Comprehensive Chinese EHR  Information Extraction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.91, \"y\": 7.604}, {\"title\": \"M4GT-Bench: Evaluation Benchmark for Black-Box Machine-Generated Text  Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.101, \"y\": 4.822}, {\"title\": \"GenDec: A robust generative Question-decomposition method for Multi-hop  reasoning\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.642, \"y\": 5.419}, {\"title\": \"PANDA (Pedantic ANswer-correctness Determination and  Adjudication):Improving Automatic Evaluation for Question Answering and Text  Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.196, \"y\": 4.979}, {\"title\": \"Grasping the Essentials: Tailoring Large Language Models for Zero-Shot  Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.046, \"y\": 6.525}, {\"title\": \"Boosting of Thoughts: Trial-and-Error Problem Solving with Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.639, \"y\": 2.551}, {\"title\": \"Contrastive Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.212, \"y\": 2.385}, {\"title\": \"Orca-Math: Unlocking the potential of SLMs in Grade School Math\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.06, \"y\": 2.704}, {\"title\": \"BlendFilter: Advancing Retrieval-Augmented Large Language Models via  Query Generation Blending and Knowledge Filtering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.925, \"y\": 4.746}, {\"title\": \"Born With a Silver Spoon? Investigating Socioeconomic Bias in Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.472, \"y\": 4.416}, {\"title\": \"II-MMR: Identifying and Improving Multi-modal Multi-hop Reasoning in  Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.156, \"y\": 7.894}, {\"title\": \"PAT-Questions: A Self-Updating Benchmark for Present-Anchored Temporal  Question-Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.421, \"y\": 5.289}, {\"title\": \"RLVF: Learning from Verbal Feedback without Overgeneralization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.103, \"y\": 1.716}, {\"title\": \"Instruction Diversity Drives Generalization To Unseen Tasks\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.243, \"y\": 2.325}, {\"title\": \"Multi-modal preference alignment remedies regression of visual  instruction tuning on language model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.395, \"y\": 7.449}, {\"title\": \"Using Hallucinations to Bypass GPT4's Filter\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.234, \"y\": 1.162}, {\"title\": \"Generative Cross-Modal Retrieval: Memorizing Images in Multimodal  Language Models for Retrieval and Beyond\", \"topic\": \"Multimodal Language Models\", \"x\": 8.193, \"y\": 7.226}, {\"title\": \"In Search of Needles in a 11M Haystack: Recurrent Memory Finds What LLMs  Miss\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.561, \"y\": 3.387}, {\"title\": \"EdgeQAT: Entropy and Distribution Guided Quantization-Aware Training for  the Acceleration of Lightweight LLMs on the Edge\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.768, \"y\": 2.181}, {\"title\": \"A Condensed Transition Graph Framework for Zero-shot Link Prediction  with Large Language Models\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.034, \"y\": 6.131}, {\"title\": \"Inference to the Best Explanation in Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.912, \"y\": 3.698}, {\"title\": \"GenRES: Rethinking Evaluation for Generative Relation Extraction in the  Era of Large Language Models\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.818, \"y\": 6.724}, {\"title\": \"Let's Learn Step by Step: Enhancing In-Context Learning Ability with  Curriculum Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.258, \"y\": 3.407}, {\"title\": \"A Novel BERT-based Classifier to Detect Political Leaning of YouTube  Videos based on their Titles\", \"topic\": \"Fake News Detection\", \"x\": 3.591, \"y\": 5.739}, {\"title\": \"\\\"Understanding AI\\\": Semantic Grounding in Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.977, \"y\": 3.816}, {\"title\": \"An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient  Language Model Inference\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.257, \"y\": 4.381}, {\"title\": \"Rethinking Human-like Translation Strategy: Integrating Drift-Diffusion  Model with Large Language Models for Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.543, \"y\": 4.205}, {\"title\": \"OpenFMNav: Towards Open-Set Zero-Shot Object Navigation via  Vision-Language Foundation Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.747, \"y\": 7.105}, {\"title\": \"Improving Demonstration Diversity by Human-Free Fusing for Text-to-SQL\", \"topic\": \"In-Context Learning\", \"x\": 8.092, \"y\": 3.508}, {\"title\": \"Fine Tuning Named Entity Extraction Models for the Fantasy Domain\", \"topic\": \"Named Entity Recognition\", \"x\": 7.327, \"y\": 6.742}, {\"title\": \"Enhancing Numerical Reasoning with the Guidance of Reliable Reasoning  Processes\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.799, \"y\": 2.637}, {\"title\": \"Can Separators Improve Chain-of-Thought Prompting?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.716, \"y\": 2.335}, {\"title\": \"`Keep it Together': Enforcing Cohesion in Extractive Summaries by  Simulating Human Memory\", \"topic\": \"Text Summarization\", \"x\": 5.512, \"y\": 6.18}, {\"title\": \"BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via  Self-Distillation\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.928, \"y\": 2.291}, {\"title\": \"Retrieve Only When It Needs: Adaptive Retrieval Augmentation for  Hallucination Mitigation in Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.209, \"y\": 1.156}, {\"title\": \"Jailbreaking Proprietary Large Language Models using Word Substitution  Cipher\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.32, \"y\": 2.259}, {\"title\": \"Efficiency at Scale: Investigating the Performance of Diminutive  Language Models in Clinical Tasks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.101, \"y\": 7.779}, {\"title\": \"Threads of Subtlety: Detecting Machine-Generated Texts Through Discourse  Motifs\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.129, \"y\": 4.769}, {\"title\": \"LinkNER: Linking Local Named Entity Recognition Models to Large Language  Models using Uncertainty\", \"topic\": \"Named Entity Recognition\", \"x\": 7.346, \"y\": 6.773}, {\"title\": \"Direct Preference Optimization with an Offset\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.352, \"y\": 1.237}, {\"title\": \"SPAR: Personalized Content-Based Recommendation via Long Engagement  Attention\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.924, \"y\": 2.929}, {\"title\": \"Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in  Disordered Texts\", \"topic\": \"Text Summarization\", \"x\": 5.425, \"y\": 6.447}, {\"title\": \"Conversational SimulMT: Efficient Simultaneous Translation with Large  Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.918, \"y\": 4.598}, {\"title\": \"Strong hallucinations from negation and how to fix them\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.214, \"y\": 1.176}, {\"title\": \"Can We Verify Step by Step for Incorrect Answer Detection?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.68, \"y\": 2.373}, {\"title\": \"Zero-shot sampling of adversarial entities in biomedical question  answering\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.155, \"y\": 3.02}, {\"title\": \"Active Preference Optimization for Sample Efficient RLHF\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.244, \"y\": 1.392}, {\"title\": \"Comparing Hallucination Detection Metrics for Multilingual Generation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.139, \"y\": 1.082}, {\"title\": \"Large Language Models as Zero-shot Dialogue State Tracker through  Function Calling\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.642, \"y\": 3.848}, {\"title\": \"QDyLoRA: Quantized Dynamic Low-Rank Adaptation for Efficient Large  Language Model Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.244, \"y\": 2.065}, {\"title\": \"FinTral: A Family of GPT-4 Level Multimodal Financial Large Language  Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.878, \"y\": 6.868}, {\"title\": \"Steering Conversational Large Language Models for Long Emotional Support  Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.59, \"y\": 7.747}, {\"title\": \"I Am Not Them: Fluid Identities and Persistent Out-group Bias in Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.712, \"y\": 4.467}, {\"title\": \"Smaller Language Models are capable of selecting Instruction-Tuning  Training Data for Larger Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.342, \"y\": 2.433}, {\"title\": \"DELL: Generating Reactions and Explanations for LLM-Based Misinformation  Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.127, \"y\": 5.53}, {\"title\": \"Understanding In-Context Learning with a Pelican Soup Framework\", \"topic\": \"In-Context Learning\", \"x\": 8.483, \"y\": 3.454}, {\"title\": \"Pushing the Limits of Zero-shot End-to-End Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.432, \"y\": 5.238}, {\"title\": \"Measuring and Reducing LLM Hallucination without Gold-Standard Answers\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.247, \"y\": 1.192}, {\"title\": \"Chain of Logic: Rule-Based Reasoning with Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.606, \"y\": 2.89}, {\"title\": \"Subgraph-level Universal Prompt Tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.699, \"y\": 3.524}, {\"title\": \"BioMistral: A Collection of Open-Source Pretrained Large Language Models  for Medical Domains\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.96, \"y\": 7.939}, {\"title\": \"Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of  Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.577, \"y\": 3.446}, {\"title\": \"Analyzing the Roles of Language and Vision in Learning from Limited Data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.444, \"y\": 7.457}, {\"title\": \"Exploration-Driven Policy Optimization in RLHF: Theoretical Insights on  Efficient Data Utilization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.203, \"y\": 1.46}, {\"title\": \"LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video  Editing\", \"topic\": \"Multimodal Language Models\", \"x\": 8.791, \"y\": 7.909}, {\"title\": \"Recovering the Pre-Fine-Tuning Weights of Generative Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.063, \"y\": 2.219}, {\"title\": \"Rewards-in-Context: Multi-objective Alignment of Foundation Models with  Dynamic Preference Adjustment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.339, \"y\": 1.369}, {\"title\": \"A StrongREJECT for Empty Jailbreaks\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.29, \"y\": 2.241}, {\"title\": \"Chain-of-Thought Reasoning Without Prompting\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.685, \"y\": 2.356}, {\"title\": \"Reward Generalization in RLHF: A Topological Perspective\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.192, \"y\": 1.5}, {\"title\": \"TDAG: A Multi-Agent Framework based on Dynamic Task Decomposition and  Agent Generation\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.71, \"y\": 2.653}, {\"title\": \"OpenMathInstruct-1: A 1.8 Million Math Instruction Tuning Dataset\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.368, \"y\": 2.726}, {\"title\": \"Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study  for Diabetes Patients\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.387, \"y\": 8.024}, {\"title\": \"TOAD: Task-Oriented Automatic Dialogs with Diverse Response Styles\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.46, \"y\": 3.786}, {\"title\": \"Selective Reflection-Tuning: Student-Selected Data Recycling for LLM  Instruction-Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.16, \"y\": 2.324}, {\"title\": \"Towards Reducing Diagnostic Errors with Interpretable Risk Prediction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.807, \"y\": 8.212}, {\"title\": \"Quantized Embedding Vectors for Controllable Diffusion Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.613, \"y\": 2.12}, {\"title\": \"GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on  Geometry Problem-Solving\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.004, \"y\": 3.049}, {\"title\": \"QUICK: Quantization-aware Interleaving and Conflict-free Kernel for  efficient LLM inference\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.693, \"y\": 2.185}, {\"title\": \"Both Matter: Enhancing the Emotional Intelligence of Large Language  Models without Compromising the General Intelligence\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.443, \"y\": 7.75}, {\"title\": \"RS-DPO: A Hybrid Rejection Sampling and Direct Preference Optimization  Method for Alignment of Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.302, \"y\": 1.316}, {\"title\": \"LoraRetriever: Input-Aware LoRA Retrieval and Composition for Mixed  Tasks in the Wild\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.21, \"y\": 1.97}, {\"title\": \"A Dataset of Open-Domain Question Answering with Multiple-Span Answers\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.499, \"y\": 5.381}, {\"title\": \"Enhancing Large Language Models with Pseudo- and Multisource- Knowledge  Graphs for Open-ended Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.841, \"y\": 5.534}, {\"title\": \"Generative Representational Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.218, \"y\": 2.541}, {\"title\": \"Not Just Novelty: A Longitudinal Study on Utility and Customization of  an AI Workflow\", \"topic\": \"Bias in Language Models\", \"x\": 5.08, \"y\": 4.312}, {\"title\": \"Camouflage is all you need: Evaluating and Enhancing Language Model  Robustness Against Camouflage Adversarial Attacks\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.161, \"y\": 3.028}, {\"title\": \"EFUF: Efficient Fine-grained Unlearning Framework for Mitigating  Hallucinations in Multimodal Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.316, \"y\": 1.041}, {\"title\": \"NutePrune: Efficient Progressive Pruning with Numerous Teachers for  Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.536, \"y\": 2.47}, {\"title\": \"Grounding Language Model with Chunking-Free In-Context Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.132, \"y\": 4.648}, {\"title\": \"Efficient Language Adaptive Pre-training: Extending State-of-the-Art  Large Language Models for Polish\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.095, \"y\": 4.125}, {\"title\": \"AI Hospital: Benchmarking Large Language Models in a Multi-agent Medical  Interaction Simulator\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.584, \"y\": 8.176}, {\"title\": \"Align before Attend: Aligning Visual and Textual Features for Multimodal  Hateful Content Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.858, \"y\": 5.649}, {\"title\": \"Do LLMs Know about Hallucination? An Empirical Investigation of LLM's  Hidden States\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.198, \"y\": 1.149}, {\"title\": \"Improving Non-autoregressive Machine Translation with Error Exposure and  Consistency Regularization\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.019, \"y\": 4.561}, {\"title\": \"Efficient Prompt Optimization Through the Lens of Best Arm  Identification\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.396, \"y\": 3.116}, {\"title\": \"PAL: Proxy-Guided Black-Box Attack on Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.43, \"y\": 2.557}, {\"title\": \"EntailE: Introducing Textual Entailment in Commonsense Knowledge Graph  Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.068, \"y\": 5.847}, {\"title\": \"CodeMind: A Framework to Challenge Large Language Models for Code  Reasoning\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.232, \"y\": 2.471}, {\"title\": \"GPT-4's assessment of its performance in a USMLE-based case study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.526, \"y\": 8.108}, {\"title\": \"API Pack: A Massive Multi-Programming Language Dataset for API Call  Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.457, \"y\": 2.566}, {\"title\": \"Probabilistic Reasoning in Generative Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.578, \"y\": 3.169}, {\"title\": \"LogicPrpBank: A Corpus for Logical Implication and Equivalence\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.737, \"y\": 3.162}, {\"title\": \"Emerging Opportunities of Using Large Language Models for Translation  Between Drug Molecules and Indications\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.033, \"y\": 7.771}, {\"title\": \"Reinforcement Learning from Human Feedback with Active Queries\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.223, \"y\": 1.467}, {\"title\": \"HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context  Learning in Factuality Evaluation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.556, \"y\": 2.588}, {\"title\": \"Transformers Can Achieve Length Generalization But Not Robustly\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.529, \"y\": 3.473}, {\"title\": \"DoRA: Weight-Decomposed Low-Rank Adaptation\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.198, \"y\": 2.034}, {\"title\": \"Generating Diverse Translation with Perturbed kNN-MT\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.941, \"y\": 4.22}, {\"title\": \"ICDPO: Effectively Borrowing Alignment Capability of Others via  In-context Direct Preference Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.337, \"y\": 1.29}, {\"title\": \"Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via  Self-Evaluation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.65, \"y\": 1.488}, {\"title\": \"SyntaxShap: Syntax-aware Explainability Method for Text Generation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.087, \"y\": 3.829}, {\"title\": \"Spectral Filters, Dark Signals, and Attention Sinks\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.435, \"y\": 3.496}, {\"title\": \"Ten Words Only Still Help: Improving Black-Box AI-Generated Text  Detection via Proxy-Guided Efficient Re-Sampling\", \"topic\": \"AI-Generated Text Detection\", \"x\": 3.981, \"y\": 4.685}, {\"title\": \"Leveraging the Context through Multi-Round Interactions for Jailbreaking  Attacks\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.323, \"y\": 2.279}, {\"title\": \"Chinese MentalBERT: Domain-Adaptive Pre-training on Social Media for  Chinese Mental Health Text Analysis\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.27, \"y\": 7.573}, {\"title\": \"SLEB: Streamlining LLMs through Redundancy Verification and Elimination  of Transformer Blocks\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.541, \"y\": 2.524}, {\"title\": \"SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware  Decoding\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.32, \"y\": 2.266}, {\"title\": \"Generalization in Healthcare AI: Evaluation of a Clinical Large Language  Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.622, \"y\": 8.042}, {\"title\": \"MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.043, \"y\": 2.802}, {\"title\": \"Premise Order Matters in Reasoning with Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.686, \"y\": 3.206}, {\"title\": \"MaxMin-RLHF: Towards Equitable Alignment of Large Language Models with  Diverse Human Preferences\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.254, \"y\": 1.403}, {\"title\": \"UniEnc-CASSNAT: An Encoder-only Non-autoregressive ASR for Speech SSL  Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.119, \"y\": 5.076}, {\"title\": \"An Embarrassingly Simple Approach for LLM with Strong ASR Capacity\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.968, \"y\": 5.215}, {\"title\": \"Syllable based DNN-HMM Cantonese Speech to Text System\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.943, \"y\": 5.441}, {\"title\": \"A Dataset for the Detection of Dehumanizing Language\", \"topic\": \"Hate Speech Detection\", \"x\": 2.81, \"y\": 5.333}, {\"title\": \"Learning How To Ask: Cycle-Consistency Refines Prompts in Multimodal  Foundation Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.331, \"y\": 7.782}, {\"title\": \"Mitigating Object Hallucination in Large Vision-Language Models via  Classifier-Free Guidance\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.361, \"y\": 1.016}, {\"title\": \"COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.295, \"y\": 2.337}, {\"title\": \"Bayesian Multi-Task Transfer Learning for Soft Prompt Tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.81, \"y\": 3.435}, {\"title\": \"PRompt Optimization in Multi-Step Tasks (PROMST): Integrating Human  Feedback and Heuristic-based Sampling\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.371, \"y\": 3.178}, {\"title\": \"Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM  Agents Exponentially Fast\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.331, \"y\": 2.412}, {\"title\": \"Higher Layers Need More LoRA Experts\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.086, \"y\": 2.021}, {\"title\": \"Plausible Extractive Rationalization through Semi-Supervised Entailment  Signal\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.762, \"y\": 3.671}, {\"title\": \"PreFLMR: Scaling Up Fine-Grained Late-Interaction Multi-modal Retrievers\", \"topic\": \"Multimodal Language Models\", \"x\": 8.114, \"y\": 7.413}, {\"title\": \"BBox-Adapter: Lightweight Adapting for Black-Box Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.994, \"y\": 2.401}, {\"title\": \"Pixel Sentence Representation Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.62, \"y\": 6.552}, {\"title\": \"CMA-R:Causal Mediation Analysis for Explaining Rumour Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.123, \"y\": 5.891}, {\"title\": \"Active Preference Learning for Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.311, \"y\": 1.378}, {\"title\": \"Addressing cognitive bias in medical language models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.512, \"y\": 7.834}, {\"title\": \"Relative Preference Optimization: Enhancing LLM Alignment through  Contrasting Responses across Identical and Diverse Prompts\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.329, \"y\": 1.3}, {\"title\": \"BASE TTS: Lessons from building a billion-parameter Text-to-Speech model  on 100K hours of data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.674, \"y\": 5.74}, {\"title\": \"Text-centric Alignment for Multi-Modality Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.028, \"y\": 7.114}, {\"title\": \"Large Language Models as Agents in Two-Player Games\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.651, \"y\": 2.636}, {\"title\": \"Beyond LLMs: Advancing the Landscape of Complex Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.471, \"y\": 2.905}, {\"title\": \"Careless Whisper: Speech-to-Text Hallucination Harms\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.114, \"y\": 1.134}, {\"title\": \"Lumos : Empowering Multimodal LLMs with Scene Text Recognition\", \"topic\": \"Multimodal Language Models\", \"x\": 8.216, \"y\": 7.395}, {\"title\": \"Refined Direct Preference Optimization with Synthetic Data for  Behavioral Alignment of LLMs\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.334, \"y\": 1.263}, {\"title\": \"EvoGPT-f: An Evolutionary GPT Framework for Benchmarking Formal Math  Languages\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.146, \"y\": 3.037}, {\"title\": \"Prismatic VLMs: Investigating the Design Space of Visually-Conditioned  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.376, \"y\": 7.706}, {\"title\": \"Lissard: Long and Simple Sequential Reasoning Datasets\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.663, \"y\": 3.332}, {\"title\": \"Mercury: A Code Efficiency Benchmark for Code Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.425, \"y\": 2.401}, {\"title\": \"Aya Model: An Instruction Finetuned Open-Access Multilingual Language  Model\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.808, \"y\": 4.132}, {\"title\": \"Retrieval-Augmented Thought Process as Sequential Decision Making\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.545, \"y\": 2.62}, {\"title\": \"Extensible Multi-Granularity Fusion Network for Aspect-based Sentiment  Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.079, \"y\": 6.876}, {\"title\": \"TELLER: A Trustworthy Framework for Explainable, Generalizable and  Controllable Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.047, \"y\": 5.731}, {\"title\": \"Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.694, \"y\": 2.292}, {\"title\": \"Towards Unified Alignment Between Agents, Humans, and Environment\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.267, \"y\": 2.887}, {\"title\": \"LoRA-drop: Efficient LoRA Parameter Pruning based on Output Evaluation\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.229, \"y\": 2.077}, {\"title\": \"Large Language Models \\\"Ad Referendum\\\": How Good Are They at Machine  Translation in the Legal Domain?\", \"topic\": \"Legal NLP\", \"x\": 5.234, \"y\": 5.378}, {\"title\": \"The Sound of Healthcare: Improving Medical Transcription ASR Accuracy  with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.749, \"y\": 7.89}, {\"title\": \"Autonomous Data Selection with Language Models for Mathematical Texts\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.348, \"y\": 2.677}, {\"title\": \"PKG API: A Tool for Personal Knowledge Graph Management\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.827, \"y\": 6.05}, {\"title\": \"BreakGPT: A Large Language Model with Multi-stage Structure for  Financial Breakout Detection\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.789, \"y\": 6.859}, {\"title\": \"MAFIA: Multi-Adapter Fused Inclusive LanguAge Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.23, \"y\": 4.346}, {\"title\": \"The Balancing Act: Unmasking and Alleviating ASR Biases in Portuguese\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.241, \"y\": 5.565}, {\"title\": \"T-RAG: Lessons from the LLM Trenches\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.909, \"y\": 4.636}, {\"title\": \"AraSpider: Democratizing Arabic-to-SQL\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.995, \"y\": 5.326}, {\"title\": \"Quality Does Matter: A Detailed Look at the Quality and Utility of  Web-Mined Parallel Corpora\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.486, \"y\": 4.797}, {\"title\": \"D\\u00f3lares or Dollars? Unraveling the Bilingual Prowess of Financial LLMs  Between Spanish and English\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.87, \"y\": 6.818}, {\"title\": \"Leveraging AI to Advance Science and Computing Education across Africa:  Challenges, Progress and Opportunities\", \"topic\": \"Bias in Language Models\", \"x\": 5.245, \"y\": 4.565}, {\"title\": \"Chain-of-Layer: Iteratively Prompting Large Language Models for Taxonomy  Induction from Limited Examples\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.676, \"y\": 2.323}, {\"title\": \"Making Flow-Matching-Based Zero-Shot Text-to-Speech Laugh as You Like\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.477, \"y\": 6.003}, {\"title\": \"ODIN: Disentangled Reward Mitigates Hacking in RLHF\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.06, \"y\": 1.6}, {\"title\": \"Power Transformer Fault Prediction Based on Knowledge Graphs\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.916, \"y\": 6.082}, {\"title\": \"Open-ended VQA benchmarking of Vision-Language models by exploiting  Classification datasets and their semantic hierarchy\", \"topic\": \"Multimodal Language Models\", \"x\": 8.357, \"y\": 7.854}, {\"title\": \"Low-Resource Counterspeech Generation for Indic Languages: The Case of  Bengali and Hindi\", \"topic\": \"Hate Speech Detection\", \"x\": 2.739, \"y\": 5.295}, {\"title\": \"Through the Lens of Split Vote: Exploring Disagreement, Difficulty and  Calibration in Legal Case Outcome Classification\", \"topic\": \"Legal NLP\", \"x\": 4.928, \"y\": 5.633}, {\"title\": \"Prompt Perturbation in Retrieval-Augmented Generation based Large  Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.231, \"y\": 3.172}, {\"title\": \"X-LoRA: Mixture of Low-Rank Adapter Experts, a Flexible Framework for  Large Language Models with Applications in Protein Mechanics and Molecular  Design\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.191, \"y\": 2.029}, {\"title\": \"Speech Rhythm-Based Speaker Embeddings Extraction from Phonemes and  Phoneme Duration for Multi-Speaker Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.679, \"y\": 5.738}, {\"title\": \"Semi-Supervised Learning for Bilingual Lexicon Induction\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.383, \"y\": 4.791}, {\"title\": \"Gemini Goes to Med School: Exploring the Capabilities of Multimodal  Large Language Models on Medical Challenge Problems & Hallucinations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.884, \"y\": 8.057}, {\"title\": \"DAEDRA: A language model for predicting outcomes in passive  pharmacovigilance reporting\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.84, \"y\": 8.029}, {\"title\": \"Event-Keyed Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.618, \"y\": 6.34}, {\"title\": \"Instruct Once, Chat Consistently in Multiple Rounds: An Efficient Tuning  Framework for Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.727, \"y\": 3.559}, {\"title\": \"SpeechCLIP+: Self-supervised multi-task representation learning for  speech via CLIP and speech-image data\", \"topic\": \"Multimodal Language Models\", \"x\": 9.145, \"y\": 7.158}, {\"title\": \"Should I try multiple optimizers when fine-tuning pre-trained  Transformers for NLP tasks? Should I tune their hyperparameters?\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.964, \"y\": 2.507}, {\"title\": \"Generating Chain-of-Thoughts with a Pairwise-Comparison Approach to  Searching for the Most Promising Intermediate Thought\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.589, \"y\": 2.294}, {\"title\": \"TL;DR Progress: Multi-faceted Literature Exploration in Text  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.665, \"y\": 6.38}, {\"title\": \"GenTranslate: Large Language Models are Generative Multilingual Speech  and Machine Translators\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.69, \"y\": 4.367}, {\"title\": \"History, Development, and Principles of Large Language Models-An  Introductory Survey\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.572, \"y\": 3.958}, {\"title\": \"The Unreasonable Effectiveness of Eccentric Automatic Prompts\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 6.963, \"y\": 3.029}, {\"title\": \"Detection of Opioid Users from Reddit Posts via an Attention-based  Bidirectional Recurrent Neural Network\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.304, \"y\": 7.34}, {\"title\": \"NICE: To Optimize In-Context Examples or Not?\", \"topic\": \"In-Context Learning\", \"x\": 8.269, \"y\": 3.152}, {\"title\": \"FaBERT: Pre-training BERT on Persian Blogs\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.893, \"y\": 5.119}, {\"title\": \"Self-consistent context aware conformer transducer for speech  recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.224, \"y\": 5.17}, {\"title\": \"What is Hiding in Medicine's Dark Matter? Learning with Missing Data in  Medical Practices\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.85, \"y\": 8.272}, {\"title\": \"Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection  via Retrieval-Augmented GPT-4 and LLaMA\", \"topic\": \"Hate Speech Detection\", \"x\": 2.931, \"y\": 5.512}, {\"title\": \"A Multi-faceted Semi-Synthetic Dataset for Automated Cyberbullying  Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.863, \"y\": 5.487}, {\"title\": \"Introspective Planning: Aligning Robots' Uncertainty with Inherent Task  Ambiguity\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.84, \"y\": 2.57}, {\"title\": \"Multimodal Clinical Trial Outcome Prediction with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.11, \"y\": 8.18}, {\"title\": \"Re-Envisioning Command and Control\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.096, \"y\": 3.316}, {\"title\": \"Inducing Systematicity in Transformers by Attending to Structurally  Quantized Embeddings\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.663, \"y\": 3.523}, {\"title\": \"Findings of the First Workshop on Simulating Conversational Intelligence  in Chat\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.167, \"y\": 3.605}, {\"title\": \"Promoting Target Data in Context-aware Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.811, \"y\": 4.42}, {\"title\": \"RareBench: Can LLMs Serve as Rare Diseases Specialists?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.841, \"y\": 8.256}, {\"title\": \"InternLM-Math: Open Math Large Language Models Toward Verifiable  Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.095, \"y\": 2.772}, {\"title\": \"Zero-shot Explainable Mental Health Analysis on Social Media by  Incorporating Mental Scales\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.353, \"y\": 7.602}, {\"title\": \"LLaVA-Docent: Instruction Tuning with Multimodal Large Language Model to  Support Art Appreciation Education\", \"topic\": \"Multimodal Language Models\", \"x\": 8.212, \"y\": 7.55}, {\"title\": \"Fight Back Against Jailbreaking via Prompt Adversarial Tuning\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.381, \"y\": 2.5}, {\"title\": \"Large Language Models: A Survey\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.395, \"y\": 4.053}, {\"title\": \"Learn To be Efficient: Build Structured Sparsity in Large Language  Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.271, \"y\": 2.533}, {\"title\": \"Exploring Group and Symmetry Principles in Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.863, \"y\": 2.978}, {\"title\": \"Rethinking Data Selection for Supervised Fine-Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.244, \"y\": 2.532}, {\"title\": \"LightCAM: A Fast and Light Implementation of Context-Aware Masking based  D-TDNN for Speaker Verification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.207, \"y\": 5.024}, {\"title\": \"A Prompt Response to the Demand for Automatic Gender-Neutral Translation\", \"topic\": \"Bias in Language Models\", \"x\": 2.897, \"y\": 4.446}, {\"title\": \"Doing Experiments and Revising Rules with Natural Language and  Probabilistic Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.555, \"y\": 3.148}, {\"title\": \"Exploring Visual Culture Awareness in GPT-4V: A Comprehensive Probing\", \"topic\": \"Multimodal Language Models\", \"x\": 8.19, \"y\": 7.798}, {\"title\": \"SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.241, \"y\": 7.324}, {\"title\": \"CREMA: Generalizable and Efficient Video-Language Reasoning via  Multimodal Modular Fusion\", \"topic\": \"Multimodal Language Models\", \"x\": 8.309, \"y\": 7.759}, {\"title\": \"How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.212, \"y\": 3.032}, {\"title\": \"Neural Models for Source Code Synthesis and Completion\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.745, \"y\": 2.574}, {\"title\": \"Integrating Self-supervised Speech Model with Pseudo Word-level Targets  from Visually-grounded Speech Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.682, \"y\": 4.971}, {\"title\": \"FAQ-Gen: An automated system to generate domain-specific FAQs to aid  content comprehension\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.281, \"y\": 5.04}, {\"title\": \"Phonetically rich corpus construction for a low-resourced language\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.461, \"y\": 5.42}, {\"title\": \"Examining Gender and Racial Bias in Large Vision-Language Models Using a  Novel Dataset of Parallel Images\", \"topic\": \"Bias in Language Models\", \"x\": 3.27, \"y\": 4.474}, {\"title\": \"TimeArena: Shaping Efficient Multitasking Language Agents in a  Time-Aware Simulation\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.83, \"y\": 2.742}, {\"title\": \"Unified Speech-Text Pretraining for Spoken Dialog Modeling\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.322, \"y\": 5.707}, {\"title\": \"Comprehensive Assessment of Jailbreak Attacks Against LLMs\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.299, \"y\": 2.254}, {\"title\": \"Efficient Models for the Detection of Hate, Abuse and Profanity\", \"topic\": \"Hate Speech Detection\", \"x\": 2.809, \"y\": 5.401}, {\"title\": \"AttnLRP: Attention-Aware Layer-Wise Relevance Propagation for  Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.616, \"y\": 3.356}, {\"title\": \"Establishing degrees of closeness between audio recordings along  different dimensions using large-scale cross-lingual models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.466, \"y\": 5.215}, {\"title\": \"Traditional Machine Learning Models and Bidirectional Encoder  Representations From Transformer (BERT)-Based Automatic Classification of  Tweets About Eating Disorders: Algorithm Development and Validation Study\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.202, \"y\": 7.197}, {\"title\": \"Benchmarking Large Language Models on Communicative Medical Coaching: a  Novel System and Dataset\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.475, \"y\": 8.142}, {\"title\": \"Named Entity Recognition for Address Extraction in Speech-to-Text  Transcriptions Using Synthetic Data\", \"topic\": \"Named Entity Recognition\", \"x\": 7.311, \"y\": 6.835}, {\"title\": \"Empowering machine learning models with contextual knowledge for  enhancing the detection of eating disorders in social media posts\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.298, \"y\": 7.289}, {\"title\": \"NoisyICL: A Little Noise in Model Parameters Calibrates In-context  Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.472, \"y\": 3.272}, {\"title\": \"Rapid Optimization for Jailbreaking LLMs via Subconscious Exploitation  and Echopraxia\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.292, \"y\": 2.224}, {\"title\": \"It's Never Too Late: Fusing Acoustic Information into Large Language  Models for Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.067, \"y\": 5.245}, {\"title\": \"Accurate LoRA-Finetuning Quantization of LLMs via Information Retention\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.675, \"y\": 2.068}, {\"title\": \"Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.562, \"y\": 2.476}, {\"title\": \"In-Context Principle Learning from Mistakes\", \"topic\": \"In-Context Learning\", \"x\": 8.14, \"y\": 3.395}, {\"title\": \"Zero-Shot Chain-of-Thought Reasoning Guided by Evolutionary Algorithms  in Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.661, \"y\": 2.558}, {\"title\": \"CIC: A framework for Culturally-aware Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.95, \"y\": 7.4}, {\"title\": \"Noise Contrastive Alignment of Language Models with Explicit Rewards\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.321, \"y\": 1.308}, {\"title\": \"Neural machine translation of clinical procedure codes for medical  diagnosis and uncertainty quantification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.817, \"y\": 8.206}, {\"title\": \"Image captioning for Brazilian Portuguese using GRIT model\", \"topic\": \"Multimodal Language Models\", \"x\": 9.028, \"y\": 7.485}, {\"title\": \"How BERT Speaks Shakespearean English? Evaluating Historical Bias in  Contextual Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.27, \"y\": 4.413}, {\"title\": \"Pedagogical Alignment of Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.31, \"y\": 1.499}, {\"title\": \"Text or Image? What is More Important in Cross-Domain Generalization  Capabilities of Hate Meme Detection Models?\", \"topic\": \"Hate Speech Detection\", \"x\": 2.835, \"y\": 5.654}, {\"title\": \"L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large  Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.569, \"y\": 2.124}, {\"title\": \"Detecting Generated Native Ads in Conversational Search\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.525, \"y\": 4.462}, {\"title\": \"On Provable Length and Compositional Generalization\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.239, \"y\": 3.72}, {\"title\": \"CodeIt: Self-Improving Language Models with Prioritized Hindsight Replay\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.554, \"y\": 2.307}, {\"title\": \"CapsF: Capsule Fusion for Extracting psychiatric stressors for suicide  from twitter\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.154, \"y\": 7.331}, {\"title\": \"Long Is More for Alignment: A Simple but Tough-to-Beat Baseline for  Instruction Fine-Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.151, \"y\": 2.292}, {\"title\": \"Learning Communication Policies for Different Follower Behaviors in a  Collaborative Reference Game\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.346, \"y\": 2.819}, {\"title\": \"Aspect-Based Sentiment Analysis for Open-Ended HR Survey Responses\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.219, \"y\": 6.765}, {\"title\": \"Direct Language Model Alignment from Online AI Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.26, \"y\": 1.44}, {\"title\": \"MLLM-as-a-Judge: Assessing Multimodal LLM-as-a-Judge with  Vision-Language Benchmark\", \"topic\": \"Multimodal Language Models\", \"x\": 7.962, \"y\": 7.579}, {\"title\": \"StableMask: Refining Causal Masking in Decoder-only Transformer\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.772, \"y\": 3.191}, {\"title\": \"ApiQ: Finetuning of 2-Bit Quantized Large Language Model\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.694, \"y\": 2.094}, {\"title\": \"Source Identification in Abstractive Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.639, \"y\": 6.346}, {\"title\": \"TransLLaMa: LLM-based Simultaneous Translation System\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.914, \"y\": 4.607}, {\"title\": \"SPARQL Generation: an analysis on fine-tuning OpenLLaMA for Question  Answering over a Life Science Knowledge Graph\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.78, \"y\": 5.4}, {\"title\": \"UltraLink: An Open-Source Knowledge-Enhanced Multilingual Supervised  Fine-tuning Dataset\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.158, \"y\": 4.182}, {\"title\": \"SumRec: A Framework for Recommendation using Open-Domain Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.921, \"y\": 3.063}, {\"title\": \"ColorSwap: A Color and Word Order Dataset for Multimodal Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.34, \"y\": 7.637}, {\"title\": \"Evaluating Embeddings for One-Shot Classification of Doctor-AI  Consultations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.831, \"y\": 8.094}, {\"title\": \"DFA-RAG: Conversational Semantic Router for Large Language Model with  Definite Finite Automaton\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.714, \"y\": 4.315}, {\"title\": \"Monitoring the evolution of antisemitic discourse on extremist social  media using BERT\", \"topic\": \"Hate Speech Detection\", \"x\": 2.883, \"y\": 5.452}, {\"title\": \"The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax  Mimicry\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.836, \"y\": 3.215}, {\"title\": \"LegalLens: Leveraging LLMs for Legal Violation Identification in  Unstructured Text\", \"topic\": \"Legal NLP\", \"x\": 5.051, \"y\": 5.654}, {\"title\": \"LESS: Selecting Influential Data for Targeted Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.362, \"y\": 2.32}, {\"title\": \"SceMQA: A Scientific College Entrance Level Multimodal Question  Answering Benchmark\", \"topic\": \"Multimodal Language Models\", \"x\": 7.865, \"y\": 7.755}, {\"title\": \"CogCoM: Train Large Vision-Language Models Diving into Details through  Chain of Manipulations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.589, \"y\": 7.581}, {\"title\": \"Can Generative Agents Predict Emotion?\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.515, \"y\": 7.689}, {\"title\": \"Attention with Markov: A Framework for Principled Analysis of  Transformers via Markov Chains\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.58, \"y\": 3.53}, {\"title\": \"Measuring Implicit Bias in Explicitly Unbiased Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.516, \"y\": 4.223}, {\"title\": \"The Use of a Large Language Model for Cyberbullying Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.806, \"y\": 5.422}, {\"title\": \"Iterative Prompt Refinement for Radiation Oncology Symptom Extraction  Using Teacher-Student Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.894, \"y\": 8.184}, {\"title\": \"REBORN: Reinforcement-Learned Boundary Segmentation with Iterative  Training for Unsupervised ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.15, \"y\": 5.187}, {\"title\": \"Enhancing Retrieval Processes for Language Generation with Augmented  Queries\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.083, \"y\": 4.645}, {\"title\": \"Can Large Language Models Detect Rumors on Social Media?\", \"topic\": \"Fake News Detection\", \"x\": 4.054, \"y\": 5.611}, {\"title\": \"CADReN: Contextual Anchor-Driven Relational Network for Controllable  Cross-Graphs Node Importance Estimation\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.056, \"y\": 6.119}, {\"title\": \"DistiLLM: Towards Streamlined Distillation for Large Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.501, \"y\": 3.785}, {\"title\": \"Beyond Lines and Circles: Unveiling the Geometric Reasoning Gap in Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.66, \"y\": 3.117}, {\"title\": \"Less than one percent of words would be affected by gender-inclusive  language in German press texts\", \"topic\": \"Bias in Language Models\", \"x\": 3.114, \"y\": 4.489}, {\"title\": \"BiLLM: Pushing the Limit of Post-Training Quantization for LLMs\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.726, \"y\": 2.166}, {\"title\": \"Learning a Decision Tree Algorithm with Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.223, \"y\": 3.668}, {\"title\": \"The Instinctive Bias: Spurious Images lead to Hallucination in MLLMs\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.197, \"y\": 1.057}, {\"title\": \"INSIDE: LLMs' Internal States Retain the Power of Hallucination  Detection\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.257, \"y\": 1.183}, {\"title\": \"Deep Outdated Fact Detection in Knowledge Graphs\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.891, \"y\": 5.972}, {\"title\": \"Listen, Chat, and Edit: Text-Guided Soundscape Modification for Enhanced  Auditory Experience\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.506, \"y\": 5.932}, {\"title\": \"Personalized Language Modeling from Personalized Human Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.219, \"y\": 1.476}, {\"title\": \"Are Machines Better at Complex Reasoning? Unveiling Human-Machine  Inference Gaps in Entailment Verification\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.661, \"y\": 3.085}, {\"title\": \"Large Language Models as an Indirect Reasoner: Contrapositive and  Contradiction for Automated Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.65, \"y\": 2.955}, {\"title\": \"Learning to Generate Explainable Stock Predictions using Self-Reflective  Large Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.806, \"y\": 6.804}, {\"title\": \"Stanceosaurus 2.0: Classifying Stance Towards Russian and Spanish  Misinformation\", \"topic\": \"Fake News Detection\", \"x\": 3.603, \"y\": 5.863}, {\"title\": \"Professional Agents -- Evolving Large Language Models into Autonomous  Experts with Human-Level Competencies\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.514, \"y\": 2.931}, {\"title\": \"Partially Recentralization Softmax Loss for Vision-Language Models  Robustness\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.168, \"y\": 2.953}, {\"title\": \"Self-Discover: Large Language Models Self-Compose Reasoning Structures\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.602, \"y\": 2.7}, {\"title\": \"Improving Contextual Congruence Across Modalities for Effective  Multimodal Marketing using Knowledge-infused Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.109, \"y\": 7.479}, {\"title\": \"Breaking Symmetry When Training Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.663, \"y\": 3.429}, {\"title\": \"Identifying Reasons for Contraceptive Switching from Real-World Data  Using Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.471, \"y\": 7.741}, {\"title\": \"Resolving Transcription Ambiguity in Spanish: A Hybrid Acoustic-Lexical  System for Punctuation Restoration\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.782, \"y\": 5.387}, {\"title\": \"An Inpainting-Infused Pipeline for Attire and Background Replacement\", \"topic\": \"Multimodal Language Models\", \"x\": 9.094, \"y\": 6.851}, {\"title\": \"Attention Meets Post-hoc Interpretability: A Mathematical Perspective\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.579, \"y\": 3.461}, {\"title\": \"A Systematic Survey of Prompt Engineering in Large Language Models:  Techniques and Applications\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.21, \"y\": 3.241}, {\"title\": \"Arabic Synonym BERT-based Adversarial Examples for Text Classification\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.137, \"y\": 2.97}, {\"title\": \"DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.058, \"y\": 2.906}, {\"title\": \"Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information  Seeking in Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.369, \"y\": 2.649}, {\"title\": \"ISPA: Inter-Species Phonetic Alphabet for Transcribing Animal Sounds\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.675, \"y\": 5.38}, {\"title\": \"Understanding Reasoning Ability of Language Models From the Perspective  of Reasoning Paths Aggregation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.708, \"y\": 2.763}, {\"title\": \"English Prompts are Better for NLI-based Zero-Shot Emotion  Classification than Target-Language Prompts\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.446, \"y\": 7.439}, {\"title\": \"\\\"Define Your Terms\\\" : Enhancing Efficient Offensive Speech  Classification with Definition\", \"topic\": \"Hate Speech Detection\", \"x\": 2.816, \"y\": 5.341}, {\"title\": \"Unified Hallucination Detection for Multimodal Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.17, \"y\": 0.978}, {\"title\": \"LB-KBQA: Large-language-model and BERT based Knowledge-Based Question  and Answering System\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.686, \"y\": 5.224}, {\"title\": \"MULTI: Multimodal Understanding Leaderboard with Text and Images\", \"topic\": \"Multimodal Language Models\", \"x\": 7.945, \"y\": 7.634}, {\"title\": \"Accurate and Well-Calibrated ICD Code Assignment Through Attention Over  Diverse Label Embeddings\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.923, \"y\": 8.465}, {\"title\": \"Homograph Attacks on Maghreb Sentiment Analyzers\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.493, \"y\": 6.475}, {\"title\": \"Linguistic features for sentence difficulty prediction in ABSA\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.136, \"y\": 6.823}, {\"title\": \"Video-LaVIT: Unified Video-Language Pre-training with Decoupled  Visual-Motional Tokenization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.881, \"y\": 7.822}, {\"title\": \"Less is KEN: a Universal and Simple Non-Parametric Pruning Algorithm for  Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.587, \"y\": 2.52}, {\"title\": \"Sociolinguistically Informed Interpretability: A Case Study on Hinglish  Emotion Classification\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.361, \"y\": 7.475}, {\"title\": \"Constrained Decoding for Cross-lingual Label Projection\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.477, \"y\": 4.931}, {\"title\": \"Intent-based Prompt Calibration: Enhancing prompt optimization with  synthetic boundary cases\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.316, \"y\": 3.222}, {\"title\": \"Enhancing the Stability of LLM-based Speech Generation Systems through  Self-Supervised Representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.832, \"y\": 5.379}, {\"title\": \"A Comprehensive Study of the Current State-of-the-Art in Nepali  Automatic Speech Recognition Systems\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.962, \"y\": 5.573}, {\"title\": \"EasyInstruct: An Easy-to-use Instruction Processing Framework for Large  Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.126, \"y\": 2.316}, {\"title\": \"SIDU-TXT: An XAI Algorithm for NLP with a Holistic Assessment Approach\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.75, \"y\": 4.155}, {\"title\": \"Decoding-time Realignment of Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.288, \"y\": 1.377}, {\"title\": \"Putting Context in Context: the Impact of Discussion Structure on Text  Classification\", \"topic\": \"Fake News Detection\", \"x\": 3.585, \"y\": 5.855}, {\"title\": \"Towards Understanding the Word Sensitivity of Attention Layers: A Study  via Random Features\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.7, \"y\": 3.279}, {\"title\": \"Enhancing Textbook Question Answering Task with Large Language Models  and Retrieval Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.915, \"y\": 4.734}, {\"title\": \"Approximate Attributions for Off-the-Shelf Siamese Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.323, \"y\": 3.522}, {\"title\": \"How do Large Language Models Learn In-Context? Query and Key Matrices of  In-Context Heads are Two Towers for Metric Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.478, \"y\": 3.361}, {\"title\": \"Shortened LLaMA: Depth Pruning for Large Language Models with Comparison  of Retraining Methods\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.488, \"y\": 2.391}, {\"title\": \"DeAL: Decoding-time Alignment for Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.258, \"y\": 1.464}, {\"title\": \"Illuminate: A novel approach for depression detection with explainable  analysis and proactive therapy using prompt engineering\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.242, \"y\": 7.613}, {\"title\": \"Understanding the planning of LLM agents: A survey\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.712, \"y\": 2.687}, {\"title\": \"Exploiting Class Probabilities for Black-box Sentence-level Attacks\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.154, \"y\": 3.042}, {\"title\": \"Adversarial Text Purification: A Large Language Model Approach for  Defense\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.135, \"y\": 3.096}, {\"title\": \"Image-Caption Encoding for Improving Zero-Shot Generalization\", \"topic\": \"Multimodal Language Models\", \"x\": 9.008, \"y\": 7.381}, {\"title\": \"Multi-step Problem Solving Through a Verifier: An Empirical Analysis on  Model-induced Process Supervision\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.683, \"y\": 2.182}, {\"title\": \"Recursive Chain-of-Feedback Prevents Performance Degradation from  Redundant Prompting\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.684, \"y\": 2.407}, {\"title\": \"Zero-Shot Clinical Trial Patient Matching with LLMs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.79, \"y\": 7.802}, {\"title\": \"Predicting Machine Translation Performance on Low-Resource Languages:  The Role of Domain Similarity\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.374, \"y\": 4.169}, {\"title\": \"GIRT-Model: Automated Generation of Issue Report Templates\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.415, \"y\": 2.419}, {\"title\": \"UniTSyn: A Large-Scale Dataset Capable of Enhancing the Prowess of Large  Language Models for Program Testing\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.347, \"y\": 2.385}, {\"title\": \"Enhancing Transformer RNNs with Multiple Temporal Perspectives\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.732, \"y\": 3.304}, {\"title\": \"DenseFormer: Enhancing Information Flow in Transformers via Depth  Weighted Averaging\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.889, \"y\": 3.213}, {\"title\": \"Layer-Wise Analysis of Self-Supervised Acoustic Word Embeddings: A Study  on Speech Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 10.439, \"y\": 5.258}, {\"title\": \"PuzzleBench: Can LLMs Solve Challenging First-Order Combinatorial  Reasoning Problems?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.443, \"y\": 3.003}, {\"title\": \"A Quantitative Discourse Analysis of Asian Workers in the US Historical  Newspapers\", \"topic\": \"Hate Speech Detection\", \"x\": 3.19, \"y\": 5.287}, {\"title\": \"Synergy-of-Thoughts: Eliciting Efficient Reasoning in Hybrid Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.49, \"y\": 2.453}, {\"title\": \"Enhancing Robustness in Biomedical NLI Models: A Probing Approach for  Clinical Trials\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.857, \"y\": 7.64}, {\"title\": \"Generalizable Entity Grounding via Assistance of Large Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.551, \"y\": 7.246}, {\"title\": \"Knowledge Generation for Zero-shot Knowledge-based VQA\", \"topic\": \"Multimodal Language Models\", \"x\": 8.215, \"y\": 8.055}, {\"title\": \"GeReA: Question-Aware Prompt Captions for Knowledge-based Visual  Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.189, \"y\": 7.932}, {\"title\": \"A Survey on Data Selection for LLM Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.231, \"y\": 2.36}, {\"title\": \"BRAIn: Bayesian Reward-conditioned Amortized Inference for natural  language generation from feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.274, \"y\": 1.447}, {\"title\": \"LQER: Low-Rank Quantization Error Reconstruction for LLMs\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.696, \"y\": 2.127}, {\"title\": \"Aligner: Efficient Alignment by Learning to Correct\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.43, \"y\": 1.419}, {\"title\": \"GLaPE: Gold Label-agnostic Prompt Evaluation and Optimization for Large  Language Model\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.233, \"y\": 3.09}, {\"title\": \"DeLLMa: A Framework for Decision Making Under Uncertainty with Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.228, \"y\": 3.18}, {\"title\": \"KICGPT: Large Language Model with Knowledge in Context for Knowledge  Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.967, \"y\": 5.891}, {\"title\": \"Solution-oriented Agent-based Models Generation with Verifier-assisted  Iterative In-context Learning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.747, \"y\": 2.673}, {\"title\": \"M$^3$Face: A Unified Multi-Modal Multilingual Framework for Human Face  Generation and Editing\", \"topic\": \"Multimodal Language Models\", \"x\": 8.254, \"y\": 7.089}, {\"title\": \"Diversity Measurement and Subset Selection for Instruction Tuning  Datasets\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.22, \"y\": 2.288}, {\"title\": \"A Survey of Large Language Models in Finance (FinLLMs)\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.877, \"y\": 6.805}, {\"title\": \"Jailbreaking Attack against Multimodal Large Language Model\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.28, \"y\": 2.395}, {\"title\": \"Predicting positive transfer for improved low-resource speech  recognition using acoustic pseudo-tokens\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.917, \"y\": 5.344}, {\"title\": \"SemPool: Simple, robust, and interpretable KG pooling for enhancing  language models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.86, \"y\": 5.483}, {\"title\": \"SynthDST: Synthetic Data is All You Need for Few-Shot Dialog State  Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.608, \"y\": 3.958}, {\"title\": \"Data Quality Matters: Suicide Intention Detection on Social Media Posts  Using a RoBERTa-CNN Model\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.14, \"y\": 7.323}, {\"title\": \"A Data Generation Perspective to the Mechanism of In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.396, \"y\": 3.275}, {\"title\": \"Enhancing Complex Question Answering over Knowledge Graphs through  Evidence Pattern Retrieval\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.743, \"y\": 5.529}, {\"title\": \"Analyzing Sentiment Polarity Reduction in News Presentation through  Contextual Perturbation and Large Language Models\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.487, \"y\": 6.51}, {\"title\": \"Probing Critical Learning Dynamics of PLMs for Hate Speech Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.652, \"y\": 5.288}, {\"title\": \"Are Large Language Models Good Prompt Optimizers?\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.106, \"y\": 3.125}, {\"title\": \"Analyzing the Evaluation of Cross-Lingual Knowledge Transfer in  Multilingual Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.347, \"y\": 4.821}, {\"title\": \"Revisiting the Markov Property for Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.907, \"y\": 4.289}, {\"title\": \"Translation Errors Significantly Impact Low-Resource Languages in  Cross-Lingual Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.391, \"y\": 4.793}, {\"title\": \"Investigating Content Planning for Navigating Trade-offs in  Knowledge-Grounded Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.544, \"y\": 3.814}, {\"title\": \"EffiBench: Benchmarking the Efficiency of Automatically Generated Code\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.438, \"y\": 2.368}, {\"title\": \"Panacea: Pareto Alignment via Preference Adaptation for LLMs\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.293, \"y\": 1.314}, {\"title\": \"A Closer Look at the Limitations of Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.198, \"y\": 2.359}, {\"title\": \"How well do LLMs cite relevant medical references? An evaluation  framework and analyses\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.781, \"y\": 7.747}, {\"title\": \"Self-Debiasing Large Language Models: Zero-Shot Recognition and  Reduction of Stereotypes\", \"topic\": \"Bias in Language Models\", \"x\": 3.376, \"y\": 4.254}, {\"title\": \"MasonPerplexity at ClimateActivism 2024: Integrating Advanced Ensemble  Techniques and Data Augmentation for Climate Activism Stance and Hate Event  Identification\", \"topic\": \"Fake News Detection\", \"x\": 3.403, \"y\": 5.789}, {\"title\": \"MasonPerplexity at Multimodal Hate Speech Event Detection 2024: Hate  Speech and Target Detection Using Transformer Ensembles\", \"topic\": \"Hate Speech Detection\", \"x\": 2.813, \"y\": 5.609}, {\"title\": \"A Morphologically-Aware Dictionary-based Data Augmentation Technique for  Machine Translation of Under-Represented Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.664, \"y\": 4.81}, {\"title\": \"Digits micro-model for accurate and secure transactions\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.15, \"y\": 5.288}, {\"title\": \"Preference Poisoning Attacks on Reward Model Learning\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.319, \"y\": 2.656}, {\"title\": \"Whispering in Norwegian: Navigating Orthographic and Dialectic  Challenges\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.039, \"y\": 5.494}, {\"title\": \"CoLe and LYS at BioASQ MESINESP8 Task: similarity based descriptor  assignment in Spanish\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.197, \"y\": 7.444}, {\"title\": \"Natural language guidance of high-fidelity text-to-speech with synthetic  annotations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.544, \"y\": 5.908}, {\"title\": \"LiPO: Listwise Preference Optimization through Learning-to-Rank\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.295, \"y\": 1.326}, {\"title\": \"COMET: Generating Commit Messages using Delta Graph Context  Representation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.464, \"y\": 2.359}, {\"title\": \"PiCO: Peer Review in LLMs based on the Consistency Optimization\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.221, \"y\": 3.589}, {\"title\": \"Predicting ATP binding sites in protein sequences using Deep Learning  and Natural Language Processing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.449, \"y\": 7.496}, {\"title\": \"TravelPlanner: A Benchmark for Real-World Planning with Language Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.828, \"y\": 2.729}, {\"title\": \"MAGDi: Structured Distillation of Multi-Agent Interaction Graphs  Improves Reasoning in Smaller Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.93, \"y\": 2.463}, {\"title\": \"Leveraging Large Language Models for Analyzing Blood Pressure Variations  Across Biological Sex from Scientific Literature\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.437, \"y\": 7.591}, {\"title\": \"Towards Sustainable Workplace Mental Health: A Novel Approach to Early  Intervention and Support\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.209, \"y\": 7.531}, {\"title\": \"How Paralingual are Paralinguistic Representations? A Case Study in  Speech Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.164, \"y\": 7.867}, {\"title\": \"A Hybrid Strategy for Chat Transcript Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.538, \"y\": 6.164}, {\"title\": \"AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through  Process Feedback\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 6.035, \"y\": 2.497}, {\"title\": \"Sequence Shortening for Context-Aware Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.731, \"y\": 4.259}, {\"title\": \"On Measuring Context Utilization in Document-Level MT Systems\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.537, \"y\": 4.305}, {\"title\": \"StepCoder: Improve Code Generation with Reinforcement Learning from  Compiler Feedback\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.332, \"y\": 2.267}, {\"title\": \"Describing Images $\\\\textit{Fast and Slow}$: Quantifying and Predicting  the Variation in Human Signals during Visuo-Linguistic Processes\", \"topic\": \"Multimodal Language Models\", \"x\": 8.645, \"y\": 7.422}, {\"title\": \"Skip \\\\n: A Simple Method to Reduce Hallucination in Large  Vision-Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.244, \"y\": 0.992}, {\"title\": \"Rethinking the Role of Proxy Rewards in Language Model Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.233, \"y\": 1.525}, {\"title\": \"HQA-Attack: Toward High Quality Black-Box Hard-Label Adversarial Attack  on Text\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.115, \"y\": 3.036}, {\"title\": \"CorpusLM: Towards a Unified Language Model on Corpus for  Knowledge-Intensive Tasks\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.074, \"y\": 4.722}, {\"title\": \"Streaming Sequence Transduction through Dynamic Compression\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.116, \"y\": 4.948}, {\"title\": \"LLM-Detector: Improving AI-Generated Chinese Text Detection with  Open-Source LLM Instruction Tuning\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.135, \"y\": 4.69}, {\"title\": \"AccentFold: A Journey through African Accents for Zero-Shot ASR  Adaptation to Target Accents\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.16, \"y\": 5.422}, {\"title\": \"Speech foundation models in healthcare: Effect of layer selection on  pathological speech feature prediction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.047, \"y\": 5.538}, {\"title\": \"A Multi-Agent Conversational Recommender System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.97, \"y\": 3.018}, {\"title\": \"PokeLLMon: A Human-Parity Agent for Pokemon Battles with Large Language  Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.176, \"y\": 3.062}, {\"title\": \"Interpretation of Intracardiac Electrograms Through Textual  Representations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.869, \"y\": 8.353}, {\"title\": \"Evaluation of Google's Voice Recognition and Sentence Classification for  Health Care Applications\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.688, \"y\": 7.904}, {\"title\": \"Reading Between the Tweets: Deciphering Ideological Stances of  Interconnected Mixed-Ideology Communities\", \"topic\": \"Fake News Detection\", \"x\": 3.634, \"y\": 5.551}, {\"title\": \"Repeat After Me: Transformers are Better than State Space Models at  Copying\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.465, \"y\": 3.32}, {\"title\": \"Executable Code Actions Elicit Better LLM Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.999, \"y\": 2.468}, {\"title\": \"HR-MultiWOZ: A Task Oriented Dialogue (TOD) Dataset for HR LLM Agent\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.404, \"y\": 3.668}, {\"title\": \"SPARQL Generation with Entity Pre-trained GPT for KG Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.814, \"y\": 5.49}, {\"title\": \"Towards Efficient Exact Optimization of Language Model Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.31, \"y\": 1.315}, {\"title\": \"Introduction to speech recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.065, \"y\": 5.437}, {\"title\": \"Formal-LLM: Integrating Formal Language and Natural Language for  Controllable LLM-based Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.957, \"y\": 2.706}, {\"title\": \"CroissantLLM: A Truly Bilingual French-English Language Model\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.034, \"y\": 4.491}, {\"title\": \"Health-LLM: Personalized Retrieval-Augmented Disease Prediction System\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.694, \"y\": 8.067}, {\"title\": \"Transforming and Combining Rewards for Aligning Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.353, \"y\": 1.292}, {\"title\": \"Prosody in Cascade and Direct Speech-to-Text Translation: a case study  on Korean Wh-Phrases\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.464, \"y\": 5.542}, {\"title\": \"A Chain-of-Thought Is as Strong as Its Weakest Link: A Benchmark for  Verifiers of Reasoning Chains\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.765, \"y\": 2.503}, {\"title\": \"Superfiltering: Weak-to-Strong Data Filtering for Fast  Instruction-Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.262, \"y\": 2.362}, {\"title\": \"EE-Tuning: An Economical yet Scalable Solution for Tuning Early-Exit  Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.002, \"y\": 2.384}, {\"title\": \"Disentangling the Roles of Target-Side Transfer and Regularization in  Multilingual Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.614, \"y\": 4.691}, {\"title\": \"SA-MDKIF: A Scalable and Adaptable Medical Domain Knowledge Injection  Framework for Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.022, \"y\": 7.924}, {\"title\": \"Investigating Bias Representations in Llama 2 Chat via Activation  Steering\", \"topic\": \"Bias in Language Models\", \"x\": 3.517, \"y\": 4.228}, {\"title\": \"Redefining \\\"Hallucination\\\" in LLMs: Towards a psychology-informed  framework for mitigating misinformation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.147, \"y\": 1.107}, {\"title\": \"A Survey on Hallucination in Large Vision-Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.157, \"y\": 1.05}, {\"title\": \"Efficient Non-Parametric Uncertainty Quantification for Black-Box Large  Language Models and Decision Planning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.855, \"y\": 2.501}, {\"title\": \"Exploring the limits of decoder-only models trained on public speech  recognition corpora\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.157, \"y\": 5.237}, {\"title\": \"Are Generative AI systems Capable of Supporting Information Needs of  Patients?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.989, \"y\": 8.433}, {\"title\": \"De-identification is not always enough\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.6, \"y\": 8.04}, {\"title\": \"Emergency Department Decision Support using Clinical Pseudo-notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.828, \"y\": 8.282}, {\"title\": \"Large Language Models for Mathematical Reasoning: Progresses and  Challenges\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.757, \"y\": 3.173}, {\"title\": \"The Impact of Language Adapters in Cross-Lingual Transfer for NLU\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.469, \"y\": 4.641}, {\"title\": \"An Early Categorization of Prompt Injection Attacks on Large Language  Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.479, \"y\": 2.644}, {\"title\": \"Making a Long Story Short in Conversation Modeling\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.283, \"y\": 4.165}, {\"title\": \"Common Sense Reasoning for Deep Fake Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.033, \"y\": 5.807}, {\"title\": \"RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.127, \"y\": 4.66}, {\"title\": \"SpeechComposer: Unifying Multiple Speech Tasks with Prompt Composition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.722, \"y\": 5.541}, {\"title\": \"Enhancing End-to-End Multi-Task Dialogue Systems: A Study on Intrinsic  Motivation Reinforcement Learning Algorithms for Improved Training and  Adaptability\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.558, \"y\": 3.389}, {\"title\": \"Desiderata for the Context Use of Question Answering Systems\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.327, \"y\": 5.157}, {\"title\": \"LOCOST: State-Space Models for Long Document Abstractive Summarization\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.741, \"y\": 3.328}, {\"title\": \"Revisiting speech segmentation and lexicon learning with better features\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.833, \"y\": 5.082}, {\"title\": \"Employing Label Models on ChatGPT Answers Improves Legal Text Entailment  Performance\", \"topic\": \"Legal NLP\", \"x\": 5.336, \"y\": 5.466}, {\"title\": \"Uncertainty-Aware Explainable Recommendation with Large Language Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.988, \"y\": 2.913}, {\"title\": \"CauESC: A Causal Aware Model for Emotional Support Conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.575, \"y\": 7.842}, {\"title\": \"Enhancing Large Language Model with Decomposed Reasoning for Emotion  Cause Pair Extraction\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.418, \"y\": 7.714}, {\"title\": \"Deductive Beam Search: Decoding Deducible Rationale for Chain-of-Thought  Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.802, \"y\": 2.805}, {\"title\": \"What Do Self-Supervised Speech and Speaker Models Learn? New Findings  From a Cross Model Layer-Wise Analysis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.689, \"y\": 4.926}, {\"title\": \"Assertion Detection Large Language Model In-context Learning LoRA  Fine-tuning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.721, \"y\": 7.891}, {\"title\": \"Good at captioning, bad at counting: Benchmarking GPT-4V on Earth  observation data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.437, \"y\": 7.619}, {\"title\": \"Local and Global Contexts for Conversation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.515, \"y\": 3.979}, {\"title\": \"PipeNet: Question Answering with Semantic Pruning over Knowledge Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.896, \"y\": 5.665}, {\"title\": \"When Large Language Models Meet Vector Databases: A Survey\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.668, \"y\": 4.234}, {\"title\": \"Detecting mental disorder on social media: a ChatGPT-augmented  explainable approach\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.224, \"y\": 7.472}, {\"title\": \"Efficient Tool Use with Chain-of-Abstraction Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.512, \"y\": 2.426}, {\"title\": \"Synthetic Dialogue Dataset Generation using LLM Agents\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.339, \"y\": 3.809}, {\"title\": \"Arabic Tweet Act: A Weighted Ensemble Pre-Trained Transformer Model for  Classifying Arabic Speech Acts on Twitter\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.563, \"y\": 6.471}, {\"title\": \"Robust Prompt Optimization for Defending Language Models Against  Jailbreaking Attacks\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.333, \"y\": 2.344}, {\"title\": \"Weak-to-Strong Jailbreaking on Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.325, \"y\": 2.317}, {\"title\": \"MouSi: Poly-Visual-Expert Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.403, \"y\": 7.435}, {\"title\": \"Gazetteer-Enhanced Bangla Named Entity Recognition with BanglaBERT  Semantic Embeddings K-Means-Infused CRF Model\", \"topic\": \"Named Entity Recognition\", \"x\": 7.386, \"y\": 6.791}, {\"title\": \"Single Word Change is All You Need: Designing Attacks and Defenses for  Text Classifiers\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.144, \"y\": 3.026}, {\"title\": \"Conditional and Modal Reasoning in Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.529, \"y\": 3.253}, {\"title\": \"MT-Ranker: Reference-free machine translation evaluation by inter-system  ranking\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.822, \"y\": 4.72}, {\"title\": \"StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis\", \"topic\": \"Multimodal Language Models\", \"x\": 8.716, \"y\": 7.136}, {\"title\": \"CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented  Generation of Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.962, \"y\": 4.616}, {\"title\": \"Aalap: AI Assistant for Legal & Paralegal Functions in India\", \"topic\": \"Legal NLP\", \"x\": 5.26, \"y\": 5.308}, {\"title\": \"Cross-Lingual Transfer from Related Languages: Treating Low-Resource  Maltese as Multilingual Code-Switching\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.44, \"y\": 4.914}, {\"title\": \"State Value Generation with Prompt Learning and Self-Training for  Low-Resource Dialogue State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.649, \"y\": 4.001}, {\"title\": \"Identifying False Content and Hate Speech in Sinhala YouTube Videos by  Analyzing the Audio\", \"topic\": \"Hate Speech Detection\", \"x\": 2.732, \"y\": 5.402}, {\"title\": \"Detecting Racist Text in Bengali: An Ensemble Deep Learning Framework\", \"topic\": \"Hate Speech Detection\", \"x\": 2.803, \"y\": 5.443}, {\"title\": \"Recent Advances in Hate Speech Moderation: Multimodality and the Role of  Large Models\", \"topic\": \"Hate Speech Detection\", \"x\": 2.803, \"y\": 5.3}, {\"title\": \"Recovering Mental Representations from Large Language Models with Markov  Chain Monte Carlo\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.371, \"y\": 3.165}, {\"title\": \"OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on  E-Branchformer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.102, \"y\": 5.196}, {\"title\": \"TeenyTinyLlama: open-source tiny language models trained in Brazilian  Portuguese\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.737, \"y\": 4.104}, {\"title\": \"Improving Reinforcement Learning from Human Feedback with Efficient  Reward Model Ensemble\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.197, \"y\": 1.451}, {\"title\": \"Massively Multilingual Text Translation For Low-Resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.644, \"y\": 4.738}, {\"title\": \"Leveraging Professional Radiologists' Expertise to Enhance LLMs'  Evaluation for Radiology Reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.1, \"y\": 8.506}, {\"title\": \"Beyond Image-Text Matching: Verb Understanding in Multimodal  Transformers Using Guided Masking\", \"topic\": \"Multimodal Language Models\", \"x\": 8.513, \"y\": 7.401}, {\"title\": \"Diverse, but Divisive: LLMs Can Exaggerate Gender Differences in Opinion  Related to Harms of Misinformation\", \"topic\": \"Bias in Language Models\", \"x\": 3.442, \"y\": 4.516}, {\"title\": \"SelectLLM: Can LLMs Select Important Instructions to Annotate?\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.17, \"y\": 2.391}, {\"title\": \"GuReT: Distinguishing Guilt and Regret related Text\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.446, \"y\": 7.396}, {\"title\": \"InternLM-XComposer2: Mastering Free-form Text-Image Composition and  Comprehension in Vision-Language Large Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.344, \"y\": 7.293}, {\"title\": \"ReGAL: Refactoring Programs to Discover Generalizable Abstractions\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.45, \"y\": 2.294}, {\"title\": \"Scaling Sparse Fine-Tuning to Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.13, \"y\": 2.225}, {\"title\": \"Iterative Data Smoothing: Mitigating Reward Overfitting and  Overoptimization in RLHF\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.179, \"y\": 1.452}, {\"title\": \"Machine Translation Meta Evaluation through Translation Accuracy  Challenge Sets\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.78, \"y\": 4.728}, {\"title\": \"GAPS: Geometry-Aware Problem Solver\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.07, \"y\": 2.876}, {\"title\": \"Capturing Pertinent Symbolic Features for Enhanced Content-Based  Misinformation Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.077, \"y\": 5.832}, {\"title\": \"Development and Testing of a Novel Large Language Model-Based Clinical  Decision Support Systems for Medication Safety in 12 Clinical Specialties\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.694, \"y\": 8.123}, {\"title\": \"Towards Red Teaming in Multimodal and Multilingual Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.496, \"y\": 4.933}, {\"title\": \"MultiMUC: Multilingual Template Filling on MUC-4\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.465, \"y\": 4.992}, {\"title\": \"LLaMandement: Large Language Models for Summarization of French  Legislative Proposals\", \"topic\": \"Legal NLP\", \"x\": 5.161, \"y\": 5.656}, {\"title\": \"X-PEFT: eXtremely Parameter-Efficient Fine-Tuning for Extreme  Multi-Profile Scenarios\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.975, \"y\": 2.31}, {\"title\": \"Beyond Direct Diagnosis: LLM-based Multi-Specialist Agent Consultation  for Automatic Diagnosis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.555, \"y\": 8.252}, {\"title\": \"Multilingual Text-to-Image Generation Magnifies Gender Stereotypes and  Prompt Engineering May Not Help You\", \"topic\": \"Bias in Language Models\", \"x\": 3.143, \"y\": 4.535}, {\"title\": \"Image-Text Out-Of-Context Detection Using Synthetic Multimodal  Misinformation\", \"topic\": \"Fake News Detection\", \"x\": 4.154, \"y\": 5.958}, {\"title\": \"Non-Fluent Synthetic Target-Language Data Improve Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.784, \"y\": 4.589}, {\"title\": \"Understanding the effects of word-level linguistic annotations in  under-resourced neural machine translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.684, \"y\": 4.593}, {\"title\": \"Credit Risk Meets Large Language Models: Building a Risk Indicator from  Loan Descriptions in P2P Lending\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.799, \"y\": 6.752}, {\"title\": \"Assistive Large Language Model Agents for Socially-Aware Negotiation  Dialogues\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.297, \"y\": 3.067}, {\"title\": \"NoFunEval: Funny How Code LMs Falter on Requirements Beyond Functional  Correctness\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.401, \"y\": 2.421}, {\"title\": \"VIALM: A Survey and Benchmark of Visually Impaired Assistance with Large  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.123, \"y\": 7.593}, {\"title\": \"E-EVAL: A Comprehensive Chinese K-12 Education Evaluation Benchmark for  Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.409, \"y\": 4.052}, {\"title\": \"Development and Testing of Retrieval Augmented Generation in Large  Language Models -- A Case Study Report\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.804, \"y\": 7.778}, {\"title\": \"Corrective Retrieval Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.044, \"y\": 4.707}, {\"title\": \"Muffin or Chihuahua? Challenging Multimodal Large Language Models with  Multipanel VQA\", \"topic\": \"Multimodal Language Models\", \"x\": 8.033, \"y\": 7.806}, {\"title\": \"UnMASKed: Quantifying Gender Biases in Masked Language Models through  Linguistically Informed Job Market Prompts\", \"topic\": \"Bias in Language Models\", \"x\": 3.155, \"y\": 4.394}, {\"title\": \"Fine-Tuned Large Language Models for Symptom Recognition from Spanish  Clinical Text\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.406, \"y\": 8.02}, {\"title\": \"cantnlp@LT-EDI-2024: Automatic Detection of Anti-LGBTQ+ Hate Speech in  Under-resourced Languages\", \"topic\": \"Hate Speech Detection\", \"x\": 2.821, \"y\": 5.442}, {\"title\": \"PILOT: Legal Case Outcome Prediction with Case Law\", \"topic\": \"Legal NLP\", \"x\": 5.093, \"y\": 5.761}, {\"title\": \"Check News in One Click: NLP-Empowered Pro-Kremlin Propaganda Detection\", \"topic\": \"Fake News Detection\", \"x\": 3.937, \"y\": 5.887}, {\"title\": \"RecDCL: Dual Contrastive Learning for Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.867, \"y\": 2.888}, {\"title\": \"C Analyzer : A Static Program Analysis Tool for C Programs\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.441, \"y\": 2.641}, {\"title\": \"TA&AT: Enhancing Task-Oriented Dialog with Turn-Level Auxiliary Tasks  and Action-Tree Based Scheduled Sampling\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.455, \"y\": 3.667}, {\"title\": \"Evaluating LLM -- Generated Multimodal Diagnosis from Medical Images and  Symptom Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.127, \"y\": 8.396}, {\"title\": \"Contextualization Distillation from Large Language Model for Knowledge  Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.06, \"y\": 5.914}, {\"title\": \"Evaluating Gender Bias in Large Language Models via Chain-of-Thought  Prompting\", \"topic\": \"Bias in Language Models\", \"x\": 3.4, \"y\": 4.196}, {\"title\": \"MunTTS: A Text-to-Speech System for Mundari\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.367, \"y\": 5.478}, {\"title\": \"PPM: Automated Generation of Diverse Programming Problems for  Benchmarking Code Generation Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.367, \"y\": 2.421}, {\"title\": \"Quantifying Stereotypes in Language\", \"topic\": \"Bias in Language Models\", \"x\": 3.361, \"y\": 4.449}, {\"title\": \"Style-News: Incorporating Stylized News Generation and Adversarial  Verification for Neural Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.011, \"y\": 5.694}, {\"title\": \"Semantic Properties of cosine based bias scores for word embeddings\", \"topic\": \"Bias in Language Models\", \"x\": 3.342, \"y\": 4.599}, {\"title\": \"Navigating the Post-API Dilemma | Search Engine Results Pages Present a  Biased View of Social Media Data\", \"topic\": \"Fake News Detection\", \"x\": 3.826, \"y\": 6.178}, {\"title\": \"To Burst or Not to Burst: Generating and Quantifying Improbable Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.309, \"y\": 4.724}, {\"title\": \"DataFrame QA: A Universal LLM Framework on DataFrame Question Answering  Without Data Exposure\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.525, \"y\": 5.354}, {\"title\": \"Learning to Trust Your Feelings: Leveraging Self-awareness in LLMs for  Hallucination Mitigation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.492, \"y\": 1.341}, {\"title\": \"Pre-training and Diagnosing Knowledge Base Completion Models\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.084, \"y\": 5.9}, {\"title\": \"AI Does Not Alter Perceptions of Text Messages\", \"topic\": \"Bias in Language Models\", \"x\": 4.626, \"y\": 4.165}, {\"title\": \"FaKnow: A Unified Library for Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.049, \"y\": 5.839}, {\"title\": \"MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop  Queries\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.866, \"y\": 4.861}, {\"title\": \"LegalDuet: Learning Effective Representations for Legal Judgment  Prediction through a Dual-View Legal Clue Reasoning\", \"topic\": \"Legal NLP\", \"x\": 5.082, \"y\": 5.733}, {\"title\": \"Importance-Aware Data Augmentation for Document-Level Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.877, \"y\": 4.327}, {\"title\": \"A Comprehensive Survey of Compression Algorithms for Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.64, \"y\": 2.592}, {\"title\": \"Equipping Language Models with Tool Use Capability for Tabular Data  Analysis in Finance\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.865, \"y\": 6.851}, {\"title\": \"CERM: Context-aware Literature-based Discovery via Sentiment Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.265, \"y\": 7.529}, {\"title\": \"Improving Medical Reasoning through Retrieval and Self-Reflection with  Retrieval-Augmented Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.972, \"y\": 7.672}, {\"title\": \"Transfer Learning for the Prediction of Entity Modifiers in Clinical  Text: Application to Opioid Use Disorder Case Detection\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.909, \"y\": 8.112}, {\"title\": \"HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.126, \"y\": 2.266}, {\"title\": \"LongFin: A Multimodal Document Understanding Model for Long Financial  Domain Documents\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.05, \"y\": 6.842}, {\"title\": \"Airavata: Introducing Hindi Instruction-tuned LLM\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.846, \"y\": 4.749}, {\"title\": \"Comparison of parameters of vowel sounds of russian and english  languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.745, \"y\": 5.388}, {\"title\": \"The Power of Noise: Redefining Retrieval for RAG Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.013, \"y\": 4.664}, {\"title\": \"F-Eval: Asssessing Fundamental Abilities with Refined Evaluation Methods\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.366, \"y\": 3.781}, {\"title\": \"Large Language Model Adaptation for Financial Sentiment Analysis\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.84, \"y\": 6.912}, {\"title\": \"Bloom-epistemic and sentiment analysis hierarchical classification in  course discussion forums\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.74, \"y\": 6.604}, {\"title\": \"MasonTigers@LT-EDI-2024: An Ensemble Approach Towards Detecting  Homophobia and Transphobia in Social Media Comments\", \"topic\": \"Hate Speech Detection\", \"x\": 2.93, \"y\": 5.537}, {\"title\": \"MaLLaM -- Malaysia Large Language Model\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.669, \"y\": 4.144}, {\"title\": \"UNIT-DSR: Dysarthric Speech Reconstruction System Using Speech Unit  Normalization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.268, \"y\": 5.483}, {\"title\": \"A Korean Legal Judgment Prediction Dataset for Insurance Disputes\", \"topic\": \"Legal NLP\", \"x\": 5.105, \"y\": 5.813}, {\"title\": \"Toward Practical Automatic Speech Recognition and Post-Processing: a  Call for Explainable Error Benchmark Guideline\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.154, \"y\": 5.454}, {\"title\": \"Alternative Speech: Complementary Method to Counter-Narrative for Better  Discourse\", \"topic\": \"Hate Speech Detection\", \"x\": 2.715, \"y\": 5.295}, {\"title\": \"Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using  Large Language Models to Mitigate Cognitive Bias\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.592, \"y\": 8.265}, {\"title\": \"Evaluating GPT-3.5's Awareness and Summarization Abilities for European  Constitutional Texts with Shared Topics\", \"topic\": \"Legal NLP\", \"x\": 4.989, \"y\": 5.797}, {\"title\": \"Prompting Large Language Models for Zero-Shot Clinical Prediction with  Structured Longitudinal Electronic Health Record Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.806, \"y\": 8.206}, {\"title\": \"K-QA: A Real-World Medical Q&A Benchmark\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.841, \"y\": 7.61}, {\"title\": \"LongHealth: A Question Answering Benchmark with Long Clinical Documents\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.732, \"y\": 7.94}, {\"title\": \"Modular Adaptation of Multilingual Encoders to Written Swiss German  Dialect\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.431, \"y\": 5.047}, {\"title\": \"Wordflow: Social Prompt Engineering for Large Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 5.998, \"y\": 3.75}, {\"title\": \"Socially Aware Synthetic Data Generation for Suicidal Ideation Detection  Using Large Language Models\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.24, \"y\": 7.435}, {\"title\": \"A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis  on Noisy Bangla Texts\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.416, \"y\": 6.561}, {\"title\": \"Demystifying Chains, Trees, and Graphs of Thoughts\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.721, \"y\": 2.77}, {\"title\": \"RomanSetu: Efficiently unlocking multilingual capabilities of Large  Language Models via Romanization\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.17, \"y\": 4.577}, {\"title\": \"Transformers and Cortical Waves: Encoders for Pulling In Context Across  Time\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.607, \"y\": 3.47}, {\"title\": \"Improving Natural Language Capability of Code Large Language Model\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.545, \"y\": 2.518}, {\"title\": \"Enhanced Labeling Technique for Reddit Text and Fine-Tuned Longformer  Models for Classifying Depression Severity in English and Luganda\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.168, \"y\": 7.441}, {\"title\": \"Commonsense-augmented Memory Construction and Management in Long-term  Conversations via Context-aware Persona Refinement\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.356, \"y\": 3.657}, {\"title\": \"DeepSeek-Coder: When the Large Language Model Meets Programming -- The  Rise of Code Intelligence\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.743, \"y\": 2.576}, {\"title\": \"Parameter-Efficient Conversational Recommender System as a Language  Processing Task\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.922, \"y\": 3.077}, {\"title\": \"BayesPrompt: Prompting Large-Scale Pre-Trained Language Models on  Few-shot Inference via Debiased Domain Abstraction\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.725, \"y\": 3.41}, {\"title\": \"Convolutional Neural Networks can achieve binary bail judgement  classification\", \"topic\": \"Legal NLP\", \"x\": 4.908, \"y\": 5.758}, {\"title\": \"CompactifAI: Extreme Compression of Large Language Models using  Quantum-Inspired Tensor Networks\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.713, \"y\": 2.342}, {\"title\": \"Towards Goal-oriented Prompt Engineering for Large Language Models: A  Survey\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.222, \"y\": 3.189}, {\"title\": \"Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent  Self-Evolution\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.729, \"y\": 2.488}, {\"title\": \"A comparative study of zero-shot inference with large language models  and supervised modeling in breast cancer pathology classification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.854, \"y\": 7.994}, {\"title\": \"Beyond Behaviorist Representational Harms: A Plan for Measurement and  Mitigation\", \"topic\": \"Bias in Language Models\", \"x\": 3.397, \"y\": 4.228}, {\"title\": \"Unmasking and Quantifying Racial Bias of Large Language Models in  Medical Report Generation\", \"topic\": \"Bias in Language Models\", \"x\": 3.357, \"y\": 4.452}, {\"title\": \"TPD: Enhancing Student Language Model Reasoning via Principle Discovery  and Guidance\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.72, \"y\": 2.559}, {\"title\": \"States as Strings as Strategies: Steering Language Models with  Game-Theoretic Solvers\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.47, \"y\": 3.053}, {\"title\": \"A Unified Approach to Emotion Detection and Task-Oriented Dialogue  Modeling\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.306, \"y\": 7.782}, {\"title\": \"Fluent dreaming for language models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.471, \"y\": 3.103}, {\"title\": \"Consistency Guided Knowledge Retrieval and Denoising in LLMs for  Zero-shot Document-level Relation Triplet Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.868, \"y\": 6.627}, {\"title\": \"Graph Guided Question Answer Generation for Procedural  Question-Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.276, \"y\": 5.294}, {\"title\": \"Evaluation of General Large Language Models in Contextually Assessing  Semantic Concepts Extracted from Adult Critical Care Electronic Health Record  Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.607, \"y\": 7.951}, {\"title\": \"Large Malaysian Language Model Based on Mistral for Enhanced Local  Language Understanding\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.726, \"y\": 4.179}, {\"title\": \"SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.44, \"y\": 5.658}, {\"title\": \"Can GPT-3.5 Generate and Code Discharge Summaries?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.924, \"y\": 8.332}, {\"title\": \"How AI Ideas Affect the Creativity, Diversity, and Evolution of Human  Ideas: Evidence From a Large, Dynamic Experiment\", \"topic\": \"Bias in Language Models\", \"x\": 4.862, \"y\": 4.384}, {\"title\": \"Question answering systems for health professionals at the point of care  -- a systematic review\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.801, \"y\": 7.618}, {\"title\": \"Large language model empowered participatory urban planning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.686, \"y\": 2.864}, {\"title\": \"APT-Pipe: A Prompt-Tuning Tool for Social Data Annotation using ChatGPT\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.583, \"y\": 3.275}, {\"title\": \"InstructDoc: A Dataset for Zero-Shot Generalization of Visual Document  Understanding with Instructions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.094, \"y\": 7.124}, {\"title\": \"MaLA-500: Massive Language Adaptation of Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.039, \"y\": 4.249}, {\"title\": \"Towards Explainable Harmful Meme Detection through Multimodal Debate  between Large Language Models\", \"topic\": \"Hate Speech Detection\", \"x\": 3.006, \"y\": 5.598}, {\"title\": \"MF-AED-AEC: Speech Emotion Recognition by Leveraging Multimodal Fusion,  Asr Error Detection, and Asr Error Correction\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.234, \"y\": 7.768}, {\"title\": \"Better Call GPT, Comparing Large Language Models Against Lawyers\", \"topic\": \"Legal NLP\", \"x\": 5.191, \"y\": 5.3}, {\"title\": \"Language-Guided World Models: A Model-Based Approach to AI Control\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.748, \"y\": 2.574}, {\"title\": \"MLLMReID: Multimodal Large Language Model-based Person Re-identification\", \"topic\": \"Multimodal Language Models\", \"x\": 8.252, \"y\": 7.237}, {\"title\": \"CFMatch: Aligning Automated Answer Equivalence Evaluation with Expert  Judgments For Open-Domain Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.283, \"y\": 4.801}, {\"title\": \"Misgendering and Assuming Gender in Machine Translation when Working  with Low-Resource Languages\", \"topic\": \"Bias in Language Models\", \"x\": 2.997, \"y\": 4.369}, {\"title\": \"Locality enhanced dynamic biasing and sampling strategies for contextual  ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.383, \"y\": 5.046}, {\"title\": \"ARGS: Alignment as Reward-Guided Search\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.376, \"y\": 1.35}, {\"title\": \"Analyzing COVID-19 Vaccination Sentiments in Nigerian Cyberspace:  Insights from a Manually Annotated Twitter Dataset\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.099, \"y\": 6.825}, {\"title\": \"Quality of Answers of Generative Large Language Models vs Peer Patients  for Interpreting Lab Test Results for Lay Patients: Evaluation Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.574, \"y\": 8.083}, {\"title\": \"Maximizing Data Efficiency for Cross-Lingual TTS Adaptation by  Self-Supervised Representation Mixing and Embedding Initialization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.72, \"y\": 5.129}, {\"title\": \"HAZARD Challenge: Embodied Decision Making in Dynamically Changing  Environments\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.589, \"y\": 2.529}, {\"title\": \"Raidar: geneRative AI Detection viA Rewriting\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.155, \"y\": 4.619}, {\"title\": \"Transformer-Based Models Are Not Yet Perfect At Learning to Emulate  Structural Recursion\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.139, \"y\": 3.716}, {\"title\": \"Multicultural Name Recognition For Previously Unseen Names\", \"topic\": \"Named Entity Recognition\", \"x\": 7.45, \"y\": 6.844}, {\"title\": \"Red Teaming Visual Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.413, \"y\": 7.752}, {\"title\": \"From Understanding to Utilization: A Survey on Explainability for Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.062, \"y\": 3.729}, {\"title\": \"Improving Machine Translation with Human Feedback: An Exploration of  Quality Estimation as a Reward Model\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.411, \"y\": 1.308}, {\"title\": \"Multilingual and Fully Non-Autoregressive ASR with Large Language Model  Fusion: A Comprehensive Study\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.195, \"y\": 5.19}, {\"title\": \"Context Matters: Pushing the Boundaries of Open-Ended Answer Generation  with Graph-Structured Knowledge Context\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.737, \"y\": 5.363}, {\"title\": \"LLMCheckup: Conversational Examination of Large Language Models via  Interpretability Tools and Self-Explanations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.825, \"y\": 3.766}, {\"title\": \"DREditor: An Time-efficient Approach for Building a Domain-specific  Dense Retrieval Model\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.601, \"y\": 5.007}, {\"title\": \"Large Language Models are Superpositions of All Characters: Attaining  Arbitrary Role-play via Self-Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.356, \"y\": 1.962}, {\"title\": \"Contrastive Learning in Distilled Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.481, \"y\": 3.984}, {\"title\": \"Fast Adversarial Training against Textual Adversarial Attacks\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.108, \"y\": 3.019}, {\"title\": \"The Neglected Tails in Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.652, \"y\": 7.348}, {\"title\": \"How Far Can 100 Samples Go? Unlocking Overall Zero-Shot Multilingual  Translation via Tiny Multi-Parallel Data\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.623, \"y\": 4.628}, {\"title\": \"Enhancing In-context Learning via Linear Probe Calibration\", \"topic\": \"In-Context Learning\", \"x\": 8.283, \"y\": 3.322}, {\"title\": \"CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.29, \"y\": 8.663}, {\"title\": \"APT: Adaptive Pruning and Tuning Pretrained Language Models for  Efficient Training and Inference\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.026, \"y\": 2.396}, {\"title\": \"WARM: On the Benefits of Weight Averaged Reward Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.173, \"y\": 1.431}, {\"title\": \"SpatialVLM: Endowing Vision-Language Models with Spatial Reasoning  Capabilities\", \"topic\": \"Multimodal Language Models\", \"x\": 8.486, \"y\": 7.692}, {\"title\": \"Anisotropy Is Inherent to Self-Attention in Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.41, \"y\": 3.542}, {\"title\": \"The Curious Case of Nonverbal Abstract Reasoning with Multi-Modal Large  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.969, \"y\": 7.608}, {\"title\": \"An Empirical Study of In-context Learning in LLMs for Machine  Translation\", \"topic\": \"In-Context Learning\", \"x\": 8.546, \"y\": 3.425}, {\"title\": \"Revisiting Demonstration Selection Strategies in In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.259, \"y\": 3.445}, {\"title\": \"West-of-N: Synthetic Preference Generation for Improved Reward Modeling\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.26, \"y\": 1.41}, {\"title\": \"Cross-lingual Transfer Learning for Javanese Dependency Parsing\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.114, \"y\": 4.985}, {\"title\": \"Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated  Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.083, \"y\": 4.751}, {\"title\": \"Applications, challenges and ethical issues of AI and ChatGPT in  education\", \"topic\": \"Bias in Language Models\", \"x\": 4.82, \"y\": 4.394}, {\"title\": \"CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding  Benchmark\", \"topic\": \"Multimodal Language Models\", \"x\": 7.817, \"y\": 7.525}, {\"title\": \"Benchmarking Large Multimodal Models against Common Corruptions\", \"topic\": \"Multimodal Language Models\", \"x\": 7.895, \"y\": 7.577}, {\"title\": \"Distilling Mathematical Reasoning Capabilities into Small Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.941, \"y\": 2.386}, {\"title\": \"The Right Model for the Job: An Evaluation of Legal Multi-Label  Classification Baselines\", \"topic\": \"Legal NLP\", \"x\": 5.24, \"y\": 5.863}, {\"title\": \"SuperCLUE-Math6: Graded Multi-Step Math Reasoning Benchmark for LLMs in  Chinese\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.812, \"y\": 3.074}, {\"title\": \"Hallucination is Inevitable: An Innate Limitation of Large Language  Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.147, \"y\": 1.094}, {\"title\": \"SemPLeS: Semantic Prompt Learning for Weakly-Supervised Semantic  Segmentation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.519, \"y\": 6.925}, {\"title\": \"A Framework to Implement 1+N Multi-task Fine-tuning Pattern in LLMs  Using the CGC-LORA Algorithm\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.0, \"y\": 2.26}, {\"title\": \"Community-based Behavioral Understanding of Crisis Activity Concerns  using Social Media Data: A Study on the 2023 Canadian Wildfires in New York  City\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.023, \"y\": 6.574}, {\"title\": \"Streaming Bilingual End-to-End ASR model using Attention over Multiple  Softmax\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.388, \"y\": 5.136}, {\"title\": \"Revolutionizing Finance with LLMs: An Overview of Applications and  Insights\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.849, \"y\": 6.827}, {\"title\": \"Text-to-Image Cross-Modal Generation: A Systematic Review\", \"topic\": \"Multimodal Language Models\", \"x\": 8.199, \"y\": 7.001}, {\"title\": \"Freely Long-Thinking Transformer (FraiLT)\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.829, \"y\": 3.286}, {\"title\": \"Large Language Model based Multi-Agents: A Survey of Progress and  Challenges\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.658, \"y\": 2.853}, {\"title\": \"In-context Learning with Retrieved Demonstrations for Language Models: A  Survey\", \"topic\": \"In-Context Learning\", \"x\": 8.193, \"y\": 3.487}, {\"title\": \"Robust Evaluation Measures for Evaluating Social Biases in Masked  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.365, \"y\": 4.428}, {\"title\": \"CheX-GPT: Harnessing Large Language Models for Enhanced Chest X-ray  Report Labeling\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.21, \"y\": 8.604}, {\"title\": \"Over-Reasoning and Redundant Calculation of Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.82, \"y\": 3.13}, {\"title\": \"Linear Alignment: A Closed-form Solution for Aligning Human Preferences  without Tuning and Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.329, \"y\": 1.371}, {\"title\": \"Majority or Minority: Data Imbalance Learning Method for Named Entity  Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.456, \"y\": 6.809}, {\"title\": \"MedLM: Exploring Language Models for Medical Question Answering Systems\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.824, \"y\": 7.847}, {\"title\": \"Using Large Language Model for End-to-End Chinese ASR and NER\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.062, \"y\": 5.135}, {\"title\": \"Finding a Needle in the Adversarial Haystack: A Targeted Paraphrasing  Approach For Uncovering Edge Cases with Minimal Distribution Distortion\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.165, \"y\": 3.049}, {\"title\": \"Confidence Preservation Property in Knowledge Distillation Abstractions\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.556, \"y\": 3.802}, {\"title\": \"Identifying and Analyzing Task-Encoding Tokens in Large Language Models\", \"topic\": \"In-Context Learning\", \"x\": 8.484, \"y\": 3.475}, {\"title\": \"PRILoRA: Pruned and Rank-Increasing Low-Rank Adaptation\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.221, \"y\": 2.097}, {\"title\": \"Word-Level ASR Quality Estimation for Efficient Corpus Sampling and  Post-Editing through Analyzing Attentions of a Reference-Free Metric\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.205, \"y\": 5.372}, {\"title\": \"STICKERCONV: Generating Multimodal Empathetic Responses from Scratch\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.688, \"y\": 7.875}, {\"title\": \"Orion-14B: Open-source Multilingual Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.793, \"y\": 4.258}, {\"title\": \"Unfair TOS: An Automated Approach using Customized BERT\", \"topic\": \"Legal NLP\", \"x\": 4.739, \"y\": 5.48}, {\"title\": \"Gaussian Adaptive Attention is All You Need: Robust Contextual  Representations Across Multiple Modalities\", \"topic\": \"Efficient Transformer Models\", \"x\": 3.486, \"y\": 7.532}, {\"title\": \"Enhancing Large Language Models for Clinical Decision Support by  Incorporating Clinical Practice Guidelines\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.576, \"y\": 8.221}, {\"title\": \"Exploiting Duality in Open Information Extraction with Predicate Prompt\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.897, \"y\": 6.562}, {\"title\": \"Evaluating and Enhancing Large Language Models Performance in  Domain-specific Medicine: Osteoarthritis Management with DocOA\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.681, \"y\": 7.988}, {\"title\": \"PubTator 3.0: an AI-powered Literature Resource for Unlocking Biomedical  Knowledge\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.203, \"y\": 7.474}, {\"title\": \"FAIR Enough: How Can We Develop and Assess a FAIR-Compliant Dataset for  Large Language Models' Training?\", \"topic\": \"Bias in Language Models\", \"x\": 3.582, \"y\": 4.13}, {\"title\": \"Analysis and Detection of Multilingual Hate Speech Using Transformer  Based Deep Learning\", \"topic\": \"Hate Speech Detection\", \"x\": 2.781, \"y\": 5.452}, {\"title\": \"The Radiation Oncology NLP Database\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.899, \"y\": 7.808}, {\"title\": \"Reinforcement learning for question answering in programming domain  using public community scoring as a human feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.169, \"y\": 1.514}, {\"title\": \"Advancements in eHealth Data Analytics through Natural Language  Processing and Deep Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.547, \"y\": 7.779}, {\"title\": \"Using LLMs to discover emerging coded antisemitic hate-speech in  extremist social media\", \"topic\": \"Hate Speech Detection\", \"x\": 2.857, \"y\": 5.458}, {\"title\": \"A survey on recent advances in named entity recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.312, \"y\": 6.789}, {\"title\": \"Knowledge Verification to Nip Hallucination in the Bud\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.301, \"y\": 1.203}, {\"title\": \"Combining topic modelling and citation network analysis to study case  law from the European Court on Human Rights on the right to respect for  private and family life\", \"topic\": \"Legal NLP\", \"x\": 5.122, \"y\": 5.819}, {\"title\": \"Q&A Prompts: Discovering Rich Visual Clues through Mining  Question-Answer Prompts for VQA requiring Diverse World Knowledge\", \"topic\": \"Multimodal Language Models\", \"x\": 8.116, \"y\": 8.018}, {\"title\": \"Weakly Supervised Gaussian Contrastive Grounding with Large Multimodal  Models for Video Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.728, \"y\": 7.984}, {\"title\": \"A Simple Framework to Accelerate Multilingual Language Model for  Monolingual Text Generation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.305, \"y\": 4.575}, {\"title\": \"Attentive Fusion: A Transformer-based Approach to Multimodal Hate Speech  Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.767, \"y\": 5.428}, {\"title\": \"PHOENIX: Open-Source Language Adaption for Direct Preference  Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.368, \"y\": 1.27}, {\"title\": \"Multilingual acoustic word embeddings for zero-resource languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.505, \"y\": 5.183}, {\"title\": \"Progressive Distillation Based on Masked Generation Feature Method for  Knowledge Graph Completion\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.621, \"y\": 3.855}, {\"title\": \"Speech Swin-Transformer: Exploring a Hierarchical Transformer with  Shifted Windows for Speech Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.193, \"y\": 7.865}, {\"title\": \"The \\\"Colonial Impulse\\\" of Natural Language Processing: An Audit of  Bengali Sentiment Analysis Tools and Their Identity-based Biases\", \"topic\": \"Bias in Language Models\", \"x\": 3.521, \"y\": 4.817}, {\"title\": \"Mementos: A Comprehensive Benchmark for Multimodal Large Language Model  Reasoning over Image Sequences\", \"topic\": \"Multimodal Language Models\", \"x\": 8.058, \"y\": 7.711}, {\"title\": \"Cross-lingual Editing in Multilingual Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.224, \"y\": 4.42}, {\"title\": \"FinSQL: Model-Agnostic LLMs-based Text-to-SQL Framework for Financial  Analysis\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.934, \"y\": 6.828}, {\"title\": \"Generative Dense Retrieval: Memory Can Be a Burden\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.537, \"y\": 4.989}, {\"title\": \"Escape Sky-high Cost: Early-stopping Self-Consistency for Multi-step  Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.748, \"y\": 2.291}, {\"title\": \"Named Entity Recognition Under Domain Shift via Metric Learning for Life  Sciences\", \"topic\": \"Named Entity Recognition\", \"x\": 7.177, \"y\": 6.903}, {\"title\": \"Data-driven grapheme-to-phoneme representations for a lexicon-free  text-to-speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.831, \"y\": 5.392}, {\"title\": \"Contextualized Automatic Speech Recognition with Attention-Based Bias  Phrase Boosted Beam Search\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.425, \"y\": 5.019}, {\"title\": \"Large Language Models are Efficient Learners of Noise-Robust Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.986, \"y\": 5.281}, {\"title\": \"Breaking the Curse of Multilinguality with Cross-lingual Expert Language  Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.315, \"y\": 4.539}, {\"title\": \"Inconsistent dialogue responses and how to recover from them\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.365, \"y\": 4.036}, {\"title\": \"Bridging Cultural Nuances in Dialogue Agents through Cultural Value  Surveys\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.947, \"y\": 3.766}, {\"title\": \"MM-Interleaved: Interleaved Image-Text Generative Modeling via  Multi-modal Feature Synchronizer\", \"topic\": \"Multimodal Language Models\", \"x\": 8.497, \"y\": 7.055}, {\"title\": \"A Comparison of Veterans with Problematic Opioid Use Identified through  Natural Language Processing of Clinical Notes versus Using Diagnostic Codes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.336, \"y\": 7.87}, {\"title\": \"Adapters Mixup: Mixing Parameter-Efficient Adapters to Enhance the  Adversarial Robustness of Fine-tuned Pre-trained Text Classifiers\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.177, \"y\": 3.114}, {\"title\": \"Power in Numbers: Robust reading comprehension by finetuning with four  adversarial sentences per example\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.084, \"y\": 3.089}, {\"title\": \"Harmonizing Code-mixed Conversations: Personality-assisted Code-mixed  Response Generation in Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.187, \"y\": 3.871}, {\"title\": \"Gender Bias in Machine Translation and The Era of Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.096, \"y\": 4.389}, {\"title\": \"Towards Hierarchical Spoken Language Dysfluency Modeling\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.109, \"y\": 5.71}, {\"title\": \"Advancing Large Multi-modal Models with Explicit Chain-of-Reasoning and  Visual Question Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.234, \"y\": 7.913}, {\"title\": \"Distantly Supervised Morpho-Syntactic Model for Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.856, \"y\": 6.856}, {\"title\": \"Better Explain Transformers by Illuminating Important Information\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.548, \"y\": 3.457}, {\"title\": \"Veagle: Advancements in Multimodal Representation Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.427, \"y\": 7.507}, {\"title\": \"Meme-ingful Analysis: Enhanced Understanding of Cyberbullying in Memes  Through Multimodal Explanations\", \"topic\": \"Hate Speech Detection\", \"x\": 2.952, \"y\": 5.748}, {\"title\": \"Attention-Based Recurrent Neural Network For Automatic Behavior Laying  Hen Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.121, \"y\": 5.297}, {\"title\": \"Evolutionary Multi-Objective Optimization of Large Language Model  Prompts for Balancing Sentiments\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.313, \"y\": 3.178}, {\"title\": \"All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.34, \"y\": 2.212}, {\"title\": \"Controllable Decontextualization of Yes/No Question and Answers into  Factual Statements\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.281, \"y\": 5.166}, {\"title\": \"On the Audio Hallucinations in Large Audio-Video Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.174, \"y\": 1.067}, {\"title\": \"Interplay of Semantic Communication and Knowledge Learning\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.124, \"y\": 5.89}, {\"title\": \"Automated Scoring of Clinical Patient Notes using Advanced NLP and  Pseudo Labeling\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.556, \"y\": 8.096}, {\"title\": \"Predicting Viral Rumors and Vulnerable Users for Infodemic Surveillance\", \"topic\": \"Fake News Detection\", \"x\": 4.014, \"y\": 6.057}, {\"title\": \"Curriculum Recommendations Using Transformer Base Model with InfoNCE  Loss And Language Switching Method\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.893, \"y\": 2.978}, {\"title\": \"Impact of Large Language Model Assistance on Patients Reading Clinical  Notes: A Mixed-Methods Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.58, \"y\": 8.091}, {\"title\": \"Aligning Large Language Models with Counterfactual DPO\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.357, \"y\": 1.342}, {\"title\": \"BERTologyNavigator: Advanced Question Answering with BERT-based  Semantics\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.607, \"y\": 5.499}, {\"title\": \"Deciphering Textual Authenticity: A Generalized Strategy through the  Lens of Large Language Semantics for Detecting Human vs. Machine-Generated  Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.046, \"y\": 4.855}, {\"title\": \"Evaluating LLMs' Mathematical and Coding Competency through  Ontology-guided Interventions\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.948, \"y\": 2.816}, {\"title\": \"SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.772, \"y\": 7.332}, {\"title\": \"Machines Do See Color: A Guideline to Classify Different Forms of Racist  Discourse in Large Corpora\", \"topic\": \"Hate Speech Detection\", \"x\": 2.764, \"y\": 5.415}, {\"title\": \"Cross-lingual Offensive Language Detection: A Systematic Review of  Datasets, Transfer Approaches and Challenges\", \"topic\": \"Hate Speech Detection\", \"x\": 2.815, \"y\": 5.345}, {\"title\": \"Estimating the severity of dental and oral problems via sentiment  classification over clinical reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.809, \"y\": 8.324}, {\"title\": \"UniVIE: A Unified Label Space Approach to Visual Information Extraction  from Form-like Documents\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.178, \"y\": 6.835}, {\"title\": \"RELIANCE: Reliable Ensemble Learning for Information and News  Credibility Evaluation\", \"topic\": \"Fake News Detection\", \"x\": 4.214, \"y\": 5.782}, {\"title\": \"QAnswer: Towards Question Answering Search over Websites\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.414, \"y\": 5.364}, {\"title\": \"TranSentence: Speech-to-speech Translation via Language-agnostic  Sentence-level Speech Encoding without Language-parallel Data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.465, \"y\": 5.335}, {\"title\": \"Bridging Research and Readers: A Multi-Modal Automated Academic Papers  Interpretation System\", \"topic\": \"Text Summarization\", \"x\": 5.927, \"y\": 6.19}, {\"title\": \"LLMs for Relational Reasoning: How Far are We?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.653, \"y\": 3.046}, {\"title\": \"Textual Summarisation of Large Sets: Towards a General Approach\", \"topic\": \"Text Summarization\", \"x\": 5.623, \"y\": 6.4}, {\"title\": \"Explain Thyself Bully: Sentiment Aided Cyberbullying Detection with  Explanation\", \"topic\": \"Hate Speech Detection\", \"x\": 2.771, \"y\": 5.639}, {\"title\": \"Augmenting Math Word Problems via Iterative Question Composing\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.037, \"y\": 2.725}, {\"title\": \"AttackEval: How to Evaluate the Effectiveness of Jailbreak Attacking on  Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.298, \"y\": 2.289}, {\"title\": \"Efficient Adapter Finetuning for Tail Languages in Streaming  Multilingual ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.913, \"y\": 4.993}, {\"title\": \"OCTO+: A Suite for Automatic Open-Vocabulary Object Placement in Mixed  Reality\", \"topic\": \"Multimodal Language Models\", \"x\": 8.784, \"y\": 7.157}, {\"title\": \"ReFT: Reasoning with Reinforced Fine-Tuning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.819, \"y\": 2.276}, {\"title\": \"NOTSOFAR-1 Challenge: New Datasets, Baseline, and Tasks for Distant  Meeting Transcription\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.091, \"y\": 5.418}, {\"title\": \"Improving ASR Contextual Biasing with Guided Attention\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.377, \"y\": 5.049}, {\"title\": \"Revisiting Self-supervised Learning of Speech Representation from a  Mutual Information Perspective\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.781, \"y\": 4.983}, {\"title\": \"AiGen-FoodReview: A Multimodal Dataset of Machine-Generated Restaurant  Reviews and Images on Social Media\", \"topic\": \"Fake News Detection\", \"x\": 3.881, \"y\": 5.999}, {\"title\": \"MultiPLY: A Multisensory Object-Centric Embodied Large Language Model in  3D World\", \"topic\": \"Multimodal Language Models\", \"x\": 8.348, \"y\": 7.243}, {\"title\": \"Connect, Collapse, Corrupt: Learning Cross-Modal Tasks with Uni-Modal  Data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.55, \"y\": 7.123}, {\"title\": \"The Gaps between Pre-train and Downstream Settings in Bias Evaluation  and Debiasing\", \"topic\": \"In-Context Learning\", \"x\": 8.102, \"y\": 3.176}, {\"title\": \"EmoLLMs: A Series of Emotional Large Language Models and Annotation  Tools for Comprehensive Affective Analysis\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.452, \"y\": 7.65}, {\"title\": \"Code Generation with AlphaCodium: From Prompt Engineering to Flow  Engineering\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.346, \"y\": 2.432}, {\"title\": \"Large Language Models Portray Socially Subordinate Groups as More  Homogeneous, Consistent with a Bias Observed in Humans\", \"topic\": \"Bias in Language Models\", \"x\": 3.46, \"y\": 4.34}, {\"title\": \"Hidden Flaws Behind Expert-Level Accuracy of GPT-4 Vision in Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.449, \"y\": 8.228}, {\"title\": \"Into the crossfire: evaluating the use of a language model to  crowdsource gun violence reports\", \"topic\": \"Hate Speech Detection\", \"x\": 3.032, \"y\": 5.506}, {\"title\": \"DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language  Models (Exemplified as A Video Agent)\", \"topic\": \"Multimodal Language Models\", \"x\": 8.86, \"y\": 7.878}, {\"title\": \"Cross-lingual neural fuzzy matching for exploiting target-language  monolingual corpora in computer-aided translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.614, \"y\": 4.771}, {\"title\": \"Few-Shot Learning for Chronic Disease Management: Leveraging Large  Language Models and Multi-Prompt Engineering with Medical Knowledge Injection\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.665, \"y\": 8.195}, {\"title\": \"Hallucination Detection and Hallucination Mitigation: An Investigation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.148, \"y\": 1.097}, {\"title\": \"Salute the Classic: Revisiting Challenges of Machine Translation in the  Age of Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.759, \"y\": 4.389}, {\"title\": \"AesBench: An Expert Benchmark for Multimodal Large Language Models on  Image Aesthetics Perception\", \"topic\": \"Multimodal Language Models\", \"x\": 7.89, \"y\": 7.607}, {\"title\": \"Large Language Models are Null-Shot Learners\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.195, \"y\": 1.136}, {\"title\": \"A Generative Adversarial Attack for Multilingual Text Classifiers\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.151, \"y\": 3.061}, {\"title\": \"Generative Multi-Modal Knowledge Retrieval with Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.129, \"y\": 7.325}, {\"title\": \"MARIO: MAth Reasoning with code Interpreter Output -- A Reproducible  Pipeline\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.029, \"y\": 2.739}, {\"title\": \"PRewrite: Prompt Rewriting with Reinforcement Learning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.401, \"y\": 3.156}, {\"title\": \"TelME: Teacher-leading Multimodal Fusion Network for Emotion Recognition  in Conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.292, \"y\": 7.791}, {\"title\": \"Enhancing Document-level Translation of Large Language Model via  Translation Mixed-instructions\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.695, \"y\": 4.203}, {\"title\": \"Code-Based English Models Surprising Performance on Chinese QA Pair  Extraction Task\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.0, \"y\": 4.578}, {\"title\": \"Enhancing Robustness of LLM-Synthetic Text Detectors for Academic  Writing: A Comprehensive Analysis\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.157, \"y\": 4.688}, {\"title\": \"Self-Imagine: Effective Unimodal Reasoning with Multimodal Models using  Self-Imagination\", \"topic\": \"Multimodal Language Models\", \"x\": 8.19, \"y\": 7.728}, {\"title\": \"A Novel Approach for Automatic Program Repair using Round-Trip  Translation with Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.341, \"y\": 2.227}, {\"title\": \"SemEval-2017 Task 4: Sentiment Analysis in Twitter using BERT\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.532, \"y\": 6.523}, {\"title\": \"A Lexicon for Studying Radicalization in Incel Communities\", \"topic\": \"Hate Speech Detection\", \"x\": 3.12, \"y\": 5.252}, {\"title\": \"The Pitfalls of Defining Hallucination\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.154, \"y\": 1.068}, {\"title\": \"Learned Best-Effort LLM Serving\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 7.221, \"y\": 1.622}, {\"title\": \"The Chronicles of RAG: The Retriever, the Chunk and the Generator\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.043, \"y\": 4.606}, {\"title\": \"JumpCoder: Go Beyond Autoregressive Coder via Online Modification\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.624, \"y\": 2.247}, {\"title\": \"Consolidating Trees of Robotic Plans Generated Using Large Language  Models to Improve Reliability\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.896, \"y\": 2.533}, {\"title\": \"Milestones in Bengali Sentiment Analysis leveraging Transformer-models:  Fundamentals, Challenges and Future Directions\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.471, \"y\": 6.584}, {\"title\": \"Consolidating Strategies for Countering Hate Speech Using Persuasive  Dialogues\", \"topic\": \"Hate Speech Detection\", \"x\": 2.752, \"y\": 5.345}, {\"title\": \"The Effect of Human v/s Synthetic Test Data and Round-tripping on  Assessment of Sentiment Analysis Systems for Bias\", \"topic\": \"Bias in Language Models\", \"x\": 3.358, \"y\": 4.702}, {\"title\": \"Cascaded Cross-Modal Transformer for Audio-Textual Classification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.753, \"y\": 5.499}, {\"title\": \"Exploiting GPT-4 Vision for Zero-shot Point Cloud Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.883, \"y\": 7.213}, {\"title\": \"MM-SAP: A Comprehensive Benchmark for Assessing Self-Awareness of  Multimodal Large Language Models in Perception\", \"topic\": \"Multimodal Language Models\", \"x\": 7.931, \"y\": 7.703}, {\"title\": \"Developing ChatGPT for Biology and Medicine: A Complete Review of  Biomedical Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.901, \"y\": 7.593}, {\"title\": \"Only Send What You Need: Learning to Communicate Efficiently in  Federated Multilingual Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.779, \"y\": 4.228}, {\"title\": \"Leveraging the power of transformers for guilt detection in text\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.438, \"y\": 7.423}, {\"title\": \"Beyond Sparse Rewards: Enhancing Reinforcement Learning with Language  Model Critique in Text Generation\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.249, \"y\": 1.788}, {\"title\": \"PersonalityChat: Conversation Distillation for Personalized Dialog  Modeling with Facts and Traits\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.992, \"y\": 3.699}, {\"title\": \"Promptformer: Prompted Conformer Transducer for ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.2, \"y\": 5.15}, {\"title\": \"ELLA-V: Stable Neural Codec Language Modeling with Alignment-guided  Sequence Reordering\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.482, \"y\": 5.628}, {\"title\": \"Harnessing Large Language Models Over Transformer Models for Detecting  Bengali Depressive Social Media Text: A Comprehensive Study\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.15, \"y\": 7.431}, {\"title\": \"EHRAgent: Code Empowers Large Language Models for Few-shot Complex  Tabular Reasoning on Electronic Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.849, \"y\": 8.132}, {\"title\": \"xCoT: Cross-lingual Instruction Tuning for Cross-lingual  Chain-of-Thought Reasoning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.342, \"y\": 4.565}, {\"title\": \"Edge-Enabled Anomaly Detection and Information Completion for Social  Network Knowledge Graphs\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.81, \"y\": 6.022}, {\"title\": \"Knowledge Distillation for Closed-Source Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.526, \"y\": 3.815}, {\"title\": \"Joint Extraction of Uyghur Medicine Knowledge with Edge Computing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.254, \"y\": 7.522}, {\"title\": \"Joint Unsupervised and Supervised Training for Automatic Speech  Recognition via Bilevel Optimization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.075, \"y\": 5.063}, {\"title\": \"CHAMP: A Competition-level Dataset for Fine-Grained Analyses of LLMs'  Mathematical Reasoning Capabilities\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.926, \"y\": 2.88}, {\"title\": \"Bridging the Preference Gap between Retrievers and LLMs\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.012, \"y\": 4.495}, {\"title\": \"MiTTenS: A Dataset for Evaluating Misgendering in Translation\", \"topic\": \"Bias in Language Models\", \"x\": 3.0, \"y\": 4.41}, {\"title\": \"DocFinQA: A Long-Context Financial Reasoning Dataset\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.934, \"y\": 6.817}, {\"title\": \"Health-LLM: Large Language Models for Health Prediction via Wearable  Sensor Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.383, \"y\": 7.925}, {\"title\": \"Fine-grained Hallucination Detection and Editing for Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.146, \"y\": 1.037}, {\"title\": \"Machine Translation Models are Zero-Shot Detectors of Translation  Direction\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.821, \"y\": 4.485}, {\"title\": \"Mind Your Format: Towards Consistent Evaluation of In-Context Learning  Improvements\", \"topic\": \"In-Context Learning\", \"x\": 8.249, \"y\": 3.434}, {\"title\": \"Using Natural Language Inference to Improve Persona Extraction from  Dialogue in a New Domain\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.28, \"y\": 3.788}, {\"title\": \"LLM-Assisted Crisis Management: Building Advanced LLM Platforms for  Effective Emergency Response and Public Collaboration\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.212, \"y\": 6.744}, {\"title\": \"Few-Shot Detection of Machine-Generated Text using Style Representations\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.113, \"y\": 4.784}, {\"title\": \"Reliability Analysis of Psychological Concept Extraction and  Classification in User-penned Text\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.166, \"y\": 7.35}, {\"title\": \"Don't Rank, Combine! Combining Machine Translation Hypotheses Using  Quality Estimation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.917, \"y\": 4.521}, {\"title\": \"Enhancing Emotional Generation Capability of Large Language Models via  Emotional Chain-of-Thought\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.534, \"y\": 7.762}, {\"title\": \"OOP: Object-Oriented Programming Evaluation Benchmark for Large Language  Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.372, \"y\": 2.488}, {\"title\": \"TransliCo: A Contrastive Learning Framework to Address the Script  Barrier in Multilingual Pretrained Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.332, \"y\": 4.885}, {\"title\": \"Prometheus-Vision: Vision-Language Model as a Judge for Fine-Grained  Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.087, \"y\": 7.704}, {\"title\": \"Mapping Transformer Leveraged Embeddings for Cross-Lingual Document  Representation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.242, \"y\": 4.997}, {\"title\": \"XLS-R Deep Learning Model for Multilingual ASR on Low- Resource  Languages: Indonesian, Javanese, and Sundanese\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.158, \"y\": 5.486}, {\"title\": \"Lost in the Source Language: How Large Language Models Evaluate the  Quality of Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.46, \"y\": 4.179}, {\"title\": \"Intention Analysis Makes LLMs A Good Jailbreak Defender\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.267, \"y\": 2.22}, {\"title\": \"Medical Dialogue Generation via Intuitive-then-Analytical Differential  Diagnosis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.447, \"y\": 8.374}, {\"title\": \"MetaHate: A Dataset for Unifying Efforts on Hate Speech Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.725, \"y\": 5.35}, {\"title\": \"AntEval: Evaluation of Social Interaction Competencies in LLM-Driven  Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.253, \"y\": 3.164}, {\"title\": \"An investigation of structures responsible for gender bias in BERT and  DistilBERT\", \"topic\": \"Bias in Language Models\", \"x\": 3.277, \"y\": 4.338}, {\"title\": \"Kun: Answer Polishment for Chinese Self-Alignment with Instruction  Back-Translation\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.075, \"y\": 2.227}, {\"title\": \"Batch-ICL: Effective, Efficient, and Order-Agnostic In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.372, \"y\": 3.37}, {\"title\": \"PersianMind: A Cross-Lingual Persian-English Large Language Model\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.955, \"y\": 4.312}, {\"title\": \"BOK-VQA: Bilingual outside Knowledge-Based Visual Question Answering via  Graph Representation Pretraining\", \"topic\": \"Multimodal Language Models\", \"x\": 8.053, \"y\": 7.96}, {\"title\": \"3D-PreMise: Can Large Language Models Generate 3D Shapes with Sharp  Features and Parametric Control?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.912, \"y\": 6.979}, {\"title\": \"DevEval: Evaluating Code Generation in Practical Software Projects\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.395, \"y\": 2.447}, {\"title\": \"Generalizing Visual Question Answering from Synthetic to Human-Written  Questions via a Chain of QA with a Large Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.102, \"y\": 8.036}, {\"title\": \"An approach for mistranslation removal from popular dataset for Indic MT  Task\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.654, \"y\": 5.084}, {\"title\": \"Adaptive Data Augmentation for Aspect Sentiment Quad Prediction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.077, \"y\": 6.832}, {\"title\": \"APLe: Token-Wise Adaptive for Multi-Modal Prompt Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.463, \"y\": 7.03}, {\"title\": \"Learning from Semi-Factuals: A Debiased and Semantic-Aware Framework for  Generalized Relation Discovery\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.031, \"y\": 6.74}, {\"title\": \"Open the Pandora's Box of LLMs: Jailbreaking LLMs through Representation  Engineering\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.334, \"y\": 2.325}, {\"title\": \"ViSAGe: A Global-Scale Analysis of Visual Stereotypes in Text-to-Image  Generation\", \"topic\": \"Bias in Language Models\", \"x\": 3.343, \"y\": 4.476}, {\"title\": \"Misconfidence-based Demonstration Selection for LLM In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.264, \"y\": 3.393}, {\"title\": \"Learning Unsupervised Semantic Document Representation for Fine-grained  Aspect-based Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.155, \"y\": 6.833}, {\"title\": \"Extreme Compression of Large Language Models via Additive Quantization\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.703, \"y\": 2.195}, {\"title\": \"Transformers are Multi-State RNNs\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.707, \"y\": 3.303}, {\"title\": \"Autocompletion of Chief Complaints in the Electronic Health Records  using Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.742, \"y\": 8.075}, {\"title\": \"GroundingGPT:Language Enhanced Multi-modal Grounding Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.562, \"y\": 7.299}, {\"title\": \"LinguAlchemy: Fusing Typological and Geographical Elements for Unseen  Language Generalization\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.365, \"y\": 4.566}, {\"title\": \"When ChatGPT is gone: Creativity reverts and homogeneity persists\", \"topic\": \"Bias in Language Models\", \"x\": 4.945, \"y\": 4.465}, {\"title\": \"Block-Diagonal Orthogonal Relation and Matrix Entity for Knowledge Graph  Embedding\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.123, \"y\": 6.072}, {\"title\": \"LLM-as-a-Coauthor: Can Mixed Human-Written and Machine-Generated Text Be  Detected?\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.149, \"y\": 4.771}, {\"title\": \"SH2: Self-Highlighted Hesitation Helps You Decode More Truthfully\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.366, \"y\": 1.255}, {\"title\": \"Mitigating Unhelpfulness in Emotional Support Conversations with  Multifaceted AI Feedback\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.584, \"y\": 7.869}, {\"title\": \"Prompt-based mental health screening from social media text\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.215, \"y\": 7.448}, {\"title\": \"EpilepsyLLM: Domain-Specific Large Language Model Fine-tuned with  Epilepsy Medical Knowledge\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.794, \"y\": 7.938}, {\"title\": \"Towards Boosting Many-to-Many Multilingual Machine Translation with  Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.603, \"y\": 4.518}, {\"title\": \"Designing Heterogeneous LLM Agents for Financial Sentiment Analysis\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.752, \"y\": 6.872}, {\"title\": \"Discovering Low-rank Subspaces for Language-agnostic Multilingual  Representations\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.276, \"y\": 4.726}, {\"title\": \"Evidence to Generate (E2G): A Single-agent Two-step Prompting for  Context Grounded and Retrieval Augmented Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.656, \"y\": 2.475}, {\"title\": \"A Shocking Amount of the Web is Machine Translated: Insights from  Multi-Way Parallelism\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.61, \"y\": 4.697}, {\"title\": \"Cross-modal Retrieval for Knowledge-based Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.134, \"y\": 7.728}, {\"title\": \"R-BI: Regularized Batched Inputs enhance Incremental Decoding Framework  for Low-Latency Simultaneous Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.436, \"y\": 5.049}, {\"title\": \"Integrating Physician Diagnostic Logic into Large Language Models:  Preference Learning from Process Feedback\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.597, \"y\": 8.2}, {\"title\": \"UCorrect: An Unsupervised Framework for Automatic Speech Recognition  Error Correction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.183, \"y\": 5.432}, {\"title\": \"End to end Hindi to English speech conversion using Bark, mBART and a  finetuned XLSR Wav2Vec2\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.417, \"y\": 5.406}, {\"title\": \"Towards Conversational Diagnostic AI\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.554, \"y\": 8.165}, {\"title\": \"The Benefits of a Concise Chain of Thought on Problem-Solving in Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.656, \"y\": 2.299}, {\"title\": \"REBUS: A Robust Evaluation Benchmark of Understanding Symbols\", \"topic\": \"Multimodal Language Models\", \"x\": 7.973, \"y\": 7.605}, {\"title\": \"POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource  Unsupervised Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.406, \"y\": 4.336}, {\"title\": \"AugSumm: towards generalizable speech summarization using synthetic  labels from large language model\", \"topic\": \"Text Summarization\", \"x\": 5.787, \"y\": 6.053}, {\"title\": \"Leveraging Print Debugging to Improve Code Generation in Large Language  Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.341, \"y\": 2.288}, {\"title\": \"INACIA: Integrating Large Language Models in Brazilian Audit Courts:  Opportunities and Challenges\", \"topic\": \"Legal NLP\", \"x\": 5.045, \"y\": 5.534}, {\"title\": \"AutoAct: Automatic Agent Learning from Scratch for QA via Self-Planning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.773, \"y\": 2.467}, {\"title\": \"Do Vision and Language Encoders Represent the World Similarly?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.858, \"y\": 7.008}, {\"title\": \"Exploring the Reasoning Abilities of Multimodal Large Language Models  (MLLMs): A Comprehensive Survey on Emerging Trends in Multimodal Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.978, \"y\": 7.511}, {\"title\": \"Pre-trained Large Language Models for Financial Sentiment Analysis\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.777, \"y\": 6.867}, {\"title\": \"A Novel Prompt-tuning Method: Incorporating Scenario-specific Concepts  into a Verbalizer\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.613, \"y\": 3.69}, {\"title\": \"Yes, this is what I was looking for! Towards Multi-modal Medical  Consultation Concern Summary Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.868, \"y\": 8.406}, {\"title\": \"BELHD: Improving Biomedical Entity Linking with Homonoym Disambiguation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.396, \"y\": 7.425}, {\"title\": \"Noise-robust zero-shot text-to-speech synthesis conditioned on  self-supervised speech-representation model with adapters\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.604, \"y\": 5.762}, {\"title\": \"Aligning Translation-Specific Understanding to General Understanding in  Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.507, \"y\": 4.481}, {\"title\": \"Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.59, \"y\": 3.561}, {\"title\": \"Whose wife is it anyway? Assessing bias against same-gender  relationships in machine translation\", \"topic\": \"Bias in Language Models\", \"x\": 2.963, \"y\": 4.423}, {\"title\": \"The Impact of Reasoning Step Length on Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.702, \"y\": 2.446}, {\"title\": \"A General-purpose AI Avatar in Healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.288, \"y\": 7.967}, {\"title\": \"Multi-User Chat Assistant (MUCA): a Framework Using LLMs to Facilitate  Group Conversations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.219, \"y\": 3.582}, {\"title\": \"An Analysis of User Behaviors for Objectively Evaluating Spoken Dialogue  Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.07, \"y\": 3.785}, {\"title\": \"User Embedding Model for Personalized Language Prompting\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.016, \"y\": 2.919}, {\"title\": \"Entity Recognition from Colloquial Text\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.048, \"y\": 7.733}, {\"title\": \"MoSECroT: Model Stitching with Static Word Embeddings for Crosslingual  Zero-shot Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.509, \"y\": 4.803}, {\"title\": \"Narrowing the Knowledge Evaluation Gap: Open-Domain Question Answering  with Multi-Granularity Answers\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.609, \"y\": 5.127}, {\"title\": \"RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.095, \"y\": 2.161}, {\"title\": \"Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence  Lengths in Large Language Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.843, \"y\": 3.1}, {\"title\": \"DepressionEmo: A novel dataset for multilabel classification of  depression emotions\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.004, \"y\": 7.389}, {\"title\": \"DebugBench: Evaluating Debugging Capability of Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.335, \"y\": 2.401}, {\"title\": \"Language Detection for Transliterated Content\", \"topic\": \"Hate Speech Detection\", \"x\": 2.844, \"y\": 5.457}, {\"title\": \"Evaluating Language Model Agency through Negotiations\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.276, \"y\": 3.028}, {\"title\": \"MERA: A Comprehensive LLM Evaluation in Russian\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.519, \"y\": 3.816}, {\"title\": \"Exploring Prompt-Based Methods for Zero-Shot Hypernym Prediction with  Large Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.45, \"y\": 3.525}, {\"title\": \"Rewriting the Code: A Simple Method for Large Language Model Augmented  Code Search\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.526, \"y\": 2.387}, {\"title\": \"Continuously Learning New Words in Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.159, \"y\": 5.088}, {\"title\": \"Uni3D-LLM: Unifying Point Cloud Perception, Generation and Editing with  Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.858, \"y\": 7.105}, {\"title\": \"Vision Reimagined: AI-Powered Breakthroughs in WiFi Indoor Imaging\", \"topic\": \"Multimodal Language Models\", \"x\": 8.392, \"y\": 7.093}, {\"title\": \"AI Hallucinations: A Misnomer Worth Clarifying\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.037, \"y\": 1.14}, {\"title\": \"LLM4PLC: Harnessing Large Language Models for Verifiable Programming of  PLCs in Industrial Control Systems\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.277, \"y\": 2.445}, {\"title\": \"High-precision Voice Search Query Correction via Retrievable Speech-text  Embedings\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.118, \"y\": 5.434}, {\"title\": \"AI and Generative AI for Research Discovery and Summarization\", \"topic\": \"Bias in Language Models\", \"x\": 5.041, \"y\": 4.5}, {\"title\": \"Empirical Analysis of Efficient Fine-Tuning Methods for Large  Pre-Trained Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.839, \"y\": 2.535}, {\"title\": \"FFSplit: Split Feed-Forward Network For Optimizing Accuracy-Efficiency  Trade-off in Language Model Inference\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.535, \"y\": 2.62}, {\"title\": \"Large language models in bioinformatics: applications and perspectives\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.769, \"y\": 7.469}, {\"title\": \"Cross-Speaker Encoding Network for Multi-Talker Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.005, \"y\": 5.151}, {\"title\": \"TextMachina: Seamless Generation of Machine-Generated Text Datasets\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.133, \"y\": 4.737}, {\"title\": \"Chain of LoRA: Efficient Fine-tuning of Language Models via Residual  Learning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.12, \"y\": 2.185}, {\"title\": \"WEBDial, a Multi-domain, Multitask Statistical Dialogue Framework with  RDF\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.613, \"y\": 3.926}, {\"title\": \"STAIR: Spatial-Temporal Reasoning with Auditable Intermediate Results  for Video Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.66, \"y\": 7.982}, {\"title\": \"PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLM\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.424, \"y\": 2.457}, {\"title\": \"Anatomy of Neural Language Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.267, \"y\": 3.572}, {\"title\": \"Can Large Language Models Beat Wall Street? Unveiling the Potential of  AI in Stock Selection\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.779, \"y\": 6.819}, {\"title\": \"Overview of the 2023 ICON Shared Task on Gendered Abuse Detection in  Indic Languages\", \"topic\": \"Hate Speech Detection\", \"x\": 2.945, \"y\": 5.589}, {\"title\": \"LightHouse: A Survey of AGI Hallucination\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.091, \"y\": 1.166}, {\"title\": \"Why Solving Multi-agent Path Finding with Large Language Model has not  Succeeded Yet\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.728, \"y\": 2.741}, {\"title\": \"ChatGPT for Conversational Recommendation: Refining Recommendations by  Reprompting with Feedback\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.938, \"y\": 2.982}, {\"title\": \"Building Efficient and Effective OpenQA Systems for Low-Resource  Languages\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.491, \"y\": 5.31}, {\"title\": \"CAPTAIN at COLIEE 2023: Efficient Methods for Legal Information  Retrieval and Entailment Tasks\", \"topic\": \"Legal NLP\", \"x\": 5.121, \"y\": 5.728}, {\"title\": \"Transfer the linguistic representations from TTS to accent conversion  with non-parallel data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.913, \"y\": 5.467}, {\"title\": \"ROIC-DM: Robust Text Inference and Classification via Diffusion Model\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.187, \"y\": 3.102}, {\"title\": \"EAT: Self-Supervised Pre-Training with Efficient Audio Transformer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.991, \"y\": 4.903}, {\"title\": \"PEneo: Unifying Line Extraction, Line Grouping, and Entity Linking for  End-to-end Document Pair Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.881, \"y\": 6.83}, {\"title\": \"GRAM: Global Reasoning for Multi-Page VQA\", \"topic\": \"Multimodal Language Models\", \"x\": 7.894, \"y\": 7.633}, {\"title\": \"Deep Learning Based Cyberbullying Detection in Bangla Language\", \"topic\": \"Hate Speech Detection\", \"x\": 2.881, \"y\": 5.514}, {\"title\": \"LLMs for Robotic Object Disambiguation\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 8.67, \"y\": 6.747}, {\"title\": \"Grimoire is All You Need for Enhancing Large Language Models\", \"topic\": \"In-Context Learning\", \"x\": 8.353, \"y\": 3.389}, {\"title\": \"An Investigation of Large Language Models for Real-World Hate Speech  Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.762, \"y\": 5.354}, {\"title\": \"Enhancing Context Through Contrast\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.626, \"y\": 4.77}, {\"title\": \"VLLaVO: Mitigating Visual Gap through LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.566, \"y\": 7.43}, {\"title\": \"Human-Instruction-Free LLM Self-Alignment with Limited Samples\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.545, \"y\": 1.523}, {\"title\": \"The Dawn After the Dark: An Empirical Study on Factuality Hallucination  in Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.16, \"y\": 1.083}, {\"title\": \"MPN: Leveraging Multilingual Patch Neuron for Cross-lingual Model  Editing\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 7.932, \"y\": 1.635}, {\"title\": \"A Joint-Reasoning based Disease Q&A System\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.807, \"y\": 7.569}, {\"title\": \"Text-Video Retrieval via Variational Multi-Modal Hypergraph Networks\", \"topic\": \"Multimodal Language Models\", \"x\": 8.84, \"y\": 7.793}, {\"title\": \"Quartet Logic: A Four-Step Reasoning (QLFR) framework for advancing  Short Text Classification\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.682, \"y\": 2.478}, {\"title\": \"Exploring Gender Biases in Language Patterns of Human-Conversational  Agent Conversations\", \"topic\": \"Bias in Language Models\", \"x\": 3.923, \"y\": 4.151}, {\"title\": \"Towards ASR Robust Spoken Language Understanding Through In-Context  Learning With Word Confusion Networks\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.005, \"y\": 5.028}, {\"title\": \"Pheme: Efficient and Conversational Speech Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.691, \"y\": 5.743}, {\"title\": \"PeFoMed: Parameter Efficient Fine-tuning of Multimodal Large Language  Models for Medical Imaging\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.445, \"y\": 8.276}, {\"title\": \"MAMI: Multi-Attentional Mutual-Information for Long Sequence Neuron  Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.54, \"y\": 7.02}, {\"title\": \"Task Oriented Dialogue as a Catalyst for Self-Supervised Automatic  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.736, \"y\": 5.083}, {\"title\": \"SPEER: Sentence-Level Planning of Long Clinical Summaries via Embedded  Entity Retrieval\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.997, \"y\": 7.979}, {\"title\": \"LLaVA-Phi: Efficient Multi-Modal Assistant with Small Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 7.997, \"y\": 7.487}, {\"title\": \"Are LLMs Robust for Spoken Dialogues?\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.618, \"y\": 3.79}, {\"title\": \"Rethinking Response Evaluation from Interlocutor's Eye for Open-Domain  Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.209, \"y\": 3.819}, {\"title\": \"Joint Multi-Facts Reasoning Network For Complex Temporal Question  Answering Over Knowledge Graph\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.608, \"y\": 5.637}, {\"title\": \"DIALIGHT: Lightweight Multilingual Development and Evaluation of  Task-Oriented Dialogue Systems with Large Language Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.597, \"y\": 3.744}, {\"title\": \"Shayona@SMM4H23: COVID-19 Self diagnosis classification using BERT and  LightGBM models\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.088, \"y\": 6.968}, {\"title\": \"Re-evaluating the Memory-balanced Pipeline Parallelism: BPipe\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.75, \"y\": 3.037}, {\"title\": \"Text2MDT: Extracting Medical Decision Trees from Medical Texts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.819, \"y\": 7.915}, {\"title\": \"Revisiting Zero-Shot Abstractive Summarization in the Era of Large  Language Models from the Perspective of Position Bias\", \"topic\": \"Text Summarization\", \"x\": 5.436, \"y\": 5.816}, {\"title\": \"A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO  and Toxicity\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.088, \"y\": 1.326}, {\"title\": \"Instruct-Imagen: Image Generation with Multi-modal Instruction\", \"topic\": \"Multimodal Language Models\", \"x\": 8.47, \"y\": 7.142}, {\"title\": \"Generalist embedding models are better at short-context clinical  semantic search than specialized embedding models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.824, \"y\": 8.093}, {\"title\": \"Theoretical guarantees on the best-of-n alignment policy\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.264, \"y\": 1.428}, {\"title\": \"A Vision Check-up for Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.571, \"y\": 7.268}, {\"title\": \"Multilingual Instruction Tuning With Just a Pinch of Multilinguality\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.205, \"y\": 4.224}, {\"title\": \"Physio: An LLM-Based Physiotherapy Advisor\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.352, \"y\": 8.015}, {\"title\": \"Cross-target Stance Detection by Exploiting Target Analytical  Perspectives\", \"topic\": \"Fake News Detection\", \"x\": 3.396, \"y\": 5.913}, {\"title\": \"VGA: Vision and Graph Fused Attention Network for Rumor Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.044, \"y\": 5.908}, {\"title\": \"Social Media Ready Caption Generation for Brands\", \"topic\": \"Multimodal Language Models\", \"x\": 9.063, \"y\": 7.332}, {\"title\": \"Large Language Model Capabilities in Perioperative Risk Prediction and  Prognostication\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.737, \"y\": 8.249}, {\"title\": \"GPT-4V(ision) is a Generalist Web Agent, if Grounded\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.633, \"y\": 2.7}, {\"title\": \"MedSumm: A Multimodal Approach to Summarizing Code-Mixed Hindi-English  Clinical Queries\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.462, \"y\": 8.23}, {\"title\": \"Hallucinations in Neural Automatic Speech Recognition: Identifying  Errors and Hallucinatory Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.145, \"y\": 1.115}, {\"title\": \"Utilizing Neural Transducers for Two-Stage Text-to-Speech via Semantic  Token Prediction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.599, \"y\": 5.562}, {\"title\": \"A Two-Stage Multimodal Emotion Recognition Model Based on Graph  Contrastive Learning\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.241, \"y\": 7.682}, {\"title\": \"Natural Language Processing and Multimodal Stock Price Prediction\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.636, \"y\": 6.82}, {\"title\": \"Studying and Recommending Information Highlighting in Stack Overflow  Answers\", \"topic\": \"Text Summarization\", \"x\": 5.79, \"y\": 6.197}, {\"title\": \"Question-Answering Based Summarization of Electronic Health Records  using Retrieval Augmented Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.858, \"y\": 7.703}, {\"title\": \"To Diverge or Not to Diverge: A Morphosyntactic Perspective on Machine  Translation vs Human Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.732, \"y\": 4.708}, {\"title\": \"An Autoregressive Text-to-Graph Framework for Joint Entity and Relation  Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.954, \"y\": 6.767}, {\"title\": \"A Comprehensive Survey of Hallucination Mitigation Techniques in Large  Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.18, \"y\": 1.104}, {\"title\": \"Large Legal Fictions: Profiling Legal Hallucinations in Large Language  Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.105, \"y\": 1.282}, {\"title\": \"Quality and Quantity of Machine Translation References for Automatic  Metrics\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.882, \"y\": 4.807}, {\"title\": \"Fairness Certification for Natural Language Processing and Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.411, \"y\": 4.189}, {\"title\": \"VideoDrafter: Content-Consistent Multi-Scene Video Generation with LLM\", \"topic\": \"Multimodal Language Models\", \"x\": 8.887, \"y\": 7.765}, {\"title\": \"Self-Supervised Position Debiasing for Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.548, \"y\": 1.572}, {\"title\": \"Unveiling Comparative Sentiments in Vietnamese Product Reviews: A  Sequential Classification Framework\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.519, \"y\": 6.651}, {\"title\": \"Discovering Significant Topics from Legal Decisions with Selective  Inference\", \"topic\": \"Legal NLP\", \"x\": 5.113, \"y\": 5.799}, {\"title\": \"LLaMA Beyond English: An Empirical Study on Language Capability Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.143, \"y\": 4.227}, {\"title\": \"Cheetah: Natural Language Generation for 517 African Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.095, \"y\": 5.089}, {\"title\": \"Detection of Machine-Generated Text: Literature Survey\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.26, \"y\": 4.812}, {\"title\": \"Fast and Optimal Weight Update for Pruned Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.581, \"y\": 2.435}, {\"title\": \"PerSHOP -- A Persian dataset for shopping dialogue systems modeling\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.558, \"y\": 4.179}, {\"title\": \"FinDABench: Benchmarking Financial Data Analysis Ability of Large  Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.011, \"y\": 6.731}, {\"title\": \"New Job, New Gender? Measuring the Social Bias in Image Generation  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.24, \"y\": 4.45}, {\"title\": \"A & B == B & A: Triggering Logical Reasoning Failures in Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.547, \"y\": 2.963}, {\"title\": \"Machine Translation Testing via Syntactic Tree Pruning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.78, \"y\": 4.446}, {\"title\": \"Large Language Models aren't all that you need\", \"topic\": \"Named Entity Recognition\", \"x\": 7.421, \"y\": 6.808}, {\"title\": \"Large language model for Bible sentiment analysis: Sermon on the Mount\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.671, \"y\": 6.559}, {\"title\": \"Fine-tuning and Utilization Methods of Domain-specific LLMs\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.882, \"y\": 6.816}, {\"title\": \"Predicting Anti-microbial Resistance using Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.014, \"y\": 7.811}, {\"title\": \"Exploring the Effectiveness of Instruction Tuning in Biomedical Language  Processing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.318, \"y\": 7.761}, {\"title\": \"A Multi-Task, Multi-Modal Approach for Predicting Categorical and  Dimensional Emotions\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.255, \"y\": 7.745}, {\"title\": \"Generation Z's Ability to Discriminate Between AI-generated and  Human-Authored Text on Discord\", \"topic\": \"Bias in Language Models\", \"x\": 4.729, \"y\": 4.299}, {\"title\": \"BatchEval: Towards Human-like Text Evaluation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.225, \"y\": 3.908}, {\"title\": \"keqing: knowledge-based question answering is a nature chain-of-thought  mentor of LLM\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.733, \"y\": 5.426}, {\"title\": \"RAGTruth: A Hallucination Corpus for Developing Trustworthy  Retrieval-Augmented Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.172, \"y\": 1.14}, {\"title\": \"FusionMind -- Improving question and answering with external context  fusion\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.761, \"y\": 5.382}, {\"title\": \"Predicting Evoked Emotions in Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.357, \"y\": 7.778}, {\"title\": \"Trace and Edit Relation Associations in GPT\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.032, \"y\": 6.651}, {\"title\": \"Red Teaming for Large Language Models At Scale: Tackling Hallucinations  on Mathematics Tasks\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.501, \"y\": 2.962}, {\"title\": \"Boosting Large Language Model for Speech Synthesis: An Empirical Study\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.531, \"y\": 5.373}, {\"title\": \"ReasoningLM: Enabling Structural Subgraph Reasoning in Pre-trained  Language Models for Question Answering over Knowledge Graph\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.84, \"y\": 5.576}, {\"title\": \"Uncovering Regulatory Affairs Complexity in Medical Products: A  Qualitative Assessment Utilizing Open Coding and Natural Language Processing  (NLP)\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.596, \"y\": 7.56}, {\"title\": \"TuPy-E: detecting hate speech in Brazilian Portuguese social media with  a novel dataset and comprehensive analysis of models\", \"topic\": \"Hate Speech Detection\", \"x\": 2.761, \"y\": 5.398}, {\"title\": \"Jatmo: Prompt Injection Defense by Task-Specific Finetuning\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.405, \"y\": 2.603}, {\"title\": \"Action-Item-Driven Summarization of Long Meeting Transcripts\", \"topic\": \"Text Summarization\", \"x\": 5.502, \"y\": 6.328}, {\"title\": \"Olapa-MCoT: Enhancing the Chinese Mathematical Reasoning Capability of  LLMs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.818, \"y\": 2.349}, {\"title\": \"Enhancing Quantitative Reasoning Skills of Large Language Models through  Dimension Perception\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.063, \"y\": 2.867}, {\"title\": \"Overview of the PromptCBLUE Shared Task in CHIP2023\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.113, \"y\": 7.672}, {\"title\": \"Cooperation on the Fly: Exploring Language Agents for Ad Hoc Teamwork in  the Avalon Game\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.343, \"y\": 2.834}, {\"title\": \"Leveraging Open-Vocabulary Diffusion to Camouflaged Instance  Segmentation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.875, \"y\": 7.002}, {\"title\": \"EHR Interaction Between Patients and AI: NoteAid EHR Interaction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.619, \"y\": 8.156}, {\"title\": \"Video Understanding with Large Language Models: A Survey\", \"topic\": \"Multimodal Language Models\", \"x\": 8.82, \"y\": 7.879}, {\"title\": \"Commonsense for Zero-Shot Natural Language Video Localization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.789, \"y\": 7.761}, {\"title\": \"AQUALLM: Audio Question Answering Data Generation Using Large Language  Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.561, \"y\": 5.301}, {\"title\": \"Do Androids Know They're Only Dreaming of Electric Sheep?\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.131, \"y\": 1.098}, {\"title\": \"The LLM Surgeon\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.582, \"y\": 2.595}, {\"title\": \"Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision,  Language, Audio, and Action\", \"topic\": \"Multimodal Language Models\", \"x\": 8.287, \"y\": 7.224}, {\"title\": \"Generative AI for Math: Part I -- MathPile: A Billion-Token-Scale  Pretraining Corpus for Math\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.308, \"y\": 2.905}, {\"title\": \"MIVC: Multiple Instance Visual Component for Visual-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.375, \"y\": 7.556}, {\"title\": \"Q-Align: Teaching LMMs for Visual Scoring via Discrete Text-Defined  Levels\", \"topic\": \"Multimodal Language Models\", \"x\": 8.778, \"y\": 7.362}, {\"title\": \"Length Extrapolation of Transformers: A Survey from the Perspective of  Positional Encoding\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.614, \"y\": 3.416}, {\"title\": \"Experiential Co-Learning of Software-Developing Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.76, \"y\": 2.316}, {\"title\": \"AI Content Self-Detection for Transformer-based Large Language Models\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.221, \"y\": 4.738}, {\"title\": \"OmniDialog: An Omnipotent Pre-training Model for Task-Oriented Dialogue  System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.554, \"y\": 3.859}, {\"title\": \"TinyGPT-V: Efficient Multimodal Large Language Model via Small Backbones\", \"topic\": \"Multimodal Language Models\", \"x\": 8.343, \"y\": 7.491}, {\"title\": \"Adversarial Representation with Intra-Modal and Inter-Modal Graph  Contrastive Learning for Multimodal Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.244, \"y\": 7.676}, {\"title\": \"Stateful Conformer with Cache-based Inference for Streaming Automatic  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.158, \"y\": 5.089}, {\"title\": \"Some things are more CRINGE than others: Iterative Preference  Optimization with the Pairwise Cringe Loss\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.319, \"y\": 1.292}, {\"title\": \"Relationship between auditory and semantic entrainment using Deep Neural  Networks (DNN)\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.344, \"y\": 5.222}, {\"title\": \"How Robust are LLMs to In-Context Majority Label Bias?\", \"topic\": \"In-Context Learning\", \"x\": 8.229, \"y\": 3.314}, {\"title\": \"Conversational Question Answering with Reformulations over Knowledge  Graph\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.432, \"y\": 5.096}, {\"title\": \"Zero-Shot Cross-Lingual Reranking with Large Language Models for  Low-Resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.891, \"y\": 4.739}, {\"title\": \"From Text to Multimodal: A Comprehensive Survey of Adversarial Example  Generation in Question Answering Systems\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.267, \"y\": 3.03}, {\"title\": \"Dotless Representation of Arabic Text: Analysis and Modeling\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.999, \"y\": 5.329}, {\"title\": \"Aligning Large Language Models with Human Preferences through  Representation Engineering\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.238, \"y\": 1.411}, {\"title\": \"Towards Probing Contact Center Large Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.353, \"y\": 2.547}, {\"title\": \"Align on the Fly: Adapting Chatbot Behavior to Established Norms\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.333, \"y\": 1.326}, {\"title\": \"KnowledgeNavigator: Leveraging Large Language Models for Enhanced  Reasoning over Knowledge Graph\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.784, \"y\": 5.383}, {\"title\": \"Medical Report Generation based on Segment-Enhanced Contrastive  Representation Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.231, \"y\": 8.552}, {\"title\": \"Knowledge Distillation of LLM for Automatic Scoring of Science Education  Assessments\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.498, \"y\": 3.821}, {\"title\": \"Alleviating Hallucinations of Large Language Models through Induced  Hallucinations\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.301, \"y\": 1.158}, {\"title\": \"What Makes Good Data for Alignment? A Comprehensive Study of Automatic  Data Selection in Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.18, \"y\": 2.28}, {\"title\": \"Advancing Abductive Reasoning in Knowledge Graphs through Complex  Logical Hypothesis Generation\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.864, \"y\": 5.617}, {\"title\": \"RDF-star2Vec: RDF-star Graph Embeddings for Data Mining\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.997, \"y\": 6.109}, {\"title\": \"A Comprehensive Evaluation of Parameter-Efficient Fine-Tuning on  Software Engineering Tasks\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.92, \"y\": 2.413}, {\"title\": \"Chatbot is Not All You Need: Information-rich Prompting for More  Realistic Responses\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.264, \"y\": 3.513}, {\"title\": \"Reducing LLM Hallucinations using Epistemic Neural Networks\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.3, \"y\": 1.092}, {\"title\": \"README: Bridging Medical Jargon and Lay Understanding for Patient  Education through Data-Centric NLP\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.695, \"y\": 8.021}, {\"title\": \"Multi-level biomedical NER through multi-granularity embeddings and  enhanced labeling\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.362, \"y\": 7.511}, {\"title\": \"A Group Fairness Lens for Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.439, \"y\": 4.233}, {\"title\": \"Fairness-Aware Structured Pruning in Transformers\", \"topic\": \"Bias in Language Models\", \"x\": 3.428, \"y\": 4.151}, {\"title\": \"Prompt Valuation Based on Shapley Values\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.129, \"y\": 3.335}, {\"title\": \"Paralinguistics-Enhanced Large Language Modeling of Spoken Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 10.291, \"y\": 5.682}, {\"title\": \"Reverse Multi-Choice Dialogue Commonsense Inference with  Graph-of-Thought\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.614, \"y\": 5.395}, {\"title\": \"TransFace: Unit-Based Audio-Visual Speech Synthesizer for Talking Head  Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.526, \"y\": 5.712}, {\"title\": \"emotion2vec: Self-Supervised Pre-Training for Speech Emotion  Representation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.22, \"y\": 7.838}, {\"title\": \"Multilingual Bias Detection and Mitigation for Indian Languages\", \"topic\": \"Bias in Language Models\", \"x\": 3.273, \"y\": 4.531}, {\"title\": \"Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in  Large Language Models\", \"topic\": \"Hate Speech Detection\", \"x\": 2.743, \"y\": 5.313}, {\"title\": \"Unsupervised Auditory and Semantic Entrainment Models with Deep Neural  Networks\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.551, \"y\": 5.131}, {\"title\": \"Towards a Unified Multimodal Reasoning Framework\", \"topic\": \"Multimodal Language Models\", \"x\": 8.001, \"y\": 7.806}, {\"title\": \"NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language  Models via Complexity Classes\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.548, \"y\": 3.187}, {\"title\": \"Robust Knowledge Extraction from Large Language Models using Social  Choice Theory\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.923, \"y\": 7.444}, {\"title\": \"Numerical Reasoning for Financial Reports\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.885, \"y\": 6.816}, {\"title\": \"VIEScore: Towards Explainable Metrics for Conditional Image Synthesis  Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.596, \"y\": 7.657}, {\"title\": \"Voila-A: Aligning Vision-Language Models with User's Gaze Attention\", \"topic\": \"Multimodal Language Models\", \"x\": 8.299, \"y\": 7.267}, {\"title\": \"Large Language Model (LLM) Bias Index -- LLMBI\", \"topic\": \"Bias in Language Models\", \"x\": 3.525, \"y\": 4.232}, {\"title\": \"Balancing the Style-Content Trade-Off in Sentiment Transfer Using  Polarity-Aware Denoising\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.431, \"y\": 6.749}, {\"title\": \"Collaborative Synthesis of Patient Records through Multi-Visit Health  State Inference\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.815, \"y\": 8.126}, {\"title\": \"BLSTM-Based Confidence Estimation for End-to-End Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.196, \"y\": 5.188}, {\"title\": \"Reasons to Reject? Aligning Language Models with Judgments\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.154, \"y\": 1.69}, {\"title\": \"Aurora:Activating Chinese chat capability for Mixtral-8x7B sparse  Mixture-of-Experts through Instruction-Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.28, \"y\": 2.304}, {\"title\": \"Theory of Hallucinations based on Equivariance\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.191, \"y\": 1.08}, {\"title\": \"Language Model is a Branch Predictor for Simultaneous Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.018, \"y\": 4.604}, {\"title\": \"Efficacy of Machine-Generated Instructions\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.087, \"y\": 2.315}, {\"title\": \"Don't Believe Everything You Read: Enhancing Summarization  Interpretability through Automatic Identification of Hallucinations in Large  Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.176, \"y\": 1.127}, {\"title\": \"Logic-Scaffolding: Personalized Aspect-Instructed Recommendation  Explanation Generation using LLMs\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.005, \"y\": 2.892}, {\"title\": \"T-Eval: Evaluating the Tool Utilization Capability of Large Language  Models Step by Step\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.219, \"y\": 3.671}, {\"title\": \"Typhoon: Thai Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.759, \"y\": 4.211}, {\"title\": \"Diversifying Knowledge Enhancement of Biomedical Language Models using  Adapter Modules and Knowledge Graphs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.333, \"y\": 7.536}, {\"title\": \"Evaluating Task-oriented Dialogue Systems: A Systematic Review of  Measures, Constructs and their Operationalisations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.259, \"y\": 3.893}, {\"title\": \"On Task Performance and Model Calibration with Supervised and  Self-Ensembled In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.385, \"y\": 3.219}, {\"title\": \"Exploiting Contextual Target Attributes for Target Sentiment  Classification\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.181, \"y\": 6.893}, {\"title\": \"Towards More Faithful Natural Language Explanation Using Multi-Level  Contrastive Learning in VQA\", \"topic\": \"Multimodal Language Models\", \"x\": 8.153, \"y\": 7.92}, {\"title\": \"Speech Translation with Large Language Models: An Industrial Practice\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.261, \"y\": 5.001}, {\"title\": \"Shai: A large language model for asset management\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.903, \"y\": 6.821}, {\"title\": \"How to Prune Your Language Model: Recovering Accuracy on the \\\"Sparsity  May Cry'' Benchmark\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.514, \"y\": 2.457}, {\"title\": \"Automated Clinical Coding for Outpatient Departments\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.906, \"y\": 8.379}, {\"title\": \"Benchmarking and Defending Against Indirect Prompt Injection Attacks on  Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.386, \"y\": 2.564}, {\"title\": \"HCDIR: End-to-end Hate Context Detection, and Intensity Reduction model  for online comments\", \"topic\": \"Hate Speech Detection\", \"x\": 2.764, \"y\": 5.412}, {\"title\": \"Contextual Code Switching for Machine Translation using Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.364, \"y\": 4.295}, {\"title\": \"Exploring Multimodal Large Language Models for Radiology Report  Error-checking\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.104, \"y\": 8.549}, {\"title\": \"FusDom: Combining In-Domain and Out-of-Domain Knowledge for Continuous  Self-Supervised Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.916, \"y\": 4.87}, {\"title\": \"AgentCoder: Multi-Agent-based Code Generation with Iterative Testing and  Optimisation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.325, \"y\": 2.36}, {\"title\": \"Benchmarking and Analyzing In-context Learning, Fine-tuning and  Supervised Learning for Biomedical Knowledge Curation: a focused study on  chemical entities of biological interest\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.301, \"y\": 7.537}, {\"title\": \"Assaying on the Robustness of Zero-Shot Machine-Generated Text Detectors\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.101, \"y\": 4.702}, {\"title\": \"Language Resources for Dutch Large Language Modelling\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.5, \"y\": 4.055}, {\"title\": \"Turning Dust into Gold: Distilling Complex Reasoning Capabilities from  LLMs by Leveraging Negative Data\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.965, \"y\": 2.495}, {\"title\": \"OCTOPUS: Open-vocabulary Content Tracking and Object Placement Using  Semantic Understanding in Mixed Reality\", \"topic\": \"Multimodal Language Models\", \"x\": 8.736, \"y\": 7.074}, {\"title\": \"MedBench: A Large-Scale Chinese Benchmark for Evaluating Medical Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.842, \"y\": 7.863}, {\"title\": \"Stable Distillation: Regularizing Continued Pre-training for  Low-Resource Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.992, \"y\": 4.803}, {\"title\": \"Lattice Rescoring Based on Large Ensemble of Complementary Neural  Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.079, \"y\": 5.156}, {\"title\": \"Spectral Prompt Tuning:Unveiling Unseen Classes for Zero-Shot Semantic  Segmentation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.699, \"y\": 7.0}, {\"title\": \"ALMANACS: A Simulatability Benchmark for Language Model Explainability\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.76, \"y\": 3.692}, {\"title\": \"ChatFDA: Medical Records Risk Assessment\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.561, \"y\": 7.917}, {\"title\": \"BloomVQA: Assessing Hierarchical Multi-modal Comprehension\", \"topic\": \"Multimodal Language Models\", \"x\": 7.971, \"y\": 7.787}, {\"title\": \"Turning English-centric LLMs Into Polyglots: How Much Multilinguality Is  Needed?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.273, \"y\": 4.445}, {\"title\": \"Mini-GPTs: Efficient Large Language Models through Contextual Pruning\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.506, \"y\": 2.572}, {\"title\": \"Is post-editing really faster than human translation?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.843, \"y\": 4.467}, {\"title\": \"An Empirical study of Unsupervised Neural Machine Translation: analyzing  NMT output, model's behavior and sentences' contribution\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.825, \"y\": 4.558}, {\"title\": \"A Challenger to GPT-4V? Early Explorations of Gemini in Visual Expertise\", \"topic\": \"Multimodal Language Models\", \"x\": 7.773, \"y\": 7.709}, {\"title\": \"Efficient Title Reranker for Fast and Improved Knowledge-Intense NLP\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.476, \"y\": 4.866}, {\"title\": \"Large Language Models in Medical Term Classification and Unexpected  Misalignment Between Response and Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.567, \"y\": 8.097}, {\"title\": \"Bypassing the Safety Training of Open-Source LLMs with Priming Attacks\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.48, \"y\": 2.425}, {\"title\": \"Automated speech audiometry: Can it work using open-source pre-trained  Kaldi-NL automatic speech recognition?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.127, \"y\": 5.518}, {\"title\": \"Geo-located Aspect Based Sentiment Analysis (ABSA) for Crowdsourced  Evaluation of Urban Environments\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.159, \"y\": 6.817}, {\"title\": \"On Early Detection of Hallucinations in Factual Question Answering\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.198, \"y\": 1.129}, {\"title\": \"Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models:  A Critical Review and Assessment\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.889, \"y\": 2.393}, {\"title\": \"Knowledge Graph Error Detection with Contrastive Confidence Adaption\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.037, \"y\": 6.012}, {\"title\": \"Active Preference Inference using Language Models and Probabilistic  Reasoning\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.269, \"y\": 1.599}, {\"title\": \"Can ChatGPT be Your Personal Medical Assistant?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.595, \"y\": 8.1}, {\"title\": \"Fluctuation-based Adaptive Structured Pruning for Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.564, \"y\": 2.409}, {\"title\": \"Emotion Rendering for Conversational Speech Synthesis with Heterogeneous  Graph-Based Context Modeling\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.363, \"y\": 7.856}, {\"title\": \"Relation-Aware Question Answering for Heterogeneous Knowledge Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.761, \"y\": 5.603}, {\"title\": \"External Knowledge Augmented Polyphone Disambiguation Using Large  Language Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.615, \"y\": 5.498}, {\"title\": \"Analyzing Public Reactions, Perceptions, and Attitudes during the MPox  Outbreak: Findings from Topic Modeling of Tweets\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 3.995, \"y\": 6.657}, {\"title\": \"Sparse is Enough in Fine-tuning Pre-trained Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.013, \"y\": 2.309}, {\"title\": \"A Revisit of Fake News Dataset with Augmented Fact-checking by ChatGPT\", \"topic\": \"Fake News Detection\", \"x\": 4.076, \"y\": 5.646}, {\"title\": \"Predicting Human Translation Difficulty with Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.799, \"y\": 4.498}, {\"title\": \"An Adaptive Placement and Parallelism Framework for Accelerating RLHF  Training\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.234, \"y\": 1.545}, {\"title\": \"Gemini: A Family of Highly Capable Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.975, \"y\": 7.576}, {\"title\": \"NLP for Maternal Healthcare: Perspectives and Guiding Principles in the  Age of LLMs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.259, \"y\": 7.667}, {\"title\": \"Tokenization Matters: Navigating Data-Scarce Tokenization for Gender  Inclusive Language Technologies\", \"topic\": \"Bias in Language Models\", \"x\": 3.035, \"y\": 4.379}, {\"title\": \"Dynamic Topic Language Model on Heterogeneous Children's Mental Health  Clinical Notes\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.401, \"y\": 7.388}, {\"title\": \"Assessing Logical Reasoning Capabilities of Encoder-Only Transformer  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.909, \"y\": 3.029}, {\"title\": \"Evaluating Language-Model Agents on Realistic Autonomous Tasks\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.646, \"y\": 2.811}, {\"title\": \"Tuning LayerNorm in Attention: Towards Efficient Multi-Modal LLM  Finetuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.077, \"y\": 2.41}, {\"title\": \"Verb Categorisation for Hindi Word Problem Solving\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.245, \"y\": 3.144}, {\"title\": \"G-LLaVA: Solving Geometric Problem with Multi-Modal Large Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.214, \"y\": 7.506}, {\"title\": \"The Problem of Coherence in Natural Language Explanations of  Recommendations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.796, \"y\": 3.833}, {\"title\": \"Implicit Affordance Acquisition via Causal Action-Effect Modeling in the  Video Domain\", \"topic\": \"Multimodal Language Models\", \"x\": 8.622, \"y\": 7.64}, {\"title\": \"Muted: Multilingual Targeted Offensive Speech Identification and  Visualization\", \"topic\": \"Hate Speech Detection\", \"x\": 2.763, \"y\": 5.406}, {\"title\": \"APE-then-QE: Correcting then Filtering Pseudo Parallel Corpora for MT  Training Data Creation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.833, \"y\": 4.665}, {\"title\": \"Prompt Based Tri-Channel Graph Convolution Neural Network for Aspect  Sentiment Triplet Extraction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.129, \"y\": 6.878}, {\"title\": \"Efficiency-oriented approaches for self-supervised speech representation  learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.767, \"y\": 4.872}, {\"title\": \"Linear Attention via Orthogonal Memory\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.738, \"y\": 2.979}, {\"title\": \"The Good, The Bad, and Why: Unveiling Emotions in Generative AI\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.519, \"y\": 7.615}, {\"title\": \"Entity or Relation Embeddings? An Analysis of Encoding Strategies for  Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.13, \"y\": 6.569}, {\"title\": \"UniGen: A Unified Generative Framework for Retrieval and Question  Answering with Large Language Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.829, \"y\": 5.088}, {\"title\": \"Retrieval-Augmented Generation for Large Language Models: A Survey\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.979, \"y\": 4.571}, {\"title\": \"Knowledge Graphs and Pre-trained Language Models enhanced Representation  Learning for Conversational Recommender Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.925, \"y\": 2.973}, {\"title\": \"Generative linguistic representation for spoken language identification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.787, \"y\": 5.262}, {\"title\": \"Aspect-Based Sentiment Analysis with Explicit Sentiment Augmentations\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.111, \"y\": 6.813}, {\"title\": \"Speaker Mask Transformer for Multi-talker Overlapped Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.03, \"y\": 5.292}, {\"title\": \"Soft Alignment of Modality Space for End-to-end Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.277, \"y\": 5.305}, {\"title\": \"LaViP:Language-Grounded Visual Prompts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.577, \"y\": 7.401}, {\"title\": \"Satellite Captioning: Large Language Models to Augment Labeling\", \"topic\": \"Multimodal Language Models\", \"x\": 9.006, \"y\": 7.371}, {\"title\": \"From Google Gemini to OpenAI Q* (Q-Star): A Survey of Reshaping the  Generative Artificial Intelligence (AI) Research Landscape\", \"topic\": \"Bias in Language Models\", \"x\": 4.986, \"y\": 4.346}, {\"title\": \"Re-parameterized Low-rank Prompt: Generalize a Vision-Language Model  within 0.5K Parameters\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.752, \"y\": 3.297}, {\"title\": \"A review-based study on different Text-to-Speech technologies\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.637, \"y\": 5.684}, {\"title\": \"Demystifying Instruction Mixing for Fine-tuning Large Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.247, \"y\": 2.391}, {\"title\": \"Distinguishing Translations by Human, NMT, and ChatGPT: A Linguistic and  Statistical Approach\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.645, \"y\": 4.691}, {\"title\": \"StyleSinger: Style Transfer for Out-of-Domain Singing Voice Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.595, \"y\": 5.895}, {\"title\": \"Mixed Distillation Helps Smaller Language Model Better Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.048, \"y\": 2.345}, {\"title\": \"Silkie: Preference Distillation for Large Visual Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 5.739, \"y\": 1.169}, {\"title\": \"FedMKGC: Privacy-Preserving Federated Multilingual Knowledge Graph  Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.07, \"y\": 5.945}, {\"title\": \"StarVector: Generating Scalable Vector Graphics Code from Images\", \"topic\": \"Multimodal Language Models\", \"x\": 8.489, \"y\": 7.308}, {\"title\": \"Do LLMs Work on Charts? Designing Few-Shot Prompts for Chart Question  Answering and Summarization\", \"topic\": \"Multimodal Language Models\", \"x\": 7.848, \"y\": 7.76}, {\"title\": \"Investigating salient representations and label Variance in Dimensional  Speech Emotion Analysis\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.245, \"y\": 7.709}, {\"title\": \"Sentiment Analysis and Text Analysis of the Public Discourse on Twitter  about COVID-19 and MPox\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 3.979, \"y\": 6.688}, {\"title\": \"DER-GCN: Dialogue and Event Relation-Aware Graph Convolutional Neural  Network for Multimodal Dialogue Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.247, \"y\": 7.729}, {\"title\": \"Cross-Linguistic Offensive Language Detection: BERT-Based Analysis of  Bengali, Assamese, & Bodo Conversational Hateful Content from Social Media\", \"topic\": \"Hate Speech Detection\", \"x\": 2.788, \"y\": 5.407}, {\"title\": \"When Parameter-efficient Tuning Meets General-purpose Vision-language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.366, \"y\": 7.374}, {\"title\": \"Resolving Crash Bugs via Large Language Models: An Empirical Study\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.286, \"y\": 2.346}, {\"title\": \"K-ESConv: Knowledge Injection for Emotional Support Dialogue Systems via  Prompt Learning\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.607, \"y\": 7.886}, {\"title\": \"CONCSS: Contrastive-based Context Comprehension for Dialogue-appropriate  Prosody in Conversational Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.602, \"y\": 5.695}, {\"title\": \"Perturbation-Invariant Adversarial Training for Neural Ranking Models:  Improving the Effectiveness-Robustness Trade-Off\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.145, \"y\": 3.05}, {\"title\": \"Continuous Prompt Generation from Linear Combination of Discrete Prompt  Embeddings\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.465, \"y\": 3.354}, {\"title\": \"One-Shot Learning as Instruction Data Prospector for Large Language  Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.231, \"y\": 2.296}, {\"title\": \"CRNNet: Copy Recurrent Neural Network Structure Network\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.809, \"y\": 8.371}, {\"title\": \"Low-resource classification of mobility functioning information in  clinical sentences using large language models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.598, \"y\": 7.979}, {\"title\": \"Student as an Inherent Denoiser of Noisy Teacher\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.566, \"y\": 3.827}, {\"title\": \"Faithful Persona-based Conversational Dataset Generation with Large  Language Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.14, \"y\": 3.635}, {\"title\": \"LLaMAntino: LLaMA 2 Models for Effective Text Generation in Italian  Language\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.646, \"y\": 3.981}, {\"title\": \"SMILE: Multimodal Dataset for Understanding Laughter in Video with  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.494, \"y\": 7.886}, {\"title\": \"Improving Biomedical Entity Linking with Retrieval-enhanced Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.493, \"y\": 7.337}, {\"title\": \"ProCoT: Stimulating Critical Thinking and Writing of Students through  Engagement with Large Language Models (LLMs)\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.386, \"y\": 2.464}, {\"title\": \"RJUA-QA: A Comprehensive QA Dataset for Urology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.926, \"y\": 7.651}, {\"title\": \"GSQA: An End-to-End Model for Generative Spoken Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.422, \"y\": 5.177}, {\"title\": \"Taxonomy-based CheckList for Large Language Model Evaluation\", \"topic\": \"Bias in Language Models\", \"x\": 3.221, \"y\": 4.339}, {\"title\": \"Discovering Highly Influential Shortcut Reasoning: An Automated  Template-Free Approach\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.162, \"y\": 2.754}, {\"title\": \"Weakly-Supervised 3D Visual Grounding based on Visual Linguistic  Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.763, \"y\": 7.278}, {\"title\": \"Binary Code Summarization: Benchmarking ChatGPT/GPT-4 and Other Large  Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.541, \"y\": 2.642}, {\"title\": \"Leveraging Language ID to Calculate Intermediate CTC Loss for Enhanced  Code-Switching Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.833, \"y\": 5.287}, {\"title\": \"Phoneme-aware Encoding for Prefix-tree-based Contextual ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.145, \"y\": 5.223}, {\"title\": \"IR-UWB Radar-Based Contactless Silent Speech Recognition of Vowels,  Consonants, Words, and Phrases\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.261, \"y\": 5.238}, {\"title\": \"Picking the Underused Heads: A Network Pruning Perspective of Attention  Head Selection for Fusing Dialogue Coreference Information\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.837, \"y\": 3.25}, {\"title\": \"IndicIRSuite: Multilingual Dataset and Neural Information Models for  Indian Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.253, \"y\": 5.239}, {\"title\": \"Lever LM: Configuring In-Context Sequence to Lever Large Vision Language  Models\", \"topic\": \"In-Context Learning\", \"x\": 8.585, \"y\": 3.356}, {\"title\": \"A Review of Repository Level Prompting for LLMs\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.458, \"y\": 2.407}, {\"title\": \"TinyGSM: achieving >80% on GSM8k with small language models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.19, \"y\": 2.7}, {\"title\": \"Topic Bias in Emotion Classification\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.418, \"y\": 7.47}, {\"title\": \"Acoustic models of Brazilian Portuguese Speech based on Neural  Transformers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.815, \"y\": 5.266}, {\"title\": \"Modeling Complex Mathematical Reasoning via Large Language Model based  MathAgent\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.888, \"y\": 2.932}, {\"title\": \"Fewer is More: Boosting LLM Reasoning with Reinforced Context Pruning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.836, \"y\": 2.332}, {\"title\": \"Improving Cross-modal Alignment with Synthetic Pairs for Text-only Image  Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.036, \"y\": 7.307}, {\"title\": \"TiMix: Text-aware Image Mixing for Effective Vision-Language  Pre-training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.634, \"y\": 7.068}, {\"title\": \"Labels Need Prompts Too: Mask Matching for Natural Language  Understanding Tasks\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.457, \"y\": 3.459}, {\"title\": \"A Comparative Analysis of Fine-Tuned LLMs and Few-Shot Learning of LLMs  for Financial Sentiment Analysis\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.745, \"y\": 6.884}, {\"title\": \"SEF-VC: Speaker Embedding Free Zero-Shot Voice Conversion with Cross  Attention\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.662, \"y\": 5.786}, {\"title\": \"Unraveling Key Factors of Knowledge Distillation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.499, \"y\": 3.8}, {\"title\": \"ZeroQuant(4+2): Redefining LLMs Quantization with a New FP6-Centric  Strategy for Diverse Generative Tasks\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.762, \"y\": 2.165}, {\"title\": \"Beyond Accuracy: Automated De-Identification of Large Real-World  Clinical Text Datasets\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.715, \"y\": 8.013}, {\"title\": \"Conceptualizing Suicidal Behavior: Utilizing Explanations of Predicted  Outcomes to Analyze Longitudinal Social Media Data\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.17, \"y\": 7.374}, {\"title\": \"High-throughput Biomedical Relation Extraction for Semi-Structured Web  Articles Empowered by Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.28, \"y\": 7.322}, {\"title\": \"Extending Whisper with prompt tuning to target-speaker ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.098, \"y\": 5.215}, {\"title\": \"Fine-Grained Image-Text Alignment in Medical Imaging Enables Explainable  Cyclic Image-Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.261, \"y\": 8.617}, {\"title\": \"CoRTEx: Contrastive Learning for Representing Terms via Explanations  with Applications on Constructing Biomedical Knowledge Graphs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.202, \"y\": 7.672}, {\"title\": \"Helping Language Models Learn More: Multi-dimensional Task Prompt for  Few-shot Tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.669, \"y\": 3.333}, {\"title\": \"SwitchHead: Accelerating Transformers with Mixture-of-Experts Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.885, \"y\": 3.156}, {\"title\": \"Assessing GPT4-V on Structured Reasoning Tasks\", \"topic\": \"Multimodal Language Models\", \"x\": 7.99, \"y\": 7.771}, {\"title\": \"SLJP: Semantic Extraction based Legal Judgment Prediction\", \"topic\": \"Legal NLP\", \"x\": 5.09, \"y\": 5.776}, {\"title\": \"CBQ: Cross-Block Quantization for Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.743, \"y\": 2.098}, {\"title\": \"Modality Plug-and-Play: Elastic Modality Adaptation in Multimodal LLMs  for Embodied AI\", \"topic\": \"Multimodal Language Models\", \"x\": 8.231, \"y\": 7.244}, {\"title\": \"Abusive Span Detection for Vietnamese Narrative Texts\", \"topic\": \"Hate Speech Detection\", \"x\": 2.781, \"y\": 5.417}, {\"title\": \"Large Language Models are Complex Table Parsers\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.73, \"y\": 5.266}, {\"title\": \"A Deep Learning-Based System for Automatic Case Summarization\", \"topic\": \"Legal NLP\", \"x\": 5.138, \"y\": 5.811}, {\"title\": \"Sentiment analysis in Tourism: Fine-tuning BERT or sentence embeddings  concatenation?\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.547, \"y\": 6.698}, {\"title\": \"Harnessing Retrieval-Augmented Generation (RAG) for Uncovering Knowledge  Gaps\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.005, \"y\": 4.766}, {\"title\": \"Large language models in healthcare and medical domain: A review\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.66, \"y\": 7.822}, {\"title\": \"A Natural Language Processing-Based Classification and Mode-Based  Ranking of Musculoskeletal Disorder Risk Factors\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.293, \"y\": 7.988}, {\"title\": \"CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor\", \"topic\": \"Multimodal Language Models\", \"x\": 8.799, \"y\": 7.149}, {\"title\": \"SocialStigmaQA: A Benchmark to Uncover Stigma Amplification in  Generative Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.395, \"y\": 4.36}, {\"title\": \"Comparable Demonstrations are Important in In-Context Learning: A Novel  Perspective on Demonstration Selection\", \"topic\": \"In-Context Learning\", \"x\": 8.272, \"y\": 3.411}, {\"title\": \"Cross-modal Contrastive Learning with Asymmetric Co-attention Network  for Video Moment Retrieval\", \"topic\": \"Multimodal Language Models\", \"x\": 8.959, \"y\": 7.609}, {\"title\": \"Towards Faster k-Nearest-Neighbor Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.857, \"y\": 4.311}, {\"title\": \"ICL Markup: Structuring In-Context Learning using Soft-Token Tags\", \"topic\": \"In-Context Learning\", \"x\": 8.264, \"y\": 3.392}, {\"title\": \"Large Language Models are Clinical Reasoners: Reasoning-Aware Diagnosis  Framework with Prompt-Generated Rationales\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.58, \"y\": 8.23}, {\"title\": \"LLMEval: A Preliminary Study on How to Evaluate Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.257, \"y\": 3.866}, {\"title\": \"A Simple Recipe for Contrastively Pre-training Video-First Encoders  Beyond 16 Frames\", \"topic\": \"Multimodal Language Models\", \"x\": 8.906, \"y\": 7.831}, {\"title\": \"Deep Learning-based Sentiment Classification: A Comparative Survey\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.636, \"y\": 6.601}, {\"title\": \"Self-supervised Adaptive Pre-training of Multilingual Speech Models for  Language and Dialect Identification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.693, \"y\": 4.964}, {\"title\": \"SCCA: Shifted Cross Chunk Attention for long contextual semantic  expansion\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.515, \"y\": 2.936}, {\"title\": \"Towards Equipping Transformer with the Ability of Systematic  Compositionality\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.617, \"y\": 3.464}, {\"title\": \"GIST: Improving Parameter Efficient Fine Tuning via Knowledge  Interaction\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.891, \"y\": 2.342}, {\"title\": \"The GUA-Speech System Description for CNVSRC Challenge 2023\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.965, \"y\": 5.635}, {\"title\": \"Neural Machine Translation of Clinical Text: An Empirical Investigation  into Multilingual Pre-Trained Language Models and Transfer-Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.093, \"y\": 7.934}, {\"title\": \"Toxic language detection: a systematic review of Arabic datasets\", \"topic\": \"Hate Speech Detection\", \"x\": 2.847, \"y\": 5.095}, {\"title\": \"Verbreitungsmechanismen sch\\u00e4digender Sprache im Netz: Anatomie zweier  Shitstorms\", \"topic\": \"Hate Speech Detection\", \"x\": 3.199, \"y\": 5.352}, {\"title\": \"Classifying complex documents: comparing bespoke solutions to large  language models\", \"topic\": \"Legal NLP\", \"x\": 5.182, \"y\": 5.623}, {\"title\": \"Multilingual large language models leak human stereotypes across  language boundaries\", \"topic\": \"Bias in Language Models\", \"x\": 3.443, \"y\": 4.398}, {\"title\": \"BED: Bi-Encoder-Decoder Model for Canonical Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.922, \"y\": 6.759}, {\"title\": \"Rethinking Compression: Reduced Order Modelling of Latent Features in  Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.566, \"y\": 2.423}, {\"title\": \"SM70: A Large Language Model for Medical Devices\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.751, \"y\": 7.976}, {\"title\": \"Rethinking the Instruction Quality: LIFT is What You Need\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.211, \"y\": 2.276}, {\"title\": \"READ-PVLA: Recurrent Adapter with Partial Video-Language Alignment for  Parameter-Efficient Transfer Learning in Low-Resource Video-Language Modeling\", \"topic\": \"Multimodal Language Models\", \"x\": 8.964, \"y\": 7.776}, {\"title\": \"Content-Localization based Neural Machine Translation for Informal  Dialectal Arabic: Spanish/French to Levantine/Gulf Arabic\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.519, \"y\": 5.116}, {\"title\": \"Mathematical Language Models: A Survey\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.61, \"y\": 3.691}, {\"title\": \"Get an A in Math: Progressive Rectification Prompting\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.86, \"y\": 2.509}, {\"title\": \"Multimodal Pretraining of Medical Time Series and Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.997, \"y\": 8.334}, {\"title\": \"Honeybee: Locality-enhanced Projector for Multimodal LLM\", \"topic\": \"Multimodal Language Models\", \"x\": 8.305, \"y\": 7.42}, {\"title\": \"Dense X Retrieval: What Retrieval Granularity Should We Use?\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.46, \"y\": 5.07}, {\"title\": \"Gated Linear Attention Transformers with Hardware-Efficient Training\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.863, \"y\": 3.23}, {\"title\": \"On Meta-Prompting\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.14, \"y\": 3.109}, {\"title\": \"TaCo: Targeted Concept Removal in Output Embeddings for NLP via  Information Theory and Explainability\", \"topic\": \"Bias in Language Models\", \"x\": 3.179, \"y\": 4.22}, {\"title\": \"Large Language Models with Retrieval-Augmented Generation for Zero-Shot  Disease Phenotyping\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.753, \"y\": 8.099}, {\"title\": \"UstanceBR: a multimodal language resource for stance prediction\", \"topic\": \"Fake News Detection\", \"x\": 3.445, \"y\": 5.889}, {\"title\": \"MMICT: Boosting Multi-Modal Fine-Tuning with In-Context Examples\", \"topic\": \"Multimodal Language Models\", \"x\": 8.186, \"y\": 7.165}, {\"title\": \"NuScenes-MQA: Integrated Evaluation of Captions and QA for Autonomous  Driving Datasets using Markup Annotations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.265, \"y\": 7.967}, {\"title\": \"Deep Imbalanced Learning for Multimodal Emotion Recognition in  Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.252, \"y\": 7.737}, {\"title\": \"GPTBIAS: A Comprehensive Framework for Evaluating Bias in Large Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.393, \"y\": 4.293}, {\"title\": \"Creating Spoken Dialog Systems in Ultra-Low Resourced Settings\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.937, \"y\": 5.271}, {\"title\": \"Improving Startup Success with Text Analysis\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.847, \"y\": 6.654}, {\"title\": \"Evaluating ChatGPT as a Question Answering System: A Comprehensive  Analysis and Comparison with Existing Models\", \"topic\": \"Bias in Language Models\", \"x\": 5.293, \"y\": 4.493}, {\"title\": \"ConvD: Attention Enhanced Dynamic Convolutional Embeddings for Knowledge  Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.025, \"y\": 6.09}, {\"title\": \"Order Matters in the Presence of Dataset Imbalance for Multilingual  Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.56, \"y\": 4.203}, {\"title\": \"Generative Large Language Models Are All-purpose Text Analytics Engines:  Text-to-text Learning Is All Your Need\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.877, \"y\": 8.046}, {\"title\": \"EgoPlan-Bench: Benchmarking Multimodal Large Language Models for  Human-Level Planning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.788, \"y\": 2.764}, {\"title\": \"Exploiting Representation Bias for Data Distillation in Abstractive Text  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.5, \"y\": 6.34}, {\"title\": \"The performance of multiple language models in identifying offensive  language on social media\", \"topic\": \"Hate Speech Detection\", \"x\": 2.848, \"y\": 5.375}, {\"title\": \"ConSequence: Synthesizing Logically Constrained Sequences for Electronic  Health Record Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.853, \"y\": 8.088}, {\"title\": \"Perceiving University Student's Opinions from Google App Reviews\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.71, \"y\": 6.615}, {\"title\": \"ASVD: Activation-aware Singular Value Decomposition for Compressing  Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.727, \"y\": 2.44}, {\"title\": \"Speech and Text-Based Emotion Recognizer\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.223, \"y\": 7.821}, {\"title\": \"Multi-Defendant Legal Judgment Prediction via Hierarchical Reasoning\", \"topic\": \"Legal NLP\", \"x\": 5.047, \"y\": 5.726}, {\"title\": \"Labrador: Exploring the Limits of Masked Language Modeling for  Laboratory Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.089, \"y\": 8.063}, {\"title\": \"Agile-Quant: Activation-Guided Quantization for Faster Inference of LLMs  on the Edge\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.703, \"y\": 2.19}, {\"title\": \"Hate Speech and Offensive Content Detection in Indo-Aryan Languages: A  Battle of LSTM and Transformers\", \"topic\": \"Hate Speech Detection\", \"x\": 2.745, \"y\": 5.388}, {\"title\": \"Understanding the Effect of Model Compression on Social Bias in Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 8.456, \"y\": 2.168}, {\"title\": \"Two Directions for Clinical Data Generation with Large Language Models:  Data-to-Label and Label-to-Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.541, \"y\": 8.207}, {\"title\": \"Keyword spotting -- Detecting commands in speech using deep learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.045, \"y\": 5.308}, {\"title\": \"PILLOW: Enhancing Efficient Instruction Fine-tuning via Prompt Matching\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.799, \"y\": 2.971}, {\"title\": \"Enhancing Medical Specialty Assignment to Patients using NLP Techniques\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.99, \"y\": 8.025}, {\"title\": \"Textual Toxicity in Social Media: Understanding the Bangla Toxic  Language Expressed in Facebook Comment\", \"topic\": \"Hate Speech Detection\", \"x\": 2.926, \"y\": 5.432}, {\"title\": \"Beneath the Surface: Unveiling Harmful Memes with Multimodal Reasoning  Distilled from Large Language Models\", \"topic\": \"Hate Speech Detection\", \"x\": 3.046, \"y\": 5.8}, {\"title\": \"An Experimental Study: Assessing the Combined Framework of WavLM and  BEST-RQ for Text-to-Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.592, \"y\": 5.787}, {\"title\": \"Generative AI in Higher Education: Seeing ChatGPT Through Universities'  Policies, Resources, and Guidelines\", \"topic\": \"Bias in Language Models\", \"x\": 4.94, \"y\": 4.443}, {\"title\": \"GlitchBench: Can large multimodal models detect video game glitches?\", \"topic\": \"Multimodal Language Models\", \"x\": 7.998, \"y\": 7.666}, {\"title\": \"HALO: An Ontology for Representing and Categorizing Hallucinations in  Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.135, \"y\": 1.044}, {\"title\": \"DelucionQA: Detecting Hallucinations in Domain-specific Question  Answering\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.178, \"y\": 1.138}, {\"title\": \"Seamless: Multilingual Expressive and Streaming Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.306, \"y\": 5.271}, {\"title\": \"LaCour!: Enabling Research on Argumentation in Hearings of the European  Court of Human Rights\", \"topic\": \"Legal NLP\", \"x\": 4.823, \"y\": 5.648}, {\"title\": \"Lyrics: Boosting Fine-grained Language-Vision Alignment and  Comprehension via Semantic-aware Visual Objects\", \"topic\": \"Multimodal Language Models\", \"x\": 8.617, \"y\": 7.337}, {\"title\": \"Ophtha-LLaMA2: A Large Language Model for Ophthalmology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.951, \"y\": 8.271}, {\"title\": \"KwaiAgents: Generalized Information-seeking Agent System with Large  Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.686, \"y\": 2.701}, {\"title\": \"Classification of Human- and AI-Generated Texts for English, French,  German, and Spanish\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.132, \"y\": 4.982}, {\"title\": \"Localized Symbolic Knowledge Distillation for Visual Commonsense Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.494, \"y\": 7.673}, {\"title\": \"Improving Neural Machine Translation by Multi-Knowledge Integration with  Prompting\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.728, \"y\": 4.357}, {\"title\": \"Hate Cannot Drive out Hate: Forecasting Conversation Incivility  following Replies to Hate Speech\", \"topic\": \"Hate Speech Detection\", \"x\": 2.801, \"y\": 5.313}, {\"title\": \"Partial Rewriting for Multi-Stage ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.994, \"y\": 5.272}, {\"title\": \"First Attempt at Building Parallel Corpora for Machine Translation of  Northeast India's Very Low-Resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.581, \"y\": 5.058}, {\"title\": \"Forcing Generative Models to Degenerate Ones: The Power of Data  Poisoning Attacks\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.428, \"y\": 2.651}, {\"title\": \"Quilt-LLaVA: Visual Instruction Tuning by Extracting Localized  Narratives from Open-Source Histopathology Videos\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.452, \"y\": 8.433}, {\"title\": \"Simul-LLM: A Framework for Exploring High-Quality Simultaneous  Translation with Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.763, \"y\": 4.422}, {\"title\": \"Latent Skill Discovery for Chain-of-Thought Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.708, \"y\": 2.37}, {\"title\": \"TOD-Flow: Modeling the Structure of Task-Oriented Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.446, \"y\": 3.766}, {\"title\": \"Improved Visual Grounding through Self-Consistent Explanations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.727, \"y\": 7.348}, {\"title\": \"Chain of Code: Reasoning with a Language Model-Augmented Code Emulator\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.947, \"y\": 2.332}, {\"title\": \"Fortify the Shortest Stave in Attention: Enhancing Context Awareness of  Large Language Models for Effective Tool Use\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.541, \"y\": 2.965}, {\"title\": \"OpenAsp: A Benchmark for Multi-document Open Aspect-based Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.48, \"y\": 6.442}, {\"title\": \"PCoQA: Persian Conversational Question Answering Dataset\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.32, \"y\": 5.164}, {\"title\": \"Enhancing Medical Task Performance in GPT-4V: A Comprehensive Study on  Prompt Engineering Strategies\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.191, \"y\": 8.225}, {\"title\": \"nerblackbox: A High-level Library for Named Entity Recognition in Python\", \"topic\": \"Named Entity Recognition\", \"x\": 7.291, \"y\": 6.774}, {\"title\": \"Prompt Highlighter: Interactive Control for Multi-Modal LLMs\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.27, \"y\": 3.396}, {\"title\": \"Hijacking Context in Large Multi-modal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.345, \"y\": 7.269}, {\"title\": \"Language Model Knowledge Distillation for Efficient Question Answering  in Spanish\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.286, \"y\": 3.595}, {\"title\": \"Analyzing the Inherent Response Tendency of LLMs: Real-World  Instructions-Driven Jailbreak\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.271, \"y\": 2.253}, {\"title\": \"Multimodal Misinformation Detection in a South African Social Media  Environment\", \"topic\": \"Fake News Detection\", \"x\": 4.079, \"y\": 5.911}, {\"title\": \"A Study on the Calibration of In-context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.199, \"y\": 3.358}, {\"title\": \"Large Language Models for Intent-Driven Session Recommendations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.018, \"y\": 2.943}, {\"title\": \"Language Model Alignment with Elastic Reset\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.256, \"y\": 1.448}, {\"title\": \"Efficient Large Language Models: A Survey\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.642, \"y\": 4.217}, {\"title\": \"Alpha-CLIP: A CLIP Model Focusing on Wherever You Want\", \"topic\": \"Multimodal Language Models\", \"x\": 8.975, \"y\": 7.129}, {\"title\": \"OneLLM: One Framework to Align All Modalities with Language\", \"topic\": \"Multimodal Language Models\", \"x\": 8.22, \"y\": 7.201}, {\"title\": \"Evaluating and Mitigating Discrimination in Language Model Decisions\", \"topic\": \"Bias in Language Models\", \"x\": 3.379, \"y\": 4.339}, {\"title\": \"LLM as OS, Agents as Apps: Envisioning AIOS, Agents and the AIOS-Agent  Ecosystem\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.439, \"y\": 2.907}, {\"title\": \"Integrating Pre-Trained Speech and Language Models for End-to-End Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.853, \"y\": 5.16}, {\"title\": \"Generative agent-based modeling with actions grounded in physical,  social, or digital space using Concordia\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.395, \"y\": 2.958}, {\"title\": \"Interpretability Illusions in the Generalization of Simplified Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.111, \"y\": 3.648}, {\"title\": \"Improving Bias Mitigation through Bias Experts in Natural Language  Understanding\", \"topic\": \"Bias in Language Models\", \"x\": 3.341, \"y\": 4.332}, {\"title\": \"Empowering ChatGPT-Like Large-Scale Language Models with Local Knowledge  Base for Industrial Prognostics and Health Management\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.738, \"y\": 7.869}, {\"title\": \"Exploring Answer Information Methods for Question Generation with  Transformers\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.243, \"y\": 4.979}, {\"title\": \"Think from Words(TFW): Initiating Human-Like Cognition in Large Language  Models Through Think from Words for Japanese Text-level Classification\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.513, \"y\": 2.511}, {\"title\": \"SmoothQuant+: Accurate and Efficient 4-bit Post-Training  WeightQuantization for LLM\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.803, \"y\": 2.081}, {\"title\": \"Compressed Context Memory For Online Language Model Interaction\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.556, \"y\": 2.869}, {\"title\": \"A Text-to-Text Model for Multilingual Offensive Language Identification\", \"topic\": \"Hate Speech Detection\", \"x\": 2.784, \"y\": 5.401}, {\"title\": \"Optimizing Two-Pass Cross-Lingual Transfer Learning: Phoneme Recognition  and Phoneme to Grapheme Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.593, \"y\": 5.363}, {\"title\": \"Dyport: Dynamic Importance-based Hypothesis Generation Benchmarking  Technique\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.043, \"y\": 7.173}, {\"title\": \"Evaluating Self-supervised Speech Models on a Taiwanese Hokkien Corpus\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.652, \"y\": 5.059}, {\"title\": \"Detecting Rumor Veracity with Only Textual Information by Double-Channel  Structure\", \"topic\": \"Fake News Detection\", \"x\": 3.995, \"y\": 5.856}, {\"title\": \"Corporate Bankruptcy Prediction with Domain-Adapted BERT\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.724, \"y\": 6.758}, {\"title\": \"Mismatch Quest: Visual and Textual Feedback for Image-Text Misalignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.92, \"y\": 7.314}, {\"title\": \"Clinical Notes Reveal Physician Fatigue\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.501, \"y\": 8.061}, {\"title\": \"Describing Differences in Image Sets with Natural Language\", \"topic\": \"Multimodal Language Models\", \"x\": 8.985, \"y\": 7.332}, {\"title\": \"Visual Program Distillation: Distilling Tools and Programmatic Reasoning  into Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.539, \"y\": 7.591}, {\"title\": \"WhisBERT: Multimodal Text-Audio Language Modeling on 100M Words\", \"topic\": \"Multimodal Language Models\", \"x\": 8.549, \"y\": 7.083}, {\"title\": \"Clustering Pseudo Language Family in Multilingual Translation Models  with Fisher Information Matrix\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.364, \"y\": 4.809}, {\"title\": \"Weakly Supervised Detection of Hallucinations in LLM Activations\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.176, \"y\": 1.068}, {\"title\": \"Scaling Laws for Adversarial Attacks on Language Model Activations\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.219, \"y\": 2.93}, {\"title\": \"Prompt Optimization via Adversarial In-Context Learning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.52, \"y\": 3.275}, {\"title\": \"Empathy and Distress Detection using Ensembles of Transformer Models\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.494, \"y\": 7.533}, {\"title\": \"Training on Synthetic Data Beats Real Data in Multimodal Relation  Extraction\", \"topic\": \"Multimodal Language Models\", \"x\": 7.933, \"y\": 7.163}, {\"title\": \"ULMA: Unified Language Model Alignment with Human Demonstration and  Point-wise Preference\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.334, \"y\": 1.328}, {\"title\": \"Beyond Isolation: Multi-Agent Synergy for Improving Knowledge Graph  Construction\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.053, \"y\": 6.092}, {\"title\": \"MKA: A Scalable Medical Knowledge Assisted Mechanism for Generative  Models on Medical Conversation Tasks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.624, \"y\": 8.104}, {\"title\": \"MedDM:LLM-executable clinical guidance tree for clinical decision-making\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.565, \"y\": 8.253}, {\"title\": \"Let's Think Outside the Box: Exploring Leap-of-Thought in Large Language  Models with Creative Humor Generation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.371, \"y\": 2.568}, {\"title\": \"MUFFIN: Curating Multi-Faceted Instructions for Improving  Instruction-Following\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.224, \"y\": 2.347}, {\"title\": \"Stock Movement and Volatility Prediction from Tweets, Macroeconomic  Factors and Historical Prices\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.449, \"y\": 6.777}, {\"title\": \"GNN2R: Weakly-Supervised Rationale-Providing Question Answering over  Knowledge Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.749, \"y\": 5.598}, {\"title\": \"Fine-tuning pre-trained extractive QA models for clinical document  parsing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.851, \"y\": 8.249}, {\"title\": \"VaQuitA: Enhancing Alignment in LLM-Assisted Video Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.8, \"y\": 7.92}, {\"title\": \"LineConGraphs: Line Conversation Graphs for Effective Emotion  Recognition using Graph Neural Networks\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.306, \"y\": 7.757}, {\"title\": \"LLMs Accelerate Annotation for Medical Information Extraction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.799, \"y\": 7.839}, {\"title\": \"Generative Powers of Ten\", \"topic\": \"Multimodal Language Models\", \"x\": 9.027, \"y\": 6.82}, {\"title\": \"Competition-Level Problems are Effective LLM Evaluators\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.576, \"y\": 3.1}, {\"title\": \"Magicoder: Empowering Code Generation with OSS-Instruct\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.719, \"y\": 2.411}, {\"title\": \"Tree of Attacks: Jailbreaking Black-Box LLMs Automatically\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.333, \"y\": 2.201}, {\"title\": \"Recursive Visual Programming\", \"topic\": \"Multimodal Language Models\", \"x\": 8.448, \"y\": 7.817}, {\"title\": \"Near-real-time Earthquake-induced Fatality Estimation using Crowdsourced  Data and Large-Language Models\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.256, \"y\": 6.702}, {\"title\": \"TimeChat: A Time-sensitive Multimodal Large Language Model for Long  Video Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.851, \"y\": 7.941}, {\"title\": \"A Machine Learning Approach Towards SKILL Code Autocompletion\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.577, \"y\": 2.505}, {\"title\": \"Prompting Disentangled Embeddings for Knowledge Graph Completion with  Pre-trained Language Model\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.932, \"y\": 5.863}, {\"title\": \"Developing Linguistic Patterns to Mitigate Inherent Human Bias in  Offensive Language Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.806, \"y\": 5.197}, {\"title\": \"Retrieval-augmented Multi-modal Chain-of-Thoughts Reasoning for Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.586, \"y\": 2.345}, {\"title\": \"Mitigating Fine-Grained Hallucination by Fine-Tuning Large  Vision-Language Models with Caption Rewrites\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.369, \"y\": 0.966}, {\"title\": \"Jellyfish: A Large Language Model for Data Preprocessing\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.012, \"y\": 2.434}, {\"title\": \"STADEE: STAtistics-based DEEp Detection of Machine Generated Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.055, \"y\": 4.764}, {\"title\": \"Expand BERT Representation with Visual Information via Grounded Language  Learning with Multimodal Partial Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.645, \"y\": 7.081}, {\"title\": \"Explaining with Contrastive Phrasal Highlighting: A Case Study in  Assisting Humans to Detect Translation Differences\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.913, \"y\": 3.897}, {\"title\": \"A Challenging Multimodal Video Summary: Simultaneously Extracting and  Generating Keyframe-Caption Pairs from Video\", \"topic\": \"Multimodal Language Models\", \"x\": 8.881, \"y\": 7.817}, {\"title\": \"APoLLo: Unified Adapter and Prompt Learning for Vision Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.564, \"y\": 7.215}, {\"title\": \"T3D: Towards 3D Medical Image Understanding through Vision-Language  Pre-training\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.597, \"y\": 8.435}, {\"title\": \"SymNoise: Advancing Language Model Fine-tuning with Symmetric Noise\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.01, \"y\": 2.312}, {\"title\": \"Bigger is not Always Better: The Effect of Context Size on Speech  Pre-Training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.003, \"y\": 4.976}, {\"title\": \"Tackling Bias in Pre-trained Language Models: Current Trends and  Under-represented Societies\", \"topic\": \"Bias in Language Models\", \"x\": 3.37, \"y\": 4.361}, {\"title\": \"Effectively Fine-tune to Improve Large Multimodal Models for Radiology  Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.269, \"y\": 8.545}, {\"title\": \"D-Bot: Database Diagnosis System using Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.559, \"y\": 8.16}, {\"title\": \"Behind the Magic, MERLIM: Multi-modal Evaluation Benchmark for Large  Image-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.25, \"y\": 7.598}, {\"title\": \"Transformers are uninterpretable with myopic methods: a case study with  bounded Dyck grammars\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.216, \"y\": 3.572}, {\"title\": \"Towards Mitigating Perceived Unfairness in Contracts from a Non-Legal  Stakeholder's Perspective\", \"topic\": \"Legal NLP\", \"x\": 4.983, \"y\": 5.582}, {\"title\": \"TextGenSHAP: Scalable Post-hoc Explanations in Text Generation with Long  Documents\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.054, \"y\": 3.717}, {\"title\": \"Axiomatic Preference Modeling for Longform Question Answering\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.145, \"y\": 1.494}, {\"title\": \"UCE-FID: Using Large Unlabeled, Medium Crowdsourced-Labeled, and Small  Expert-Labeled Tweets for Foodborne Illness Detection\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.172, \"y\": 6.97}, {\"title\": \"English to Arabic machine translation of mathematical documents\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.541, \"y\": 4.945}, {\"title\": \"Which linguistic cues make people fall for fake news? A comparison of  cognitive and affective processing\", \"topic\": \"Fake News Detection\", \"x\": 3.912, \"y\": 5.825}, {\"title\": \"Self Generated Wargame AI: Double Layer Agent Task Planning Based on  Large Language Model\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.437, \"y\": 3.014}, {\"title\": \"RLHF and IIA: Perverse Incentives\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.162, \"y\": 1.543}, {\"title\": \"End-to-End Speech-to-Text Translation: A Survey\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.482, \"y\": 5.247}, {\"title\": \"Detection and Analysis of Stress-Related Posts in Reddit Acamedic  Communities\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.112, \"y\": 7.335}, {\"title\": \"From Beginner to Expert: Modeling Medical Knowledge into General LLMs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.784, \"y\": 8.006}, {\"title\": \"Harnessing the Power of Prompt-based Techniques for Generating  School-Level Questions using Large Language Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.303, \"y\": 4.92}, {\"title\": \"Knowledge Graph Enhanced Aspect-Level Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.129, \"y\": 6.876}, {\"title\": \"Dual-Teacher De-biasing Distillation Framework for Multi-domain Fake  News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.027, \"y\": 5.757}, {\"title\": \"Video Summarization: Towards Entity-Aware Captions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.904, \"y\": 7.788}, {\"title\": \"Location Sensitive Embedding for Knowledge Graph Reasoning\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.139, \"y\": 6.11}, {\"title\": \"The Cost of Compression: Investigating the Impact of Compression on  Parametric Knowledge in Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.517, \"y\": 2.463}, {\"title\": \"Hyperparameter Optimization for Large Language Model Instruction-Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.1, \"y\": 2.197}, {\"title\": \"Knowledge Graph Driven Recommendation System Algorithm\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.928, \"y\": 2.952}, {\"title\": \"Semantic Parsing for Question Answering over Knowledge Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.87, \"y\": 5.492}, {\"title\": \"Analyzing the Impact of Fake News on the Anticipated Outcome of the 2024  Election Ahead of Time\", \"topic\": \"Fake News Detection\", \"x\": 3.909, \"y\": 5.662}, {\"title\": \"Rule-Guided Joint Embedding Learning over Knowledge Graphs\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.189, \"y\": 6.089}, {\"title\": \"ViP-LLaVA: Making Large Multimodal Models Understand Arbitrary Visual  Prompts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.243, \"y\": 7.749}, {\"title\": \"Context Retrieval via Normalized Contextual Latent Interaction for  Conversational Agent\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.683, \"y\": 4.138}, {\"title\": \"Mitigating Over-smoothing in Transformers via Regularized Nonlocal  Functionals\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.956, \"y\": 3.248}, {\"title\": \"Nonparametric Variational Regularisation of Pretrained Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.635, \"y\": 3.335}, {\"title\": \"Instruction-tuning Aligns LLMs to the Human Brain\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.168, \"y\": 2.525}, {\"title\": \"Explanatory Argument Extraction of Correct Answers in Resident Medical  Exams\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.778, \"y\": 7.736}, {\"title\": \"Questioning Biases in Case Judgment Summaries: Legal Datasets or Large  Language Models?\", \"topic\": \"Bias in Language Models\", \"x\": 3.509, \"y\": 4.517}, {\"title\": \"Improving Unsupervised Relation Extraction by Augmenting Diverse  Sentence Pairs\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.108, \"y\": 6.703}, {\"title\": \"Trained MT Metrics Learn to Cope with Machine-translated References\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.768, \"y\": 4.67}, {\"title\": \"SurreyAI 2023 Submission for the Quality Estimation Shared Task\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.882, \"y\": 4.772}, {\"title\": \"RLHF-V: Towards Trustworthy MLLMs via Behavior Alignment from  Fine-grained Correctional Human Feedback\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.607, \"y\": 1.186}, {\"title\": \"Japanese Tort-case Dataset for Rationale-supported Legal Judgment  Prediction\", \"topic\": \"Legal NLP\", \"x\": 5.087, \"y\": 5.759}, {\"title\": \"RTQ: Rethinking Video-language Understanding Based on Image-text Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.88, \"y\": 7.919}, {\"title\": \"SEPSIS: I Can Catch Your Lies -- A New Paradigm for Deception Detection\", \"topic\": \"Fake News Detection\", \"x\": 3.948, \"y\": 5.615}, {\"title\": \"Multi-Modal Video Topic Segmentation with Dual-Contrastive Domain  Adaptation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.884, \"y\": 7.738}, {\"title\": \"Relevance-guided Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.875, \"y\": 4.44}, {\"title\": \"Compression of end-to-end non-autoregressive image-to-speech system for  low-resourced devices\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.942, \"y\": 5.302}, {\"title\": \"A Video is Worth 10,000 Words: Training and Benchmarking with Diverse  Captions for Better Long Video Retrieval\", \"topic\": \"Multimodal Language Models\", \"x\": 8.91, \"y\": 7.866}, {\"title\": \"What Do Llamas Really Think? Revealing Preference Biases in Language  Model Representations\", \"topic\": \"Bias in Language Models\", \"x\": 3.732, \"y\": 4.229}, {\"title\": \"BioCLIP: A Vision Foundation Model for the Tree of Life\", \"topic\": \"Multimodal Language Models\", \"x\": 8.659, \"y\": 7.141}, {\"title\": \"X-InstructBLIP: A Framework for aligning X-Modal instruction-aware  representations to LLMs and Emergent Cross-modal Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.414, \"y\": 7.345}, {\"title\": \"Mavericks at BLP-2023 Task 1: Ensemble-based Approach Using Language  Models for Violence Inciting Text Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.811, \"y\": 5.467}, {\"title\": \"CoDi-2: In-Context, Interleaved, and Interactive Any-to-Any Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.279, \"y\": 7.19}, {\"title\": \"MLLMs-Augmented Visual-Language Representation Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.501, \"y\": 7.42}, {\"title\": \"Women Are Beautiful, Men Are Leaders: Gender Stereotypes in Machine  Translation and Language Modeling\", \"topic\": \"Bias in Language Models\", \"x\": 3.007, \"y\": 4.422}, {\"title\": \"RaDialog: A Large Vision-Language Model for Radiology Report Generation  and Conversational Assistance\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.158, \"y\": 8.6}, {\"title\": \"ArthModel: Enhance Arithmetic Skills to Large Language Model\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.465, \"y\": 2.796}, {\"title\": \"IAG: Induction-Augmented Generation Framework for Answering Reasoning  Questions\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.694, \"y\": 5.019}, {\"title\": \"Consensus, dissensus and synergy between clinicians and specialist  foundation models in radiology report generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.187, \"y\": 8.592}, {\"title\": \"Positional Information Matters for Invariant In-Context Learning: A Case  Study of Simple Function Classes\", \"topic\": \"In-Context Learning\", \"x\": 8.618, \"y\": 3.364}, {\"title\": \"DisCGen: A Framework for Discourse-Informed Counterspeech Generation\", \"topic\": \"Hate Speech Detection\", \"x\": 2.7, \"y\": 5.282}, {\"title\": \"ROBBIE: Robust Bias Evaluation of Large Generative Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.319, \"y\": 4.291}, {\"title\": \"Dynamic interactive group decision making method on two-dimensional  language\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.586, \"y\": 3.194}, {\"title\": \"Hyperpolyglot LLMs: Cross-Lingual Interpretability in Token Embeddings\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.028, \"y\": 4.658}, {\"title\": \"Filtered Semi-Markov CRF\", \"topic\": \"Named Entity Recognition\", \"x\": 7.583, \"y\": 6.718}, {\"title\": \"Knowledge Pursuit Prompting for Zero-Shot Multimodal Synthesis\", \"topic\": \"Multimodal Language Models\", \"x\": 8.296, \"y\": 7.263}, {\"title\": \"Supervising the Centroid Baseline for Extractive Multi-Document  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.666, \"y\": 6.277}, {\"title\": \"Self-Infilling Code Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.581, \"y\": 2.342}, {\"title\": \"End-to-end Joint Rich and Normalized ASR with a limited amount of rich  training data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.112, \"y\": 5.286}, {\"title\": \"Text as Images: Can Multimodal Large Language Models Follow Printed  Instructions in Pixels?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.487, \"y\": 7.229}, {\"title\": \"Introduction to Transformers: an NLP Perspective\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.332, \"y\": 3.665}, {\"title\": \"Enhancing Answer Selection in Community Question Answering with  Pre-trained and Large Language Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.513, \"y\": 5.109}, {\"title\": \"Mergen: The First Manchu-Korean Machine Translation Model Trained on  Augmented Data\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.73, \"y\": 4.705}, {\"title\": \"How Generative-AI can be Effectively used in Government Chatbots\", \"topic\": \"Bias in Language Models\", \"x\": 4.943, \"y\": 4.281}, {\"title\": \"VITATECS: A Diagnostic Dataset for Temporal Concept Understanding of  Video-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.706, \"y\": 8.005}, {\"title\": \"Improving the Robustness of Transformer-based Large Language Models with  Dynamic Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 3.181, \"y\": 3.05}, {\"title\": \"CESAR: Automatic Induction of Compositional Instructions for Multi-turn  Dialogs\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.667, \"y\": 3.703}, {\"title\": \"Clinical Risk Prediction Using Language Models: Benefits And  Considerations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.824, \"y\": 8.152}, {\"title\": \"DreamSync: Aligning Text-to-Image Generation with Image Understanding  Feedback\", \"topic\": \"Multimodal Language Models\", \"x\": 9.007, \"y\": 6.83}, {\"title\": \"RoKEPG: RoBERTa and Knowledge Enhancement for Prescription Generation of  Traditional Chinese Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.885, \"y\": 8.071}, {\"title\": \"War and Peace (WarAgent): Large Language Model-based Multi-Agent  Simulation of World Wars\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.182, \"y\": 3.122}, {\"title\": \"General-Purpose vs. Domain-Adapted Large Language Models for Extraction  of Structured Data from Chest Radiology Reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.128, \"y\": 8.551}, {\"title\": \"Pragmatic Radiology Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.235, \"y\": 8.643}, {\"title\": \"MobileCLIP: Fast Image-Text Models through Multi-Modal Reinforced  Training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.904, \"y\": 7.249}, {\"title\": \"LLaMA-VID: An Image is Worth 2 Tokens in Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.828, \"y\": 7.801}, {\"title\": \"Efficient In-Context Learning in Vision-Language Models for Egocentric  Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.72, \"y\": 7.493}, {\"title\": \"A Survey on Prompting Techniques in LLMs\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.264, \"y\": 3.193}, {\"title\": \"Training Chain-of-Thought via Latent-Variable Inference\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.739, \"y\": 2.217}, {\"title\": \"Natural Language Processing Through Transfer Learning: A Case Study on  Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.482, \"y\": 6.594}, {\"title\": \"Mitigating Object Hallucinations in Large Vision-Language Models through  Visual Contrastive Decoding\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.305, \"y\": 1.034}, {\"title\": \"Syntax-Informed Interactive Model for Comprehensive Aspect-Based  Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.096, \"y\": 6.83}, {\"title\": \"Optimisation-Based Multi-Modal Semantic Image Editing\", \"topic\": \"Multimodal Language Models\", \"x\": 9.006, \"y\": 6.873}, {\"title\": \"Syntactic Fusion: Enhancing Aspect-Level Sentiment Analysis Through  Multi-Tree Graph Integration\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.099, \"y\": 6.88}, {\"title\": \"A Benchmark for Evaluating Machine Translation Metrics on Dialects  Without Standard Orthography\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.519, \"y\": 5.122}, {\"title\": \"Beyond Hallucinations: Enhancing LVLMs through Hallucination-Aware  Direct Preference Optimization\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.511, \"y\": 1.073}, {\"title\": \"Reason out Your Layout: Evoking the Layout Master from Large Language  Models for Text-to-Image Synthesis\", \"topic\": \"Multimodal Language Models\", \"x\": 8.978, \"y\": 6.808}, {\"title\": \"CharacterGLM: Customizing Chinese Conversational AI Characters with  Large Language Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.182, \"y\": 3.53}, {\"title\": \"A Survey of the Evolution of Language Model-Based Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.583, \"y\": 3.827}, {\"title\": \"Evaluating Optimal Reference Translations\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.819, \"y\": 4.716}, {\"title\": \"A Generic NLI approach for Classification of Sentiment Associated with  Therapies\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.621, \"y\": 6.749}, {\"title\": \"De-identification of clinical free text using natural language  processing: A systematic review of current approaches\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.526, \"y\": 7.797}, {\"title\": \"Radiology-Aware Model-Based Evaluation Metric for Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.151, \"y\": 8.581}, {\"title\": \"Entity-Aspect-Opinion-Sentiment Quadruple Extraction for Fine-grained  Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.131, \"y\": 6.834}, {\"title\": \"Text2Tree: Aligning Text Representation to the Label Tree Hierarchy for  Imbalanced Medical Classification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.002, \"y\": 8.302}, {\"title\": \"On the Long Range Abilities of Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.82, \"y\": 3.312}, {\"title\": \"Ascle: A Python Natural Language Processing Toolkit for Medical Text  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.98, \"y\": 7.607}, {\"title\": \"Recognizing Conditional Causal Relationships about Emotions and Their  Corresponding Conditions\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 6.173, \"y\": 6.17}, {\"title\": \"Methods to Estimate Large Language Model Confidence\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.523, \"y\": 8.12}, {\"title\": \"A Rank Stabilization Scaling Factor for Fine-Tuning with LoRA\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.141, \"y\": 2.119}, {\"title\": \"Can Generalist Foundation Models Outcompete Special-Purpose Tuning? Case  Study in Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.858, \"y\": 7.905}, {\"title\": \"Exo2EgoDVC: Dense Video Captioning of Egocentric Procedural Activities  Using Web Instructional Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.908, \"y\": 7.65}, {\"title\": \"Reducing Gender Bias in Machine Translation through Counterfactual Data  Generation\", \"topic\": \"Bias in Language Models\", \"x\": 3.038, \"y\": 4.399}, {\"title\": \"Compositional Chain-of-Thought Prompting for Large Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.086, \"y\": 7.724}, {\"title\": \"Releasing the CRaQAn (Coreference Resolution in Question-Answering): An  open-source dataset and dataset creation methodology using  instruction-following models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.421, \"y\": 5.386}, {\"title\": \"FakeWatch ElectionShield: A Benchmarking Framework to Detect Fake News  for Credible US Elections\", \"topic\": \"Fake News Detection\", \"x\": 3.999, \"y\": 5.77}, {\"title\": \"Student Mastery or AI Deception? Analyzing ChatGPT's Assessment  Proficiency and Evaluating Detection Strategies\", \"topic\": \"Bias in Language Models\", \"x\": 5.178, \"y\": 4.486}, {\"title\": \"Novel Preprocessing Technique for Data Embedding in Engineering Code  Generation Using Large Language Model\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.52, \"y\": 2.481}, {\"title\": \"Safe-CLIP: Removing NSFW Concepts from Vision-and-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.725, \"y\": 7.161}, {\"title\": \"How Many Unicorns Are in This Image? A Safety Evaluation Benchmark for  Vision LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.312, \"y\": 7.729}, {\"title\": \"MEDITRON-70B: Scaling Medical Pretraining for Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.904, \"y\": 8.03}, {\"title\": \"BioLORD-2023: Semantic Textual Representations Fusing LLM and Clinical  Knowledge Graph Insights\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.12, \"y\": 7.914}, {\"title\": \"MMMU: A Massive Multi-discipline Multimodal Understanding and Reasoning  Benchmark for Expert AGI\", \"topic\": \"Multimodal Language Models\", \"x\": 7.866, \"y\": 7.566}, {\"title\": \"Efficient Pre-training for Localized Instruction Generation of Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.958, \"y\": 7.662}, {\"title\": \"A Quantitative Approach to Understand Self-Supervised Models as  Cross-lingual Feature Extractors\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.551, \"y\": 5.046}, {\"title\": \"Leveraging deep active learning to identify low-resource mobility  functioning information in public clinical notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.604, \"y\": 7.989}, {\"title\": \"WorldSense: A Synthetic Benchmark for Grounded Reasoning in Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.331, \"y\": 3.509}, {\"title\": \"ChartLlama: A Multimodal LLM for Chart Understanding and Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.1, \"y\": 7.559}, {\"title\": \"Increasing Coverage and Precision of Textual Information in Multilingual  Knowledge Graphs\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.155, \"y\": 5.965}, {\"title\": \"Towards Vision Enhancing LLMs: Empowering Multimodal Knowledge Storage  and Sharing in LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.305, \"y\": 7.574}, {\"title\": \"Justifiable Artificial Intelligence: Engineering Large Language Models  for Legal Applications\", \"topic\": \"Legal NLP\", \"x\": 5.099, \"y\": 5.392}, {\"title\": \"MoDS: Model-oriented Data Selection for Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.248, \"y\": 2.333}, {\"title\": \"InfoPattern: Unveiling Information Propagation Patterns in Social Media\", \"topic\": \"Fake News Detection\", \"x\": 3.757, \"y\": 5.647}, {\"title\": \"Injecting linguistic knowledge into BERT for Dialogue State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.644, \"y\": 3.868}, {\"title\": \"EgoThink: Evaluating First-Person Perspective Thinking Capability of  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.258, \"y\": 7.836}, {\"title\": \"Pre-trained Language Models Do Not Help Auto-regressive Text-to-Image  Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.893, \"y\": 6.787}, {\"title\": \"Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing  AI-Generated Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.276, \"y\": 4.832}, {\"title\": \"Deficiency of Large Language Models in Finance: An Empirical Examination  of Hallucination\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.161, \"y\": 1.244}, {\"title\": \"WsiCaption: Multiple Instance Generation of Pathology Reports for  Gigapixel Whole-Slide Images\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.26, \"y\": 8.519}, {\"title\": \"Overview of the VLSP 2022 -- Abmusu Shared Task: A Data Challenge for  Vietnamese Abstractive Multi-document Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.561, \"y\": 6.355}, {\"title\": \"A Comparative and Experimental Study on Automatic Question Answering  Systems and its Robustness against Word Jumbling\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.067, \"y\": 4.967}, {\"title\": \"A Corpus for Named Entity Recognition in Chinese Novels with  Multi-genres\", \"topic\": \"Named Entity Recognition\", \"x\": 7.385, \"y\": 6.769}, {\"title\": \"Function-constrained Program Synthesis\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.309, \"y\": 2.368}, {\"title\": \"ChatGPT Application In Summarizing An Evolution Of Deep Learning  Techniques In Imaging: A Qualitative Study\", \"topic\": \"Text Summarization\", \"x\": 5.559, \"y\": 6.46}, {\"title\": \"Machine-Generated Text Detection using Deep Learning\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.15, \"y\": 4.736}, {\"title\": \"Sibyl: Sensible Empathetic Dialogue Generation with Visionary  Commonsense Knowledge\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.66, \"y\": 7.873}, {\"title\": \"UHGEval: Benchmarking the Hallucination of Chinese Large Language Models  via Unconstrained Generation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.148, \"y\": 1.113}, {\"title\": \"Real-Time Online Stock Forecasting Utilizing Integrated Quantitative and  Qualitative Analysis\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.626, \"y\": 6.815}, {\"title\": \"ChatGPT and Beyond: The Generative AI Revolution in Education\", \"topic\": \"Bias in Language Models\", \"x\": 4.97, \"y\": 4.391}, {\"title\": \"Benchmarking Large Language Model Volatility\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.748, \"y\": 6.885}, {\"title\": \"Large Language Models in Law: A Survey\", \"topic\": \"Legal NLP\", \"x\": 5.15, \"y\": 5.464}, {\"title\": \"Relevance feedback strategies for recall-oriented neural information  retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.389, \"y\": 4.999}, {\"title\": \"Solving the Right Problem is Key for Translational NLP: A Case Study in  UMLS Vocabulary Insertion\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.263, \"y\": 7.564}, {\"title\": \"Enhancing Sentiment Analysis Results through Outlier Detection  Optimization\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.587, \"y\": 6.985}, {\"title\": \"Multilingual self-supervised speech representations improve the speech  recognition of low-resource African languages with codeswitching\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.777, \"y\": 5.106}, {\"title\": \"nlpBDpatriots at BLP-2023 Task 2: A Transfer Learning Approach to Bangla  Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.358, \"y\": 6.553}, {\"title\": \"nlpBDpatriots at BLP-2023 Task 1: A Two-Step Classification for Violence  Inciting Text Detection in Bangla\", \"topic\": \"Hate Speech Detection\", \"x\": 2.963, \"y\": 5.752}, {\"title\": \"Offensive Language Identification in Transliterated and Code-Mixed  Bangla\", \"topic\": \"Hate Speech Detection\", \"x\": 2.813, \"y\": 5.436}, {\"title\": \"E-CORE: Emotion Correlation Enhanced Empathetic Dialogue Generation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.585, \"y\": 7.865}, {\"title\": \"Code Search Debiasing:Improve Search Results beyond Overall Ranking  Performance\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.505, \"y\": 2.384}, {\"title\": \"Improving Cross-Domain Hate Speech Generalizability with Emotion  Knowledge\", \"topic\": \"Hate Speech Detection\", \"x\": 2.717, \"y\": 5.423}, {\"title\": \"Gender inference: can chatGPT outperform common commercial tools?\", \"topic\": \"Bias in Language Models\", \"x\": 3.601, \"y\": 4.494}, {\"title\": \"OpusCleaner and OpusTrainer, open source toolkits for training Machine  Translation and Large language models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.522, \"y\": 4.505}, {\"title\": \"Custom Data Augmentation for low resource ASR using Bark and  Retrieval-Based Voice Conversion\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.855, \"y\": 5.441}, {\"title\": \"Weak Alignment Supervision from Hybrid Model Improves End-to-end ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.211, \"y\": 5.099}, {\"title\": \"Data-to-Text Bilingual Generation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.363, \"y\": 4.885}, {\"title\": \"Evaluating Large Language Models through Gender and Racial Stereotypes\", \"topic\": \"Bias in Language Models\", \"x\": 3.268, \"y\": 4.413}, {\"title\": \"One Pass Streaming Algorithm for Super Long Token Attention  Approximation in Sublinear Space\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.61, \"y\": 2.931}, {\"title\": \"Calibrated Language Models Must Hallucinate\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.207, \"y\": 1.166}, {\"title\": \"Data-Efficient Alignment of Large Language Models with Human Feedback  Through Natural Language\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.262, \"y\": 1.568}, {\"title\": \"CMed-GPT: Prompt Tuning for Entity-Aware Chinese Medical Dialogue  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.809, \"y\": 8.077}, {\"title\": \"Machine Translation for Ge'ez Language\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.71, \"y\": 4.496}, {\"title\": \"Automatic detection of problem-gambling signs from online texts using  large language models\", \"topic\": \"Hate Speech Detection\", \"x\": 3.171, \"y\": 5.338}, {\"title\": \"SER_AMPEL: a multi-source dataset for speech emotion recognition of  Italian older adults\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.082, \"y\": 7.942}, {\"title\": \"Universal Jailbreak Backdoors from Poisoned Human Feedback\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.255, \"y\": 2.419}, {\"title\": \"Average Token Delay: A Duration-aware Latency Metric for Simultaneous  Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.509, \"y\": 5.142}, {\"title\": \"A Systematic Review of Deep Learning-based Research on Radiology Report  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.213, \"y\": 8.591}, {\"title\": \"Towards Auditing Large Language Models: Improving Text-based Stereotype  Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.445, \"y\": 4.377}, {\"title\": \"A density estimation perspective on learning from pairwise human  preferences\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.217, \"y\": 1.437}, {\"title\": \"Searching for Snippets of Open-Domain Dialogue in Task-Oriented Dialogue  Datasets\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.272, \"y\": 3.749}, {\"title\": \"Enhancing Task-Oriented Dialogues with Chitchat: a Comparative Study  Based on Lexical Diversity and Divergence\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.458, \"y\": 3.753}, {\"title\": \"Do VSR Models Generalize Beyond LRS3?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.949, \"y\": 5.55}, {\"title\": \"Probabilistic Tree-of-thought Reasoning for Answering  Knowledge-intensive Complex Questions\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.617, \"y\": 2.723}, {\"title\": \"Dialogue Quality and Emotion Annotations for Customer Support  Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.412, \"y\": 7.694}, {\"title\": \"General Phrase Debiaser: Debiasing Masked Language Models at a  Multi-Token Level\", \"topic\": \"Bias in Language Models\", \"x\": 3.254, \"y\": 4.314}, {\"title\": \"Lego: Learning to Disentangle and Invert Concepts Beyond Object  Appearance in Text-to-Image Diffusion Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.812, \"y\": 6.576}, {\"title\": \"Surpassing GPT-4 Medical Coding with a Two-Stage Approach\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.839, \"y\": 8.364}, {\"title\": \"Comparison of pipeline, sequence-to-sequence, and GPT models for  end-to-end relation extraction: experiments with the rare disease use-case\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.441, \"y\": 7.386}, {\"title\": \"MAIRA-1: A specialised large multimodal model for radiology report  generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.238, \"y\": 8.613}, {\"title\": \"Prompt Risk Control: A Rigorous Framework for Responsible Deployment of  Large Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.101, \"y\": 3.281}, {\"title\": \"Efficient Deep Speech Understanding at the Edge\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.005, \"y\": 5.075}, {\"title\": \"Current Topological and Machine Learning Applications for Bias Detection  in Text\", \"topic\": \"Bias in Language Models\", \"x\": 3.36, \"y\": 4.696}, {\"title\": \"Machine Translation to Control Formality Features in the Target Language\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.418, \"y\": 4.871}, {\"title\": \"Fact-based Court Judgment Prediction\", \"topic\": \"Legal NLP\", \"x\": 5.025, \"y\": 5.844}, {\"title\": \"Rethinking Radiology Report Generation via Causal Reasoning and  Counterfactual Augmentation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.269, \"y\": 8.584}, {\"title\": \"Intention and Context Elicitation with Large Language Models in the  Legal Aid Intake Process\", \"topic\": \"Legal NLP\", \"x\": 5.185, \"y\": 5.447}, {\"title\": \"Enhancing Summarization Performance through Transformer-Based Prompt  Engineering in Automated Medical Reporting\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.773, \"y\": 7.98}, {\"title\": \"Comparative Experimentation of Accuracy Metrics in Automated Medical  Reporting: The Case of Otitis Consultations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.619, \"y\": 7.895}, {\"title\": \"ViStruct: Visual Structural Knowledge Extraction via Curriculum Guided  Code-Vision Representation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.518, \"y\": 7.512}, {\"title\": \"CoachLM: Automatic Instruction Revisions Improve the Data Quality in LLM  Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.135, \"y\": 2.304}, {\"title\": \"Enhancing Uncertainty-Based Hallucination Detection with Stronger Focus\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.217, \"y\": 1.127}, {\"title\": \"ComPEFT: Compression for Communicating Parameter Efficient Updates via  Sparsification and Quantization\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.118, \"y\": 2.19}, {\"title\": \"LIMIT: Less Is More for Instruction Tuning Across Evaluation Paradigms\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.274, \"y\": 2.387}, {\"title\": \"Conditions for Length Generalization in Learning Reasoning Skills\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.57, \"y\": 2.963}, {\"title\": \"White-Box Transformers via Sparse Rate Reduction: Compression Is All  There Is?\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.749, \"y\": 3.232}, {\"title\": \"Enhancing Logical Reasoning in Large Language Models to Facilitate Legal  Applications\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.497, \"y\": 2.722}, {\"title\": \"Positional Description Matters for Transformers Arithmetic\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.625, \"y\": 3.472}, {\"title\": \"Attribution and Alignment: Effects of Local Context Repetition on  Utterance Production and Comprehension in Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.604, \"y\": 3.879}, {\"title\": \"Beyond Text: Unveiling Multimodal Proficiency of Large Language Models  with MultiAPI Benchmark\", \"topic\": \"Multimodal Language Models\", \"x\": 7.943, \"y\": 7.445}, {\"title\": \"Data Diversity Matters for Robust Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.247, \"y\": 2.27}, {\"title\": \"A Baseline Analysis of Reward Models' Ability To Accurately Analyze  Foundation Models Under Distribution Shift\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.156, \"y\": 1.468}, {\"title\": \"Can Large Language Models Understand Content and Propagation for  Misinformation Detection: An Empirical Study\", \"topic\": \"Fake News Detection\", \"x\": 4.156, \"y\": 5.49}, {\"title\": \"Fair Text Classification with Wasserstein Independence\", \"topic\": \"Bias in Language Models\", \"x\": 3.333, \"y\": 4.254}, {\"title\": \"MathGloss: Building mathematical glossaries from text\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.126, \"y\": 2.975}, {\"title\": \"IMGTB: A Framework for Machine-Generated Text Detection Benchmarking\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.037, \"y\": 4.889}, {\"title\": \"In-Context Learning Functions with Varying Number of Minima\", \"topic\": \"In-Context Learning\", \"x\": 8.412, \"y\": 3.344}, {\"title\": \"Multilingual Word Embeddings for Low-Resource Languages using Anchors  and a Chain of Related Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.333, \"y\": 4.838}, {\"title\": \"Speaker-Adapted End-to-End Visual Speech Recognition for Continuous  Spanish\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.759, \"y\": 5.604}, {\"title\": \"Analysis of Visual Features for Continuous Lipreading in Spanish\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.81, \"y\": 5.645}, {\"title\": \"LIP-RTVE: An Audiovisual Database for Continuous Spanish in the Wild\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.716, \"y\": 5.638}, {\"title\": \"InterPrompt: Interpretable Prompting for Interrelated Interpersonal Risk  Factors in Reddit Posts\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.227, \"y\": 7.51}, {\"title\": \"Problems of Non-equivalent Words in Technical Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.447, \"y\": 4.814}, {\"title\": \"The Obscure Limitation of Modular Multilingual Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.204, \"y\": 4.357}, {\"title\": \"Beyond Turing: A Comparative Analysis of Approaches for Detecting  Machine-Generated Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.157, \"y\": 4.779}, {\"title\": \"Utilizing Language Models for Tour Itinerary Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.991, \"y\": 2.891}, {\"title\": \"Modeling Political Orientation of Social Media Posts: An Extended  Analysis\", \"topic\": \"Fake News Detection\", \"x\": 3.613, \"y\": 5.616}, {\"title\": \"Leveraging Closed-Access Multilingual Embedding for Automatic Sentence  Alignment in Low Resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.456, \"y\": 5.006}, {\"title\": \"Context-aware Neural Machine Translation for English-Japanese Business  Scene Dialogues\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.694, \"y\": 4.302}, {\"title\": \"Adaptive Training Distributions with Scalable Online Bilevel  Optimization\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.114, \"y\": 2.498}, {\"title\": \"FinanceBench: A New Benchmark for Financial Question Answering\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.924, \"y\": 6.877}, {\"title\": \"LLMs as Visual Explainers: Advancing Image Classification with Evolving  Visual Descriptions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.606, \"y\": 7.433}, {\"title\": \"Generating Valid and Natural Adversarial Examples with Large Language  Models\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.251, \"y\": 2.944}, {\"title\": \"System 2 Attention (is something you might need too)\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.609, \"y\": 3.309}, {\"title\": \"Igniting Language Intelligence: The Hitchhiker's Guide From  Chain-of-Thought Reasoning to Language Agents\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.441, \"y\": 2.374}, {\"title\": \"ELF: Encoding Speaker-Specific Latent Speech Feature for Speech  Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.694, \"y\": 5.522}, {\"title\": \"Sparse Low-rank Adaptation of Pre-trained Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.19, \"y\": 2.099}, {\"title\": \"Refactoring Programs Using Large Language Models with Few-Shot Examples\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.316, \"y\": 2.404}, {\"title\": \"Taiyi: A Bilingual Fine-Tuned Large Language Model for Diverse  Biomedical Tasks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.17, \"y\": 7.816}, {\"title\": \"Addressing the Length Bias Problem in Document-Level Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.912, \"y\": 4.237}, {\"title\": \"Filling the Image Information Gap for VQA: Prompting Large Language  Models to Proactively Ask Questions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.246, \"y\": 7.983}, {\"title\": \"KBioXLM: A Knowledge-anchored Biomedical Multilingual Pretrained  Language Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.27, \"y\": 7.835}, {\"title\": \"Token-Level Adversarial Prompt Detection Based on Perplexity Measures  and Contextual Information\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.42, \"y\": 2.738}, {\"title\": \"What's left can't be right -- The remaining positional incompetence of  contrastive vision-language models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.702, \"y\": 7.072}, {\"title\": \"Spot the Bot: Distinguishing Human-Written and Bot-Generated Texts Using  Clustering and Information Theory Techniques\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.288, \"y\": 4.904}, {\"title\": \"ML-LMCL: Mutual Learning and Large-Margin Contrastive Learning for  Improving ASR Robustness in Spoken Language Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.87, \"y\": 5.001}, {\"title\": \"Zero-Shot Question Answering over Financial Documents using Large  Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.929, \"y\": 6.814}, {\"title\": \"Visual AI and Linguistic Intelligence Through Steerability and  Composability\", \"topic\": \"Multimodal Language Models\", \"x\": 8.151, \"y\": 7.621}, {\"title\": \"A Principled Framework for Knowledge-enhanced Large Language Model\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.658, \"y\": 3.234}, {\"title\": \"Utilizing Speech Emotion Recognition and Recommender Systems for  Negative Emotion Handling in Therapy Chatbots\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.676, \"y\": 7.865}, {\"title\": \"Radiology Report Generation Using Transformers Conditioned with  Non-imaging Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.238, \"y\": 8.633}, {\"title\": \"Beyond Images: An Integrative Multi-modal Approach to Chest X-Ray Report  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.221, \"y\": 8.584}, {\"title\": \"Joyful: Joint Modality Fusion and Graph Contrastive Learning for  Multimodal Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.283, \"y\": 7.674}, {\"title\": \"Gendec: A Machine Learning-based Framework for Gender Detection from  Japanese Names\", \"topic\": \"Bias in Language Models\", \"x\": 3.152, \"y\": 4.405}, {\"title\": \"Journey of Hallucination-minimized Generative AI Solutions for Financial  Decision Makers\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.897, \"y\": 6.718}, {\"title\": \"An Empirical Bayes Framework for Open-Domain Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.45, \"y\": 3.927}, {\"title\": \"Deception Detection from Linguistic and Physiological Data Streams Using  Bimodal Convolutional Neural Networks\", \"topic\": \"Fake News Detection\", \"x\": 3.969, \"y\": 5.744}, {\"title\": \"Partially Randomizing Transformer Weights for Dialogue Response  Diversity\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 9.612, \"y\": 3.213}, {\"title\": \"Representing visual classification as a linear combination of words\", \"topic\": \"Multimodal Language Models\", \"x\": 8.501, \"y\": 7.469}, {\"title\": \"Extraction and Summarization of Explicit Video Content using Multi-Modal  Deep Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.861, \"y\": 7.844}, {\"title\": \"Labeling Indoor Scenes with Fusion of Out-of-the-Box Perception Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.76, \"y\": 7.153}, {\"title\": \"Token-Level Adaptation of LoRA Adapters for Downstream Task  Generalization\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.239, \"y\": 2.039}, {\"title\": \"PEFT-MedAware: Large Language Model for Medical Awareness\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.878, \"y\": 7.963}, {\"title\": \"Use GPT-J Prompt Generation with RoBERTa for NER Models on Diagnosis  Extraction of Periodontal Diagnosis from Electronic Dental Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.102, \"y\": 7.687}, {\"title\": \"Rethinking Attention: Exploring Shallow Feed-Forward Neural Networks as  an Alternative to Attention Layers in Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.841, \"y\": 3.34}, {\"title\": \"Detection of Offensive and Threatening Online Content in a Low Resource  Language\", \"topic\": \"Hate Speech Detection\", \"x\": 2.851, \"y\": 5.357}, {\"title\": \"When a Language Question Is at Stake. A Revisited Approach to Label  Sensitive Content\", \"topic\": \"Hate Speech Detection\", \"x\": 2.856, \"y\": 5.363}, {\"title\": \"A Study on Altering the Latent Space of Pretrained Text to Speech Models  for Improved Expressiveness\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.427, \"y\": 6.031}, {\"title\": \"Sinhala-English Word Embedding Alignment: Introducing Datasets and  Benchmark for a Low Resource Language\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.287, \"y\": 5.104}, {\"title\": \"Bias A-head? Analyzing Bias in Transformer-Based Language Model  Attention Heads\", \"topic\": \"Bias in Language Models\", \"x\": 3.218, \"y\": 4.426}, {\"title\": \"FOAL: Fine-grained Contrastive Learning for Cross-domain Aspect  Sentiment Triplet Extraction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.098, \"y\": 6.846}, {\"title\": \"Exploring the Relationship between In-Context Learning and Instruction  Tuning\", \"topic\": \"In-Context Learning\", \"x\": 8.368, \"y\": 3.244}, {\"title\": \"TaCo: Enhancing Cross-Lingual Transfer for Low-Resource Languages in  LLMs through Translation-Assisted Chain-of-Thought Processes\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.293, \"y\": 4.549}, {\"title\": \"Complementary Advantages of ChatGPTs and Human Readers in Reasoning:  Evidence from English Text Reading Comprehension\", \"topic\": \"Bias in Language Models\", \"x\": 5.396, \"y\": 4.485}, {\"title\": \"Latent Feature-based Data Splits to Improve Generalisation Evaluation: A  Hate Speech Detection Case Study\", \"topic\": \"Hate Speech Detection\", \"x\": 2.734, \"y\": 5.368}, {\"title\": \"A Computationally Efficient Sparsified Online Newton Method\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.31, \"y\": 2.62}, {\"title\": \"DRESS: Instructing Large Vision-Language Models to Align and Interact  with Humans via Natural Language Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.051, \"y\": 1.425}, {\"title\": \"ChatGPT-3.5, ChatGPT-4, Google Bard, and Microsoft Bing to Improve  Health Literacy and Communication in Pediatric Populations and Beyond\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.582, \"y\": 7.921}, {\"title\": \"Generative AI for Hate Speech Detection: Evaluation and Findings\", \"topic\": \"Hate Speech Detection\", \"x\": 2.707, \"y\": 5.345}, {\"title\": \"ExFake: Towards an Explainable Fake News Detection Based on Content and  Social Context Information\", \"topic\": \"Fake News Detection\", \"x\": 3.982, \"y\": 5.78}, {\"title\": \"Hijacking Large Language Models via Adversarial In-Context Learning\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.294, \"y\": 2.604}, {\"title\": \"A BERT based Ensemble Approach for Sentiment Classification of Customer  Reviews and its Application to Nudge Marketing in e-Commerce\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.699, \"y\": 6.532}, {\"title\": \"Leveraging LLMs in Scholarly Knowledge Graph Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.677, \"y\": 5.53}, {\"title\": \"PELMS: Pre-training for Effective Low-Shot Multi-Document Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.761, \"y\": 6.356}, {\"title\": \"ML-Bench: Evaluating Large Language Models and Agents for Machine  Learning Tasks on Repository-Level Code\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.195, \"y\": 2.601}, {\"title\": \"Overview of the HASOC Subtrack at FIRE 2023: Identification of Tokens  Contributing to Explicit Hate in English by Span Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.811, \"y\": 5.457}, {\"title\": \"AutoPlanBench: Automatically generating benchmarks for LLM planners from  PDDL\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.974, \"y\": 2.634}, {\"title\": \"AfriMTE and AfriCOMET: Enhancing COMET to Embrace Under-resourced  African Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.648, \"y\": 5.041}, {\"title\": \"Cognitive Overload: Jailbreaking Large Language Models with Overloaded  Logical Thinking\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.372, \"y\": 2.283}, {\"title\": \"MedAgents: Large Language Models as Collaborators for Zero-shot Medical  Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.715, \"y\": 8.213}, {\"title\": \"Neuro-Symbolic Integration Brings Causal and Reliable Reasoning Proofs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.649, \"y\": 2.949}, {\"title\": \"KnowledgeMath: Knowledge-Intensive Math Word Problem Solving in Finance  Domains\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.937, \"y\": 3.164}, {\"title\": \"HuatuoGPT-II, One-stage Training for Medical Adaption of LLMs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.944, \"y\": 7.993}, {\"title\": \"To be or not to be? an exploration of continuously controllable prompt  engineering\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.247, \"y\": 3.205}, {\"title\": \"Test-time Backdoor Mitigation for Black-Box Large Language Models with  Defensive Demonstrations\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.287, \"y\": 2.443}, {\"title\": \"FairytaleCQA: Integrating a Commonsense Knowledge Graph into Children's  Storybook Narratives\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.305, \"y\": 5.051}, {\"title\": \"How Does Calibration Data Affect the Post-training Pruning and  Quantization of Large Language Models?\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.621, \"y\": 2.344}, {\"title\": \"CARE: Extracting Experimental Findings From Clinical Literature\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.66, \"y\": 7.672}, {\"title\": \"Aligning with Whom? Large Language Models Have Gender and Racial Biases  in Subjective NLP Tasks\", \"topic\": \"Bias in Language Models\", \"x\": 3.644, \"y\": 4.384}, {\"title\": \"Regularized Conventions: Equilibrium Computation as a Model of Pragmatic  Reasoning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.429, \"y\": 2.963}, {\"title\": \"A Self-enhancement Multitask Framework for Unsupervised Aspect Category  Detection\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.052, \"y\": 6.887}, {\"title\": \"GenCodeSearchNet: A Benchmark Test Suite for Evaluating Generalization  in Programming Language Understanding\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.575, \"y\": 2.475}, {\"title\": \"Deceptive Semantic Shortcuts on Reasoning Chains: How Far Can Models Go  without Hallucination?\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.42, \"y\": 1.415}, {\"title\": \"BLT: Can Large Language Models Handle Basic Legal Text?\", \"topic\": \"Legal NLP\", \"x\": 5.173, \"y\": 5.514}, {\"title\": \"Do Physicians Know How to Prompt? The Need for Automatic Prompt  Optimization Help in Clinical Note Generation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 5.843, \"y\": 7.56}, {\"title\": \"RLHFPoison: Reward Poisoning Attack for Reinforcement Learning with  Human Feedback in Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.603, \"y\": 2.42}, {\"title\": \"Bergeron: Combating Adversarial Attacks through a Conscience-Based  Alignment Framework\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.48, \"y\": 2.577}, {\"title\": \"Mitigating Biases for Instruction-following Language Models via Bias  Neurons Elimination\", \"topic\": \"Bias in Language Models\", \"x\": 3.339, \"y\": 4.046}, {\"title\": \"Take One Step at a Time to Know Incremental Utility of Demonstration: An  Analysis on Reranking for Few-Shot In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.342, \"y\": 3.405}, {\"title\": \"Digital Socrates: Evaluating LLMs through Explanation Critiques\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.547, \"y\": 3.589}, {\"title\": \"Efficient End-to-End Visual Document Understanding with Rationale  Distillation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.264, \"y\": 7.25}, {\"title\": \"GistScore: Learning Better Representations for In-Context Example  Selection with Gist Bottlenecks\", \"topic\": \"In-Context Learning\", \"x\": 8.241, \"y\": 3.315}, {\"title\": \"Language Models (Mostly) Do Not Consider Emotion Triggers When  Predicting Emotion\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.456, \"y\": 7.453}, {\"title\": \"Multi-Step Dialogue Workflow Action Prediction\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.525, \"y\": 3.647}, {\"title\": \"A Systematic Review of Aspect-based Sentiment Analysis (ABSA): Domains,  Methods, and Trends\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.141, \"y\": 6.79}, {\"title\": \"DocLens: Multi-aspect Fine-grained Evaluation for Medical Text  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.765, \"y\": 7.601}, {\"title\": \"Tied-Lora: Enhancing parameter efficiency of LoRA with weight tying\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.16, \"y\": 2.029}, {\"title\": \"Work State-Centric AI Agents: Design, Implementation, and Management of  Cognitive Work Threads\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.701, \"y\": 2.817}, {\"title\": \"Strings from the Library of Babel: Random Sampling as a Strong Baseline  for Prompt Optimisation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.352, \"y\": 3.28}, {\"title\": \"LongBoX: Evaluating Transformers on Long-Sequence Clinical Tasks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.813, \"y\": 7.935}, {\"title\": \"A Speed Odyssey for Deployable Quantization of LLMs\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.723, \"y\": 2.157}, {\"title\": \"HelpSteer: Multi-attribute Helpfulness Dataset for SteerLM\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.122, \"y\": 1.483}, {\"title\": \"Leveraging Code to Improve In-context Learning for Semantic Parsing\", \"topic\": \"In-Context Learning\", \"x\": 8.158, \"y\": 3.621}, {\"title\": \"ARES: An Automated Evaluation Framework for Retrieval-Augmented  Generation Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.933, \"y\": 4.649}, {\"title\": \"Think While You Write: Hypothesis Verification Promotes Faithful  Knowledge-to-Text Generation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.445, \"y\": 1.288}, {\"title\": \"MMC: Advancing Multimodal Chart Understanding with Large-scale  Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.998, \"y\": 7.603}, {\"title\": \"Subtle Misogyny Detection and Mitigation: An Expert-Annotated Dataset\", \"topic\": \"Bias in Language Models\", \"x\": 3.191, \"y\": 4.536}, {\"title\": \"Striped Attention: Faster Ring Attention for Causal Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.897, \"y\": 3.172}, {\"title\": \"Alternatives to the Scaled Dot Product for Attention in the Transformer  Neural Network Architecture\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.886, \"y\": 3.305}, {\"title\": \"To Translate or Not to Translate: A Systematic Investigation of  Translation-Based Cross-Lingual Transfer to Low-Resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.569, \"y\": 4.765}, {\"title\": \"LEEETs-Dial: Linguistic Entrainment in End-to-End Task-oriented Dialogue  systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 10.227, \"y\": 5.307}, {\"title\": \"zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with  Large Language Models\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.911, \"y\": 5.893}, {\"title\": \"Long-form Question Answering: An Iterative Planning-Retrieval-Generation  Approach\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.461, \"y\": 5.187}, {\"title\": \"A Survey on Online User Aggression: Content Detection and Behavioural  Analysis on Social Media Platforms\", \"topic\": \"Hate Speech Detection\", \"x\": 3.038, \"y\": 5.422}, {\"title\": \"Investigating the Emergent Audio Classification Ability of ASR  Foundation Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.109, \"y\": 5.251}, {\"title\": \"LePaRD: A Large-Scale Dataset of Judges Citing Precedents\", \"topic\": \"Legal NLP\", \"x\": 5.058, \"y\": 5.791}, {\"title\": \"Language and Task Arithmetic with Parameter-Efficient Layers for  Zero-Shot Summarization\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.474, \"y\": 4.661}, {\"title\": \"VideoCon: Robust Video-Language Alignment via Contrast Captions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.927, \"y\": 7.795}, {\"title\": \"Investigating Hallucinations in Pruned Large Language Models for  Abstractive Summarization\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.169, \"y\": 1.125}, {\"title\": \"Automatic Restoration of Diacritics for Speech Data Sets\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.82, \"y\": 5.546}, {\"title\": \"Assessing Translation capabilities of Large Language Models involving  English and Indian Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.267, \"y\": 4.448}, {\"title\": \"Mind's Mirror: Distilling Self-Evaluation Capability and Comprehensive  Thinking from Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.761, \"y\": 2.32}, {\"title\": \"Controllable Text Summarization: Unraveling Challenges, Approaches, and  Prospects -- A Survey\", \"topic\": \"Text Summarization\", \"x\": 5.68, \"y\": 6.278}, {\"title\": \"Contrastive Chain-of-Thought Prompting\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.737, \"y\": 2.377}, {\"title\": \"When Is Multilinguality a Curse? Language Modeling for 250 High- and  Low-Resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.161, \"y\": 4.49}, {\"title\": \"The Role of Chain-of-Thought in Complex Vision-Language Reasoning Task\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.662, \"y\": 2.308}, {\"title\": \"Aligning Neural Machine Translation Models: Human Feedback in Training  and Inference\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.287, \"y\": 1.439}, {\"title\": \"Universal NER: A Gold-Standard Multilingual Named Entity Recognition  Benchmark\", \"topic\": \"Named Entity Recognition\", \"x\": 7.417, \"y\": 6.811}, {\"title\": \"R-Spin: Efficient Speaker and Noise-invariant Representation Learning  with Acoustic Pieces\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.954, \"y\": 5.098}, {\"title\": \"Ever: Mitigating Hallucination in Large Language Models through  Real-Time Verification and Rectification\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.279, \"y\": 1.19}, {\"title\": \"Does Pre-trained Language Model Actually Infer Unseen Links in Knowledge  Graph Completion?\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.072, \"y\": 5.968}, {\"title\": \"\\\"We Demand Justice!\\\": Towards Social Context Grounding of Political  Texts\", \"topic\": \"Fake News Detection\", \"x\": 3.655, \"y\": 5.518}, {\"title\": \"Towards A Unified View of Answer Calibration for Multi-Step Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.721, \"y\": 2.497}, {\"title\": \"Defending Large Language Models Against Jailbreaking Attacks Through  Goal Prioritization\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.266, \"y\": 2.248}, {\"title\": \"Social Bias Probing: Fairness Benchmarking for Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.35, \"y\": 4.392}, {\"title\": \"The Uli Dataset: An Exercise in Experience Led Annotation of oGBV\", \"topic\": \"Hate Speech Detection\", \"x\": 2.79, \"y\": 5.483}, {\"title\": \"How Vocabulary Sharing Facilitates Multilingualism in LLaMA?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.113, \"y\": 4.386}, {\"title\": \"Identifying Self-Disclosures of Use, Misuse and Addiction in  Community-based Social Media Posts\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.347, \"y\": 7.334}, {\"title\": \"GRASP: A novel benchmark for evaluating language GRounding And Situated  Physics understanding in multimodal language models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.344, \"y\": 7.356}, {\"title\": \"End-to-end Task-oriented Dialogue: A Survey of Tasks, Methods, and  Future Directions\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.484, \"y\": 3.738}, {\"title\": \"When does In-context Learning Fall Short and Why? A Study on  Specification-Heavy Tasks\", \"topic\": \"In-Context Learning\", \"x\": 8.406, \"y\": 3.267}, {\"title\": \"SentAlign: Accurate and Scalable Sentence Alignment\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.57, \"y\": 4.995}, {\"title\": \"Improving Large-scale Deep Biasing with Phoneme Features and Text-only  Data in Streaming Transducer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.25, \"y\": 5.2}, {\"title\": \"Self-Improving for Zero-Shot Named Entity Recognition with Large  Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 7.41, \"y\": 6.638}, {\"title\": \"Few-shot Transfer Learning for Knowledge Base Question Answering: Fusing  Supervised Models with In-Context Learning\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.729, \"y\": 5.397}, {\"title\": \"Large Language Models are legal but they are not: Making the case for a  powerful LegalLLM\", \"topic\": \"Legal NLP\", \"x\": 5.232, \"y\": 5.457}, {\"title\": \"Violet: A Vision-Language Model for Arabic Image Captioning with Gemini  Decoder\", \"topic\": \"Multimodal Language Models\", \"x\": 8.949, \"y\": 7.571}, {\"title\": \"Evaluating Gender Bias in the Translation of Gender-Neutral Languages  into English\", \"topic\": \"Bias in Language Models\", \"x\": 3.051, \"y\": 4.385}, {\"title\": \"German FinBERT: A German Pre-trained Language Model\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.887, \"y\": 6.872}, {\"title\": \"Auto-ICL: In-Context Learning without Human Supervision\", \"topic\": \"In-Context Learning\", \"x\": 8.259, \"y\": 3.375}, {\"title\": \"Thread of Thought Unraveling Chaotic Contexts\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.355, \"y\": 2.421}, {\"title\": \"Uncertainty Estimation on Sequential Labeling via Uncertainty  Transmission\", \"topic\": \"Named Entity Recognition\", \"x\": 7.408, \"y\": 6.62}, {\"title\": \"Knowledge Graph Construction in Power Distribution Networks\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.963, \"y\": 6.13}, {\"title\": \"Token Prediction as Implicit Classification to Identify LLM-Generated  Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.285, \"y\": 4.635}, {\"title\": \"Attribute Diversity Determines the Systematicity Gap in VQA\", \"topic\": \"Multimodal Language Models\", \"x\": 8.256, \"y\": 8.033}, {\"title\": \"An Eye on Clinical BERT: Investigating Language Model Generalization for  Diabetic Eye Disease Phenotyping\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.103, \"y\": 8.12}, {\"title\": \"Safer-Instruct: Aligning Language Models with Automated Preference Data\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.148, \"y\": 1.349}, {\"title\": \"It Takes Two to Negotiate: Modeling Social Exchange in Online  Multiplayer Games\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.161, \"y\": 3.1}, {\"title\": \"Multistage Collaborative Knowledge Distillation from a Large Language  Model for Semi-Supervised Sequence Generation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.558, \"y\": 3.876}, {\"title\": \"Comparing Generalization in Learning with Limited Numbers of Exemplars:  Transformer vs. RNN in Attractor Dynamics\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.417, \"y\": 3.44}, {\"title\": \"Towards Generalizable SER: Soft Labeling and Data Augmentation for  Modeling Temporal Emotion Shifts in Large-Scale Multilingual Speech\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.162, \"y\": 7.885}, {\"title\": \"Exploring the Jungle of Bias: Political Bias Attribution in Language  Models via Dependency Analysis\", \"topic\": \"Bias in Language Models\", \"x\": 3.519, \"y\": 4.452}, {\"title\": \"ACID: Abstractive, Content-Based IDs for Document Retrieval with  Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.342, \"y\": 5.13}, {\"title\": \"PEMA: An Offsite-Tunable Plug-in External Memory Adaptation for Language  Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.047, \"y\": 2.438}, {\"title\": \"CodeScope: An Execution-based Multilingual Multitask Multidimensional  Benchmark for Evaluating LLMs on Code Understanding and Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.441, \"y\": 2.532}, {\"title\": \"Asking More Informative Questions for Grounded Retrieval\", \"topic\": \"Multimodal Language Models\", \"x\": 8.151, \"y\": 7.975}, {\"title\": \"Low-Rank Adaptation for Multilingual Summarization: An Empirical Study\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.184, \"y\": 2.066}, {\"title\": \"MAgIC: Investigation of Large Language Model Powered Multi-Agent in  Cognition, Adaptability, Rationality and Collaboration\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.609, \"y\": 3.024}, {\"title\": \"Extending Multilingual Machine Translation through Imitation Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.63, \"y\": 4.554}, {\"title\": \"Natural Language Processing for Financial Regulation\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.931, \"y\": 6.705}, {\"title\": \"GLiNER: Generalist Model for Named Entity Recognition using  Bidirectional Transformer\", \"topic\": \"Named Entity Recognition\", \"x\": 7.279, \"y\": 6.816}, {\"title\": \"LLMs cannot find reasoning errors, but can correct them given the error  location\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.657, \"y\": 2.391}, {\"title\": \"CoRE-CoG: Conversational Recommendation of Entities using Constrained  Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.912, \"y\": 3.073}, {\"title\": \"Functionality learning through specification instructions\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.265, \"y\": 2.394}, {\"title\": \"Selecting Shots for Demographic Fairness in Few-Shot Learning with Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.495, \"y\": 4.22}, {\"title\": \"Retrieve and Copy: Scaling ASR Personalization to Large Catalogs\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.257, \"y\": 5.132}, {\"title\": \"How You Prompt Matters! Even Task-Oriented Constraints in Instructions  Affect LLM-Generated Text Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 3.816, \"y\": 3.725}, {\"title\": \"AI-generated text boundary detection with RoFT\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.151, \"y\": 4.758}, {\"title\": \"Anti-LM Decoding for Zero-shot In-context Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.688, \"y\": 4.34}, {\"title\": \"Extrinsically-Focused Evaluation of Omissions in Medical Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.575, \"y\": 7.477}, {\"title\": \"Workflow-Guided Response Generation for Task-Oriented Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.457, \"y\": 3.675}, {\"title\": \"How Well Do Large Language Models Understand Syntax? An Evaluation by  Asking Natural Language Questions\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.106, \"y\": 3.737}, {\"title\": \"Examining Modularity in Multilingual LMs via Language-Specialized  Subnetworks\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.29, \"y\": 4.367}, {\"title\": \"A Wolf in Sheep's Clothing: Generalized Nested Jailbreak Prompts can  Fool Large Language Models Easily\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.305, \"y\": 2.281}, {\"title\": \"Unlock the Power: Competitive Distillation for Multi-Modal Large  Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.567, \"y\": 4.011}, {\"title\": \"Self-Evolved Diverse Data Sampling for Efficient Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.171, \"y\": 2.344}, {\"title\": \"Just Ask One More Time! Self-Agreement Improves Reasoning of Language  Models in (Almost) All Scenarios\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.63, \"y\": 2.238}, {\"title\": \"Sinkhorn Transformations for Single-Query Postprocessing in Text-Video  Retrieval\", \"topic\": \"Multimodal Language Models\", \"x\": 8.932, \"y\": 7.748}, {\"title\": \"Memory-efficient Stochastic methods for Memory-based Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.719, \"y\": 3.062}, {\"title\": \"Insights into Classifying and Mitigating LLMs' Hallucinations\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.15, \"y\": 1.138}, {\"title\": \"Improving Hateful Meme Detection through Retrieval-Guided Contrastive  Learning\", \"topic\": \"Hate Speech Detection\", \"x\": 2.78, \"y\": 5.506}, {\"title\": \"Exploring Semi-supervised Hierarchical Stacked Encoder for Legal  Judgement Prediction\", \"topic\": \"Legal NLP\", \"x\": 5.105, \"y\": 5.831}, {\"title\": \"Empowering Multi-step Reasoning across Languages via Tree-of-Thoughts\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.772, \"y\": 2.536}, {\"title\": \"Improving In-context Learning of Multilingual Generative Language Models  with Cross-lingual Alignment\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.268, \"y\": 4.92}, {\"title\": \"Data and models for stance and premise detection in COVID-19 tweets:  insights from the Social Media Mining for Health (SMM4H) 2022 shared task\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.031, \"y\": 6.881}, {\"title\": \"Adversarial Preference Optimization: Enhancing Your Alignment via RM-LLM  Game\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.283, \"y\": 1.344}, {\"title\": \"Distantly-Supervised Named Entity Recognition with Uncertainty-aware  Teacher Learning and Student-student Collaborative Learning\", \"topic\": \"Named Entity Recognition\", \"x\": 7.434, \"y\": 6.662}, {\"title\": \"TempTabQA: Temporal Question Answering for Semi-Structured Tables\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.441, \"y\": 5.455}, {\"title\": \"Non-Parametric Memory Guidance for Multi-Document Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.687, \"y\": 6.384}, {\"title\": \"A Closer Look at the Self-Verification Abilities of Large Language  Models in Logical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.618, \"y\": 3.022}, {\"title\": \"First-Step Advantage: Importance of Starting Right in Multi-Step Math  Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.827, \"y\": 2.445}, {\"title\": \"Non-autoregressive Machine Translation with Probabilistic Context-free  Grammar\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.152, \"y\": 4.41}, {\"title\": \"Qwen-Audio: Advancing Universal Audio Understanding via Unified  Large-Scale Audio-Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.551, \"y\": 5.299}, {\"title\": \"Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.26, \"y\": 1.195}, {\"title\": \"Fair Abstractive Summarization of Diverse Perspectives\", \"topic\": \"Bias in Language Models\", \"x\": 3.569, \"y\": 4.313}, {\"title\": \"Bring Your Own KG: Self-Supervised Program Synthesis for Zero-Shot KGQA\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.717, \"y\": 5.365}, {\"title\": \"In-context Learning Generalizes, But Not Always Robustly: The Case of  Syntax\", \"topic\": \"In-Context Learning\", \"x\": 8.374, \"y\": 3.371}, {\"title\": \"IruMozhi: Automatically classifying diglossia in Tamil\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.157, \"y\": 5.23}, {\"title\": \"In-context Learning and Gradient Descent Revisited\", \"topic\": \"In-Context Learning\", \"x\": 8.543, \"y\": 3.315}, {\"title\": \"GreekT5: A Series of Greek Sequence-to-Sequence Models for News  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.561, \"y\": 6.406}, {\"title\": \"Vision-Language Integration in Multimodal Video Transformers (Partially)  Aligns with the Brain\", \"topic\": \"Multimodal Language Models\", \"x\": 8.278, \"y\": 7.242}, {\"title\": \"Generalization Analogies: A Testbed for Generalizing AI Oversight to  Hard-To-Measure Domains\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.187, \"y\": 1.707}, {\"title\": \"AuthentiGPT: Detecting Machine-Generated Text via Black-Box Language  Models Denoising\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.129, \"y\": 4.72}, {\"title\": \"SPHINX: The Joint Mixing of Weights, Tasks, and Visual Embeddings for  Multi-modal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.226, \"y\": 7.386}, {\"title\": \"A Comprehensive Evaluation of GPT-4V on Knowledge-Intensive Visual  Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.043, \"y\": 7.818}, {\"title\": \"It's Not Easy Being Wrong: Large Language Models Struggle with Process  of Elimination Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.646, \"y\": 2.356}, {\"title\": \"A Benchmark to Understand the Role of Knowledge Graphs on Large Language  Model's Accuracy for Question Answering on Enterprise SQL Databases\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.809, \"y\": 5.281}, {\"title\": \"Finding and Editing Multi-Modal Neurons in Pre-Trained Transformers\", \"topic\": \"Multimodal Language Models\", \"x\": 8.234, \"y\": 7.255}, {\"title\": \"Think Before You Speak: Cultivating Communication Skills of Large  Language Models via Inner Monologue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.385, \"y\": 3.396}, {\"title\": \"Investigating Multi-Pivot Ensembling with Massively Multilingual Machine  Translation Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.674, \"y\": 4.605}, {\"title\": \"Hallucination Augmented Recitations for Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.301, \"y\": 1.227}, {\"title\": \"AMBER: An LLM-free Multi-dimensional Benchmark for MLLMs Hallucination  Evaluation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.152, \"y\": 1.042}, {\"title\": \"Assessing Logical Puzzle Solving in Large Language Models: Insights from  a Minesweeper Case Study\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.466, \"y\": 2.958}, {\"title\": \"Past as a Guide: Leveraging Retrospective Learning for Python Code  Completion\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.341, \"y\": 2.38}, {\"title\": \"Volcano: Mitigating Multimodal Hallucination through Self-Feedback  Guided Revision\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.405, \"y\": 1.023}, {\"title\": \"Semi-automatic Data Enhancement for Document-Level Relation Extraction  with Distant Supervision from Large Language Models\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.903, \"y\": 6.807}, {\"title\": \"BIDRN: A Method of Bidirectional Recurrent Neural Network for Sentiment  Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.553, \"y\": 6.733}, {\"title\": \"AdaCCD: Adaptive Semantic Contrasts Discovery Based Cross Lingual  Adaptation for Code Clone Detection\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.369, \"y\": 4.764}, {\"title\": \"Danish Foundation Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.711, \"y\": 4.137}, {\"title\": \"In Search of the Long-Tail: Systematic Generation of Long-Tail  Inferential Knowledge via Logical Rule Guided Search\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.643, \"y\": 2.949}, {\"title\": \"How are Prompts Different in Terms of Sensitivity?\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.647, \"y\": 3.309}, {\"title\": \"Coffee: Boost Your Code LLMs by Fixing Bugs with Feedback\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.505, \"y\": 2.308}, {\"title\": \"VerityMath: Advancing Mathematical Reasoning by Self-Verification  Through Unit Consistency\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.002, \"y\": 2.868}, {\"title\": \"Developing a Named Entity Recognition Dataset for Tagalog\", \"topic\": \"Named Entity Recognition\", \"x\": 7.338, \"y\": 6.757}, {\"title\": \"Fovea Transformer: Efficient Long-Context Modeling with Structured  Fine-to-Coarse Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.771, \"y\": 3.202}, {\"title\": \"On the Effectiveness of ASR Representations in Real-world Noisy Speech  Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.203, \"y\": 7.848}, {\"title\": \"Context Consistency between Training and Testing in Simultaneous Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.853, \"y\": 4.607}, {\"title\": \"Towards the Law of Capacity Gap in Distilling Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.424, \"y\": 3.701}, {\"title\": \"Phonological Level wav2vec2-based Mispronunciation Detection and  Diagnosis Method\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.962, \"y\": 5.502}, {\"title\": \"ViLMA: A Zero-Shot Benchmark for Linguistic and Temporal Grounding in  Video-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.703, \"y\": 7.68}, {\"title\": \"Teach me with a Whisper: Enhancing Large Language Models for Analyzing  Spoken Transcripts using Speech Embeddings\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.83, \"y\": 5.124}, {\"title\": \"Context-dependent Instruction Tuning for Dialogue Response Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.68, \"y\": 3.94}, {\"title\": \"Can Large Language Models Augment a Biomedical Ontology with missing  Concepts and Relations?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.87, \"y\": 7.849}, {\"title\": \"DialMAT: Dialogue-Enabled Transformer with Moment-Based Adversarial  Training\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.236, \"y\": 3.511}, {\"title\": \"Automatic Textual Normalization for Hate Speech Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.756, \"y\": 5.413}, {\"title\": \"Evaluation of GPT-4 for chest X-ray impression generation: A reader  study on performance and perception\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.222, \"y\": 8.562}, {\"title\": \"On the Robustness of Question Rewriting Systems to Questions of Varying  Hardness\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.502, \"y\": 5.097}, {\"title\": \"Learning Globally Optimized Language Structure via Adversarial Training\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.153, \"y\": 3.057}, {\"title\": \"Large Language Models' Understanding of Math: Source Criticism and  Extrapolation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.675, \"y\": 3.539}, {\"title\": \"Sharing, Teaching and Aligning: Knowledgeable Transfer Learning for  Cross-Lingual Machine Reading Comprehension\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.375, \"y\": 4.876}, {\"title\": \"From Complex to Simple: Unraveling the Cognitive Tree for Reasoning with  Small Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.422, \"y\": 2.836}, {\"title\": \"AudioChatLlama: Towards General-Purpose Speech Abilities for LLMs\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.402, \"y\": 5.435}, {\"title\": \"Detecting and Correcting Hate Speech in Multimodal Memes with Large  Visual Language Model\", \"topic\": \"Hate Speech Detection\", \"x\": 2.776, \"y\": 5.499}, {\"title\": \"Are LLMs Rigorous Logical Reasoner? Empowering Natural Language Proof  Generation with Contrastive Stepwise Decoding\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.666, \"y\": 2.819}, {\"title\": \"Controllable Topic-Focused Abstractive Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.67, \"y\": 6.304}, {\"title\": \"Which One? Leveraging Context Between Objects and Multiple Views for  Language Grounding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.769, \"y\": 7.351}, {\"title\": \"In-context Vectors: Making In Context Learning More Effective and  Controllable Through Latent Space Steering\", \"topic\": \"In-Context Learning\", \"x\": 8.454, \"y\": 3.352}, {\"title\": \"Robust Text Classification: Analyzing Prototype-Based Networks\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.221, \"y\": 3.059}, {\"title\": \"TrainerAgent: Customizable and Efficient Model Training through  LLM-Powered Multi-Agent System\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.697, \"y\": 2.67}, {\"title\": \"PerceptionGPT: Effectively Fusing Visual Perception into LLM\", \"topic\": \"Multimodal Language Models\", \"x\": 8.487, \"y\": 7.472}, {\"title\": \"Monkey: Image Resolution and Text Label Are Important Things for Large  Multi-modal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.323, \"y\": 7.481}, {\"title\": \"BizBench: A Quantitative Reasoning Benchmark for Business and Finance\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.99, \"y\": 6.766}, {\"title\": \"Heuristic-Driven Link-of-Analogy Prompting: Enhancing Large Language  Models for Document-Level Event Argument Extraction\", \"topic\": \"In-Context Learning\", \"x\": 7.954, \"y\": 3.431}, {\"title\": \"Translating Legalese: Enhancing Public Understanding of Court Opinions  with Legal Summarizers\", \"topic\": \"Legal NLP\", \"x\": 5.126, \"y\": 5.798}, {\"title\": \"Exploring ChatGPT's Capabilities on Vulnerability Management\", \"topic\": \"Bias in Language Models\", \"x\": 5.225, \"y\": 4.482}, {\"title\": \"Don't Overlook the Grammatical Gender: Bias Evaluation for Hindi-English  Machine Translation\", \"topic\": \"Bias in Language Models\", \"x\": 3.042, \"y\": 4.408}, {\"title\": \"Step by Step to Fairness: Attributing Societal Bias in Task-oriented  Dialogue Systems\", \"topic\": \"Bias in Language Models\", \"x\": 3.444, \"y\": 4.259}, {\"title\": \"THOS: A Benchmark Dataset for Targeted Hate and Offensive Speech\", \"topic\": \"Hate Speech Detection\", \"x\": 2.822, \"y\": 5.416}, {\"title\": \"ChatGPT Prompting Cannot Estimate Predictive Uncertainty in  High-Resource Languages\", \"topic\": \"Bias in Language Models\", \"x\": 5.346, \"y\": 4.562}, {\"title\": \"Knowledge Graphs are not Created Equal: Exploring the Properties and  Structure of Real KGs\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.993, \"y\": 5.793}, {\"title\": \"Analyzing Modular Approaches for Visual Question Decomposition\", \"topic\": \"Multimodal Language Models\", \"x\": 8.29, \"y\": 7.961}, {\"title\": \"Autoregressive Language Models For Estimating the Entropy of Epic EHR  Audit Logs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.704, \"y\": 8.159}, {\"title\": \"DeMuX: Data-efficient Multilingual Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.504, \"y\": 4.666}, {\"title\": \"ChatGPT Exhibits Gender and Racial Biases in Acute Coronary Syndrome  Management\", \"topic\": \"Bias in Language Models\", \"x\": 3.515, \"y\": 4.53}, {\"title\": \"Relation Extraction in underexplored biomedical domains: A  diversity-optimised sampling and synthetic data generation approach\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.326, \"y\": 7.428}, {\"title\": \"Schema Graph-Guided Prompt for Multi-Domain Dialogue State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.593, \"y\": 3.916}, {\"title\": \"Parameter-Efficient Orthogonal Finetuning via Butterfly Factorization\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.08, \"y\": 2.195}, {\"title\": \"Smart Agent-Based Modeling: On the Use of Large Language Models in  Computer Simulations\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.642, \"y\": 2.93}, {\"title\": \"A Comparison of Lexicon-Based and ML-Based Sentiment Analysis: Are There  Outlier Words?\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.527, \"y\": 6.654}, {\"title\": \"MultiIoT: Towards Large-scale Multisensory Learning for the Internet of  Things\", \"topic\": \"Multimodal Language Models\", \"x\": 8.02, \"y\": 7.123}, {\"title\": \"Language Models can be Logical Solvers\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.68, \"y\": 2.926}, {\"title\": \"Making LLMs Worth Every Penny: Resource-Limited Text Classification in  Banking\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.933, \"y\": 6.832}, {\"title\": \"Multi-Label Topic Model for Financial Textual Data\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.711, \"y\": 6.818}, {\"title\": \"ChiMed-GPT: A Chinese Medical Large Language Model with Full Training  Regime and Better Alignment to Human Preferences\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.875, \"y\": 8.032}, {\"title\": \"How to Bridge the Gap between Modalities: A Comprehensive Survey on  Multimodal Large Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.12, \"y\": 7.264}, {\"title\": \"The Shape of Learning: Anisotropy and Intrinsic Dimensions in  Transformer-Based Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.47, \"y\": 3.581}, {\"title\": \"Follow-Up Differential Descriptions: Language Models Resolve Ambiguities  for Image Classification\", \"topic\": \"Multimodal Language Models\", \"x\": 8.852, \"y\": 7.25}, {\"title\": \"Tamil-Llama: A New Tamil Language Model Based on Llama 2\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.709, \"y\": 4.076}, {\"title\": \"CFBenchmark: Chinese Financial Assistant Benchmark for Large Language  Model\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.905, \"y\": 6.838}, {\"title\": \"Leveraging LLMs for Synthesizing Training Data Across Many Languages in  Multilingual Dense Retrieval\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.139, \"y\": 4.792}, {\"title\": \"Hallucination-minimized Data-to-answer Framework for Financial  Decision-makers\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.872, \"y\": 6.839}, {\"title\": \"Bridging the Digital Divide: Performance Variation across Socio-Economic  Factors in Vision-Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.614, \"y\": 4.798}, {\"title\": \"Long-Horizon Dialogue Understanding for Role Identification in the Game  of Avalon with Large Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.13, \"y\": 3.074}, {\"title\": \"FigStep: Jailbreaking Large Vision-language Models via Typographic  Visual Prompts\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.259, \"y\": 2.375}, {\"title\": \"Accuracy of a Vision-Language Model on Challenging Medical Cases\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.114, \"y\": 8.356}, {\"title\": \"Zero-Shot Goal-Directed Dialogue via RL on Imagined Conversations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.467, \"y\": 3.463}, {\"title\": \"Text Representation Distillation via Information Bottleneck Principle\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.584, \"y\": 3.865}, {\"title\": \"All Should Be Equal in the Eyes of Language Models: Counterfactually  Aware Fair Text Generation\", \"topic\": \"Bias in Language Models\", \"x\": 3.353, \"y\": 4.246}, {\"title\": \"LLaVA-Plus: Learning to Use Tools for Creating Multimodal Agents\", \"topic\": \"Multimodal Language Models\", \"x\": 8.107, \"y\": 7.434}, {\"title\": \"Mirror: A Universal Framework for Various Information Extraction Tasks\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.92, \"y\": 6.707}, {\"title\": \"There's no Data Like Better Data: Using QE Metrics for MT Data Filtering\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.854, \"y\": 4.616}, {\"title\": \"A Survey on Hallucination in Large Language Models: Principles,  Taxonomy, Challenges, and Open Questions\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.151, \"y\": 1.094}, {\"title\": \"PRODIGy: a PROfile-based DIalogue Generation dataset\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.2, \"y\": 3.663}, {\"title\": \"Prompt Engineering a Prompt Engineer\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.169, \"y\": 3.167}, {\"title\": \"Large Language Models and Prompt Engineering for Biomedical Query  Focused Multi-Document Summarisation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.865, \"y\": 7.411}, {\"title\": \"Enhancing Computation Efficiency in Large Language Models through Weight  and Activation Quantization\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.726, \"y\": 2.147}, {\"title\": \"Unsupervised Translation Quality Estimation Exploiting Synthetic Data  and Pre-trained Multilingual Encoder\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.893, \"y\": 4.579}, {\"title\": \"Conic10K: A Challenging Math Problem Understanding and Reasoning Dataset\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.917, \"y\": 3.107}, {\"title\": \"A Survey of Large Language Models in Medicine: Progress, Application,  and Challenge\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.615, \"y\": 7.855}, {\"title\": \"Legal-HNet: Mixing Legal Long-Context Tokens with Hartley Transform\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.802, \"y\": 3.423}, {\"title\": \"Agent Lumos: Unified and Modular Training for Open-Source Language  Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.823, \"y\": 2.59}, {\"title\": \"Mental Health Diagnosis in the Digital Age: Harnessing Sentiment  Analysis on Social Media Platforms upon Ultra-Sparse Feature Content\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.273, \"y\": 7.503}, {\"title\": \"Deep Learning Brasil at ABSAPT 2022: Portuguese Transformer Ensemble  Approaches\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.16, \"y\": 6.805}, {\"title\": \"DeepLearningBrasil@LT-EDI-2023: Exploring Deep Learning Techniques for  Detecting Depression in Social Media Text\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.137, \"y\": 7.398}, {\"title\": \"Zero-shot Translation of Attention Patterns in VQA Models to Natural  Language\", \"topic\": \"Multimodal Language Models\", \"x\": 8.418, \"y\": 7.912}, {\"title\": \"NLQxform: A Language Model-based Question to SPARQL Transformer\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.554, \"y\": 5.445}, {\"title\": \"Beyond Size: How Gradients Shape Pruning Decisions in Large Language  Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.547, \"y\": 2.481}, {\"title\": \"Prompt Sketching for Large Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.157, \"y\": 3.15}, {\"title\": \"Future Lens: Anticipating Subsequent Tokens from a Single Hidden State\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.418, \"y\": 3.526}, {\"title\": \"Bias Runs Deep: Implicit Reasoning Biases in Persona-Assigned LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.837, \"y\": 4.142}, {\"title\": \"SEMQA: Semi-Extractive Multi-Source Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.417, \"y\": 5.265}, {\"title\": \"ADaPT: As-Needed Decomposition and Planning with Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 6.01, \"y\": 2.495}, {\"title\": \"Hierarchically Gated Recurrent Neural Network for Sequence Modeling\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.557, \"y\": 3.374}, {\"title\": \"Determination of toxic comments and unintended model bias minimization  using Deep learning approach\", \"topic\": \"Hate Speech Detection\", \"x\": 2.973, \"y\": 5.151}, {\"title\": \"TEAL: Tokenize and Embed ALL for Multi-modal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.303, \"y\": 7.225}, {\"title\": \"Assessing Distractors in Multiple-Choice Tests\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.171, \"y\": 4.857}, {\"title\": \"Loss Masking Is Not Needed in Decoder-only Transformer for  Discrete-token-based ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.101, \"y\": 4.958}, {\"title\": \"Conversation Understanding using Relational Temporal Graph Neural  Networks with Auxiliary Cross-Modality Interaction\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.322, \"y\": 7.79}, {\"title\": \"NExT-Chat: An LMM for Chat, Detection and Segmentation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.399, \"y\": 7.373}, {\"title\": \"Multi-label and Multi-target Sampling of Machine Annotation for  Computational Stance Detection\", \"topic\": \"Fake News Detection\", \"x\": 3.579, \"y\": 5.744}, {\"title\": \"CLearViD: Curriculum Learning for Video Description\", \"topic\": \"Multimodal Language Models\", \"x\": 8.938, \"y\": 7.811}, {\"title\": \"Twitter Sentiment Analysis of Covid Vacciness\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.06, \"y\": 6.809}, {\"title\": \"RDGCN: Reinforced Dependency Graph Convolutional Network for  Aspect-based Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.126, \"y\": 6.859}, {\"title\": \"Recursion in Recursion: Two-Level Nested Recursion for Length  Generalization with Scalability\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.52, \"y\": 3.343}, {\"title\": \"Evaluating multiple large language models in pediatric ophthalmology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.863, \"y\": 8.178}, {\"title\": \"A comparative analysis between Conformer-Transducer, Whisper, and  wav2vec2 for improving the child speech recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.219, \"y\": 5.265}, {\"title\": \"Aspect-based Meeting Transcript Summarization: A Two-Stage Approach with  Weak Supervision on Sentence Classification\", \"topic\": \"Text Summarization\", \"x\": 5.312, \"y\": 6.388}, {\"title\": \"Exploring Recommendation Capabilities of GPT-4V(ision): A Preliminary  Case Study\", \"topic\": \"Multimodal Language Models\", \"x\": 7.768, \"y\": 7.797}, {\"title\": \"JaSPICE: Automatic Evaluation Metric Using Predicate-Argument Structures  for Image Captioning Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.996, \"y\": 7.381}, {\"title\": \"Enhancing LLM Intelligence with ARM-RAG: Auxiliary Rationale Memory for  Retrieval Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.024, \"y\": 4.522}, {\"title\": \"Black-Box Prompt Optimization: Aligning Large Language Models without  Model Training\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.381, \"y\": 1.355}, {\"title\": \"What is Lost in Knowledge Distillation?\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.526, \"y\": 3.798}, {\"title\": \"Modelling Sentiment Analysis: LLMs and data augmentation techniques\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.603, \"y\": 6.648}, {\"title\": \"Evaluating Large Language Models in Ophthalmology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.856, \"y\": 8.142}, {\"title\": \"Fully Automated Task Management for Generation, Execution, and  Evaluation: A Framework for Fetch-and-Carry Tasks with Natural Language  Instructions in Continuous Space\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 8.716, \"y\": 6.733}, {\"title\": \"Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.414, \"y\": 1.461}, {\"title\": \"mPLUG-Owl2: Revolutionizing Multi-modal Large Language Model with  Modality Collaboration\", \"topic\": \"Multimodal Language Models\", \"x\": 8.221, \"y\": 7.235}, {\"title\": \"Factoring Hate Speech: A New Annotation Framework to Study Hate Speech  in Social Media\", \"topic\": \"Hate Speech Detection\", \"x\": 2.844, \"y\": 5.43}, {\"title\": \"An Analysis of Dialogue Repair in Voice Assistants\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.074, \"y\": 3.833}, {\"title\": \"iACOS: Advancing Implicit Sentiment Extraction with Informative and  Adaptive Negative Examples\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.131, \"y\": 6.814}, {\"title\": \"Unifying Structure and Language Semantic for Efficient Contrastive  Knowledge Graph Completion with Structured Entity Anchors\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.114, \"y\": 6.006}, {\"title\": \"Conversations in Galician: a Large Language Model for an  Underrepresented Language\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.037, \"y\": 4.266}, {\"title\": \"Rethinking and Improving Multi-task Learning for End-to-end Speech  Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.262, \"y\": 5.195}, {\"title\": \"Language Representation Projection: Can We Transfer Factual Knowledge  across Languages in Multilingual Language Models?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.29, \"y\": 4.744}, {\"title\": \"DynaSemble: Dynamic Ensembling of Textual and Structure-Based Models for  Knowledge Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.027, \"y\": 6.072}, {\"title\": \"Gender Inflected or Bias Inflicted: On Using Grammatical Gender Cues for  Bias Evaluation in Machine Translation\", \"topic\": \"Bias in Language Models\", \"x\": 3.026, \"y\": 4.43}, {\"title\": \"Multilingual Mathematical Autoformalization\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.41, \"y\": 2.75}, {\"title\": \"Unified Low-Resource Sequence Labeling by Sample-Aware Dynamic Sparse  Finetuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.977, \"y\": 2.342}, {\"title\": \"Leveraging Structured Information for Explainable Multi-hop Question  Answering and Reasoning\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.748, \"y\": 5.366}, {\"title\": \"LLM as an Art Director (LaDi): Using LLMs to improve Text-to-Media  Generators\", \"topic\": \"Multimodal Language Models\", \"x\": 8.949, \"y\": 7.073}, {\"title\": \"Bilingual Corpus Mining and Multistage Fine-Tuning for Improving Machine  Translation of Lecture Transcripts\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.569, \"y\": 4.786}, {\"title\": \"CBSiMT: Mitigating Hallucination in Simultaneous Machine Translation  with Weighted Prefix-to-Prefix Training\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.009, \"y\": 4.625}, {\"title\": \"Principles from Clinical Research for NLP Model Generalization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.0, \"y\": 7.987}, {\"title\": \"Measuring Adversarial Datasets\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.176, \"y\": 3.078}, {\"title\": \"Context Unlocks Emotions: Text-based Emotion Classification Dataset  Auditing with Large Language Models\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.408, \"y\": 7.635}, {\"title\": \"Spoken Dialogue System for Medical Prescription Acquisition on  Smartphone: Development, Corpus and Evaluation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.577, \"y\": 8.197}, {\"title\": \"In-Context Exemplars as Clues to Retrieving from Large Associative  Memory\", \"topic\": \"In-Context Learning\", \"x\": 8.551, \"y\": 3.367}, {\"title\": \"DAIL: Data Augmentation for In-Context Learning via Self-Paraphrase\", \"topic\": \"In-Context Learning\", \"x\": 8.244, \"y\": 3.371}, {\"title\": \"Unraveling Downstream Gender Bias from Large Language Models: A Study on  AI Educational Writing Assistance\", \"topic\": \"Bias in Language Models\", \"x\": 3.391, \"y\": 4.375}, {\"title\": \"Holistic Analysis of Hallucination in GPT-4V(ision): Bias and  Interference Challenges\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.151, \"y\": 1.037}, {\"title\": \"Safurai-Csharp: Harnessing Synthetic Data to improve language-specific  Code LLM\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.538, \"y\": 2.326}, {\"title\": \"p-Laplacian Transformer\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.865, \"y\": 3.262}, {\"title\": \"Performance Prediction of Data-Driven Knowledge summarization of High  Entropy Alloys (HEAs) literature implementing Natural Language Processing  algorithms\", \"topic\": \"Text Summarization\", \"x\": 5.722, \"y\": 6.06}, {\"title\": \"ALYMPICS: LLM Agents Meet Game Theory -- Exploring Strategic  Decision-Making with AI Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.328, \"y\": 3.051}, {\"title\": \"Pseudo-Labeling for Domain-Agnostic Bangla Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.063, \"y\": 5.354}, {\"title\": \"Model-based Counterfactual Generator for Gender Bias Mitigation\", \"topic\": \"Bias in Language Models\", \"x\": 3.287, \"y\": 4.37}, {\"title\": \"Findings of the WMT 2023 Shared Task on Discourse-Level Literary  Translation: A Fresh Orb in the Cosmos of LLMs\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.817, \"y\": 4.676}, {\"title\": \"Injecting Categorical Labels and Syntactic Information into Biomedical  NER\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.521, \"y\": 7.417}, {\"title\": \"A Simple yet Efficient Ensemble Approach for AI-generated Text Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.106, \"y\": 4.767}, {\"title\": \"Detecting agreement in multi-party dialogue: evaluating speaker  diarisation versus a procedural baseline to enhance user engagement\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.191, \"y\": 3.682}, {\"title\": \"Towards a Transformer-Based Reverse Dictionary Model for Quality  Estimation of Definitions\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.282, \"y\": 3.62}, {\"title\": \"Adapting Pre-trained Generative Models for Extractive Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.471, \"y\": 5.242}, {\"title\": \"In-Context Learning for Knowledge Base Question Answering for Unmanned  Systems based on Large Language Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.606, \"y\": 5.382}, {\"title\": \"Less than One-shot: Named Entity Recognition via Extremely Weak  Supervision\", \"topic\": \"Named Entity Recognition\", \"x\": 7.423, \"y\": 6.702}, {\"title\": \"Improving Machine Translation with Large Language Models: A Preliminary  Study with Cooperative Decoding\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.696, \"y\": 4.283}, {\"title\": \"Co-training and Co-distillation for Quality Improvement and Compression  of Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.494, \"y\": 3.762}, {\"title\": \"Large language models implicitly learn to straighten neural sentence  trajectories to construct a predictive representation of natural language\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.219, \"y\": 3.645}, {\"title\": \"Attention or Convolution: Transformer Encoders in Audio Language Models  for Inference Efficiency\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.909, \"y\": 4.868}, {\"title\": \"Rule Learning as Machine Translation using the Atomic Knowledge Bank\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.715, \"y\": 3.06}, {\"title\": \"Pyclipse, a library for deidentification of free-text clinical notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.674, \"y\": 7.752}, {\"title\": \"Extraction of Atypical Aspects from Customer Reviews: Datasets and  Experiments with Language Models\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.408, \"y\": 6.643}, {\"title\": \"Nepali Video Captioning using CNN-RNN Architecture\", \"topic\": \"Multimodal Language Models\", \"x\": 9.019, \"y\": 7.72}, {\"title\": \"Octavius: Mitigating Task Interference in MLLMs via LoRA-MoE\", \"topic\": \"Multimodal Language Models\", \"x\": 8.276, \"y\": 7.195}, {\"title\": \"Divide & Conquer for Entailment-aware Multi-hop Evidence Retrieval\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.799, \"y\": 5.382}, {\"title\": \"Relation Extraction Model Based on Semantic Enhancement Mechanism\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.967, \"y\": 6.781}, {\"title\": \"Can Chat GPT solve a Linguistics Exam?\", \"topic\": \"Bias in Language Models\", \"x\": 5.461, \"y\": 4.423}, {\"title\": \"Citance-Contextualized Summarization of Scientific Papers\", \"topic\": \"Text Summarization\", \"x\": 5.742, \"y\": 6.259}, {\"title\": \"TreeSwap: Data Augmentation for Machine Translation via Dependency  Subtree Swapping\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.721, \"y\": 4.642}, {\"title\": \"Identifying Context-Dependent Translations for Evaluation Set Production\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.814, \"y\": 4.384}, {\"title\": \"Narrowing the Gap between Zero- and Few-shot Machine Translation by  Matching Styles\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.568, \"y\": 4.495}, {\"title\": \"COSMIC: Data Efficient Instruction-tuning For Speech In-Context Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.915, \"y\": 5.068}, {\"title\": \"Exploring the Numerical Reasoning Capabilities of Language Models: A  Comprehensive Analysis on Tabular Data\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.821, \"y\": 3.307}, {\"title\": \"An Introduction to Natural Language Processing Techniques and Framework  for Clinical Implementation in Radiation Oncology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.595, \"y\": 7.719}, {\"title\": \"Leveraging Large Language Models for Collective Decision-Making\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.444, \"y\": 3.176}, {\"title\": \"Grounded Intuition of GPT-Vision's Abilities with Scientific Images\", \"topic\": \"Multimodal Language Models\", \"x\": 8.654, \"y\": 7.433}, {\"title\": \"VQPy: An Object-Oriented Approach to Modern Video Analytics\", \"topic\": \"Multimodal Language Models\", \"x\": 8.756, \"y\": 7.957}, {\"title\": \"Vicinal Risk Minimization for Few-Shot Cross-lingual Transfer in Abusive  Language Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.771, \"y\": 5.282}, {\"title\": \"ProSG: Using Prompt Synthetic Gradients to Alleviate Prompt Forgetting  of RNN-like Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.654, \"y\": 3.145}, {\"title\": \"The language of prompting: What linguistic properties make a prompt  successful?\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.185, \"y\": 3.249}, {\"title\": \"More Robots are Coming: Large Multimodal Models (ChatGPT) can Solve  Visually Diverse Images of Parsons Problems\", \"topic\": \"Multimodal Language Models\", \"x\": 8.127, \"y\": 7.717}, {\"title\": \"Hint-enhanced In-Context Learning wakes Large Language Models up for  knowledge-intensive tasks\", \"topic\": \"In-Context Learning\", \"x\": 8.108, \"y\": 3.444}, {\"title\": \"GateLoop: Fully Data-Controlled Linear Recurrence for Sequence Modeling\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.698, \"y\": 3.233}, {\"title\": \"Investigating Deep-Learning NLP for Automating the Extraction of  Oncology Efficacy Endpoints from Scientific Literature\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.857, \"y\": 7.748}, {\"title\": \"Large Language Models Illuminate a Progressive Pathway to Artificial  Healthcare Assistant: A Review\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.559, \"y\": 7.908}, {\"title\": \"Efficient Black-Box Adversarial Attacks on Neural Text Detectors\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.211, \"y\": 3.058}, {\"title\": \"Multi-EuP: The Multilingual European Parliament Dataset for Analysis of  Bias in Information Retrieval\", \"topic\": \"Bias in Language Models\", \"x\": 3.315, \"y\": 4.544}, {\"title\": \"Mitigating Framing Bias with Polarity Minimization Loss\", \"topic\": \"Fake News Detection\", \"x\": 3.727, \"y\": 5.839}, {\"title\": \"AFPQ: Asymmetric Floating Point Quantization for LLMs\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.762, \"y\": 2.133}, {\"title\": \"Is one brick enough to break the wall of spoken dialogue state tracking?\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.609, \"y\": 3.909}, {\"title\": \"TCM-GPT: Efficient Pre-training of Large Language Models for Domain  Adaptation in Traditional Chinese Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.06, \"y\": 8.033}, {\"title\": \"Are cascade dialogue state tracking models speaking out of turn in  spoken dialogues?\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.501, \"y\": 3.774}, {\"title\": \"FinGPT: Large Generative Models for a Small Language\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.825, \"y\": 4.192}, {\"title\": \"Indo LEGO-ABSA: A Multitask Generative Aspect Based Sentiment Analysis  for Indonesian Language\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.113, \"y\": 6.826}, {\"title\": \"SAC3: Reliable Hallucination Detection in Black-Box Language Models via  Semantic-aware Cross-check Consistency\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.242, \"y\": 1.116}, {\"title\": \"An Empirical Study of Benchmarking Chinese Aspect Sentiment Quad  Prediction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.129, \"y\": 6.831}, {\"title\": \"Data-Free Distillation of Language Model by Text-to-Text Transfer\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.422, \"y\": 3.788}, {\"title\": \"MARRS: Multimodal Reference Resolution System\", \"topic\": \"Multimodal Language Models\", \"x\": 8.092, \"y\": 7.272}, {\"title\": \"ACQUIRED: A Dataset for Answering Counterfactual Questions In Real-Life  Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.307, \"y\": 7.957}, {\"title\": \"FLAP: Fast Language-Audio Pre-training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.8, \"y\": 5.094}, {\"title\": \"MetaReVision: Meta-Learning with Retrieval for Visually Grounded  Compositional Concept Acquisition\", \"topic\": \"Multimodal Language Models\", \"x\": 8.595, \"y\": 7.273}, {\"title\": \"Preserving the knowledge of long clinical texts using aggregated  ensembles of large language models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.818, \"y\": 8.111}, {\"title\": \"Implicit Chain of Thought Reasoning via Knowledge Distillation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.809, \"y\": 2.322}, {\"title\": \"Server-side Rescoring of Spoken Entity-centric Knowledge Queries for  Virtual Assistants\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.852, \"y\": 5.03}, {\"title\": \"Graph Neural Networks for Topological Feature Extraction in ECG  Classification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.897, \"y\": 8.351}, {\"title\": \"GPT-4V(ision) as a Generalist Evaluator for Vision-Language Tasks\", \"topic\": \"Multimodal Language Models\", \"x\": 7.892, \"y\": 7.797}, {\"title\": \"Better Together: Enhancing Generative Knowledge Graph Completion with  Language Models and Neighborhood Information\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.058, \"y\": 6.0}, {\"title\": \"What Makes for Good Visual Instructions? Synthesizing Complex Visual  Reasoning Instructions for Visual Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.464, \"y\": 7.616}, {\"title\": \"AWEQ: Post-Training Quantization with Activation-Weight Equalization for  Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.707, \"y\": 2.136}, {\"title\": \"ProAgent: From Robotic Process Automation to Agentic Process Automation\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.596, \"y\": 2.883}, {\"title\": \"Modular Blended Attention Network for Video Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.505, \"y\": 7.954}, {\"title\": \"An energy-based comparative analysis of common approaches to text  classification in the Legal domain\", \"topic\": \"Legal NLP\", \"x\": 5.266, \"y\": 5.492}, {\"title\": \"The Impact of Preference Agreement in Reinforcement Learning from Human  Feedback: A Case Study in Summarization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.17, \"y\": 1.515}, {\"title\": \"ACES: Translation Accuracy Challenge Sets at WMT 2023\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.789, \"y\": 4.656}, {\"title\": \"Low-Resource Named Entity Recognition: Can One-vs-All AUC Maximization  Help?\", \"topic\": \"Named Entity Recognition\", \"x\": 7.418, \"y\": 6.807}, {\"title\": \"Adapting Fake News Detection to the Era of Large Language Models\", \"topic\": \"Fake News Detection\", \"x\": 4.035, \"y\": 5.547}, {\"title\": \"Multilingual DistilWhisper: Efficient Distillation of Multi-task Speech  Models via Language-Specific Experts\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.006, \"y\": 5.011}, {\"title\": \"Learn to Refuse: Making Large Language Models More Controllable and  Reliable through Knowledge Scope Limitation and Refusal Mechanism\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.428, \"y\": 1.393}, {\"title\": \"Joint Learning of Local and Global Features for Aspect-based Sentiment  Classification\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.073, \"y\": 6.868}, {\"title\": \"Replicable Benchmarking of Neural Machine Translation (NMT) on  Low-Resource Local Languages in Indonesia\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.748, \"y\": 4.641}, {\"title\": \"Explainable Identification of Hate Speech towards Islam using Graph  Neural Networks\", \"topic\": \"Hate Speech Detection\", \"x\": 2.797, \"y\": 5.377}, {\"title\": \"IndoToD: A Multi-Domain Indonesian Benchmark For End-to-End  Task-Oriented Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.645, \"y\": 3.925}, {\"title\": \"E3 TTS: Easy End-to-End Diffusion-based Text to Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.545, \"y\": 5.872}, {\"title\": \"Automatic Disfluency Detection from Untranscribed Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.119, \"y\": 5.671}, {\"title\": \"Calibrated Seq2seq Models for Efficient and Generalizable Ultra-fine  Entity Typing\", \"topic\": \"Named Entity Recognition\", \"x\": 7.341, \"y\": 6.436}, {\"title\": \"From Text to Structure: Using Large Language Models to Support the  Development of Legal Expert Systems\", \"topic\": \"Legal NLP\", \"x\": 5.124, \"y\": 5.578}, {\"title\": \"Language Model Training Paradigms for Clinical Feature Embeddings\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.017, \"y\": 8.331}, {\"title\": \"End-to-End Single-Channel Speaker-Turn Aware Conversational Speech  Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.654, \"y\": 5.328}, {\"title\": \"Improving Interpersonal Communication by Simulating Audiences with  Language Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.258, \"y\": 3.471}, {\"title\": \"Attention Alignment and Flexible Positional Embeddings Improve  Transformer Length Extrapolation\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.787, \"y\": 3.309}, {\"title\": \"Emotion Detection for Misinformation: A Review\", \"topic\": \"Fake News Detection\", \"x\": 3.92, \"y\": 6.112}, {\"title\": \"Boosting Summarization with Normalizing Flows and Aggressive Training\", \"topic\": \"Text Summarization\", \"x\": 5.59, \"y\": 6.27}, {\"title\": \"Crosslingual Retrieval Augmented In-context Learning for Bangla\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.177, \"y\": 4.604}, {\"title\": \"A Systematic Comparison of Syllogistic Reasoning in Humans and Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.488, \"y\": 3.222}, {\"title\": \"Efficient Human-AI Coordination via Preparatory Language-based  Convention\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.393, \"y\": 2.838}, {\"title\": \"Enhanced Knowledge Injection for Radiology Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.209, \"y\": 8.592}, {\"title\": \"tmn at #SMM4H 2023: Comparing Text Preprocessing Techniques for  Detecting Tweets Self-reporting a COVID-19 Diagnosis\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.088, \"y\": 6.837}, {\"title\": \"HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning\", \"topic\": \"Hate Speech Detection\", \"x\": 2.704, \"y\": 5.326}, {\"title\": \"Data Augmentation for Code Translation with Comparable Corpora and  Multiple References\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 7.789, \"y\": 2.687}, {\"title\": \"Probing Explicit and Implicit Gender Bias through LLM Conditional Text  Generation\", \"topic\": \"Bias in Language Models\", \"x\": 3.194, \"y\": 4.329}, {\"title\": \"Detecting Syllable-Level Pronunciation Stress with A Self-Attention  Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.723, \"y\": 5.45}, {\"title\": \"IBADR: an Iterative Bias-Aware Dataset Refinement Framework for  Debiasing NLU models\", \"topic\": \"Bias in Language Models\", \"x\": 3.365, \"y\": 4.335}, {\"title\": \"Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data  Generation with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.799, \"y\": 8.019}, {\"title\": \"Plug-and-Play Policy Planner for Large Language Model Powered Dialogue  Agents\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.512, \"y\": 3.453}, {\"title\": \"The Mystery of In-Context Learning: A Comprehensive Survey on  Interpretation and Analysis\", \"topic\": \"In-Context Learning\", \"x\": 8.444, \"y\": 3.28}, {\"title\": \"Instructive Decoding: Instruction-Tuned Large Language Models are  Self-Refiner from Noisy Instructions\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.166, \"y\": 2.42}, {\"title\": \"What Formal Languages Can Transformers Express? A Survey\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.373, \"y\": 3.661}, {\"title\": \"Continuous Training and Fine-tuning for Domain-Specific Language Models  in Medical Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.907, \"y\": 7.972}, {\"title\": \"Beyond Denouncing Hate: Strategies for Countering Implied Biases and  Stereotypes in Language\", \"topic\": \"Hate Speech Detection\", \"x\": 2.825, \"y\": 5.148}, {\"title\": \"Two-Stage Classifier for Campaign Negativity Detection using Axis  Embeddings: A Case Study on Tweets of Political Users during 2021  Presidential Election in Iran\", \"topic\": \"Fake News Detection\", \"x\": 3.556, \"y\": 5.977}, {\"title\": \"The Generative AI Paradox: \\\"What It Can Create, It May Not Understand\\\"\", \"topic\": \"Bias in Language Models\", \"x\": 5.023, \"y\": 4.249}, {\"title\": \"Grounding Visual Illusions in Language: Do Vision-Language Models  Perceive Illusions Like Humans?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.529, \"y\": 7.593}, {\"title\": \"Learning From Mistakes Makes LLM Better Reasoner\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.839, \"y\": 2.396}, {\"title\": \"Non-Compositionality in Sentiment: New Data and Analyses\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.563, \"y\": 6.747}, {\"title\": \"Zero-Shot Medical Information Retrieval via Knowledge Graph Embedding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.177, \"y\": 7.832}, {\"title\": \"CapsFusion: Rethinking Image-Text Data at Scale\", \"topic\": \"Multimodal Language Models\", \"x\": 8.895, \"y\": 7.543}, {\"title\": \"Leveraging Word Guessing Games to Assess the Intelligence of Large  Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.47, \"y\": 2.991}, {\"title\": \"Multi-User MultiWOZ: Task-Oriented Dialogues among Multiple Users\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.386, \"y\": 3.758}, {\"title\": \"Towards a Deep Understanding of Multilingual End-to-End Speech  Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.348, \"y\": 5.256}, {\"title\": \"InstructCoder: Instruction Tuning Large Language Models for Code Editing\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.026, \"y\": 2.203}, {\"title\": \"Breaking Language Barriers in Multilingual Mathematical Reasoning:  Insights and Observations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.198, \"y\": 2.925}, {\"title\": \"General-Purpose Retrieval-Enhanced Medical Prediction Model Using  Near-Infinite History\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.815, \"y\": 8.168}, {\"title\": \"Video-Helpful Multimodal Machine Translation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.672, \"y\": 7.412}, {\"title\": \"GAR-meets-RAG Paradigm for Zero-Shot Information Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.417, \"y\": 4.888}, {\"title\": \"Multi-Agent Consensus Seeking via Large Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.442, \"y\": 2.83}, {\"title\": \"Improving Prompt Tuning with Learned Prompting Layers\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.715, \"y\": 3.361}, {\"title\": \"Keyword-optimized Template Insertion for Clinical Information Extraction  via Prompt-based Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.755, \"y\": 7.898}, {\"title\": \"Automatic Evaluation of Generative Models with Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.011, \"y\": 2.405}, {\"title\": \"Synthetic Imitation Edit Feedback for Factual Alignment in Clinical  Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.575, \"y\": 7.638}, {\"title\": \"Early Detection of Depression and Eating Disorders in Spanish: UNSL at  MentalRiskES 2023\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.214, \"y\": 7.468}, {\"title\": \"Faithful and Robust Local Interpretability for Textual Predictions\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.815, \"y\": 3.931}, {\"title\": \"BioInstruct: Instruction Tuning of Large Language Models for Biomedical  Natural Language Processing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.447, \"y\": 7.602}, {\"title\": \"Strategies to Harness the Transformers' Potential: UNSL at eRisk 2023\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.176, \"y\": 7.212}, {\"title\": \"Remember what you did so you know what to do next\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.895, \"y\": 2.228}, {\"title\": \"The Impact of Depth on Compositional Generalization in Transformer  Language Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.461, \"y\": 3.558}, {\"title\": \"Split-NER: Named Entity Recognition via Two Question-Answering-based  Classifications\", \"topic\": \"Named Entity Recognition\", \"x\": 7.309, \"y\": 6.887}, {\"title\": \"LILO: Learning Interpretable Libraries by Compressing and Documenting  Code\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.461, \"y\": 2.357}, {\"title\": \"What's \\\"up\\\" with vision-language models? Investigating their struggle  with spatial reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.446, \"y\": 7.612}, {\"title\": \"Generating Medical Prescriptions with Conditional Transformer\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.025, \"y\": 8.012}, {\"title\": \"When Do Prompting and Prefix-Tuning Work? A Theory of Capabilities and  Limitations\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.726, \"y\": 3.234}, {\"title\": \"Sentiment Analysis in Digital Spaces: An Overview of Reviews\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.715, \"y\": 6.505}, {\"title\": \"Integrating Pre-trained Language Model into Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.932, \"y\": 4.455}, {\"title\": \"Explaining Tree Model Decisions in Natural Language for Network  Intrusion Detection\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.769, \"y\": 3.792}, {\"title\": \"Dynamics of Instruction Tuning: Each Ability of Large Language Models  Has Its Own Growth Pace\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.175, \"y\": 2.353}, {\"title\": \"DPATD: Dual-Phase Audio Transformer for Denoising\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.119, \"y\": 5.071}, {\"title\": \"Improving Input-label Mapping with Demonstration Replay for In-context  Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.3, \"y\": 3.341}, {\"title\": \"CreoleVal: Multilingual Multitask Benchmarks for Creoles\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.216, \"y\": 5.019}, {\"title\": \"A Lightweight Method to Generate Unanswerable Questions in English\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.488, \"y\": 5.018}, {\"title\": \"Improving Factual Consistency of Text Summarization by Adversarially  Decoupling Comprehension and Embellishment Abilities of LLMs\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.217, \"y\": 1.29}, {\"title\": \"Test Suites Task: Evaluation of Gender Fairness in MT with MuST-SHE and  INES\", \"topic\": \"Bias in Language Models\", \"x\": 2.988, \"y\": 4.393}, {\"title\": \"Skywork: A More Open Bilingual Foundation Model\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.638, \"y\": 4.043}, {\"title\": \"ROME: Evaluating Pre-trained Vision-Language Models on Reasoning beyond  Visual Common Sense\", \"topic\": \"Multimodal Language Models\", \"x\": 8.425, \"y\": 7.721}, {\"title\": \"Fusing Temporal Graphs into Transformers for Time-Sensitive Question  Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.499, \"y\": 5.649}, {\"title\": \"EHRTutor: Enhancing Patient Understanding of Discharge Instructions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.685, \"y\": 8.072}, {\"title\": \"Robustifying Language Models with Test-Time Adaptation\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.239, \"y\": 2.971}, {\"title\": \"BERT Lost Patience Won't Be Robust to Adversarial Slowdown\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.189, \"y\": 2.912}, {\"title\": \"Learning to Follow Object-Centric Image Editing Instructions Faithfully\", \"topic\": \"Multimodal Language Models\", \"x\": 9.092, \"y\": 6.845}, {\"title\": \"Women Wearing Lipstick: Measuring the Bias Between an Object and Its  Related Gender\", \"topic\": \"Bias in Language Models\", \"x\": 3.113, \"y\": 4.491}, {\"title\": \"Pushdown Layers: Encoding Recursive Structure in Transformer Language  Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.682, \"y\": 3.398}, {\"title\": \"TESTA: Temporal-Spatial Token Aggregation for Long-form Video-Language  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.896, \"y\": 7.887}, {\"title\": \"A Few-Shot Learning Focused Survey on Recent Named Entity Recognition  and Relation Classification Methods\", \"topic\": \"Named Entity Recognition\", \"x\": 7.395, \"y\": 6.73}, {\"title\": \"LLMs and Finetuning: Benchmarking cross-domain performance for hate  speech detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.723, \"y\": 5.334}, {\"title\": \"S2F-NER: Exploring Sequence-to-Forest Generation for Complex Entity  Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.379, \"y\": 6.748}, {\"title\": \"Retrofitting Light-weight Language Models for Emotions using Supervised  Contrastive Learning\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.284, \"y\": 7.546}, {\"title\": \"Debiasing Algorithm through Model Adaptation\", \"topic\": \"Bias in Language Models\", \"x\": 3.188, \"y\": 4.345}, {\"title\": \"Stacking the Odds: Transformer-Based Ensemble for AI-Generated Text  Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.147, \"y\": 4.848}, {\"title\": \"Prompt-Engineering and Transformer-based Question Generation and  Evaluation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.256, \"y\": 5.01}, {\"title\": \"MUST: A Multilingual Student-Teacher Learning approach for low-resource  speech recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.828, \"y\": 5.012}, {\"title\": \"Counterfactually Probing Language Identity in Multilingual Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.082, \"y\": 4.523}, {\"title\": \"All Things Considered: Detecting Partisan Events from News Media with  Cross-Article Comparison\", \"topic\": \"Fake News Detection\", \"x\": 3.832, \"y\": 5.714}, {\"title\": \"Open Visual Knowledge Extraction via Relation-Oriented Multimodality  Model Prompting\", \"topic\": \"Multimodal Language Models\", \"x\": 8.085, \"y\": 7.656}, {\"title\": \"Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded  Dialogue Generation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.313, \"y\": 1.507}, {\"title\": \"ProMap: Effective Bilingual Lexicon Induction via Language Model  Prompting\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.393, \"y\": 4.642}, {\"title\": \"Crossing the Aisle: Unveiling Partisan and Counter-Partisan Events in  News Reporting\", \"topic\": \"Fake News Detection\", \"x\": 3.879, \"y\": 5.586}, {\"title\": \"Emotion-Oriented Behavior Model Using Deep Learning\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.492, \"y\": 7.714}, {\"title\": \"TLM: Token-Level Masking for Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.849, \"y\": 3.31}, {\"title\": \"Using Large Language Models to Support Thematic Analysis in Empirical  Legal Studies\", \"topic\": \"Legal NLP\", \"x\": 5.119, \"y\": 5.472}, {\"title\": \"DetermLR: Augmenting LLM-based Logical Reasoning from Indeterminacy to  Determinacy\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.638, \"y\": 2.83}, {\"title\": \"Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive  Learning for Code Generation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 7.746, \"y\": 2.184}, {\"title\": \"Anaphor Assisted Document-Level Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.826, \"y\": 6.833}, {\"title\": \"MILDSum: A Novel Benchmark Dataset for Multilingual Summarization of  Indian Legal Case Judgments\", \"topic\": \"Legal NLP\", \"x\": 5.276, \"y\": 5.918}, {\"title\": \"LLMs-Healthcare : Current Applications and Challenges of Large Language  Models in various Medical Specialties\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.627, \"y\": 7.937}, {\"title\": \"Identifying Conspiracy Theories News based on Event Relation Graph\", \"topic\": \"Fake News Detection\", \"x\": 3.961, \"y\": 5.829}, {\"title\": \"Discourse Structures Guided Fine-grained Propaganda Identification\", \"topic\": \"Fake News Detection\", \"x\": 3.965, \"y\": 5.734}, {\"title\": \"Benchingmaking Large Langage Models in Biomedical Triple Extraction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.186, \"y\": 7.333}, {\"title\": \"Do Not Harm Protected Groups in Debiasing Language Representation Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.278, \"y\": 4.285}, {\"title\": \"Modeling Legal Reasoning: LM Annotation at the Edge of Human Agreement\", \"topic\": \"Legal NLP\", \"x\": 5.114, \"y\": 5.615}, {\"title\": \"SDOH-NLI: a Dataset for Inferring Social Determinants of Health from  Clinical Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.347, \"y\": 7.692}, {\"title\": \"FP8-LM: Training FP8 Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.456, \"y\": 2.243}, {\"title\": \"MalFake: A Multimodal Fake News Identification for Malayalam using  Recurrent Neural Networks and VGG-16\", \"topic\": \"Fake News Detection\", \"x\": 4.003, \"y\": 5.852}, {\"title\": \"Davidsonian Scene Graph: Improving Reliability in Fine-grained  Evaluation for Text-to-Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.728, \"y\": 7.414}, {\"title\": \"Style Description based Text-to-Speech with Conditional Prosodic Layer  Normalization based Diffusion GAN\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.582, \"y\": 5.891}, {\"title\": \"MPrompt: Exploring Multi-level Prompt Tuning for Machine Reading  Comprehension\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.762, \"y\": 3.365}, {\"title\": \"OpinSummEval: Revisiting Automated Evaluation for Opinion Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.375, \"y\": 6.235}, {\"title\": \"Multi-grained Evidence Inference for Multi-choice Reading Comprehension\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.494, \"y\": 5.264}, {\"title\": \"ViCLEVR: A Visual Reasoning Dataset and Hybrid Multimodal Fusion Model  for Visual Question Answering in Vietnamese\", \"topic\": \"Multimodal Language Models\", \"x\": 8.141, \"y\": 7.983}, {\"title\": \"Large language models for aspect-based sentiment analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.142, \"y\": 6.817}, {\"title\": \"Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General  Healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.271, \"y\": 8.174}, {\"title\": \"MADGF: Multi-Agent Data Generation Framework\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.123, \"y\": 5.313}, {\"title\": \"Unified Segment-to-Segment Framework for Simultaneous Sequence  Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.499, \"y\": 5.247}, {\"title\": \"Transformers as Graph-to-Graph Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.584, \"y\": 3.576}, {\"title\": \"SOUL: Towards Sentiment and Opinion Understanding of Language\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.498, \"y\": 6.746}, {\"title\": \"3D-Aware Visual Question Answering about Parts, Poses and Occlusions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.343, \"y\": 7.869}, {\"title\": \"From Values to Opinions: Predicting Human Behaviors and Stances Using  Value-Injected Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.155, \"y\": 4.111}, {\"title\": \"Style-Aware Radiology Report Generation with RadGraph and Few-Shot  Prompting\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.168, \"y\": 8.608}, {\"title\": \"Evaluation of large language models using an Indian language LGBTI+  lexicon\", \"topic\": \"Bias in Language Models\", \"x\": 3.403, \"y\": 4.544}, {\"title\": \"GROOViST: A Metric for Grounding Objects in Visual Storytelling\", \"topic\": \"Multimodal Language Models\", \"x\": 8.685, \"y\": 7.373}, {\"title\": \"ArchBERT: Bi-Modal Understanding of Neural Architectures and Natural  Languages\", \"topic\": \"Multimodal Language Models\", \"x\": 8.268, \"y\": 7.312}, {\"title\": \"ZeroQuant-HERO: Hardware-Enhanced Robust Optimized Post-Training  Quantization Framework for W8A8 Transformers\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.803, \"y\": 2.306}, {\"title\": \"Large Language Models as Generalizable Policies for Embodied Tasks\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.897, \"y\": 2.369}, {\"title\": \"From Transcripts to Insights: Uncovering Corporate Risks Using  Generative AI\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.796, \"y\": 6.472}, {\"title\": \"The impact of responding to patient messages with large language model  assistance\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.496, \"y\": 8.076}, {\"title\": \"In-Context Learning Dynamics with Random Binary Sequences\", \"topic\": \"In-Context Learning\", \"x\": 8.457, \"y\": 3.441}, {\"title\": \"InstOptima: Evolutionary Multi-objective Instruction Optimization via  Large Language Model-based Instruction Operators\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.131, \"y\": 2.311}, {\"title\": \"LeCaRDv2: A Large-Scale Chinese Legal Case Retrieval Dataset\", \"topic\": \"Legal NLP\", \"x\": 5.096, \"y\": 5.79}, {\"title\": \"Using State-of-the-Art Speech Models to Evaluate Oral Reading Fluency in  Ghana\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.162, \"y\": 5.455}, {\"title\": \"Global Voices, Local Biases: Socio-Cultural Prejudices across Languages\", \"topic\": \"Bias in Language Models\", \"x\": 3.524, \"y\": 4.495}, {\"title\": \"Towards Matching Phones and Speech Representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.775, \"y\": 4.933}, {\"title\": \"Evaluating Bias and Fairness in Gender-Neutral Pretrained  Vision-and-Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.306, \"y\": 4.388}, {\"title\": \"CompeteAI: Understanding the Competition Dynamics in Large Language  Model-based Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.254, \"y\": 2.944}, {\"title\": \"The IMS Toucan System for the Blizzard Challenge 2023\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.768, \"y\": 5.692}, {\"title\": \"LightLM: A Lightweight Deep and Narrow Language Model for Generative  Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.907, \"y\": 2.867}, {\"title\": \"Dialect Adaptation and Data Augmentation for Low-Resource ASR: TalTech  Systems for the MADASR 2023 Challenge\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.025, \"y\": 5.354}, {\"title\": \"''Fifty Shades of Bias'': Normative Ratings of Gender Bias in GPT  Generated English Text\", \"topic\": \"Bias in Language Models\", \"x\": 3.212, \"y\": 4.492}, {\"title\": \"PETA: Evaluating the Impact of Protein Transfer Learning with Sub-word  Tokenization on Downstream Applications\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.766, \"y\": 7.432}, {\"title\": \"Harnessing GPT-3.5-turbo for Rhetorical Role Prediction in Legal Cases\", \"topic\": \"Legal NLP\", \"x\": 5.131, \"y\": 5.685}, {\"title\": \"Meaning and understanding in large language models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.096, \"y\": 3.73}, {\"title\": \"Language and Mental Health: Measures of Emotion Dynamics from Text as  Linguistic Biosocial Markers\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.123, \"y\": 7.463}, {\"title\": \"Arabic Fine-Grained Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.448, \"y\": 6.758}, {\"title\": \"An Ensemble Method Based on the Combination of Transformers with  Convolutional Neural Networks to Detect Artificially Generated Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.14, \"y\": 4.971}, {\"title\": \"In-Context Ability Transfer for Question Decomposition in Complex QA\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.605, \"y\": 5.352}, {\"title\": \"CodeFusion: A Pre-trained Diffusion Model for Code Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.559, \"y\": 2.337}, {\"title\": \"Joint Entity and Relation Extraction with Span Pruning and Hypergraph  Neural Networks\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.883, \"y\": 6.754}, {\"title\": \"EMMA-X: An EM-like Multilingual Pre-training Algorithm for Cross-lingual  Representation Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.256, \"y\": 4.869}, {\"title\": \"Codebook Features: Sparse and Discrete Interpretability for Neural  Networks\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.046, \"y\": 3.738}, {\"title\": \"X-SNS: Cross-Lingual Transfer Prediction through Sub-Network Similarity\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.443, \"y\": 4.851}, {\"title\": \"Incorporating Probing Signals into Multimodal Machine Translation via  Visual Question-Answering Pairs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.22, \"y\": 7.648}, {\"title\": \"M2C: Towards Automatic Multimodal Manga Complement\", \"topic\": \"Multimodal Language Models\", \"x\": 7.975, \"y\": 7.286}, {\"title\": \"math-PVS: A Large Language Model Framework to Map Scientific  Publications to PVS Theories\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.991, \"y\": 3.023}, {\"title\": \"On Surgical Fine-tuning for Language Encoders\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.906, \"y\": 2.488}, {\"title\": \"Apollo: Zero-shot MultiModal Reasoning with Multiple Experts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.025, \"y\": 7.541}, {\"title\": \"Data Augmentation for Emotion Detection in Small Imbalanced Text Data\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.329, \"y\": 7.43}, {\"title\": \"How well can machine-generated texts be identified and can language  models be trained to avoid identification?\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.183, \"y\": 4.828}, {\"title\": \"Critic-Driven Decoding for Mitigating Hallucinations in Data-to-text  Generation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.291, \"y\": 1.163}, {\"title\": \"Muslim-Violence Bias Persists in Debiased GPT Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.469, \"y\": 4.633}, {\"title\": \"Zephyr: Direct Distillation of LM Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.34, \"y\": 1.248}, {\"title\": \"Learning Transfers over Several Programming Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.375, \"y\": 4.7}, {\"title\": \"CL-MASR: A Continual Learning Benchmark for Multilingual ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.081, \"y\": 5.23}, {\"title\": \"Language Agnostic Code Embeddings\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.996, \"y\": 4.317}, {\"title\": \"Improving a Named Entity Recognizer Trained on Noisy Data with a Few  Clean Instances\", \"topic\": \"Named Entity Recognition\", \"x\": 7.319, \"y\": 6.757}, {\"title\": \"SuperHF: Supervised Iterative Learning from Human Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.207, \"y\": 1.536}, {\"title\": \"DISCO: A Large Scale Human Annotated Corpus for Disfluency Correction in  Indo-European Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.092, \"y\": 5.65}, {\"title\": \"Improving Conversational Recommendation Systems via Bias Analysis and  Language-Model-Enhanced Data Augmentation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.012, \"y\": 3.176}, {\"title\": \"SkyMath: Technical Report\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.013, \"y\": 2.839}, {\"title\": \"Detection of news written by the ChatGPT through authorship attribution  performed by a Bidirectional LSTM model\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.21, \"y\": 5.124}, {\"title\": \"BabyStories: Can Reinforcement Learning Teach Baby Language Models to  Write Better Stories?\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.145, \"y\": 1.832}, {\"title\": \"SSLCL: An Efficient Model-Agnostic Supervised Contrastive Learning  Framework for Emotion Recognition in Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.24, \"y\": 7.807}, {\"title\": \"Context Does Matter: End-to-end Panoptic Narrative Grounding with  Deformable Attention Refined Matching Network\", \"topic\": \"Multimodal Language Models\", \"x\": 8.749, \"y\": 7.218}, {\"title\": \"Back Transcription as a Method for Evaluating Robustness of Natural  Language Understanding Models to Speech Recognition Errors\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.029, \"y\": 5.391}, {\"title\": \"On the Interplay between Fairness and Explainability\", \"topic\": \"Bias in Language Models\", \"x\": 3.48, \"y\": 4.207}, {\"title\": \"WSDMS: Debunk Fake News via Weakly Supervised Detection of Misinforming  Sentences with Contextualized Social Wisdom\", \"topic\": \"Fake News Detection\", \"x\": 3.996, \"y\": 5.819}, {\"title\": \"R$^3$ Prompting: Review, Rephrase and Resolve for Chain-of-Thought  Reasoning in Large Language Models under Noisy Context\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.647, \"y\": 2.48}, {\"title\": \"OccuQuest: Mitigating Occupational Bias for Inclusive Large Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.638, \"y\": 4.237}, {\"title\": \"Diversity Enhanced Narrative Question Generation for Storybooks\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.208, \"y\": 5.015}, {\"title\": \"PromptAgent: Strategic Planning with Language Models Enables  Expert-level Prompt Optimization\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.31, \"y\": 3.192}, {\"title\": \"Enhanced Simultaneous Machine Translation with Word-level Policies\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.971, \"y\": 4.574}, {\"title\": \"Decoding Stumpers: Large Language Models vs. Human Problem-Solvers\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.497, \"y\": 3.374}, {\"title\": \"Video Referring Expression Comprehension via Transformer with  Content-conditioned Query\", \"topic\": \"Multimodal Language Models\", \"x\": 8.824, \"y\": 7.897}, {\"title\": \"LlamaRec: Two-Stage Recommendation using Large Language Models for  Ranking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.931, \"y\": 2.874}, {\"title\": \"ZGUL: Zero-shot Generalization to Unseen Languages using Multi-source  Ensembling of Language Adapters\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.472, \"y\": 4.624}, {\"title\": \"InstructPTS: Instruction-Tuning LLMs for Product Title Summarization\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.152, \"y\": 2.461}, {\"title\": \"Generative Pre-training for Speech with Flow Matching\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.631, \"y\": 5.385}, {\"title\": \"Samsung R&D Institute Philippines at WMT 2023\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.877, \"y\": 4.683}, {\"title\": \"DiQAD: A Benchmark Dataset for End-to-End Open-domain Dialogue  Assessment\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.438, \"y\": 3.856}, {\"title\": \"CycleAlign: Iterative Distillation from Black-box LLM to White-box  Models for Better Human Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.361, \"y\": 1.387}, {\"title\": \"Attention Lens: A Tool for Mechanistically Interpreting the Attention  Head Information Retrieval Mechanism\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.414, \"y\": 3.476}, {\"title\": \"Multilingual Coarse Political Stance Classification of Media. The  Editorial Line of a ChatGPT and Bard Newspaper\", \"topic\": \"Fake News Detection\", \"x\": 3.69, \"y\": 5.736}, {\"title\": \"ZzzGPT: An Interactive GPT Approach to Enhance Sleep Quality\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.524, \"y\": 7.56}, {\"title\": \"Mixture-of-Linguistic-Experts Adapters for Improving and Interpreting  Pre-trained Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.932, \"y\": 2.132}, {\"title\": \"TiC-CLIP: Continual Training of CLIP Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.94, \"y\": 7.1}, {\"title\": \"CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset\", \"topic\": \"Named Entity Recognition\", \"x\": 7.285, \"y\": 6.756}, {\"title\": \"Background Summarization of Event Timelines\", \"topic\": \"Text Summarization\", \"x\": 5.634, \"y\": 6.3}, {\"title\": \"BLP-2023 Task 2: Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.389, \"y\": 6.577}, {\"title\": \"Correction with Backtracking Reduces Hallucination in Summarization\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.209, \"y\": 1.211}, {\"title\": \"PreWoMe: Exploiting Presuppositions as Working Memory for Long Form  Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.4, \"y\": 5.209}, {\"title\": \"From Heuristic to Analytic: Cognitively Motivated Strategies for  Coherent Physical Commonsense Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.594, \"y\": 2.792}, {\"title\": \"Clinfo.ai: An Open-Source Retrieval-Augmented Large Language Model  System for Answering Medical Questions using Scientific Literature\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.794, \"y\": 7.609}, {\"title\": \"A Language Model with Limited Memory Capacity Captures Interference in  Human Sentence Processing\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.147, \"y\": 3.587}, {\"title\": \"CR-COPEC: Causal Rationale of Corporate Performance Changes to Learn  from Financial Reports\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.038, \"y\": 6.672}, {\"title\": \"MuSR: Testing the Limits of Chain-of-thought with Multistep Soft  Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.718, \"y\": 2.495}, {\"title\": \"Woodpecker: Hallucination Correction for Multimodal Large Language  Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.239, \"y\": 1.021}, {\"title\": \"WebWISE: Web Interface Control and Sequential Exploration with Large  Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.579, \"y\": 2.499}, {\"title\": \"Towards Perceiving Small Visual Details in Zero-shot Visual Question  Answering with Multimodal LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.358, \"y\": 7.838}, {\"title\": \"What Algorithms can Transformers Learn? A Study in Length Generalization\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.453, \"y\": 3.463}, {\"title\": \"Dissecting In-Context Learning of Translations in GPTs\", \"topic\": \"In-Context Learning\", \"x\": 8.995, \"y\": 3.821}, {\"title\": \"Accented Speech Recognition With Accent-specific Codebooks\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.109, \"y\": 5.259}, {\"title\": \"NoteChat: A Dataset of Synthetic Doctor-Patient Conversations  Conditioned on Clinical Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.475, \"y\": 8.102}, {\"title\": \"E-Sparse: Boosting the Large Language Model Inference through  Entropy-based N:M Sparsity\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.556, \"y\": 2.389}, {\"title\": \"Do Stochastic Parrots have Feelings Too? Improving Neural Detection of  Synthetic Text via Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.44, \"y\": 7.656}, {\"title\": \"BianQue: Balancing the Questioning and Suggestion Ability of Health LLMs  with Multi-turn Health Conversations Polished by ChatGPT\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.492, \"y\": 7.968}, {\"title\": \"A Contextualized Real-Time Multimodal Emotion Recognition for  Conversational Agents using Graph Convolutional Networks in Reinforcement  Learning\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.265, \"y\": 7.768}, {\"title\": \"Using Artificial French Data to Understand the Emergence of Gender Bias  in Transformer Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.037, \"y\": 4.387}, {\"title\": \"Self-Guard: Empower the LLM to Safeguard Itself\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.345, \"y\": 2.314}, {\"title\": \"Unnatural language processing: How do language models handle  machine-generated prompts?\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.03, \"y\": 3.324}, {\"title\": \"Generative Language Models Exhibit Social Identity Biases\", \"topic\": \"Bias in Language Models\", \"x\": 3.587, \"y\": 4.355}, {\"title\": \"DALE: Generative Data Augmentation for Low-Resource Legal NLP\", \"topic\": \"Legal NLP\", \"x\": 5.281, \"y\": 5.595}, {\"title\": \"Random Entity Quantization for Parameter-Efficient Compositional  Knowledge Graph Representation\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.174, \"y\": 6.135}, {\"title\": \"Improving generalization in large language models by learning prefix  subspaces\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.013, \"y\": 2.356}, {\"title\": \"Learning From Free-Text Human Feedback -- Collect New Datasets Or Extend  Existing Ones?\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.345, \"y\": 3.935}, {\"title\": \"Integrating Language Models into Direct Speech Translation: An  Inference-Time Solution to Control Gender Inflection\", \"topic\": \"Bias in Language Models\", \"x\": 3.018, \"y\": 4.367}, {\"title\": \"RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot  Document-Level Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.099, \"y\": 6.765}, {\"title\": \"Re-Temp: Relation-Aware Temporal Representation Learning for Temporal  Knowledge Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.797, \"y\": 6.013}, {\"title\": \"COPR: Continual Learning Human Preference through Optimal Policy  Regularization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.148, \"y\": 1.544}, {\"title\": \"How Much Context Does My Attention-Based ASR System Need?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.245, \"y\": 5.074}, {\"title\": \"A Survey on Detection of LLMs-Generated Content\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.147, \"y\": 4.739}, {\"title\": \"Machine Translation for Nko: Tools, Corpora and Baseline Results\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.628, \"y\": 5.043}, {\"title\": \"MUSER: A Multi-View Similar Case Retrieval Dataset\", \"topic\": \"Legal NLP\", \"x\": 5.146, \"y\": 5.805}, {\"title\": \"Multimodal Representations for Teacher-Guided Compositional Visual  Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.294, \"y\": 7.745}, {\"title\": \"CONTRASTE: Supervised Contrastive Pre-training With Aspect-based Prompts  For Aspect Sentiment Triplet Extraction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.116, \"y\": 6.838}, {\"title\": \"POE: Process of Elimination for Multiple Choice Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.599, \"y\": 2.624}, {\"title\": \"Natural Language Processing for Drug Discovery Knowledge Graphs:  promises and pitfalls\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.206, \"y\": 7.061}, {\"title\": \"MarkQA: A large scale KBQA dataset with numerical reasoning\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.592, \"y\": 5.368}, {\"title\": \"TRAMS: Training-free Memory Selection for Long-range Language Modeling\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.741, \"y\": 3.107}, {\"title\": \"NuTrea: Neural Tree Search for Context-guided Multi-hop KGQA\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.79, \"y\": 5.553}, {\"title\": \"A Communication Theory Perspective on Prompting Engineering Methods for  Large Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.189, \"y\": 3.194}, {\"title\": \"Interpreting Answers to Yes-No Questions in User-Generated Content\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.158, \"y\": 5.106}, {\"title\": \"K-HATERS: A Hate Speech Detection Corpus in Korean with Target-Specific  Ratings\", \"topic\": \"Hate Speech Detection\", \"x\": 2.746, \"y\": 5.362}, {\"title\": \"Beyond Sentiment: Leveraging Topic Metrics for Political Stance  Classification\", \"topic\": \"Fake News Detection\", \"x\": 3.622, \"y\": 5.885}, {\"title\": \"LoRAShear: Efficient Large Language Model Structured Pruning and  Knowledge Recovery\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.324, \"y\": 2.298}, {\"title\": \"The Mason-Alberta Phonetic Segmenter: A forced alignment system based on  deep neural networks and interpolation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.935, \"y\": 5.38}, {\"title\": \"Mind the Gap Between Conversations for Improved Long-Term Dialogue  Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.437, \"y\": 3.723}, {\"title\": \"\\\"One-Size-Fits-All\\\"? Examining Expectations around What Constitute  \\\"Fair\\\" or \\\"Good\\\" NLG System Behaviors\", \"topic\": \"Bias in Language Models\", \"x\": 3.415, \"y\": 4.211}, {\"title\": \"Health Disparities through Generative AI Models: A Comparison Study  Using A Domain Specific large language model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.445, \"y\": 7.896}, {\"title\": \"EpiK-Eval: Evaluation for Language Models as Epistemic Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.509, \"y\": 3.726}, {\"title\": \"Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual,  Intensional, and Extensional Learning for Faithful Natural Language  Generation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.205, \"y\": 1.195}, {\"title\": \"Specialist or Generalist? Instruction Tuning for Specific NLP Tasks\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.409, \"y\": 2.454}, {\"title\": \"LXMERT Model Compression for Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.283, \"y\": 7.966}, {\"title\": \"Hallucination Detection for Grounded Instruction Generation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.199, \"y\": 1.066}, {\"title\": \"TaskDiff: A Similarity Metric for Task-Oriented Conversations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.371, \"y\": 3.801}, {\"title\": \"Towards Possibilities & Impossibilities of AI-generated Text Detection:  A Survey\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.196, \"y\": 4.693}, {\"title\": \"Data Augmentation Techniques for Machine Translation of Code-Switched  Texts: A Comparative Study\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.399, \"y\": 5.112}, {\"title\": \"Breaking the Language Barrier: Improving Cross-Lingual Reasoning with  Structured Self-Attention\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.232, \"y\": 4.782}, {\"title\": \"Large Language Models are Visual Reasoning Coordinators\", \"topic\": \"Multimodal Language Models\", \"x\": 8.36, \"y\": 7.633}, {\"title\": \"LINC: A Neurosymbolic Approach for Logical Reasoning by Combining  Language Models with First-Order Logic Provers\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.708, \"y\": 2.78}, {\"title\": \"Linear Representations of Sentiment in Large Language Models\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.601, \"y\": 6.672}, {\"title\": \"S3Eval: A Synthetic, Scalable, Systematic Evaluation Suite for Large  Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.486, \"y\": 3.843}, {\"title\": \"AutoDAN: Interpretable Gradient-Based Adversarial Attacks on Large  Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.244, \"y\": 2.525}, {\"title\": \"Location-Aware Visual Question Generation with Lightweight Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.049, \"y\": 7.995}, {\"title\": \"How To Build Competitive Multi-gender Speech Translation Models For  Controlling Speaker Gender Translation\", \"topic\": \"Bias in Language Models\", \"x\": 2.927, \"y\": 4.381}, {\"title\": \"'Don't Get Too Technical with Me': A Discourse Structure-Based Framework  for Science Journalism\", \"topic\": \"Text Summarization\", \"x\": 5.787, \"y\": 6.324}, {\"title\": \"Localizing Active Objects from Egocentric Vision with Symbolic World  Knowledge\", \"topic\": \"Multimodal Language Models\", \"x\": 8.658, \"y\": 7.261}, {\"title\": \"The BLA Benchmark: Investigating Basic Language Abilities of Pre-Trained  Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.428, \"y\": 7.499}, {\"title\": \"Efficient Data Learning for Open Information Extraction with Pre-trained  Language Models\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.012, \"y\": 6.514}, {\"title\": \"Simple Hardware-Efficient PCFGs with Independent Left and Right  Productions\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.502, \"y\": 2.263}, {\"title\": \"LLM-Based Agent Society Investigation: Collaboration and Confrontation  in Avalon Gameplay\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.17, \"y\": 3.023}, {\"title\": \"Towards LLM-driven Dialogue State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.571, \"y\": 3.891}, {\"title\": \"Key Frame Mechanism For Efficient Conformer Based End-to-end Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.246, \"y\": 4.971}, {\"title\": \"PartialFormer: Modeling Part Instead of Whole for Machine Translation\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.832, \"y\": 3.403}, {\"title\": \"Linking Surface Facts to Large-Scale Knowledge Graphs\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.704, \"y\": 6.04}, {\"title\": \"Non-autoregressive Streaming Transformer for Simultaneous Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.146, \"y\": 4.579}, {\"title\": \"Can ChatGPT Perform Reasoning Using the IRAC Method in Analyzing Legal  Scenarios Like a Lawyer?\", \"topic\": \"Legal NLP\", \"x\": 5.118, \"y\": 5.552}, {\"title\": \"Assessing Step-by-Step Reasoning against Lexical Negation: A Case Study  on Syllogism\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.664, \"y\": 3.041}, {\"title\": \"Adaptive Policy with Wait-$k$ Model for Simultaneous Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.086, \"y\": 4.621}, {\"title\": \"DISC-FinLLM: A Chinese Financial Large Language Model based on Multiple  Experts Fine-tuning\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.854, \"y\": 6.875}, {\"title\": \"Leveraging Timestamp Information for Serialized Joint Streaming  Recognition and Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.706, \"y\": 5.088}, {\"title\": \"Cross-Modal Conceptualization in Bottleneck Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.522, \"y\": 8.425}, {\"title\": \"Large Language Models can Share Images, Too!\", \"topic\": \"Multimodal Language Models\", \"x\": 8.384, \"y\": 7.262}, {\"title\": \"Cross-lingual Prompting: Improving Zero-shot Chain-of-Thought Reasoning  across Languages\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.968, \"y\": 2.539}, {\"title\": \"Evaluating the Knowledge Base Completion Potential of GPT\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.918, \"y\": 5.963}, {\"title\": \"MCC-KD: Multi-CoT Consistent Knowledge Distillation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.891, \"y\": 2.369}, {\"title\": \"Unleashing the potential of prompt engineering in Large Language Models:  a comprehensive review\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.138, \"y\": 3.256}, {\"title\": \"A Survey on LLM-Generated Text Detection: Necessity, Methods, and Future  Directions\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.087, \"y\": 4.691}, {\"title\": \"SpEL: Structured Prediction for Entity Linking\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.987, \"y\": 6.55}, {\"title\": \"Dataset Bias Mitigation in Multiple-Choice Visual Question Answering and  Beyond\", \"topic\": \"Multimodal Language Models\", \"x\": 8.246, \"y\": 8.007}, {\"title\": \"DPP-TTS: Diversifying prosodic features of speech via determinantal  point processes\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.626, \"y\": 5.857}, {\"title\": \"Multilingual k-Nearest-Neighbor Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.772, \"y\": 4.635}, {\"title\": \"Plan, Verify and Switch: Integrated Reasoning with Diverse X-of-Thoughts\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.548, \"y\": 2.578}, {\"title\": \"Conversational Recommender System and Large Language Model Are Made for  Each Other in E-commerce Pre-sales Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.952, \"y\": 2.939}, {\"title\": \"CoF-CoT: Enhancing Large Language Models with Coarse-to-Fine  Chain-of-Thought Prompting for Multi-domain NLU Tasks\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.629, \"y\": 2.33}, {\"title\": \"Efficient Cross-Task Prompt Tuning for Few-Shot Conversational Emotion  Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.297, \"y\": 7.803}, {\"title\": \"Long Short-Term Planning for Conversational Recommendation Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.987, \"y\": 3.026}, {\"title\": \"Confronting LLMs with Traditional ML: Rethinking the Fairness of Large  Language Models in Tabular Classifications\", \"topic\": \"Bias in Language Models\", \"x\": 3.479, \"y\": 4.209}, {\"title\": \"DeCrisisMB: Debiased Semi-Supervised Learning for Crisis Tweet  Classification via Memory Bank\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.158, \"y\": 6.701}, {\"title\": \"Exploring the Boundaries of GPT-4 in Radiology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.987, \"y\": 8.317}, {\"title\": \"A Boundary Offset Prediction Network for Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.392, \"y\": 6.776}, {\"title\": \"HallusionBench: An Advanced Diagnostic Suite for Entangled Language  Hallucination and Visual Illusion in Large Vision-Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.232, \"y\": 1.04}, {\"title\": \"AlpaCare:Instruction-tuned Large Language Models for Medical Application\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.97, \"y\": 8.054}, {\"title\": \"The Skipped Beat: A Study of Sociopragmatic Understanding in LLMs for 64  Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.087, \"y\": 4.305}, {\"title\": \"Continual Named Entity Recognition without Catastrophic Forgetting\", \"topic\": \"Named Entity Recognition\", \"x\": 7.389, \"y\": 6.701}, {\"title\": \"Dual-Feedback Knowledge Retrieval for Task-Oriented Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.726, \"y\": 4.093}, {\"title\": \"QUDEVAL: The Evaluation of Questions Under Discussion Discourse Parsing\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.254, \"y\": 4.976}, {\"title\": \"Turn-Level Active Learning for Dialogue State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.618, \"y\": 3.871}, {\"title\": \"Sentiment analysis with adaptive multi-head attention in Transformer\", \"topic\": \"Efficient Transformer Models\", \"x\": 3.537, \"y\": 6.828}, {\"title\": \"Diversify Question Generation with Retrieval-Augmented Style Transfer\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.387, \"y\": 5.066}, {\"title\": \"Towards a Mechanistic Interpretation of Multi-Step Reasoning  Capabilities of Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.688, \"y\": 2.674}, {\"title\": \"DetectGPT-SC: Improving Detection of Text Generated by Large Language  Models through Self-Consistency with Masked Predictions\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.187, \"y\": 4.764}, {\"title\": \"Domain Terminology Integration into Machine Translation: Leveraging  Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.725, \"y\": 4.386}, {\"title\": \"TATA: Stance Detection via Topic-Agnostic and Topic-Aware Embeddings\", \"topic\": \"Fake News Detection\", \"x\": 3.445, \"y\": 5.847}, {\"title\": \"Retrieval-Augmented Chain-of-Thought in Semi-structured Domains\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.021, \"y\": 6.456}, {\"title\": \"Evaluating Subjective Cognitive Appraisals of Emotions from Large  Language Models\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.557, \"y\": 7.458}, {\"title\": \"ARCOQ: Arabic Closest Opposite Questions Dataset\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.813, \"y\": 5.117}, {\"title\": \"Bi-Encoders based Species Normalization -- Pairwise Sentence Learning to  Rank\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.426, \"y\": 7.464}, {\"title\": \"The Law and NLP: Bridging Disciplinary Disconnects\", \"topic\": \"Legal NLP\", \"x\": 5.275, \"y\": 5.644}, {\"title\": \"DiFair: A Benchmark for Disentangled Assessment of Gender Knowledge and  Bias\", \"topic\": \"Bias in Language Models\", \"x\": 3.263, \"y\": 4.324}, {\"title\": \"Chainpoll: A high efficacy method for LLM hallucination detection\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.165, \"y\": 1.085}, {\"title\": \"NERetrieve: Dataset for Next Generation Named Entity Recognition and  Retrieval\", \"topic\": \"Named Entity Recognition\", \"x\": 7.288, \"y\": 6.805}, {\"title\": \"Conversational Speech Recognition by Learning Audio-textual Cross-modal  Contextual Representation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.099, \"y\": 5.216}, {\"title\": \"CT-GAT: Cross-Task Generative Adversarial Attack based on  Transferability\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.123, \"y\": 3.004}, {\"title\": \"Boosting Unsupervised Machine Translation with Pseudo-Parallel Data\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.785, \"y\": 4.655}, {\"title\": \"RSM-NLP at BLP-2023 Task 2: Bangla Sentiment Analysis using Weighted and  Majority Voted Fine-Tuned Transformers\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.416, \"y\": 6.525}, {\"title\": \"MIRACLE: Towards Personalized Dialogue Generation with Latent-Space  Multiple Personal Attribute Control\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.227, \"y\": 3.715}, {\"title\": \"Customising General Large Language Models for Specialised Emotion  Recognition Tasks\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.373, \"y\": 7.692}, {\"title\": \"Manifold-Preserving Transformers are Effective for Short-Long Range  Encoding\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.885, \"y\": 3.297}, {\"title\": \"CXR-LLAVA: a multimodal large language model for interpreting chest  X-ray images\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.238, \"y\": 8.606}, {\"title\": \"PromptMix: A Class Boundary Augmentation Method for Large Language Model  Distillation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.498, \"y\": 3.446}, {\"title\": \"An In-Context Schema Understanding Method for Knowledge Base Question  Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.84, \"y\": 5.362}, {\"title\": \"Orthogonal Subspace Learning for Language Model Continual Learning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.128, \"y\": 2.18}, {\"title\": \"PromptCBLUE: A Chinese Prompt Tuning Benchmark for the Medical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.974, \"y\": 7.883}, {\"title\": \"Ask To The Point: Open-Domain Entity-Centric Question Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.18, \"y\": 5.141}, {\"title\": \"On the Transferability of Visually Grounded PCFGs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.809, \"y\": 7.218}, {\"title\": \"Revisiting Instruction Fine-tuned Model Evaluation to Guide Industrial  Applications\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.248, \"y\": 2.304}, {\"title\": \"MedEval: A Multi-Level, Multi-Task, and Multi-Domain Medical Benchmark  for Language Model Evaluation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.927, \"y\": 7.933}, {\"title\": \"Code-Switching with Word Senses for Pretraining in Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.522, \"y\": 4.758}, {\"title\": \"Small Language Models Fine-tuned to Coordinate Larger Language Models  improve Complex Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.81, \"y\": 2.489}, {\"title\": \"Tree Prompting: Efficient Task Adaptation without Fine-Tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.38, \"y\": 3.134}, {\"title\": \"Analysing State-Backed Propaganda Websites: a New Dataset and Linguistic  Study\", \"topic\": \"Fake News Detection\", \"x\": 3.877, \"y\": 5.763}, {\"title\": \"Large Language Models and Multimodal Retrieval for Visual Word Sense  Disambiguation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.337, \"y\": 7.502}, {\"title\": \"Toward Stronger Textual Attack Detectors\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.155, \"y\": 3.039}, {\"title\": \"Emulating the Human Mind: A Neural-symbolic Link Prediction Model with  Fast and Slow Reasoning and Filtered Rules\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.935, \"y\": 5.985}, {\"title\": \"On Bilingual Lexicon Induction with Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.237, \"y\": 4.383}, {\"title\": \"HateRephrase: Zero- and Few-Shot Reduction of Hate Intensity in Online  Posts using Large Language Models\", \"topic\": \"Hate Speech Detection\", \"x\": 2.741, \"y\": 5.281}, {\"title\": \"Automatic Pronunciation Assessment -- A Review\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.023, \"y\": 5.518}, {\"title\": \"Ensemble-Instruct: Generating Instruction-Tuning Data with a  Heterogeneous Mixture of LMs\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 7.998, \"y\": 2.459}, {\"title\": \"RTSUM: Relation Triple-based Interpretable Summarization with  Multi-level Salience Visualization\", \"topic\": \"Text Summarization\", \"x\": 5.705, \"y\": 6.296}, {\"title\": \"RECAP: Towards Precise Radiology Report Generation via Dynamic Disease  Progression Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.214, \"y\": 8.629}, {\"title\": \"Not all Fake News is Written: A Dataset and Analysis of Misleading Video  Headlines\", \"topic\": \"Fake News Detection\", \"x\": 4.111, \"y\": 5.814}, {\"title\": \"Plausibility Processing in Transformer Language Models: Focusing on the  Role of Attention Heads in GPT\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.259, \"y\": 3.61}, {\"title\": \"Enhancing Abstractiveness of Summarization Models through Calibrated  Distillation\", \"topic\": \"Text Summarization\", \"x\": 5.517, \"y\": 6.236}, {\"title\": \"Long-Form Speech Translation through Segmentation with Finite-State  Decoding Constraints on Large Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.534, \"y\": 5.006}, {\"title\": \"On Synthetic Data for Back Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.832, \"y\": 4.682}, {\"title\": \"StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.431, \"y\": 4.384}, {\"title\": \"Explainable Depression Symptom Detection in Social Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.196, \"y\": 7.489}, {\"title\": \"Three Questions Concerning the Use of Large Language Models to  Facilitate Mathematics Learning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.749, \"y\": 3.138}, {\"title\": \"Hunayn: Elevating Translation Beyond the Literal\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.535, \"y\": 5.071}, {\"title\": \"MULTITuDE: Large-Scale Multilingual Machine-Generated Text Detection  Benchmark\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.032, \"y\": 4.901}, {\"title\": \"Simultaneous Machine Translation with Tailored Reference\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.037, \"y\": 4.555}, {\"title\": \"Improving Cross-Lingual Transfer through Subtree-Aware Word Reordering\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.319, \"y\": 4.85}, {\"title\": \"Why Can Large Language Models Generate Correct Chain-of-Thoughts?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.559, \"y\": 2.62}, {\"title\": \"Retrieval-Augmented Neural Response Generation Using Logical Reasoning  and Relevance Scoring\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.684, \"y\": 4.207}, {\"title\": \"Self-prompted Chain-of-Thought on Large Language Models for Open-domain  Multi-hop Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.726, \"y\": 2.263}, {\"title\": \"Improving Question Generation with Multi-level Content Planning\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.383, \"y\": 5.075}, {\"title\": \"Explaining Interactions Between Text Spans\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.91, \"y\": 4.0}, {\"title\": \"DistillCSE: Distilled Contrastive Learning for Sentence Embeddings\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.443, \"y\": 3.964}, {\"title\": \"Ask Language Model to Clean Your Noisy Translation Data\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.839, \"y\": 4.405}, {\"title\": \"Multiscale Superpixel Structured Difference Graph Convolutional Network  for VL Representation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.45, \"y\": 7.275}, {\"title\": \"Conversation Chronicles: Towards Diverse Temporal and Relational  Dynamics in Multi-Session Conversations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.367, \"y\": 3.855}, {\"title\": \"Towards Enhancing Relational Rules for Knowledge Graph Link Prediction\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.02, \"y\": 6.037}, {\"title\": \"Explicit Alignment and Many-to-many Entailment Based Reasoning for  Conversational Machine Reading\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.53, \"y\": 5.174}, {\"title\": \"POSQA: Probe the World Models of LLMs with Size Comparisons\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.953, \"y\": 3.478}, {\"title\": \"Tuna: Instruction Tuning using Feedback from Large Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.098, \"y\": 2.37}, {\"title\": \"Bridging the Gap between Synthetic and Authentic Images for Multimodal  Machine Translation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.487, \"y\": 7.035}, {\"title\": \"Democratizing Reasoning Ability: Tailored Learning from Large Language  Model\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.751, \"y\": 2.547}, {\"title\": \"Zero-Shot Sharpness-Aware Quantization for Pre-trained Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.718, \"y\": 2.136}, {\"title\": \"Exploring the Impact of Corpus Diversity on Financial Pretrained  Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.903, \"y\": 6.856}, {\"title\": \"SALMONN: Towards Generic Hearing Abilities for Large Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.668, \"y\": 5.436}, {\"title\": \"The Less the Merrier? Investigating Language Representation in  Multilingual Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.059, \"y\": 4.819}, {\"title\": \"Enhancing Zero-Shot Crypto Sentiment with Fine-tuned Language Model and  Prompt Engineering\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.169, \"y\": 2.374}, {\"title\": \"MultiCoNER v2: a Large Multilingual dataset for Fine-grained and Noisy  Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.403, \"y\": 6.791}, {\"title\": \"Primacy Effect of ChatGPT\", \"topic\": \"Bias in Language Models\", \"x\": 5.545, \"y\": 4.427}, {\"title\": \"CLIFT: Analysing Natural Distribution Shift on Question Answering Models  in Clinical Domain\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.825, \"y\": 5.29}, {\"title\": \"Better to Ask in English: Cross-Lingual Evaluation of Large Language  Models for Healthcare Queries\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.757, \"y\": 7.739}, {\"title\": \"Auto-Instruct: Automatic Instruction Generation and Ranking for  Black-Box Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 7.927, \"y\": 2.311}, {\"title\": \"Unsupervised Candidate Answer Extraction through Differentiable  Masker-Reconstructor Model\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.446, \"y\": 5.186}, {\"title\": \"Do Language Models Learn about Legal Entity Types during Pretraining?\", \"topic\": \"Legal NLP\", \"x\": 5.248, \"y\": 5.485}, {\"title\": \"From Multilingual Complexity to Emotional Clarity: Leveraging  Commonsense to Unveil Emotions in Code-Mixed Dialogues\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.337, \"y\": 7.801}, {\"title\": \"Frozen Transformers in Language Models Are Effective Visual Encoder  Layers\", \"topic\": \"Multimodal Language Models\", \"x\": 8.593, \"y\": 7.44}, {\"title\": \"CLAIR: Evaluating Image Captions with Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 9.041, \"y\": 7.429}, {\"title\": \"A Predictive Factor Analysis of Social Biases and Task-Performance in  Pretrained Masked Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.409, \"y\": 4.53}, {\"title\": \"Experimental Narratives: A Comparison of Human Crowdsourced Storytelling  and AI Storytelling\", \"topic\": \"Bias in Language Models\", \"x\": 5.029, \"y\": 4.534}, {\"title\": \"Proceedings of the 3rd International Workshop on Mining and Learning in  the Legal Domain (MLLD-23)\", \"topic\": \"Legal NLP\", \"x\": 5.241, \"y\": 5.719}, {\"title\": \"Probing LLMs for hate speech detection: strengths and vulnerabilities\", \"topic\": \"Hate Speech Detection\", \"x\": 2.719, \"y\": 5.289}, {\"title\": \"EmoDiarize: Speaker Diarization and Emotion Identification from Speech  Signals using Convolutional Neural Networks\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.228, \"y\": 7.826}, {\"title\": \"AgentTuning: Enabling Generalized Agent Abilities for LLMs\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.855, \"y\": 2.452}, {\"title\": \"Formalizing and Benchmarking Prompt Injection Attacks and Defenses\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.38, \"y\": 2.53}, {\"title\": \"Are Structural Concepts Universal in Transformer Language Models?  Towards Interpretable Cross-Lingual Generalization\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.234, \"y\": 4.785}, {\"title\": \"Survival of the Most Influential Prompts: Efficient Black-Box Prompt  Search via Clustering and Pruning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.557, \"y\": 3.251}, {\"title\": \"Transformer-based Entity Legal Form Classification\", \"topic\": \"Legal NLP\", \"x\": 5.162, \"y\": 5.948}, {\"title\": \"Is ChatGPT a Financial Expert? Evaluating Language Models on Financial  Natural Language Processing\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.865, \"y\": 6.85}, {\"title\": \"Towards Real-World Streaming Speech Translation for Code-Switched Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.311, \"y\": 5.182}, {\"title\": \"Predict the Future from the Past? On the Temporal Data Distribution  Shift in Financial Sentiment Classifications\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.651, \"y\": 6.801}, {\"title\": \"Identifying and Adapting Transformer-Components Responsible for Gender  Bias in an English Language Model\", \"topic\": \"Bias in Language Models\", \"x\": 3.157, \"y\": 4.327}, {\"title\": \"Time-Aware Representation Learning for Time-Sensitive Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.573, \"y\": 5.501}, {\"title\": \"ICU: Conquering Language Barriers in Vision-and-Language Modeling by  Dividing the Tasks into Image Captioning and Language Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.507, \"y\": 7.535}, {\"title\": \"Named Entity Recognition for Monitoring Plant Health Threats in Tweets:  a ChouBERT Approach\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.256, \"y\": 6.762}, {\"title\": \"Powerset multi-class cross entropy loss for neural speaker diarization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.877, \"y\": 5.244}, {\"title\": \"Lost in Translation: When GPT-4V(ision) Can't See Eye to Eye with Text.  A Vision-Language-Consistency Analysis of VLLMs and Beyond\", \"topic\": \"Multimodal Language Models\", \"x\": 8.198, \"y\": 7.625}, {\"title\": \"ReEval: Automatic Hallucination Evaluation for Retrieval-Augmented Large  Language Models via Transferable Adversarial Attacks\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.11, \"y\": 1.148}, {\"title\": \"Co$^2$PT: Mitigating Bias in Pre-trained Language Models through  Counterfactual Contrastive Prompt Tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 3.652, \"y\": 3.995}, {\"title\": \"MedAI Dialog Corpus (MEDIC): Zero-Shot Classification of Doctor and AI  Responses in Health Consultations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.843, \"y\": 8.151}, {\"title\": \"Exploring In-Context Learning of Textless Speech Language Model for  Speech Classification Tasks\", \"topic\": \"In-Context Learning\", \"x\": 8.362, \"y\": 3.41}, {\"title\": \"Unmasking Transformers: A Theoretical Approach to Data Recovery via  Attention Weights\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.735, \"y\": 3.387}, {\"title\": \"Efficient Long-Range Transformers: You Need to Attend More, but Not  Necessarily at Every Layer\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.863, \"y\": 3.282}, {\"title\": \"FinEntity: Entity-level Sentiment Classification for Financial Texts\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.611, \"y\": 6.862}, {\"title\": \"knn-seq: Efficient, Extensible kNN-MT Framework\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.911, \"y\": 4.353}, {\"title\": \"Eliminating Reasoning via Inferring with Planning: A New Framework to  Guide LLMs' Non-linear Thinking\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.502, \"y\": 2.467}, {\"title\": \"The Sentiment Problem: A Critical Survey towards Deconstructing  Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.571, \"y\": 6.504}, {\"title\": \"Document-Level Language Models for Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.757, \"y\": 4.479}, {\"title\": \"Measuring Pointwise $\\\\mathcal{V}$-Usable Information In-Context-ly\", \"topic\": \"In-Context Learning\", \"x\": 8.36, \"y\": 3.37}, {\"title\": \"An Image is Worth Multiple Words: Discovering Object Level Concepts  using Multi-Concept Prompt Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.453, \"y\": 7.152}, {\"title\": \"Direct Neural Machine Translation with Task-level Mixture of Experts  models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.861, \"y\": 4.392}, {\"title\": \"A Tale of Pronouns: Interpretability Informs Gender Bias Mitigation for  Fairer Instruction-Tuned Machine Translation\", \"topic\": \"Bias in Language Models\", \"x\": 2.985, \"y\": 4.397}, {\"title\": \"SHARCS: Efficient Transformers through Routing with Dynamic Width  Sub-networks\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.775, \"y\": 3.053}, {\"title\": \"Harnessing Dataset Cartography for Improved Compositional Generalization  in Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.325, \"y\": 3.615}, {\"title\": \"Non-Intrusive Adaptation: Input-Centric Parameter-efficient Fine-Tuning  for Versatile Multimodal Modeling\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.014, \"y\": 2.298}, {\"title\": \"FactCHD: Benchmarking Fact-Conflicting Hallucination Detection\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.199, \"y\": 1.139}, {\"title\": \"Concept-Guided Chain-of-Thought Prompting for Pairwise Comparison  Scaling of Texts with Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.484, \"y\": 2.361}, {\"title\": \"Gold: A Global and Local-aware Denoising Framework for Commonsense  Knowledge Graph Noise Detection\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.96, \"y\": 5.902}, {\"title\": \"Multi-view Contrastive Learning for Entity Typing over Knowledge Graphs\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.287, \"y\": 6.306}, {\"title\": \"From Interpolation to Extrapolation: Complete Length Generalization for  Arithmetic Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.658, \"y\": 3.338}, {\"title\": \"Fast Multipole Attention: A Divide-and-Conquer Attention Mechanism for  Long Sequences\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.907, \"y\": 3.168}, {\"title\": \"A Benchmark for Semi-Inductive Link Prediction in Knowledge Graphs\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.062, \"y\": 6.106}, {\"title\": \"Rather a Nurse than a Physician -- Contrastive Explanations under  Investigation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.82, \"y\": 3.89}, {\"title\": \"From Dissonance to Insights: Dissecting Disagreements in Rationale  Construction for Case Outcome Classification\", \"topic\": \"Legal NLP\", \"x\": 5.03, \"y\": 5.75}, {\"title\": \"The Curious Case of Hallucinatory (Un)answerability: Finding Truths in  the Hidden States of Over-Confident Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.284, \"y\": 1.304}, {\"title\": \"Language Agents for Detecting Implicit Stereotypes in Text-to-image  Models at Scale\", \"topic\": \"Bias in Language Models\", \"x\": 3.204, \"y\": 4.518}, {\"title\": \"A Comprehensive Evaluation of Large Language Models on Legal Judgment  Prediction\", \"topic\": \"Legal NLP\", \"x\": 5.183, \"y\": 5.413}, {\"title\": \"Quantifying Self-diagnostic Atomic Knowledge in Chinese Medical  Foundation Model: A Computational Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.84, \"y\": 8.212}, {\"title\": \"Chain-of-Thought Tuning: Masked Language Models can also Think Step By  Step in Natural Language Understanding\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.633, \"y\": 2.212}, {\"title\": \"Reflection-Tuning: Data Recycling Improves LLM Instruction-Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.093, \"y\": 2.244}, {\"title\": \"Enhancing Low-resource Fine-grained Named Entity Recognition by  Leveraging Coarse-grained Datasets\", \"topic\": \"Named Entity Recognition\", \"x\": 7.421, \"y\": 6.726}, {\"title\": \"MISAR: A Multimodal Instructional System with Augmented Reality\", \"topic\": \"Multimodal Language Models\", \"x\": 8.421, \"y\": 7.28}, {\"title\": \"Superiority of Softmax: Unveiling the Performance Edge Over Linear  Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.833, \"y\": 3.238}, {\"title\": \"Descriptive Knowledge Graph in Biomedical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.185, \"y\": 7.501}, {\"title\": \"Prototype-based HyperAdapter for Sample-Efficient Multi-task Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.966, \"y\": 2.372}, {\"title\": \"SOTOPIA: Interactive Evaluation for Social Intelligence in Language  Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.175, \"y\": 3.176}, {\"title\": \"Audio-AdapterFusion: A Task-ID-free Approach for Efficient and  Non-Destructive Multi-task Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.162, \"y\": 5.055}, {\"title\": \"BasahaCorpus: An Expanded Linguistic Resource for Readability Assessment  in Central Philippine Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.896, \"y\": 5.211}, {\"title\": \"Pragmatic Evaluation of Clarifying Questions with Fact-Level Masking\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.329, \"y\": 5.037}, {\"title\": \"Personalized Soups: Personalized Large Language Model Alignment via  Post-hoc Parameter Merging\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.232, \"y\": 1.345}, {\"title\": \"MUST&P-SRL: Multi-lingual and Unified Syllabification in Text and  Phonetic Domains for Speech Representation Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.486, \"y\": 5.387}, {\"title\": \"Multi-stage Large Language Model Correction for Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.975, \"y\": 5.251}, {\"title\": \"Group Preference Optimization: Few-Shot Alignment of Large Language  Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.305, \"y\": 1.318}, {\"title\": \"Automatic News Summerization\", \"topic\": \"Text Summarization\", \"x\": 5.481, \"y\": 6.316}, {\"title\": \"Self-RAG: Learning to Retrieve, Generate, and Critique through  Self-Reflection\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.951, \"y\": 4.512}, {\"title\": \"VeRA: Vector-based Random Matrix Adaptation\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.246, \"y\": 1.998}, {\"title\": \"Set-of-Mark Prompting Unleashes Extraordinary Visual Grounding in GPT-4V\", \"topic\": \"Multimodal Language Models\", \"x\": 8.49, \"y\": 7.639}, {\"title\": \"Neural Attention: Enhancing QKV Calculation in Self-Attention Mechanism  with Neural Networks\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.834, \"y\": 3.401}, {\"title\": \"Robust Wake-Up Word Detection by Two-stage Multi-resolution Ensembles\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.24, \"y\": 5.23}, {\"title\": \"DialogueLLM: Context and Emotion Knowledge-Tuned Large Language Models  for Emotion Recognition in Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.331, \"y\": 7.739}, {\"title\": \"VECHR: A Dataset for Explainable and Robust Classification of  Vulnerability Type in the European Court of Human Rights\", \"topic\": \"Legal NLP\", \"x\": 4.992, \"y\": 5.758}, {\"title\": \"Enhancing Neural Machine Translation with Semantic Units\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.879, \"y\": 4.621}, {\"title\": \"The effect of stemming and lemmatization on Portuguese fake news text  classification\", \"topic\": \"Fake News Detection\", \"x\": 3.936, \"y\": 5.839}, {\"title\": \"Quantifying Language Models' Sensitivity to Spurious Features in Prompt  Design or: How I learned to start worrying about prompt formatting\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.129, \"y\": 3.335}, {\"title\": \"Generative error correction for code-switching speech recognition using  large language models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.061, \"y\": 5.192}, {\"title\": \"QADYNAMICS: Training Dynamics-Driven Synthetic QA Diagnostic for  Zero-Shot Commonsense Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.528, \"y\": 5.098}, {\"title\": \"xMEN: A Modular Toolkit for Cross-Lingual Medical Entity Normalization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.271, \"y\": 7.779}, {\"title\": \"Emulating Human Cognitive Processes for Expert-Level Medical  Question-Answering with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.717, \"y\": 7.998}, {\"title\": \"CrossCodeEval: A Diverse and Multilingual Benchmark for Cross-File Code  Completion\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.631, \"y\": 2.623}, {\"title\": \"Can Large Language Models Explain Themselves? A Study of LLM-Generated  Self-Explanations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.915, \"y\": 3.674}, {\"title\": \"IMTLab: An Open-Source Platform for Building, Evaluating, and Diagnosing  Interactive Machine Translation Systems\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.87, \"y\": 4.899}, {\"title\": \"Long-form Simultaneous Speech Translation: Thesis Proposal\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.501, \"y\": 5.494}, {\"title\": \"Experimenting AI Technologies for Disinformation Combat: the IDMO  Project\", \"topic\": \"Fake News Detection\", \"x\": 4.021, \"y\": 5.746}, {\"title\": \"Document-Level In-Context Few-Shot Relation Extraction via Pre-Trained  Language Models\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.955, \"y\": 6.822}, {\"title\": \"Learning from Red Teaming: Gender Bias Provocation and Mitigation in  Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.369, \"y\": 4.082}, {\"title\": \"VoxArabica: A Robust Dialect-Aware Arabic Speech Recognition System\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.6, \"y\": 5.533}, {\"title\": \"Nonet at SemEval-2023 Task 6: Methodologies for Legal Evaluation\", \"topic\": \"Legal NLP\", \"x\": 5.081, \"y\": 5.764}, {\"title\": \"Iterative Shallow Fusion of Backward Language Model for End-to-End  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.147, \"y\": 5.164}, {\"title\": \"Correction Focused Language Model Training for Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.184, \"y\": 5.151}, {\"title\": \"TEQ: Trainable Equivalent Transformation for Quantization of LLMs\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.681, \"y\": 2.164}, {\"title\": \"MASON-NLP at eRisk 2023: Deep Learning-Based Detection of Depression  Symptoms from Social Media Texts\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.21, \"y\": 7.494}, {\"title\": \"Enhanced Transformer Architecture for Natural Language Processing\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.842, \"y\": 3.777}, {\"title\": \"Spatial HuBERT: Self-supervised Spatial Speech Representation Learning  for a Single Talker from Multi-channel Audio\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.813, \"y\": 4.93}, {\"title\": \"Compositional preference models for aligning LMs\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.248, \"y\": 1.355}, {\"title\": \"Emergent AI-Assisted Discourse: Case Study of a Second Language Writer  Authoring with ChatGPT\", \"topic\": \"Bias in Language Models\", \"x\": 4.901, \"y\": 4.602}, {\"title\": \"Will the Prince Get True Love's Kiss? On the Model Sensitivity to Gender  Perturbation over Fairytale Texts\", \"topic\": \"Bias in Language Models\", \"x\": 3.17, \"y\": 4.352}, {\"title\": \"CoTFormer: More Tokens With Attention Make Up For Less Depth\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.702, \"y\": 3.41}, {\"title\": \"Fake News in Sheep's Clothing: Robust Fake News Detection Against  LLM-Empowered Style Attacks\", \"topic\": \"Fake News Detection\", \"x\": 4.024, \"y\": 5.656}, {\"title\": \"SD-HuBERT: Sentence-Level Self-Distillation Induces Syllabic  Organization in HuBERT\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.679, \"y\": 4.913}, {\"title\": \"Self-Supervised Models of Speech Infer Universal Articulatory Kinematics\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.683, \"y\": 4.986}, {\"title\": \"BanglaNLP at BLP-2023 Task 1: Benchmarking different Transformer Models  for Violence Inciting Text Detection in Bengali\", \"topic\": \"Hate Speech Detection\", \"x\": 2.962, \"y\": 5.688}, {\"title\": \"BiomedJourney: Counterfactual Biomedical Image Generation by  Instruction-Learning from Multimodal Patient Journeys\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.534, \"y\": 8.355}, {\"title\": \"Towards reducing hallucination in extracting information from financial  reports using Large Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.85, \"y\": 6.832}, {\"title\": \"Building Persona Consistent Dialogue Agents with Offline Reinforcement  Learning\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.276, \"y\": 3.437}, {\"title\": \"Bridging the Novice-Expert Gap via Models of Decision-Making: A Case  Study on Remediating Math Mistakes\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.789, \"y\": 2.873}, {\"title\": \"OpenAgents: An Open Platform for Language Agents in the Wild\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.624, \"y\": 2.865}, {\"title\": \"Factored Verification: Detecting and Reducing Hallucination in Summaries  of Academic Papers\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.149, \"y\": 1.158}, {\"title\": \"VidCoM: Fast Video Comprehension through Large Language Models with  Multimodal Tools\", \"topic\": \"Multimodal Language Models\", \"x\": 8.781, \"y\": 7.922}, {\"title\": \"Emerging Challenges in Personalized Medicine: Assessing Demographic  Effects on Biomedical Question Answering Systems\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.591, \"y\": 7.588}, {\"title\": \"Demonstrations Are All You Need: Advancing Offensive Content  Paraphrasing using In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.2, \"y\": 3.469}, {\"title\": \"ViPE: Visualise Pretty-much Everything\", \"topic\": \"Multimodal Language Models\", \"x\": 8.759, \"y\": 7.4}, {\"title\": \"One For All & All For One: Bypassing Hyperparameter Tuning with Model  Averaging For Cross-Lingual Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.412, \"y\": 4.739}, {\"title\": \"Semantic Parsing by Large Language Models for Intricate Updating  Strategies of Zero-Shot Dialogue State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.755, \"y\": 3.945}, {\"title\": \"Metric Ensembles For Hallucination Detection\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.117, \"y\": 1.153}, {\"title\": \"Text Summarization Using Large Language Models: A Comparative Study of  MPT-7b-instruct, Falcon-7b-instruct, and OpenAI Chat-GPT Models\", \"topic\": \"Text Summarization\", \"x\": 5.633, \"y\": 6.084}, {\"title\": \"Exploiting User Comments for Early Detection of Fake News Prior to  Users' Commenting\", \"topic\": \"Fake News Detection\", \"x\": 3.988, \"y\": 5.836}, {\"title\": \"Towards a Better Understanding of Variations in Zero-Shot Neural Machine  Translation Performance\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.786, \"y\": 4.502}, {\"title\": \"Contextual Data Augmentation for Task-Oriented Dialog Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.566, \"y\": 3.9}, {\"title\": \"Optimized Tokenization for Transcribed Error Correction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.042, \"y\": 5.624}, {\"title\": \"Investigating Bias in Multilingual Language Models: Cross-Lingual  Transfer of Debiasing Techniques\", \"topic\": \"Bias in Language Models\", \"x\": 3.283, \"y\": 4.513}, {\"title\": \"Multi-Stage Pre-training Enhanced by ChatGPT for Multi-Scenario  Multi-Domain Dialogue Summarization\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.583, \"y\": 4.205}, {\"title\": \"Generative Calibration for In-context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.247, \"y\": 3.339}, {\"title\": \"Prediction of Arabic Legal Rulings using Large Language Models\", \"topic\": \"Legal NLP\", \"x\": 5.15, \"y\": 5.601}, {\"title\": \"AdaLomo: Low-memory Optimization with Adaptive Learning Rate\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.169, \"y\": 2.264}, {\"title\": \"TRIGO: Benchmarking Formal Mathematical Proof Reduction for Generative  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.121, \"y\": 2.889}, {\"title\": \"Theory of Mind for Multi-Agent Collaboration via Large Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.546, \"y\": 2.77}, {\"title\": \"Learning to Rank Context for Named Entity Recognition Using a Synthetic  Dataset\", \"topic\": \"Named Entity Recognition\", \"x\": 7.439, \"y\": 6.805}, {\"title\": \"End-to-end Multichannel Speaker-Attributed ASR: Speaker Guided Decoder  and Input Feature Analysis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.077, \"y\": 5.198}, {\"title\": \"Navigation with Large Language Models: Semantic Guesswork as a Heuristic  for Planning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 6.002, \"y\": 2.625}, {\"title\": \"Decomposed Prompt Tuning via Low-Rank Reparameterization\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.781, \"y\": 3.208}, {\"title\": \"JMedLoRA:Medical Domain Adaptation on Japanese Large Language Models  using Instruction-tuning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.047, \"y\": 7.897}, {\"title\": \"Prompt Packer: Deceiving LLMs through Compositional Instruction with  Hidden Attacks\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.358, \"y\": 2.598}, {\"title\": \"Verbosity Bias in Preference Labeling by Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.045, \"y\": 1.688}, {\"title\": \"Bridging Code Semantic and LLMs: Semantic Chain-of-Thought Prompting for  Code Generation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.837, \"y\": 2.412}, {\"title\": \"Farzi Data: Autoregressive Data Distillation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.503, \"y\": 3.868}, {\"title\": \"UvA-MT's Participation in the WMT23 General Translation Shared Task\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.957, \"y\": 4.703}, {\"title\": \"Prompting Scientific Names for Zero-Shot Species Recognition\", \"topic\": \"Multimodal Language Models\", \"x\": 8.684, \"y\": 6.991}, {\"title\": \"Empirical study of pretrained multilingual language models for zero-shot  cross-lingual knowledge transfer in generation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.532, \"y\": 4.644}, {\"title\": \"Can GPT-4V(ision) Serve Medical Applications? Case Studies on GPT-4V for  Multimodal Medical Diagnosis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.241, \"y\": 8.295}, {\"title\": \"In-Context Learning with Iterative Demonstration Selection\", \"topic\": \"In-Context Learning\", \"x\": 8.273, \"y\": 3.319}, {\"title\": \"Bounding and Filling: A Fast and Flexible Framework for Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.113, \"y\": 7.38}, {\"title\": \"Enhancing Stance Classification with Quantified Moral Foundations\", \"topic\": \"Fake News Detection\", \"x\": 3.495, \"y\": 5.795}, {\"title\": \"RSVP: Customer Intent Detection via Agent Response Contrastive and  Generative Pre-Training\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.348, \"y\": 3.878}, {\"title\": \"VLIS: Unimodal Language Models Guide Multimodal Language Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.429, \"y\": 7.377}, {\"title\": \"Improving Access to Justice for the Indian Population: A Benchmark for  Evaluating Translation of Legal Text to Indian Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.574, \"y\": 5.265}, {\"title\": \"Large Language Model-Aware In-Context Learning for Code Generation\", \"topic\": \"In-Context Learning\", \"x\": 8.054, \"y\": 3.109}, {\"title\": \"Domain-Specific Language Model Post-Training for Indonesian Financial  NLP\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.954, \"y\": 6.93}, {\"title\": \"Improved Contextual Recognition In Automatic Speech Recognition Systems  By Semantic Lattice Rescoring\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.185, \"y\": 5.059}, {\"title\": \"Lexical Entrainment for Conversational Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 10.329, \"y\": 5.536}, {\"title\": \"An Expression Tree Decoding Strategy for Mathematical Equation  Generation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.393, \"y\": 3.012}, {\"title\": \"Moral consensus and divergence in partisan language use\", \"topic\": \"Fake News Detection\", \"x\": 3.567, \"y\": 5.493}, {\"title\": \"Solving Math Word Problems with Reexamination\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.056, \"y\": 2.7}, {\"title\": \"Leveraging Generative AI: Improving Software Metadata Classification  with Generated Code-Comment Pairs\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.521, \"y\": 2.449}, {\"title\": \"A study of the impact of generative AI-based data augmentation on  software metadata classification\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.62, \"y\": 2.641}, {\"title\": \"Chatbot-supported Thesis Writing: An Autoethnographic Report\", \"topic\": \"Bias in Language Models\", \"x\": 5.023, \"y\": 4.64}, {\"title\": \"Instruction Tuning with Human Curriculum\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.118, \"y\": 2.299}, {\"title\": \"One-Shot Sensitivity-Aware Mixed Sparsity Pruning for Large Language  Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.562, \"y\": 2.293}, {\"title\": \"Enhancing BERT-Based Visual Question Answering through Keyword-Driven  Sentence Selection\", \"topic\": \"Multimodal Language Models\", \"x\": 8.093, \"y\": 7.975}, {\"title\": \"Assessing and Enhancing the Robustness of Large Language Models with  Task Structure Variations for Logical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.635, \"y\": 3.084}, {\"title\": \"SALM: Speech-augmented Language Model with In-context Learning for  Speech Recognition and Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.495, \"y\": 5.417}, {\"title\": \"Surveying the Landscape of Text Summarization with Deep Learning: A  Comprehensive Review\", \"topic\": \"Text Summarization\", \"x\": 5.814, \"y\": 6.23}, {\"title\": \"Dialogue Chain-of-Thought Distillation for Commonsense-aware  Conversational Agents\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.69, \"y\": 2.291}, {\"title\": \"Ranking LLM-Generated Loop Invariants for Program Verification\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.277, \"y\": 2.413}, {\"title\": \"PromptRE: Weakly-Supervised Document-Level Relation Extraction via  Prompting-Based Data Programming\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.881, \"y\": 6.892}, {\"title\": \"Hypernymy Understanding Evaluation of Text-to-Image Models via WordNet  Hierarchy\", \"topic\": \"Multimodal Language Models\", \"x\": 8.845, \"y\": 6.629}, {\"title\": \"Precedent-Enhanced Legal Judgment Prediction with LLM and Domain-Model  Collaboration\", \"topic\": \"Legal NLP\", \"x\": 5.087, \"y\": 5.722}, {\"title\": \"BanglaNLP at BLP-2023 Task 2: Benchmarking different Transformer Models  for Sentiment Analysis of Bangla Social Media Posts\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.377, \"y\": 6.456}, {\"title\": \"\\\"Kelly is a Warm Person, Joseph is a Role Model\\\": Gender Biases in  LLM-Generated Reference Letters\", \"topic\": \"Bias in Language Models\", \"x\": 3.347, \"y\": 4.394}, {\"title\": \"Explore-Instruct: Enhancing Domain-Specific Instruction Coverage through  Active Exploration\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.159, \"y\": 2.297}, {\"title\": \"PuoBERTa: Training and evaluation of a curated language model for  Setswana\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.005, \"y\": 5.153}, {\"title\": \"The Consensus Game: Language Model Generation via Equilibrium Search\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.561, \"y\": 2.835}, {\"title\": \"GLoRE: Evaluating Logical Reasoning of Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.665, \"y\": 3.085}, {\"title\": \"Qilin-Med: Multi-stage Knowledge Injection Advanced Medical Large  Language Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.959, \"y\": 8.04}, {\"title\": \"KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level  Hallucination Detection\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.289, \"y\": 1.171}, {\"title\": \"MM-BigBench: Evaluating Multimodal Models on Multimodal Content  Comprehension Tasks\", \"topic\": \"Multimodal Language Models\", \"x\": 8.001, \"y\": 7.502}, {\"title\": \"Dont Add, dont Miss: Effective Content Preserving Generation from  Pre-Selected Text Spans\", \"topic\": \"Text Summarization\", \"x\": 5.749, \"y\": 6.18}, {\"title\": \"CodeChain: Towards Modular Code Generation Through Chain of  Self-revisions with Representative Sub-modules\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.26, \"y\": 2.298}, {\"title\": \"ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question  Answering with Fine-tuned Large Language Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.722, \"y\": 5.418}, {\"title\": \"Towards Example-Based NMT with Multi-Levenshtein Transformers\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.792, \"y\": 4.326}, {\"title\": \"EasyGen: Easing Multimodal Generation with BiDiffuser and LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.339, \"y\": 7.214}, {\"title\": \"Relation-aware Ensemble Learning for Knowledge Graph Embedding\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.121, \"y\": 6.087}, {\"title\": \"SeqXGPT: Sentence-Level AI-Generated Text Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.168, \"y\": 4.761}, {\"title\": \"Welfare Diplomacy: Benchmarking Language Model Cooperation\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.202, \"y\": 2.919}, {\"title\": \"InstructTODS: Large Language Models for End-to-End Task-Oriented  Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.562, \"y\": 3.673}, {\"title\": \"Retrieval-Generation Alignment for End-to-End Task-Oriented Dialogue  System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.661, \"y\": 4.0}, {\"title\": \"Large Language Models as Source Planner for Personalized  Knowledge-grounded Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.494, \"y\": 3.909}, {\"title\": \"A Comparative Analysis of Task-Agnostic Distillation Methods for  Compressing Transformer Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.487, \"y\": 3.801}, {\"title\": \"\\\"Im not Racist but...\\\": Discovering Bias in the Internal Knowledge of  Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.393, \"y\": 4.345}, {\"title\": \"A Zero-Shot Language Agent for Computer Control with Structured  Reflection\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.964, \"y\": 2.356}, {\"title\": \"Toward Joint Language Modeling for Speech Units and Text\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.335, \"y\": 5.19}, {\"title\": \"Can GPT models be Financial Analysts? An Evaluation of ChatGPT and GPT-4  on mock CFA Exams\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.843, \"y\": 6.837}, {\"title\": \"LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.582, \"y\": 2.137}, {\"title\": \"Visual Data-Type Understanding does not emerge from Scaling  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.628, \"y\": 7.446}, {\"title\": \"Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of  Language Models with Hypothesis Refinement\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.589, \"y\": 2.984}, {\"title\": \"Formally Specifying the High-Level Behavior of LLM-Based Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.774, \"y\": 2.561}, {\"title\": \"LLM-augmented Preference Learning from Natural Language\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.373, \"y\": 1.642}, {\"title\": \"Prometheus: Inducing Fine-grained Evaluation Capability in Language  Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.272, \"y\": 3.834}, {\"title\": \"GraphextQA: A Benchmark for Evaluating Graph-Enhanced Large Language  Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.938, \"y\": 5.599}, {\"title\": \"MCU: A Task-centric Framework for Open-ended Agent Evaluation in  Minecraft\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.619, \"y\": 2.831}, {\"title\": \"From Large Language Models to Knowledge Graphs for Biomarker Discovery  in Cancer\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.003, \"y\": 7.63}, {\"title\": \"Not All Demonstration Examples are Equally Beneficial: Reweighting  Demonstration Examples for In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.284, \"y\": 3.435}, {\"title\": \"MProto: Multi-Prototype Network with Denoised Optimal Transport for  Distantly Supervised Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.359, \"y\": 6.794}, {\"title\": \"Enhancing Text-based Knowledge Graph Completion with Zero-Shot Large  Language Models: A Focus on Semantic Enhancement\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.995, \"y\": 5.76}, {\"title\": \"Who Said That? Benchmarking Social Media AI Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.15, \"y\": 4.881}, {\"title\": \"Fast Word Error Rate Estimation Using Self-Supervised Representations  For Speech And Text\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.251, \"y\": 5.185}, {\"title\": \"Visual Question Generation in Bengali\", \"topic\": \"Multimodal Language Models\", \"x\": 8.13, \"y\": 8.086}, {\"title\": \"Ziya-Visual: Bilingual Large Vision-Language Model via Multi-Task  Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.421, \"y\": 7.523}, {\"title\": \"On the Relevance of Phoneme Duration Variability of Synthesized Training  Data for Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.946, \"y\": 5.34}, {\"title\": \"Fine-grained Conversational Decoding via Isotropic and Proximal Search\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.543, \"y\": 4.026}, {\"title\": \"Voice Conversion for Stuttered Speech, Instruments, Unseen Languages and  Textually Described Voices\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.715, \"y\": 5.625}, {\"title\": \"QASiNa: Religious Domain Question Answering using Sirah Nabawiyah\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.456, \"y\": 5.295}, {\"title\": \"Promptor: A Conversational and Autonomous Prompt Generation Agent for  Intelligent Text Entry Techniques\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.315, \"y\": 3.407}, {\"title\": \"To token or not to token: A Comparative Study of Text Representations  for Cross-Lingual Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.29, \"y\": 4.918}, {\"title\": \"Training Generative Question-Answering on Synthetic Data Obtained from  an Instruct-tuned Model\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.407, \"y\": 5.008}, {\"title\": \"QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large  Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.737, \"y\": 2.145}, {\"title\": \"A New Approach Towards Autoformalization\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.206, \"y\": 2.87}, {\"title\": \"Pit One Against Many: Leveraging Attention-head Embeddings for  Parameter-efficient Multi-head Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.846, \"y\": 3.151}, {\"title\": \"Framework for Question-Answering in Sanskrit through Automated  Construction of Knowledge Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.763, \"y\": 5.62}, {\"title\": \"InstructRetro: Instruction Tuning post Retrieval-Augmented Pretraining\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.316, \"y\": 2.504}, {\"title\": \"MatFormer: Nested Transformer for Elastic Inference\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.806, \"y\": 3.214}, {\"title\": \"Ferret: Refer and Ground Anything Anywhere at Any Granularity\", \"topic\": \"Multimodal Language Models\", \"x\": 8.533, \"y\": 7.29}, {\"title\": \"Well Begun is Half Done: Generator-agnostic Knowledge Pre-Selection for  Knowledge-Grounded Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.719, \"y\": 4.077}, {\"title\": \"The Past, Present and Better Future of Feedback Learning in Large  Language Models for Subjective Human Preferences and Values\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.111, \"y\": 1.694}, {\"title\": \"KwaiYiiMath: Technical Report\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.176, \"y\": 2.865}, {\"title\": \"Adapting the adapters for code-switching in multilingual ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.866, \"y\": 5.243}, {\"title\": \"DASpeech: Directed Acyclic Transformer for Fast and High-quality  Speech-to-Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.563, \"y\": 5.398}, {\"title\": \"Target-oriented Proactive Dialogue Systems with Personalization: Problem  Formulation and Dataset Curation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.312, \"y\": 3.816}, {\"title\": \"How Do Large Language Models Capture the Ever-changing World Knowledge?  A Review of Recent Advances\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.592, \"y\": 4.121}, {\"title\": \"An Empirical Study of Instruction-tuning Large Language Models in  Chinese\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.188, \"y\": 2.416}, {\"title\": \"Typing to Listen at the Cocktail Party: Text-Guided Target Speaker  Extraction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.76, \"y\": 5.547}, {\"title\": \"An Analysis on Large Language Models in Healthcare: A Case Study of  BioBERT\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.625, \"y\": 7.816}, {\"title\": \"Enhancing expressivity transfer in textless speech-to-speech translation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.218, \"y\": 7.832}, {\"title\": \"Exploring the landscape of large language models in medical question  answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.731, \"y\": 7.819}, {\"title\": \"Psychoacoustic Challenges Of Speech Enhancement On VoIP Platforms\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.877, \"y\": 5.55}, {\"title\": \"\\\"A Tale of Two Movements\\\": Identifying and Comparing Perspectives in  #BlackLivesMatter and #BlueLivesMatter Movements-related Tweets using Weakly  Supervised Graph-based Structured Prediction\", \"topic\": \"Fake News Detection\", \"x\": 3.635, \"y\": 5.837}, {\"title\": \"QFT: Quantized Full-parameter Tuning of LLMs with Affordable Resources\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.589, \"y\": 2.151}, {\"title\": \"Argumentative Stance Prediction: An Exploratory Study on Multimodality  and Few-Shot Learning\", \"topic\": \"Fake News Detection\", \"x\": 3.494, \"y\": 5.881}, {\"title\": \"Jaeger: A Concatenation-Based Multi-Transformer VQA Model\", \"topic\": \"Multimodal Language Models\", \"x\": 7.992, \"y\": 7.984}, {\"title\": \"Crossing the Threshold: Idiomatic Machine Translation through Retrieval  Augmentation and Loss Weighting\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.552, \"y\": 4.788}, {\"title\": \"Don't Fine-Tune, Decode: Syntax Error-Free Tool Use via Constrained  Decoding\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.104, \"y\": 2.46}, {\"title\": \"Large Language Models can Learn Rules\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.74, \"y\": 2.849}, {\"title\": \"DKEC: Domain Knowledge Enhanced Multi-Label Classification for Diagnosis  Prediction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.958, \"y\": 8.157}, {\"title\": \"LLMs as Potential Brainstorming Partners for Math and Science Problems\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.468, \"y\": 3.076}, {\"title\": \"Answer Candidate Type Selection: Text-to-Text Language Model for Closed  Book Question Answering Meets Knowledge Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.752, \"y\": 5.465}, {\"title\": \"Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.361, \"y\": 2.354}, {\"title\": \"Document-Level Supervision for Multi-Aspect Sentiment Analysis Without  Fine-grained Labels\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.121, \"y\": 6.801}, {\"title\": \"Teaching Language Models to Hallucinate Less with Synthetic Tasks\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.247, \"y\": 1.138}, {\"title\": \"Uni3D: Exploring Unified 3D Representation at Scale\", \"topic\": \"Multimodal Language Models\", \"x\": 8.852, \"y\": 7.088}, {\"title\": \"SWE-bench: Can Language Models Resolve Real-World GitHub Issues?\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.256, \"y\": 2.528}, {\"title\": \"OmniLingo: Listening- and speaking-based language learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.5, \"y\": 5.48}, {\"title\": \"Quality-Aware Translation Models: Efficient Generation and Quality  Estimation in a Single Model\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.022, \"y\": 4.315}, {\"title\": \"Sheared LLaMA: Accelerating Language Model Pre-training via Structured  Pruning\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.441, \"y\": 2.43}, {\"title\": \"Generalizable Chain-of-Thought Prompting in Mixed-task Scenarios with  Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.618, \"y\": 2.364}, {\"title\": \"Making Large Language Models Perform Better in Knowledge Graph  Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.986, \"y\": 5.743}, {\"title\": \"What If the TV Was Off? Examining Counterfactual Reasoning Abilities of  Multi-modal Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.22, \"y\": 7.953}, {\"title\": \"No Pitch Left Behind: Addressing Gender Unbalance in Automatic Speech  Recognition through Pitch Manipulation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.188, \"y\": 5.385}, {\"title\": \"FTFT: Efficient and Robust Fine-Tuning by Transferring Training Dynamics\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.942, \"y\": 2.4}, {\"title\": \"Automated clinical coding using off-the-shelf large language models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.887, \"y\": 8.307}, {\"title\": \"Rationale-Enhanced Language Models are Better Continual Relation  Learners\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.032, \"y\": 6.687}, {\"title\": \"AutoCycle-VC: Towards Bottleneck-Independent Zero-Shot Cross-Lingual  Voice Conversion\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.622, \"y\": 5.738}, {\"title\": \"EmoTwiCS: A Corpus for Modelling Emotion Trajectories in Dutch Customer  Service Dialogues on Twitter\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.557, \"y\": 7.43}, {\"title\": \"The Limits of ChatGPT in Extracting Aspect-Category-Opinion-Sentiment  Quadruples: A Comparative Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.212, \"y\": 6.803}, {\"title\": \"A New Benchmark and Reverse Validation Method for Passage-level  Hallucination Detection\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.213, \"y\": 1.148}, {\"title\": \"SpikeCLIP: A Contrastive Language-Image Pretrained Spiking Neural  Network\", \"topic\": \"Multimodal Language Models\", \"x\": 9.001, \"y\": 7.02}, {\"title\": \"Multilingual Jailbreak Challenges in Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.408, \"y\": 2.419}, {\"title\": \"Understanding the Effects of RLHF on LLM Generalisation and Diversity\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.173, \"y\": 1.618}, {\"title\": \"Constructive Large Language Models Alignment with Diverse Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.251, \"y\": 1.669}, {\"title\": \"Whispering LLaMA: A Cross-Modal Generative Error Correction Framework  for Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.079, \"y\": 5.399}, {\"title\": \"Hexa: Self-Improving for Knowledge-Grounded Dialogue System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.654, \"y\": 4.039}, {\"title\": \"P5: Plug-and-Play Persona Prompting for Personalized Response Selection\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.361, \"y\": 3.889}, {\"title\": \"Jailbreak and Guard Aligned Language Models with Only Few In-Context  Demonstrations\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.408, \"y\": 2.336}, {\"title\": \"Selective Demonstrations for Cross-domain Text-to-SQL\", \"topic\": \"In-Context Learning\", \"x\": 8.17, \"y\": 3.455}, {\"title\": \"Towards Mitigating Hallucination in Large Language Models via  Self-Reflection\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.201, \"y\": 1.172}, {\"title\": \"We are what we repeatedly do: Inducing and deploying habitual schemas in  persona-based responses\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.257, \"y\": 3.778}, {\"title\": \"Model Tuning or Prompt Tuning? A Study of Large Language Models for  Clinical Concept and Relation Extraction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.863, \"y\": 7.929}, {\"title\": \"Tackling Data Bias in MUSIC-AVQA: Crafting a Balanced Dataset for  Unbiased Question-Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.16, \"y\": 8.005}, {\"title\": \"GPT-who: An Information Density-based Machine-Generated Text Detector\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.1, \"y\": 4.737}, {\"title\": \"Take a Step Back: Evoking Reasoning via Abstraction in Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.78, \"y\": 2.635}, {\"title\": \"Leveraging Multilingual Self-Supervised Pretrained Models for  Sequence-to-Sequence End-to-End Spoken Language Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.554, \"y\": 5.08}, {\"title\": \"Auditing Gender Analyzers on Text Data\", \"topic\": \"Bias in Language Models\", \"x\": 3.256, \"y\": 4.431}, {\"title\": \"Few-Shot Spoken Language Understanding via Joint Speech-Text Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.409, \"y\": 5.151}, {\"title\": \"SALMON: Self-Alignment with Instructable Reward Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.367, \"y\": 1.453}, {\"title\": \"A Meta-Learning Perspective on Transformers for Causal Language Modeling\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.388, \"y\": 3.484}, {\"title\": \"Controllable Chest X-Ray Report Generation from Longitudinal  Representations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.249, \"y\": 8.622}, {\"title\": \"ViCor: Bridging Visual Understanding and Commonsense Reasoning with  Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.399, \"y\": 7.705}, {\"title\": \"Rephrase, Augment, Reason: Visual Grounding of Questions for  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.33, \"y\": 7.869}, {\"title\": \"Terminology-Aware Translation with Constrained Decoding and Large  Language Model Prompting\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.851, \"y\": 4.316}, {\"title\": \"Are Large Language Models Post Hoc Explainers?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.005, \"y\": 3.654}, {\"title\": \"Aligning Language Models with Human Preferences via a Bayesian Approach\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.327, \"y\": 1.428}, {\"title\": \"Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and  Execution of LLM Agents in an Auction Arena\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.508, \"y\": 3.018}, {\"title\": \"The Program Testing Ability of Large Language Models for Code\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.306, \"y\": 2.48}, {\"title\": \"Guiding Language Model Math Reasoning with Planning Tokens\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.706, \"y\": 2.639}, {\"title\": \"Towards Emotion-Based Synthetic Consciousness: Using LLMs to Estimate  Emotion Probability Vectors\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.514, \"y\": 7.555}, {\"title\": \"A Survey of Large Language Models for Healthcare: from Data, Technology,  and Applications to Accountability and Ethics\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.526, \"y\": 7.885}, {\"title\": \"Larth: Dataset and Machine Translation for Etruscan\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.266, \"y\": 5.09}, {\"title\": \"RAUCG: Retrieval-Augmented Unsupervised Counter Narrative Generation for  Hate Speech\", \"topic\": \"Hate Speech Detection\", \"x\": 2.704, \"y\": 5.259}, {\"title\": \"Integrating Stock Features and Global Information via Large Language  Models for Enhanced Stock Return Prediction\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.788, \"y\": 6.832}, {\"title\": \"LAiW: A Chinese Legal Large Language Models Benchmark\", \"topic\": \"Legal NLP\", \"x\": 5.224, \"y\": 5.416}, {\"title\": \"InterroLang: Exploring NLP Models and Datasets through Dialogue-based  Explanations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.713, \"y\": 3.897}, {\"title\": \"Findings of the 2023 ML-SUPERB Challenge: Pre-Training and Evaluation  over More Languages and Beyond\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.626, \"y\": 5.017}, {\"title\": \"Query and Response Augmentation Cannot Help Out-of-domain Math Reasoning  Generalization\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.135, \"y\": 2.749}, {\"title\": \"How Abilities in Large Language Models are Affected by Supervised  Fine-tuning Data Composition\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.253, \"y\": 2.537}, {\"title\": \"Empower Nested Boolean Logic via Self-Supervised Curriculum Learning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.869, \"y\": 2.821}, {\"title\": \"Automating Customer Service using LangChain: Building custom open-source  GPT Chatbot for organizations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.177, \"y\": 3.787}, {\"title\": \"Exploring the Maze of Multilingual Modeling\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.965, \"y\": 4.53}, {\"title\": \"Improving End-to-End Speech Processing by Efficient Text Data  Utilization with Latent Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.813, \"y\": 5.351}, {\"title\": \"A Glance is Enough: Extract Target Sentence By Looking at A keyword\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.005, \"y\": 5.187}, {\"title\": \"SteerLM: Attribute Conditioned SFT as an (User-Steerable) Alternative to  RLHF\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.227, \"y\": 1.478}, {\"title\": \"Negative Object Presence Evaluation (NOPE) to Measure Object  Hallucination in Vision-Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.243, \"y\": 1.038}, {\"title\": \"Hi Guys or Hi Folks? Benchmarking Gender-Neutral Machine Translation  with the GeNTE Corpus\", \"topic\": \"Bias in Language Models\", \"x\": 2.981, \"y\": 4.412}, {\"title\": \"Enhancing Pre-Trained Language Models with Sentence Position Embeddings  for Rhetorical Roles Recognition in Legal Opinions\", \"topic\": \"Legal NLP\", \"x\": 5.046, \"y\": 5.774}, {\"title\": \"ChatRadio-Valuer: A Chat Large Language Model for Generalizable  Radiology Report Generation Based on Multi-institution and Multi-system Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.096, \"y\": 8.58}, {\"title\": \"XLS-R fine-tuning on noisy word boundaries for unsupervised speech  segmentation into words\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.888, \"y\": 5.134}, {\"title\": \"Generative Spoken Language Model based on continuous word-sized audio  tokens\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.441, \"y\": 5.314}, {\"title\": \"A Comparative Study of Voice Conversion Models with Large-Scale Speech  and Singing Data: The T13 Systems for the Singing Voice Conversion Challenge  2023\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.764, \"y\": 5.729}, {\"title\": \"Loose lips sink ships: Mitigating Length Bias in Reinforcement Learning  from Human Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.154, \"y\": 1.515}, {\"title\": \"Text2NKG: Fine-Grained N-ary Relation Extraction for N-ary relational  Knowledge Graph Construction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.021, \"y\": 6.669}, {\"title\": \"Optimizing Large Language Models to Expedite the Development of Smart  Contracts\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.309, \"y\": 2.623}, {\"title\": \"On the Zero-Shot Generalization of Machine-Generated Text Detectors\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.084, \"y\": 4.74}, {\"title\": \"Harnessing the Power of Large Language Models for Empathetic Response  Generation: Empirical Investigations and Improvements\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.775, \"y\": 7.901}, {\"title\": \"Are Emily and Greg Still More Employable than Lakisha and Jamal?  Investigating Algorithmic Hiring Bias in the Era of ChatGPT\", \"topic\": \"Bias in Language Models\", \"x\": 3.48, \"y\": 4.387}, {\"title\": \"Fast-DetectGPT: Efficient Zero-Shot Detection of Machine-Generated Text  via Conditional Probability Curvature\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.076, \"y\": 4.756}, {\"title\": \"Zero-Shot Detection of Machine-Generated Codes\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.088, \"y\": 4.732}, {\"title\": \"How Reliable Are AI-Generated-Text Detectors? An Assessment Framework  Using Evasive Soft Prompts\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.154, \"y\": 4.513}, {\"title\": \"\\\"A Nova Eletricidade: Aplica\\u00e7\\u00f5es, Riscos e Tend\\u00eancias da IA  Moderna -- \\\"The New Electricity\\\": Applications, Risks, and Trends in Current  AI\", \"topic\": \"Bias in Language Models\", \"x\": 4.685, \"y\": 4.307}, {\"title\": \"DialCoT Meets PPO: Decomposing and Exploring Reasoning Paths in Smaller  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.605, \"y\": 2.313}, {\"title\": \"Unleashing the Multilingual Encoder Potential: Boosting Zero-Shot  Performance via Probability Calibration\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.414, \"y\": 4.696}, {\"title\": \"Guideline Learning for In-context Information Extraction\", \"topic\": \"In-Context Learning\", \"x\": 8.288, \"y\": 3.34}, {\"title\": \"FakeGPT: Fake News Generation, Explanation and Detection of Large  Language Models\", \"topic\": \"Fake News Detection\", \"x\": 4.142, \"y\": 5.689}, {\"title\": \"AvalonBench: Evaluating LLMs Playing the Game of Avalon\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.401, \"y\": 2.993}, {\"title\": \"Counter Turing Test CT^2: AI-Generated Text Detection is Not as Easy as  You May Think -- Introducing AI Detectability Index\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.219, \"y\": 4.666}, {\"title\": \"Synslator: An Interactive Machine Translation Tool with Online Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.916, \"y\": 4.92}, {\"title\": \"Comparative Analysis of Transfer Learning in Deep Learning  Text-to-Speech Models on a Few-Shot, Low-Resource, Customized Dataset\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.715, \"y\": 5.434}, {\"title\": \"MULTISCRIPT: Multimodal Script Learning for Supporting Open Domain  Everyday Tasks\", \"topic\": \"Multimodal Language Models\", \"x\": 8.483, \"y\": 7.492}, {\"title\": \"Towards Better Chain-of-Thought Prompting Strategies: A Survey\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.63, \"y\": 2.356}, {\"title\": \"Crystal: Introspective Reasoners Reinforced with Self-Feedback\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.774, \"y\": 2.322}, {\"title\": \"Analyzing Zero-Shot Abilities of Vision-Language Models on Video  Understanding Tasks\", \"topic\": \"Multimodal Language Models\", \"x\": 8.774, \"y\": 7.751}, {\"title\": \"ILuvUI: Instruction-tuned LangUage-Vision modeling of UIs from Machine  Conversations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.534, \"y\": 7.485}, {\"title\": \"ForeSeer: Product Aspect Forecasting Using Temporal Graph Embedding\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.5, \"y\": 6.724}, {\"title\": \"End-to-End Lip Reading in Romanian with Cross-Lingual Domain Adaptation  and Lateral Inhibition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.732, \"y\": 5.476}, {\"title\": \"FinGPT: Instruction Tuning Benchmark for Open-Source Large Language  Models in Financial Datasets\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.877, \"y\": 6.844}, {\"title\": \"Resprompt: Residual Connection Prompting Advances Multi-Step Reasoning  in Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.683, \"y\": 2.511}, {\"title\": \"Zero-shot Cross-lingual Transfer without Parallel Corpus\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.457, \"y\": 4.852}, {\"title\": \"Integrating Contrastive Learning into a Multitask Transformer Model for  Effective Domain Adaptation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.222, \"y\": 7.791}, {\"title\": \"Data-Centric Financial Large Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.885, \"y\": 6.834}, {\"title\": \"Automatic Anonymization of Swiss Federal Supreme Court Rulings\", \"topic\": \"Legal NLP\", \"x\": 5.016, \"y\": 5.787}, {\"title\": \"Segmented Harmonic Loss: Handling Class-Imbalanced Multi-Label Clinical  Data for Medical Coding with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.772, \"y\": 8.037}, {\"title\": \"From Nuisance to News Sense: Augmenting the News with Cross-Document  Evidence and Context\", \"topic\": \"Fake News Detection\", \"x\": 4.18, \"y\": 5.938}, {\"title\": \"Can pruning make Large Language Models more efficient?\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.566, \"y\": 2.514}, {\"title\": \"Towards Foundation Models for Knowledge Graph Reasoning\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.114, \"y\": 6.037}, {\"title\": \"Measuring Information in Text Explanations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.844, \"y\": 3.874}, {\"title\": \"Module-wise Adaptive Distillation for Multimodality Foundation Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.438, \"y\": 7.04}, {\"title\": \"Improving Stability in Simultaneous Speech Translation: A  Revision-Controllable Decoding Approach\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.362, \"y\": 5.046}, {\"title\": \"KoMultiText: Large-Scale Korean Text Dataset for Classifying Biased  Speech in Real-World Online Services\", \"topic\": \"Hate Speech Detection\", \"x\": 2.777, \"y\": 5.383}, {\"title\": \"A Comprehensive Evaluation of Large Language Models on Benchmark  Biomedical Text Processing Tasks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.101, \"y\": 7.633}, {\"title\": \"Ada-Instruct: Adapting Instruction Generators for Complex Reasoning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 7.969, \"y\": 2.396}, {\"title\": \"Reward Dropout Improves Control: Bi-objective Perspective on Reinforced  LM\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.213, \"y\": 1.463}, {\"title\": \"Conversational Financial Information Retrieval Model (ConFIRM)\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.928, \"y\": 6.855}, {\"title\": \"Document-Level Relation Extraction with Relation Correlation Enhancement\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.932, \"y\": 6.807}, {\"title\": \"Acoustic and linguistic representations for speech continuous emotion  recognition in call center conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.211, \"y\": 7.877}, {\"title\": \"How to Capture Higher-order Correlations? Generalizing Matrix Softmax  Attention to Kronecker Computation\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.885, \"y\": 3.17}, {\"title\": \"Analysis of the Reasoning with Redundant Information Provided Ability of  Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.463, \"y\": 3.699}, {\"title\": \"Enhancing Financial Sentiment Analysis via Retrieval Augmented Large  Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.777, \"y\": 6.868}, {\"title\": \"HuBERTopic: Enhancing Semantic Representation of HuBERT through  Self-supervision Utilizing Topic Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.781, \"y\": 4.793}, {\"title\": \"Thought Propagation: An Analogical Approach to Complex Reasoning with  Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.591, \"y\": 2.537}, {\"title\": \"Chain of Natural Language Inference for Reducing Large Language Model  Ungrounded Hallucinations\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.208, \"y\": 1.111}, {\"title\": \"LLM-Coordination: Evaluating and Analyzing Multi-agent Coordination  Abilities in Large Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.556, \"y\": 2.82}, {\"title\": \"Benchmarking a foundation LLM on its ability to re-label structure names  in accordance with the AAPM TG-263 report\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.037, \"y\": 8.324}, {\"title\": \"Validating transformers for redaction of text from electronic health  records in real-world healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.747, \"y\": 8.147}, {\"title\": \"Improved Baselines with Visual Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.325, \"y\": 7.472}, {\"title\": \"MathCoder: Seamless Code Integration in LLMs for Enhanced Mathematical  Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.222, \"y\": 2.715}, {\"title\": \"A Long Way to Go: Investigating Length Correlations in RLHF\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.163, \"y\": 1.523}, {\"title\": \"DecoderLens: Layerwise Interpretation of Encoder-Decoder Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.457, \"y\": 3.561}, {\"title\": \"TRAM: Bridging Trust Regions and Sharpness Aware Minimization\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.785, \"y\": 2.449}, {\"title\": \"Evaluating Self-Supervised Speech Representations for Indigenous  American Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.742, \"y\": 5.075}, {\"title\": \"Redefining Digital Health Interfaces with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.45, \"y\": 8.022}, {\"title\": \"Tik-to-Tok: Translating Language Models One Token at a Time: An  Embedding Initialization Strategy for Efficient Language Adaptation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.498, \"y\": 4.436}, {\"title\": \"Controllable Multi-document Summarization: Coverage & Coherence  Intuitive Policy with Large Language Model Based Rewards\", \"topic\": \"Text Summarization\", \"x\": 5.618, \"y\": 6.15}, {\"title\": \"The North System for Formosa Speech Recognition Challenge 2023\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.006, \"y\": 5.558}, {\"title\": \"LLM Based Multi-Document Summarization Exploiting Main-Event Biased  Monotone Submodular Content Extraction\", \"topic\": \"Text Summarization\", \"x\": 5.547, \"y\": 6.36}, {\"title\": \"Evaluating Hallucinations in Chinese Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.12, \"y\": 1.09}, {\"title\": \"Concise and Organized Perception Facilitates Reasoning in Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.678, \"y\": 2.88}, {\"title\": \"A New Dialogue Response Generation Agent for Large Language Models by  Asking Questions to Detect User's Intentions\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.547, \"y\": 3.807}, {\"title\": \"Investigating Alternative Feature Extraction Pipelines For Clinical Note  Phenotyping\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.654, \"y\": 7.966}, {\"title\": \"Deep Representations of First-person Pronouns for Prediction of  Depression Symptom Severity\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.175, \"y\": 7.499}, {\"title\": \"On the Performance of Multimodal Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.295, \"y\": 7.35}, {\"title\": \"Robust and Interpretable Medical Image Classifiers via Concept  Bottleneck Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.347, \"y\": 8.349}, {\"title\": \"Large Language Model Cascades with Mixture of Thoughts Representations  for Cost-efficient Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.603, \"y\": 2.554}, {\"title\": \"Zero Resource Code-switched Speech Benchmark Using Speech Utterance  Pairs For Multiple Spoken Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.592, \"y\": 5.136}, {\"title\": \"Multimodal Question Answering for Unified Information Extraction\", \"topic\": \"Multimodal Language Models\", \"x\": 7.884, \"y\": 7.717}, {\"title\": \"ECoFLaP: Efficient Coarse-to-Fine Layer-Wise Pruning for Vision-Language  Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.613, \"y\": 2.448}, {\"title\": \"Kosmos-G: Generating Images in Context with Multimodal Large Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.409, \"y\": 7.144}, {\"title\": \"T$^3$Bench: Benchmarking Current Progress in Text-to-3D Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 9.029, \"y\": 7.039}, {\"title\": \"UniverSLU: Universal Spoken Language Understanding for Diverse Tasks  with Natural Language Instructions\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.633, \"y\": 5.04}, {\"title\": \"Prompting and Adapter Tuning for Self-supervised Encoder-Decoder Speech  Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.92, \"y\": 4.839}, {\"title\": \"JsonTuning: Towards Generalizable, Robust, and Controllable Instruction  Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.305, \"y\": 2.431}, {\"title\": \"A Survey of GPT-3 Family Large Language Models Including ChatGPT and  GPT-4\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.385, \"y\": 4.286}, {\"title\": \"LibriSpeech-PC: Benchmark for Evaluation of Punctuation and  Capitalization Capabilities of end-to-end ASR Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.986, \"y\": 5.373}, {\"title\": \"Hate Speech Detection in Limited Data Contexts using Synthetic Data  Generation\", \"topic\": \"Hate Speech Detection\", \"x\": 2.746, \"y\": 5.399}, {\"title\": \"Sweeping Heterogeneity with Smart MoPs: Mixture of Prompts for LLM Task  Adaptation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.619, \"y\": 3.065}, {\"title\": \"Multimodal Prompt Transformer with Hybrid Contrastive Learning for  Emotion Recognition in Conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.294, \"y\": 7.754}, {\"title\": \"DOMINO: A Dual-System for Multi-step Visual Language Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.168, \"y\": 7.787}, {\"title\": \"Integrating UMLS Knowledge into Large Language Models for Medical  Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.699, \"y\": 7.93}, {\"title\": \"The Role of Linguistic Priors in Measuring Compositional Generalization  of Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.699, \"y\": 6.952}, {\"title\": \"Spherical Position Encoding for Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.494, \"y\": 3.64}, {\"title\": \"Improving Automatic VQA Evaluation Using Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.216, \"y\": 7.702}, {\"title\": \"NOLA: Compressing LoRA using Linear Combination of Random Basis\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.262, \"y\": 2.092}, {\"title\": \"CITING: Large Language Models Create Curriculum for Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 7.996, \"y\": 2.388}, {\"title\": \"Backdoor Adjustment of Confounding by Provenance for Robust Text  Classification of Multi-institutional Clinical Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.527, \"y\": 7.723}, {\"title\": \"Novice Learner and Expert Tutor: Evaluating Math Reasoning Abilities of  Large Language Models with Misconceptions\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.792, \"y\": 3.005}, {\"title\": \"Can a student Large Language Model perform as well as it's teacher?\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.493, \"y\": 3.825}, {\"title\": \"Dodo: Dynamic Contextual Compression for Decoder-only LMs\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.39, \"y\": 2.804}, {\"title\": \"AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language  Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.288, \"y\": 2.272}, {\"title\": \"Unsupervised Speech Recognition with N-Skipgram and Positional Unigram  Matching\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.154, \"y\": 5.264}, {\"title\": \"Conversational Health Agents: A Personalized LLM-Powered Agent Framework\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.256, \"y\": 7.95}, {\"title\": \"Automatic Pair Construction for Contrastive Post-training\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.424, \"y\": 1.355}, {\"title\": \"Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.379, \"y\": 2.3}, {\"title\": \"MathVista: Evaluating Mathematical Reasoning of Foundation Models in  Visual Contexts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.063, \"y\": 7.589}, {\"title\": \"Harnessing Pre-Trained Sentence Transformers for Offensive Language  Detection in Indian Languages\", \"topic\": \"Hate Speech Detection\", \"x\": 2.77, \"y\": 5.4}, {\"title\": \"Extraction of Medication and Temporal Relation from Clinical Text using  Neural Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.067, \"y\": 7.771}, {\"title\": \"What's Next in Affective Modeling? Large Language Models\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.488, \"y\": 7.474}, {\"title\": \"Investigating Large Language Models' Perception of Emotion Using  Appraisal Theory\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.522, \"y\": 7.596}, {\"title\": \"Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with  Agent Team Optimization\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.567, \"y\": 2.7}, {\"title\": \"Exploring Collaboration Mechanisms for LLM Agents: A Social Psychology  View\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.356, \"y\": 2.911}, {\"title\": \"Instances Need More Care: Rewriting Prompts for Instances with LLMs in  the Loop Yields Better Zero-Shot Performance\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.167, \"y\": 3.016}, {\"title\": \"Towards End-to-End Embodied Decision Making via Multi-modal Large  Language Model: Explorations with GPT4-Vision and Beyond\", \"topic\": \"Multimodal Language Models\", \"x\": 8.119, \"y\": 7.509}, {\"title\": \"Tuning Large language model for End-to-end Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.165, \"y\": 5.056}, {\"title\": \"Fill in the Blank: Exploring and Enhancing LLM Capabilities for Backward  Reasoning in Math Word Problems\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.931, \"y\": 2.798}, {\"title\": \"Language Models as Knowledge Bases for Visual Word Sense Disambiguation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.52, \"y\": 7.452}, {\"title\": \"Ring Attention with Blockwise Transformers for Near-Infinite Context\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.812, \"y\": 3.129}, {\"title\": \"Zero-Shot Refinement of Buildings' Segmentation Models using SAM\", \"topic\": \"Multimodal Language Models\", \"x\": 8.725, \"y\": 7.101}, {\"title\": \"Preserving Phonemic Distinctions for Ordinal Regression: A Novel Loss  Function for Automatic Pronunciation Assessment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.975, \"y\": 5.532}, {\"title\": \"Extending CAM-based XAI methods for Remote Sensing Imagery Segmentation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.675, \"y\": 7.228}, {\"title\": \"Trainable Noise Model as an XAI evaluation method: application on Sobol  for remote sensing image segmentation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.775, \"y\": 7.111}, {\"title\": \"Empirical Study of PEFT techniques for Winter Wheat Segmentation\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.986, \"y\": 2.286}, {\"title\": \"SEA: Sparse Linear Attention with Estimated Attention Mask\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.845, \"y\": 3.207}, {\"title\": \"Stack Attention: Improving the Ability of Transformers to Model  Hierarchical Patterns\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.649, \"y\": 3.437}, {\"title\": \"Deciphering Diagnoses: How Large Language Models Explanations Influence  Clinical Decision Making\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.55, \"y\": 8.142}, {\"title\": \"LoFT: Local Proxy Fine-tuning For Improving Transferability Of  Adversarial Attacks Against Large Language Model\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.366, \"y\": 2.625}, {\"title\": \"Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across  Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.747, \"y\": 3.607}, {\"title\": \"One model to rule them all ? Towards End-to-End Joint Speaker  Diarization and Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.157, \"y\": 5.212}, {\"title\": \"What's the Magic Word? A Control Theory of LLM Prompting\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.243, \"y\": 3.225}, {\"title\": \"Making Retrieval-Augmented Language Models Robust to Irrelevant Context\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.096, \"y\": 4.551}, {\"title\": \"Compressing LLMs: The Truth is Rarely Pure and Never Simple\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.487, \"y\": 2.422}, {\"title\": \"DiffAR: Denoising Diffusion Autoregressive Model for Raw Speech Waveform  Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.421, \"y\": 5.957}, {\"title\": \"UltraFeedback: Boosting Language Models with High-quality Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.191, \"y\": 1.494}, {\"title\": \"Improving Dialogue Management: Quality Datasets vs Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.479, \"y\": 3.696}, {\"title\": \"LLM Lies: Hallucinations are not Bugs, but Features as Adversarial  Examples\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.135, \"y\": 1.163}, {\"title\": \"On the Generalization of Training-based ChatGPT Detection Methods\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.308, \"y\": 4.717}, {\"title\": \"Generating Explanations in Medical Question-Answering by Expectation  Maximization Inference over Evidence\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.756, \"y\": 7.589}, {\"title\": \"Knowledge Crosswords: Geometric Knowledge Reasoning with Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.717, \"y\": 3.388}, {\"title\": \"LEEC: A Legal Element Extraction Dataset with an Extensive  Domain-Specific Label System\", \"topic\": \"Legal NLP\", \"x\": 5.129, \"y\": 5.836}, {\"title\": \"SPELL: Semantic Prompt Evolution based on a LLM\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.352, \"y\": 3.139}, {\"title\": \"Quantifying the Plausibility of Context Reliance in Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.453, \"y\": 4.33}, {\"title\": \"End-to-End Continuous Speech Emotion Recognition in Real-life Customer  Service Call Center Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.288, \"y\": 7.797}, {\"title\": \"Towards human-like spoken dialogue generation between AI agents from  written dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.216, \"y\": 3.749}, {\"title\": \"Tool-Augmented Reward Modeling\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.217, \"y\": 1.497}, {\"title\": \"Fooling the Textual Fooler via Randomizing Latent Representations\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.166, \"y\": 3.036}, {\"title\": \"uSee: Unified Speech Enhancement and Editing with Conditional Diffusion  Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.628, \"y\": 5.868}, {\"title\": \"Use Your INSTINCT: INSTruction optimization for LLMs usIng Neural  bandits Coupled with Transformers\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.08, \"y\": 2.403}, {\"title\": \"Application of frozen large-scale models to multimodal task-oriented  dialogue\", \"topic\": \"Multimodal Language Models\", \"x\": 8.107, \"y\": 7.4}, {\"title\": \"Towards LogiGLUE: A Brief Survey and A Benchmark for Analyzing Logical  Reasoning Capabilities of Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.693, \"y\": 3.011}, {\"title\": \"Parameter-Efficient Tuning Helps Language Model Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.437, \"y\": 1.406}, {\"title\": \"Injecting a Structural Inductive Bias into a Seq2Seq Model by Simulation\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.241, \"y\": 3.535}, {\"title\": \"BooookScore: A systematic exploration of book-length summarization in  the era of LLMs\", \"topic\": \"Text Summarization\", \"x\": 5.642, \"y\": 5.875}, {\"title\": \"Analyzing and Mitigating Object Hallucination in Large Vision-Language  Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.258, \"y\": 1.001}, {\"title\": \"Robust Sentiment Analysis for Low Resource languages Using Data  Augmentation Approaches: A Case Study in Marathi\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.525, \"y\": 6.641}, {\"title\": \"Evaluating Speech Synthesis by Training Recognizers on Synthetic Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.967, \"y\": 5.554}, {\"title\": \"Do the Benefits of Joint Models for Relation Extraction Extend to  Document-level Tasks?\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.898, \"y\": 6.826}, {\"title\": \"CebuaNER: A New Baseline Cebuano Named Entity Recognition Model\", \"topic\": \"Named Entity Recognition\", \"x\": 7.443, \"y\": 6.8}, {\"title\": \"Faithful Explanations of Black-box NLP Models Using LLM-generated  Counterfactuals\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.764, \"y\": 3.776}, {\"title\": \"Wavelet Scattering Transform for Improving Generalization in  Low-Resourced Spoken Language Identification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.716, \"y\": 5.33}, {\"title\": \"A Task-oriented Dialog Model with Task-progressive and Policy-aware  Pre-training\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.489, \"y\": 3.746}, {\"title\": \"Empowering Many, Biasing a Few: Generalist Credit Scoring through Large  Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.845, \"y\": 6.781}, {\"title\": \"Siamese Representation Learning for Unsupervised Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.025, \"y\": 6.787}, {\"title\": \"JoMA: Demystifying Multilayer Transformers via JOint Dynamics of MLP and  Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.677, \"y\": 3.391}, {\"title\": \"A Brief History of Prompt: Leveraging Language Models. (Through Advanced  Prompting)\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.18, \"y\": 3.258}, {\"title\": \"From Language Modeling to Instruction Following: Understanding the  Behavior Shift in LLMs after Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.211, \"y\": 2.439}, {\"title\": \"Question-Answering Model for Schizophrenia Symptoms and Their Impact on  Daily Life using Mental Health Forums Data\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.393, \"y\": 7.568}, {\"title\": \"Open-Domain Dialogue Quality Evaluation: Deriving Nugget-level Scores  from Turn-level Scores\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.328, \"y\": 3.863}, {\"title\": \"Dynamic Demonstrations Controller for In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.273, \"y\": 3.35}, {\"title\": \"Unlocking Bias Detection: Leveraging Transformer-Based Models for  Content Analysis\", \"topic\": \"Bias in Language Models\", \"x\": 3.396, \"y\": 4.899}, {\"title\": \"Understanding In-Context Learning from Repetitions\", \"topic\": \"In-Context Learning\", \"x\": 8.415, \"y\": 3.364}, {\"title\": \"AfriSpeech-200: Pan-African Accented Speech Dataset for Clinical and  General Domain ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.033, \"y\": 5.591}, {\"title\": \"Investigating the Efficacy of Large Language Models in Reflective  Assessment Methods through Chain of Thoughts Prompting\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.542, \"y\": 2.391}, {\"title\": \"AutoHall: Automated Hallucination Dataset Generation for Large Language  Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.16, \"y\": 1.115}, {\"title\": \"SLM: Bridge the thin gap between speech and text foundation models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.395, \"y\": 5.182}, {\"title\": \"Pairwise Proximal Policy Optimization: Harnessing Relative Feedback for  LLM Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.267, \"y\": 1.413}, {\"title\": \"Contextual Biasing with the Knuth-Morris-Pratt Matching Algorithm\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.373, \"y\": 5.063}, {\"title\": \"Learning to Rewrite Prompts for Personalized Text Generation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.413, \"y\": 3.236}, {\"title\": \"The Gift of Feedback: Improving ASR Model Quality by Learning from User  Corrections through Federated Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.202, \"y\": 5.116}, {\"title\": \"Multilingual Natural Language Processing Model for Radiology Reports --  The Summary is all you need!\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.118, \"y\": 8.565}, {\"title\": \"Clinical Text Deduplication Practices for Efficient Pretraining and  Improved Clinical Tasks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.925, \"y\": 8.138}, {\"title\": \"SocREval: Large Language Models with the Socratic Method for  Reference-Free Reasoning Evaluation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.62, \"y\": 2.633}, {\"title\": \"Efficient Streaming Language Models with Attention Sinks\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.402, \"y\": 2.864}, {\"title\": \"ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.917, \"y\": 2.821}, {\"title\": \"L2CEval: Evaluating Language-to-Code Generation Capabilities of Large  Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.302, \"y\": 2.597}, {\"title\": \"LLM-grounded Video Diffusion Models\", \"topic\": \"Multimodal Language Models\", \"x\": 9.077, \"y\": 7.46}, {\"title\": \"The Dawn of LMMs: Preliminary Explorations with GPT-4V(ision)\", \"topic\": \"Multimodal Language Models\", \"x\": 7.826, \"y\": 7.764}, {\"title\": \"Few-Shot Domain Adaptation for Charge Prediction on Unprofessional  Descriptions\", \"topic\": \"Legal NLP\", \"x\": 5.113, \"y\": 5.87}, {\"title\": \"PB-LLM: Partially Binarized Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.75, \"y\": 2.157}, {\"title\": \"STRONG -- Structure Controllable Legal Opinion Summary Generation\", \"topic\": \"Legal NLP\", \"x\": 5.075, \"y\": 5.989}, {\"title\": \"Wiki-En-ASR-Adapt: Large-scale synthetic dataset for English ASR  Customization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.052, \"y\": 5.411}, {\"title\": \"Batch Calibration: Rethinking Calibration for In-Context Learning and  Prompt Engineering\", \"topic\": \"In-Context Learning\", \"x\": 8.122, \"y\": 3.358}, {\"title\": \"Cooperation, Competition, and Maliciousness: LLM-Stakeholders  Interactive Negotiation\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.232, \"y\": 3.014}, {\"title\": \"Comparative Analysis of Named Entity Recognition in the Dungeons and  Dragons Domain\", \"topic\": \"Named Entity Recognition\", \"x\": 7.274, \"y\": 6.745}, {\"title\": \"An evaluation of GPT models for phenotype concept recognition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.807, \"y\": 8.029}, {\"title\": \"Promoting Generalized Cross-lingual Question Answering in Few-resource  Scenarios via Self-knowledge Distillation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.435, \"y\": 4.876}, {\"title\": \"Fine-grained Late-interaction Multi-modal Retrieval for Retrieval  Augmented Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.185, \"y\": 7.745}, {\"title\": \"SCALE: Synergized Collaboration of Asymmetric Language Translation  Engines\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.495, \"y\": 4.224}, {\"title\": \"Interpretable Long-Form Legal Question Answering with  Retrieval-Augmented Large Language Models\", \"topic\": \"Legal NLP\", \"x\": 5.256, \"y\": 5.589}, {\"title\": \"SSHR: Leveraging Self-supervised Hierarchical Representations for  Multilingual Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.792, \"y\": 5.139}, {\"title\": \"Towards a Unified Framework for Adaptable Problematic Content Detection  via Continual Learning\", \"topic\": \"Hate Speech Detection\", \"x\": 2.771, \"y\": 5.369}, {\"title\": \"DeBERTinha: A Multistep Approach to Adapt DebertaV3 XSmall for Brazilian  Portuguese Natural Language Processing Task\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.913, \"y\": 4.606}, {\"title\": \"Promptbreeder: Self-Referential Self-Improvement Via Prompt Evolution\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.316, \"y\": 3.033}, {\"title\": \"Hallucination Reduction in Long Input Text Summarization\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.114, \"y\": 1.215}, {\"title\": \"How many words does ChatGPT know? The answer is ChatWords\", \"topic\": \"Bias in Language Models\", \"x\": 5.126, \"y\": 4.536}, {\"title\": \"Persona-Coded Poly-Encoder: Persona-Guided Multi-Stream Conversational  Sentence Scoring\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.182, \"y\": 3.85}, {\"title\": \"Demystifying CLIP Data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.985, \"y\": 7.212}, {\"title\": \"Stress Testing Chain-of-Thought Prompting for Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.63, \"y\": 2.291}, {\"title\": \"Unlikelihood Tuning on Negative Samples Amazingly Improves Zero-Shot  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.755, \"y\": 4.542}, {\"title\": \"GPT-Fathom: Benchmarking Large Language Models to Decipher the  Evolutionary Path towards GPT-4 and Beyond\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.392, \"y\": 3.927}, {\"title\": \"A Benchmark for Learning to Translate a New Language from One Grammar  Book\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.395, \"y\": 4.39}, {\"title\": \"Language Models as a Service: Overview of a New Paradigm and its  Challenges\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.553, \"y\": 3.934}, {\"title\": \"Toloka Visual Question Answering Benchmark\", \"topic\": \"Multimodal Language Models\", \"x\": 8.153, \"y\": 8.063}, {\"title\": \"Augmenting LLMs with Knowledge: A survey on hallucination prevention\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.213, \"y\": 1.143}, {\"title\": \"Prompt-and-Align: Prompt-Based Social Alignment for Few-Shot Fake News  Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.07, \"y\": 5.828}, {\"title\": \"A Comprehensive Survey of Document-level Relation Extraction (2016-2023)\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.775, \"y\": 6.813}, {\"title\": \"Transformer-VQ: Linear-Time Transformers via Vector Quantization\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.85, \"y\": 3.292}, {\"title\": \"LawBench: Benchmarking Legal Knowledge of Large Language Models\", \"topic\": \"Legal NLP\", \"x\": 5.367, \"y\": 5.326}, {\"title\": \"Self-supervised Cross-view Representation Reconstruction for Change  Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.083, \"y\": 7.27}, {\"title\": \"Spider4SPARQL: A Complex Benchmark for Evaluating Knowledge Graph  Question Answering Systems\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.691, \"y\": 5.445}, {\"title\": \"Large Language Models in Finance: A Survey\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.89, \"y\": 6.822}, {\"title\": \"The Trickle-down Impact of Reward (In-)consistency on RLHF\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.081, \"y\": 1.567}, {\"title\": \"AE-GPT: Using Large Language Models to Extract Adverse Events from  Surveillance Reports-A Use Case with Influenza Vaccine Adverse Events\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.592, \"y\": 7.731}, {\"title\": \"AnyMAL: An Efficient and Scalable Any-Modality Augmented Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.217, \"y\": 7.198}, {\"title\": \"Targeted Image Data Augmentation Increases Basic Skills Captioning  Robustness\", \"topic\": \"Multimodal Language Models\", \"x\": 9.07, \"y\": 7.162}, {\"title\": \"Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard  Parameter Sharing\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.261, \"y\": 5.243}, {\"title\": \"Exploring Speech Recognition, Translation, and Understanding with  Discrete Speech Units: A Comparative Study\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.559, \"y\": 5.16}, {\"title\": \"Question answering using deep learning in low resource Indian language  Marathi\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.725, \"y\": 5.298}, {\"title\": \"Experience and Evidence are the eyes of an excellent summarizer! Towards  Knowledge Infused Multi-modal Clinical Conversation Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.936, \"y\": 8.198}, {\"title\": \"HyPoradise: An Open Baseline for Generative Speech Recognition with  Large Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.128, \"y\": 5.37}, {\"title\": \"Enhancing End-to-End Conversational Speech Translation Through Target  Language Context Utilization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.423, \"y\": 5.21}, {\"title\": \"Speech collage: code-switched audio generation by collaging monolingual  corpora\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.692, \"y\": 5.418}, {\"title\": \"MONOVAB : An Annotated Corpus for Bangla Multi-label Emotion Detection\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.421, \"y\": 6.736}, {\"title\": \"Generative Speech Recognition Error Correction with Large Language  Models and Task-Activating Prompting\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.921, \"y\": 5.259}, {\"title\": \"An Empirical Study of AI Generated Text Detection Tools\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.315, \"y\": 4.775}, {\"title\": \"Developing automatic verbatim transcripts for international multilingual  meetings: an end-to-end solution\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.4, \"y\": 5.395}, {\"title\": \"Jointly Training Large Autoregressive Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.37, \"y\": 7.162}, {\"title\": \"Direct Models for Simultaneous Translation and Automatic Subtitling:  FBK@IWSLT2023\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.244, \"y\": 5.131}, {\"title\": \"High-Fidelity Speech Synthesis with Minimal Supervision: All Using  Diffusion Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.623, \"y\": 5.803}, {\"title\": \"VideoAdviser: Video Knowledge Distillation for Multimodal Transfer  Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.629, \"y\": 7.5}, {\"title\": \"Dynamic Multi-Scale Context Aggregation for Conversational Aspect-Based  Sentiment Quadruple Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.176, \"y\": 6.891}, {\"title\": \"Navigate through Enigmatic Labyrinth A Survey of Chain of Thought  Reasoning: Advances, Frontiers and Future\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.607, \"y\": 2.376}, {\"title\": \"Unsupervised Pre-Training for Vietnamese Automatic Speech Recognition in  the HYKIST Project\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.147, \"y\": 5.507}, {\"title\": \"Creating Trustworthy LLMs: Dealing with Hallucinations in Healthcare AI\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.056, \"y\": 1.196}, {\"title\": \"RAGAS: Automated Evaluation of Retrieval Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.93, \"y\": 4.683}, {\"title\": \"Robust Stance Detection: Understanding Public Perceptions in Social  Media\", \"topic\": \"Fake News Detection\", \"x\": 3.446, \"y\": 5.864}, {\"title\": \"VideoDirectorGPT: Consistent Multi-scene Video Generation via LLM-Guided  Planning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.987, \"y\": 7.767}, {\"title\": \"Question-Answering Approach to Evaluating Legal Summaries\", \"topic\": \"Legal NLP\", \"x\": 5.103, \"y\": 5.88}, {\"title\": \"Updated Corpora and Benchmarks for Long-Form Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.134, \"y\": 5.413}, {\"title\": \"Automating question generation from educational text\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.106, \"y\": 4.804}, {\"title\": \"Interactively Learning Social Media Representations Improves News Source  Factuality Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.062, \"y\": 5.814}, {\"title\": \"Learning from Flawed Data: Weakly Supervised Automatic Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.174, \"y\": 5.403}, {\"title\": \"Segmentation-Free Streaming Machine Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.49, \"y\": 5.215}, {\"title\": \"BLIP-Adapter: Parameter-Efficient Transfer Learning for Mobile  Screenshot Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.92, \"y\": 7.313}, {\"title\": \"Knowledgeable In-Context Tuning: Exploring and Exploiting Factual  Knowledge for In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.239, \"y\": 3.279}, {\"title\": \"KERMIT: Knowledge Graph Completion of Enhanced Relation Modeling with  Inverse Transformation\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.039, \"y\": 6.045}, {\"title\": \"Program Repair with Minimal Edits Using CodeT5\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.454, \"y\": 2.252}, {\"title\": \"Legal Question-Answering in the Indian Context: Efficacy, Challenges,  and Potential of Modern AI Models\", \"topic\": \"Legal NLP\", \"x\": 5.286, \"y\": 5.458}, {\"title\": \"A Simple Text to Video Model via Transformer\", \"topic\": \"Multimodal Language Models\", \"x\": 8.963, \"y\": 7.722}, {\"title\": \"Efficient Post-training Quantization with FP8 Formats\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.78, \"y\": 2.18}, {\"title\": \"Aligning Large Multimodal Models with Factually Augmented RLHF\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.745, \"y\": 1.219}, {\"title\": \"DeepSpeed Ulysses: System Optimizations for Enabling Training of Extreme  Long Sequence Transformer Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.756, \"y\": 2.971}, {\"title\": \"DeepSpeed-VisualChat: Multi-Round Multi-Image Interleave Chat via  Multi-Modal Causal Attention\", \"topic\": \"Multimodal Language Models\", \"x\": 8.174, \"y\": 7.376}, {\"title\": \"Towards General-Purpose Text-Instruction-Guided Voice Conversion\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.653, \"y\": 5.792}, {\"title\": \"Examining Temporal Bias in Abusive Language Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.868, \"y\": 5.103}, {\"title\": \"Face-StyleSpeech: Improved Face-to-Voice latent mapping for Natural  Zero-shot Speech Synthesis from a Face Image\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.538, \"y\": 5.955}, {\"title\": \"On the Relation between Internal Language Model and Sequence  Discriminative Training for Neural Transducers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.882, \"y\": 5.007}, {\"title\": \"Wav2vec-based Detection and Severity Level Classification of Dysarthria  from Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.248, \"y\": 5.609}, {\"title\": \"Comprehensive Overview of Named Entity Recognition: Models,  Domain-Specific Applications and Challenges\", \"topic\": \"Named Entity Recognition\", \"x\": 7.199, \"y\": 6.845}, {\"title\": \"Analysis and Detection of Pathological Voice using Glottal Source  Features\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.109, \"y\": 5.701}, {\"title\": \"LORD: Low Rank Decomposition Of Monolingual Code LLMs For One-Shot  Compression\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.55, \"y\": 2.334}, {\"title\": \"Connecting Speech Encoder and Large Language Model for ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.001, \"y\": 5.129}, {\"title\": \"VidChapters-7M: Video Chapters at Scale\", \"topic\": \"Multimodal Language Models\", \"x\": 8.964, \"y\": 7.842}, {\"title\": \"Reproducing Whisper-Style Training Using an Open-Source Toolkit and  Publicly Available Data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.873, \"y\": 5.263}, {\"title\": \"PRiSM: Enhancing Low-Resource Document-Level Relation Extraction with  Relation-Aware Score Calibration\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.913, \"y\": 6.777}, {\"title\": \"Fast-HuBERT: An Efficient Training Framework for Self-Supervised Speech  Representation Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.825, \"y\": 4.854}, {\"title\": \"Does the \\\"most sinfully decadent cake ever\\\" taste good? Answering Yes/No  Questions from Figurative Contexts\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.424, \"y\": 5.064}, {\"title\": \"Prompting and Fine-Tuning Open-Sourced Large Language Models for Stance  Classification\", \"topic\": \"Fake News Detection\", \"x\": 3.543, \"y\": 5.77}, {\"title\": \"Arabic Sentiment Analysis with Noisy Deep Explainable Model\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.43, \"y\": 6.689}, {\"title\": \"Agree To Disagree\", \"topic\": \"Legal NLP\", \"x\": 5.097, \"y\": 5.745}, {\"title\": \"Skill Check: Some Considerations on the Evaluation of Gamemastering  Models for Role-playing Games\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.358, \"y\": 3.253}, {\"title\": \"Survey of Social Bias in Vision-Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.265, \"y\": 4.464}, {\"title\": \"VoiceLDM: Text-to-Speech with Environmental Context\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.539, \"y\": 5.817}, {\"title\": \"MentaLLaMA: Interpretable Mental Health Analysis on Social Media with  Large Language Models\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.323, \"y\": 7.586}, {\"title\": \"Cordyceps@LT-EDI: Patching Language-Specific Homophobia/Transphobia  Classifiers with a Multilingual Understanding\", \"topic\": \"Hate Speech Detection\", \"x\": 2.771, \"y\": 5.392}, {\"title\": \"Human Transcription Quality Improvement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.12, \"y\": 5.453}, {\"title\": \"Cordyceps@LT-EDI: Depression Detection with Reddit and Self-training\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.163, \"y\": 7.378}, {\"title\": \"The Study of Perceptual Training of Chinese Mandarin Tones for  Monolingual Speakers of English Using Adaptive Computer Based Training  Software\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.224, \"y\": 5.602}, {\"title\": \"Experimental Evidence on Negative Impact of Generative AI on Scientific  Learning Outcomes\", \"topic\": \"Bias in Language Models\", \"x\": 5.039, \"y\": 4.603}, {\"title\": \"Hierarchical attention interpretation: an interpretable speech-level  transformer for bi-modal depression detection\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.204, \"y\": 7.53}, {\"title\": \"Grounding Description-Driven Dialogue State Trackers with  Knowledge-Seeking Turns\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.53, \"y\": 3.833}, {\"title\": \"Resolving References in Visually-Grounded Dialogue via Text Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.665, \"y\": 7.49}, {\"title\": \"A Survey on Image-text Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.696, \"y\": 7.572}, {\"title\": \"Lexical Squad@Multimodal Hate Speech Event Detection 2023: Multimodal  Hate Speech Detection using Fused Ensemble Approach\", \"topic\": \"Hate Speech Detection\", \"x\": 2.727, \"y\": 5.441}, {\"title\": \"An In-depth Survey of Large Language Model-based Artificial Intelligence  Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.623, \"y\": 2.922}, {\"title\": \"Towards LLM-guided Causal Explainability for Black-box Text Classifiers\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.78, \"y\": 3.996}, {\"title\": \"Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models  through Logic\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.637, \"y\": 2.478}, {\"title\": \"Diversifying Question Generation over Knowledge Base via External  Natural Questions\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.279, \"y\": 5.114}, {\"title\": \"From Text to Source: Results in Detecting Large Language Model-Generated  Content\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.148, \"y\": 4.603}, {\"title\": \"GlotScript: A Resource and Tool for Low Resource Writing System  Identification\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.358, \"y\": 5.313}, {\"title\": \"OATS: Opinion Aspect Target Sentiment Quadruple Extraction Dataset for  Aspect-Based Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.14, \"y\": 6.805}, {\"title\": \"User Simulation with Large Language Models for Evaluating Task-Oriented  Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.436, \"y\": 3.639}, {\"title\": \"Unify word-level and span-level tasks: NJUNLP's Participation for the  WMT2023 Quality Estimation Shared Task\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.869, \"y\": 4.654}, {\"title\": \"Hindi to English: Transformer-Based Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.745, \"y\": 4.778}, {\"title\": \"A Practical Survey on Zero-shot Prompt Design for In-context Learning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.349, \"y\": 3.31}, {\"title\": \"Investigating Large Language Models and Control Mechanisms to Improve  Text Readability of Biomedical Abstracts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.057, \"y\": 7.409}, {\"title\": \"Document Understanding for Healthcare Referrals\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.971, \"y\": 8.232}, {\"title\": \"Cardiovascular Disease Risk Prediction via Social Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.149, \"y\": 7.033}, {\"title\": \"Dynamic ASR Pathways: An Adaptive Masking Approach Towards Efficient  Pruning of A Multilingual ASR Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.954, \"y\": 4.762}, {\"title\": \"Audience-specific Explanations for Machine Translation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.961, \"y\": 3.795}, {\"title\": \"On Separate Normalization in Self-supervised Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.783, \"y\": 3.477}, {\"title\": \"PopBERT. Detecting populism and its host ideologies in the German  Bundestag\", \"topic\": \"Fake News Detection\", \"x\": 3.656, \"y\": 5.463}, {\"title\": \"Affect Recognition in Conversations Using Large Language Models\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.47, \"y\": 7.702}, {\"title\": \"Reduce, Reuse, Recycle: Is Perturbed Data better than Other Language  augmentation for Low Resource Self-Supervised Speech Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.782, \"y\": 5.324}, {\"title\": \"Decoding Emotional Experiences in Dyadic Conversations of Married  Couples: Leveraging Semantic Similarity through Sentence Embedding\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.5, \"y\": 7.761}, {\"title\": \"Construction contract risk identification based on knowledge-augmented  language model\", \"topic\": \"Legal NLP\", \"x\": 5.517, \"y\": 5.112}, {\"title\": \"DRG-LLaMA : Tuning LLaMA Model to Predict Diagnosis-related Group for  Hospitalized Patients\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.752, \"y\": 8.184}, {\"title\": \"PlanFitting: Tailoring Personalized Exercise Plans with Large Language  Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.779, \"y\": 2.948}, {\"title\": \"Automatic Answerability Evaluation for Question Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.109, \"y\": 4.862}, {\"title\": \"Knowledge Graph Embedding: An Overview\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.104, \"y\": 6.031}, {\"title\": \"Exploring the Impact of Training Data Distribution and Subword  Tokenization on Gender Bias in Machine Translation\", \"topic\": \"Bias in Language Models\", \"x\": 3.117, \"y\": 4.426}, {\"title\": \"LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language  Model as an Agent\", \"topic\": \"Multimodal Language Models\", \"x\": 8.771, \"y\": 7.258}, {\"title\": \"MetaMath: Bootstrap Your Own Mathematical Questions for Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.051, \"y\": 2.885}, {\"title\": \"Inspire the Large Language Model by External Knowledge on BioMedical  Named Entity Recognition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.398, \"y\": 7.464}, {\"title\": \"Improving VTE Identification through Adaptive NLP Model Selection and  Clinical Expert Rule-based Classifier from Radiology Reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.072, \"y\": 8.463}, {\"title\": \"The Cambridge Law Corpus: A Dataset for Legal AI Research\", \"topic\": \"Legal NLP\", \"x\": 5.083, \"y\": 5.755}, {\"title\": \"On the Relationship between Skill Neurons and Robustness in Prompt  Tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.699, \"y\": 3.291}, {\"title\": \"SQUARE: Automatic Question Answering Evaluation using Multiple Positive  and Negative References\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.23, \"y\": 4.917}, {\"title\": \"Bad Actor, Good Advisor: Exploring the Role of Large Language Models in  Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.044, \"y\": 5.672}, {\"title\": \"ChaCha: Leveraging Large Language Models to Prompt Children to Share  Their Emotions about Personal Events\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.75, \"y\": 7.751}, {\"title\": \"Bridging the Gaps of Both Modality and Language: Synchronous Bilingual  CTC for Speech Translation and Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.573, \"y\": 5.223}, {\"title\": \"PEFTT: Parameter-Efficient Fine-Tuning for low-resource Tibetan  pre-trained language models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.935, \"y\": 2.349}, {\"title\": \"Stock Market Sentiment Classification and Backtesting via Fine-tuned  BERT\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.491, \"y\": 6.842}, {\"title\": \"SPICED: News Similarity Detection Dataset with Multiple Topics and  Complexity Levels\", \"topic\": \"Fake News Detection\", \"x\": 4.132, \"y\": 5.926}, {\"title\": \"InstructERC: Reforming Emotion Recognition in Conversation with a  Retrieval Multi-task LLMs Framework\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.309, \"y\": 7.777}, {\"title\": \"MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for  Domain-specific Large Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.001, \"y\": 7.613}, {\"title\": \"Focal Inferential Infusion Coupled with Tractable Density Discrimination  for Implicit Hate Speech Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.693, \"y\": 5.367}, {\"title\": \"Audio Contrastive based Fine-tuning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.882, \"y\": 5.012}, {\"title\": \"BitCoin: Bidirectional Tagging and Supervised Contrastive Learning based  Joint Relational Triple Extraction Framework\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.897, \"y\": 6.723}, {\"title\": \"How Prevalent is Gender Bias in ChatGPT? -- Exploring German and English  ChatGPT Responses\", \"topic\": \"Bias in Language Models\", \"x\": 3.554, \"y\": 4.395}, {\"title\": \"A Discourse-level Multi-scale Prosodic Model for Fine-grained Emotion  Analysis\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.302, \"y\": 7.895}, {\"title\": \"Evaluating Large Language Models for Document-grounded Response  Generation in Information-Seeking Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.567, \"y\": 3.99}, {\"title\": \"ContextRef: Evaluating Referenceless Metrics For Image Description  Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.923, \"y\": 7.353}, {\"title\": \"LLM-based Medical Assistant Personalization with Short- and Long-Term  Memory Coordination\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.915, \"y\": 8.031}, {\"title\": \"LLM Guided Inductive Inference for Solving Compositional Problems\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.599, \"y\": 2.776}, {\"title\": \"Towards Effective Disambiguation for Machine Translation with Large  Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.35, \"y\": 4.412}, {\"title\": \"Hate speech detection in algerian dialect using deep learning\", \"topic\": \"Hate Speech Detection\", \"x\": 2.74, \"y\": 5.424}, {\"title\": \"SpeechAlign: a Framework for Speech Translation Alignment Evaluation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.263, \"y\": 5.31}, {\"title\": \"Examining the Limitations of Computational Rumor Detection Models  Trained on Static Datasets\", \"topic\": \"Fake News Detection\", \"x\": 4.083, \"y\": 5.903}, {\"title\": \"DreamLLM: Synergistic Multimodal Comprehension and Creation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.332, \"y\": 7.269}, {\"title\": \"Chain-of-Verification Reduces Hallucination in Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.422, \"y\": 2.181}, {\"title\": \"SCREWS: A Modular Framework for Reasoning with Revisions\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.576, \"y\": 2.504}, {\"title\": \"Kosmos-2.5: A Multimodal Literate Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.213, \"y\": 7.197}, {\"title\": \"Safurai 001: New Qualitative Approach for Code LLM Evaluation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.479, \"y\": 2.528}, {\"title\": \"Long-Form End-to-End Speech Translation via Latent Alignment  Segmentation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.507, \"y\": 5.257}, {\"title\": \"Incremental Blockwise Beam Search for Simultaneous Speech Translation  with Controllable Quality-Latency Tradeoff\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.383, \"y\": 5.051}, {\"title\": \"Leveraging Data Collection and Unsupervised Learning for Code-switched  Tunisian Arabic Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.792, \"y\": 5.473}, {\"title\": \"DISC-LawLLM: Fine-tuning Large Language Models for Intelligent Legal  Services\", \"topic\": \"Legal NLP\", \"x\": 5.163, \"y\": 5.522}, {\"title\": \"Rating Prediction in Conversational Task Assistants with Behavioral and  Conversational-Flow Features\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.103, \"y\": 3.765}, {\"title\": \"CPLLM: Clinical Prediction with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.69, \"y\": 8.171}, {\"title\": \"Overview of AuTexTification at IberLEF 2023: Detection and Attribution  of Machine-Generated Text in Multiple Domains\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.064, \"y\": 5.242}, {\"title\": \"The Wizard of Curiosities: Enriching Dialogues with Fun Facts\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.054, \"y\": 3.697}, {\"title\": \"Grounded Complex Task Segmentation for Conversational Assistants\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.439, \"y\": 3.968}, {\"title\": \"The Scenario Refiner: Grounding subjects in images at the morphological  level\", \"topic\": \"Multimodal Language Models\", \"x\": 8.533, \"y\": 7.351}, {\"title\": \"Speak While You Think: Streaming Speech Synthesis During Text Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.461, \"y\": 5.583}, {\"title\": \"Retrieve-Rewrite-Answer: A KG-to-Text Enhanced LLMs Framework for  Knowledge Graph Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.814, \"y\": 5.612}, {\"title\": \"Dual-Modal Attention-Enhanced Text-Video Retrieval with Triplet Partial  Margin Contrastive Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.807, \"y\": 7.564}, {\"title\": \"UniPCM: Universal Pre-trained Conversation Model with Task-aware  Automatic Prompt\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.523, \"y\": 3.855}, {\"title\": \"Design of Chain-of-Thought in Math Problem Solving\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.88, \"y\": 2.261}, {\"title\": \"fakenewsbr: A Fake News Detection Platform for Brazilian Portuguese\", \"topic\": \"Fake News Detection\", \"x\": 4.065, \"y\": 5.875}, {\"title\": \"Named Entity Recognition via Machine Reading Comprehension: A Multi-Task  Learning Approach\", \"topic\": \"Named Entity Recognition\", \"x\": 7.318, \"y\": 6.653}, {\"title\": \"Towards Joint Modeling of Dialogue Response and Speech Synthesis based  on Large Language Model\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 10.295, \"y\": 5.695}, {\"title\": \"Benchmarks for Pir\\u00e1 2.0, a Reading Comprehension Dataset about the  Ocean, the Brazilian Coast, and Climate Change\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.46, \"y\": 5.222}, {\"title\": \"Semi-Autoregressive Streaming ASR With Label Context\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.177, \"y\": 4.97}, {\"title\": \"End-to-End Speech Recognition Contextualization with Large Language  Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.841, \"y\": 5.175}, {\"title\": \"What Learned Representations and Influence Functions Can Tell Us About  Adversarial Examples\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.121, \"y\": 3.046}, {\"title\": \"Enhancing Health Data Interoperability with Large Language Models: A  FHIR Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.551, \"y\": 7.887}, {\"title\": \"Self-Augmentation Improves Zero-Shot Cross-Lingual Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.432, \"y\": 4.84}, {\"title\": \"Language as the Medium: Multimodal Video Classification through text  only\", \"topic\": \"Multimodal Language Models\", \"x\": 8.831, \"y\": 7.798}, {\"title\": \"Interactive Distillation of Large Single-Topic Corpora of Scientific  Papers\", \"topic\": \"Text Summarization\", \"x\": 5.924, \"y\": 6.362}, {\"title\": \"FRASIMED: a Clinical French Annotated Resource Produced through  Crosslingual BERT-Based Annotation Projection\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.115, \"y\": 7.672}, {\"title\": \"CFGPT: Chinese Financial Assistant with Large Language Model\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.876, \"y\": 6.872}, {\"title\": \"Improving Medical Dialogue Generation with Abstract Meaning  Representations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.642, \"y\": 8.171}, {\"title\": \"NSOAMT -- New Search Only Approach to Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.753, \"y\": 4.811}, {\"title\": \"Harnessing the Zero-Shot Power of Instruction-Tuned Large Language Model  in End-to-End Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.918, \"y\": 5.134}, {\"title\": \"Improving Speaker Diarization using Semantic Information: Joint Pairwise  Constraints Propagation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.782, \"y\": 5.261}, {\"title\": \"Reformulating Sequential Recommendation: Learning Dynamic User Interest  with Content-enriched Language Modeling\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.963, \"y\": 2.924}, {\"title\": \"PICK: Polished & Informed Candidate Scoring for Knowledge-Grounded  Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.623, \"y\": 3.893}, {\"title\": \"Explaining Agent Behavior with Large Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.954, \"y\": 2.58}, {\"title\": \"KoBigBird-large: Transformation of Transformer for Korean Language  Understanding\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.903, \"y\": 3.975}, {\"title\": \"QASnowball: An Iterative Bootstrapping Framework for High-Quality  Question-Answering Data Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.29, \"y\": 5.133}, {\"title\": \"Investigating the Catastrophic Forgetting in Multimodal Large Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.207, \"y\": 7.41}, {\"title\": \"Rigorously Assessing Natural Language Explanations of Neurons\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.936, \"y\": 3.784}, {\"title\": \"Using fine-tuning and min lookahead beam search to improve Whisper\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.051, \"y\": 5.028}, {\"title\": \"Leveraging Speech PTM, Text LLM, and Emotional TTS for Speech Emotion  Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.214, \"y\": 7.857}, {\"title\": \"Mixed-Distil-BERT: Code-mixed Language Modeling for Bangla, English, and  Hindi\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.054, \"y\": 4.951}, {\"title\": \"Stabilizing RLHF through Advantage Model and Selective Rehearsal\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.183, \"y\": 1.483}, {\"title\": \"Machine Learning Technique Based Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.09, \"y\": 5.882}, {\"title\": \"Unified Coarse-to-Fine Alignment for Video-Text Retrieval\", \"topic\": \"Multimodal Language Models\", \"x\": 8.874, \"y\": 7.67}, {\"title\": \"HTEC: Human Transcription Error Correction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.089, \"y\": 5.539}, {\"title\": \"Automatic Personalized Impression Generation for PET Reports Using Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.998, \"y\": 8.475}, {\"title\": \"Multimodal Foundation Models: From Specialists to General-Purpose  Assistants\", \"topic\": \"Multimodal Language Models\", \"x\": 8.021, \"y\": 7.402}, {\"title\": \"An Empirical Study of Scaling Instruct-Tuned Large Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.204, \"y\": 7.387}, {\"title\": \"Corpus Synthesis for Zero-shot ASR domain Adaptation using Large  Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.937, \"y\": 5.132}, {\"title\": \"Not Enough Labeled Data? Just Add Semantics: A Data-Efficient Method for  Inferring Online Health Texts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.885, \"y\": 7.687}, {\"title\": \"Instruction-Following Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.803, \"y\": 5.151}, {\"title\": \"HypR: A comprehensive study for ASR hypothesis revising with a reference  corpus\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.272, \"y\": 5.374}, {\"title\": \"Task Selection and Assignment for Multi-modal Multi-task Dialogue Act  Classification with Non-stationary Multi-armed Bandits\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.511, \"y\": 3.48}, {\"title\": \"Watch the Speakers: A Hybrid Continuous Attribution Network for Emotion  Recognition in Conversation With Emotion Disentanglement\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.271, \"y\": 7.811}, {\"title\": \"Dealing with negative samples with multi-task learning on span-based  joint entity-relation extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.144, \"y\": 6.725}, {\"title\": \"Evaluating Gender Bias of Pre-trained Language Models in Natural  Language Inference by Considering All Labels\", \"topic\": \"Bias in Language Models\", \"x\": 3.243, \"y\": 4.38}, {\"title\": \"Speeding Up Speech Synthesis In Diffusion Models By Reducing Data  Distribution Recovery Steps Via Content Transfer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.526, \"y\": 5.899}, {\"title\": \"Summarization is (Almost) Dead\", \"topic\": \"Text Summarization\", \"x\": 5.646, \"y\": 5.942}, {\"title\": \"A Multitask Training Approach to Enhance Whisper with Contextual Biasing  and Open-Vocabulary Keyword Spotting\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.106, \"y\": 5.275}, {\"title\": \"Improved Factorized Neural Transducer Model For text-only Domain  Adaptation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.076, \"y\": 4.937}, {\"title\": \"Understanding Divergent Framing of the Supreme Court Controversies:  Social Media vs. News Outlets\", \"topic\": \"Fake News Detection\", \"x\": 3.771, \"y\": 5.741}, {\"title\": \"Pruning Large Language Models via Accuracy Predictor\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.546, \"y\": 2.416}, {\"title\": \"Enhancing Multilingual Speech Recognition through Language Prompt Tuning  and Frame-Level Language Adapter\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.735, \"y\": 4.953}, {\"title\": \"Defending Against Alignment-Breaking Attacks via Robustly Aligned LLM\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.477, \"y\": 2.439}, {\"title\": \"Does Video Summarization Require Videos? Quantifying the Effectiveness  of Language in Video Summarization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.876, \"y\": 7.817}, {\"title\": \"CulturaX: A Cleaned, Enormous, and Multilingual Dataset for Large  Language Models in 167 Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.655, \"y\": 4.058}, {\"title\": \"Augmenting text for spoken language understanding with Large Language  Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.104, \"y\": 5.297}, {\"title\": \"Embrace Divergence for Richer Insights: A Multi-document Summarization  Benchmark and a Case Study on Summarizing Diverse Information from News  Articles\", \"topic\": \"Text Summarization\", \"x\": 5.386, \"y\": 6.332}, {\"title\": \"Language models are susceptible to incorrect patient self-diagnosis in  medical applications\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.446, \"y\": 8.243}, {\"title\": \"Talk2Care: Facilitating Asynchronous Patient-Provider Communication with  Large-Language-Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.283, \"y\": 7.928}, {\"title\": \"A Few-Shot Approach to Dysarthric Speech Intelligibility Level  Classification Using Transformers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.311, \"y\": 5.607}, {\"title\": \"Model-based Subsampling for Knowledge Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.134, \"y\": 5.953}, {\"title\": \"Code quality assessment using transformers\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.7, \"y\": 2.686}, {\"title\": \"How much can ChatGPT really help Computational Biologists in  Programming?\", \"topic\": \"Bias in Language Models\", \"x\": 5.17, \"y\": 4.532}, {\"title\": \"The Impact of Debiasing on the Performance of Language Models in  Downstream Tasks is Underestimated\", \"topic\": \"Bias in Language Models\", \"x\": 3.256, \"y\": 4.344}, {\"title\": \"Improving Speech Recognition for African American English With Audio  Classification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.164, \"y\": 5.408}, {\"title\": \"NOWJ1@ALQAC 2023: Enhancing Legal Task Performance with Classic  Statistical Models and Pre-trained Language Models\", \"topic\": \"Legal NLP\", \"x\": 5.332, \"y\": 5.68}, {\"title\": \"Constructing a Knowledge Graph for Vietnamese Legal Cases with  Heterogeneous Graphs\", \"topic\": \"Legal NLP\", \"x\": 5.231, \"y\": 5.86}, {\"title\": \"Exploring the impact of low-rank adaptation on the performance,  efficiency, and regularization of RLHF\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.209, \"y\": 2.064}, {\"title\": \"Context-aware Adversarial Attack on Named Entity Recognition\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.137, \"y\": 3.009}, {\"title\": \"Rethinking STS and NLI in Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.621, \"y\": 7.597}, {\"title\": \"ODSum: New Benchmarks for Open Domain Multi-Document Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.668, \"y\": 6.284}, {\"title\": \"Enhancing Large Language Model Induced Task-Oriented Dialogue Systems  Through Look-Forward Motivated Goals\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.503, \"y\": 3.617}, {\"title\": \"Contextual Label Projection for Cross-Lingual Structured Prediction\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.51, \"y\": 4.929}, {\"title\": \"Investigating Subtler Biases in LLMs: Ageism, Beauty, Institutional, and  Nationality Bias in Generative Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.438, \"y\": 4.352}, {\"title\": \"X-PARADE: Cross-Lingual Textual Entailment and Information Divergence  across Paragraphs\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.144, \"y\": 4.851}, {\"title\": \"MHLAT: Multi-hop Label-wise Attention Model for Automatic ICD Coding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.927, \"y\": 8.476}, {\"title\": \"Bias and Fairness in Chatbots: An Overview\", \"topic\": \"Bias in Language Models\", \"x\": 3.563, \"y\": 4.187}, {\"title\": \"SLIDE: Reference-free Evaluation for Machine Translation using a Sliding  Document Window\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.801, \"y\": 4.656}, {\"title\": \"S3-DST: Structured Open-Domain Dialogue Segmentation and State Tracking  in the Era of LLMs\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.62, \"y\": 3.895}, {\"title\": \"Self-training Strategies for Sentiment Analysis: An Empirical Study\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.514, \"y\": 6.652}, {\"title\": \"Frustratingly Simple Memory Efficiency for Pre-trained Language Models  via Dynamic Embedding Pruning\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.5, \"y\": 2.52}, {\"title\": \"Resolving Legalese: A Multilingual Exploration of Negation Scope  Resolution in Legal Documents\", \"topic\": \"Legal NLP\", \"x\": 5.244, \"y\": 5.699}, {\"title\": \"Fake News Detectors are Biased against Texts Generated by Large Language  Models\", \"topic\": \"Fake News Detection\", \"x\": 4.013, \"y\": 5.577}, {\"title\": \"Chain-of-Thought Reasoning is a Policy Improvement Operator\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.639, \"y\": 2.194}, {\"title\": \"Casteist but Not Racist? Quantifying Disparities in Large Language Model  Bias between India and the West\", \"topic\": \"Bias in Language Models\", \"x\": 3.43, \"y\": 4.443}, {\"title\": \"How Transferable are Attribute Controllers on Pretrained Multilingual  Translation Models?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.491, \"y\": 4.652}, {\"title\": \"Augmenting conformers with structured state-space sequence models for  online speech recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.236, \"y\": 5.0}, {\"title\": \"Connecting Large Language Models with Evolutionary Algorithms Yields  Powerful Prompt Optimizers\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.364, \"y\": 3.124}, {\"title\": \"Towards Practical and Efficient Image-to-Speech Captioning with  Vision-Language Pre-training and Multi-modal Tokens\", \"topic\": \"Multimodal Language Models\", \"x\": 8.892, \"y\": 7.426}, {\"title\": \"Mixture Encoder Supporting Continuous Speech Separation for Meeting  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.196, \"y\": 5.285}, {\"title\": \"MAPLE: Mobile App Prediction Leveraging Large Language Model Embeddings\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.992, \"y\": 2.901}, {\"title\": \"DiaCorrect: Error Correction Back-end For Speaker Diarization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.169, \"y\": 5.432}, {\"title\": \"Self-Consistent Narrative Prompts on Abductive Natural Language  Inference\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.189, \"y\": 3.305}, {\"title\": \"Cross-lingual Knowledge Distillation via Flow-based Voice Conversion for  Robust Polyglot Text-To-Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.5, \"y\": 5.474}, {\"title\": \"Investigating Answerability of LLMs for Long-Form Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.356, \"y\": 4.988}, {\"title\": \"Encoded Summarization: Summarizing Documents into Continuous Vector  Space for Legal Case Retrieval\", \"topic\": \"Legal NLP\", \"x\": 5.185, \"y\": 5.875}, {\"title\": \"Multilingual Sentence-Level Semantic Search using Meta-Distillation  Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.345, \"y\": 5.0}, {\"title\": \"Using Large Language Model to Solve and Explain Physics Word Problems  Approaching Human Level\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.782, \"y\": 3.105}, {\"title\": \"LASER: LLM Agent with State-Space Exploration for Web Navigation\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.784, \"y\": 2.434}, {\"title\": \"RADE: Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.451, \"y\": 3.904}, {\"title\": \"Unimodal Aggregation for CTC-based Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.996, \"y\": 5.096}, {\"title\": \"PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech  Using Natural Language Descriptions\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.519, \"y\": 5.893}, {\"title\": \"InvestLM: A Large Language Model for Investment using Financial Domain  Instruction Tuning\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.819, \"y\": 6.898}, {\"title\": \"Research on Joint Representation Learning Methods for Entity  Neighborhood Information and Description Information\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.158, \"y\": 6.135}, {\"title\": \"Characterizing the temporal dynamics of universal speech representations  for generalizable deepfake detection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.89, \"y\": 5.395}, {\"title\": \"Connecting the Dots in News Analysis: Bridging the Cross-Disciplinary  Disparities in Media Bias and Framing\", \"topic\": \"Fake News Detection\", \"x\": 3.853, \"y\": 5.574}, {\"title\": \"Bias in News Summarization: Measures, Pitfalls and Corpora\", \"topic\": \"Bias in Language Models\", \"x\": 3.504, \"y\": 4.644}, {\"title\": \"AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised  Features for Audio-Visual Speech Enhancement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.631, \"y\": 5.88}, {\"title\": \"An Empirical Evaluation of Prompting Strategies for Large Language  Models in Zero-Shot Clinical Natural Language Processing\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 5.939, \"y\": 7.713}, {\"title\": \"DiariST: Streaming Speech Translation with Speaker Diarization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.624, \"y\": 5.266}, {\"title\": \"MMICL: Empowering Vision-language Model with Multi-Modal In-Context  Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.439, \"y\": 7.343}, {\"title\": \"Ambiguity-Aware In-Context Learning with Large Language Models\", \"topic\": \"In-Context Learning\", \"x\": 8.293, \"y\": 3.402}, {\"title\": \"Agents: An Open-source Framework for Autonomous Language Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.686, \"y\": 2.845}, {\"title\": \"The Rise and Potential of Large Language Model Based Agents: A Survey\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.513, \"y\": 2.893}, {\"title\": \"CiwaGAN: Articulatory information exchange\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.435, \"y\": 5.273}, {\"title\": \"Text Classification of Cancer Clinical Trial Eligibility Criteria\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.664, \"y\": 7.87}, {\"title\": \"TextBind: Multi-turn Interleaved Multimodal Instruction-following in the  Wild\", \"topic\": \"Multimodal Language Models\", \"x\": 8.271, \"y\": 7.172}, {\"title\": \"Echotune: A Modular Extractor Leveraging the Variable-Length Nature of  Speech in ASR Tasks\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.198, \"y\": 5.005}, {\"title\": \"Generative AI Text Classification using Ensemble LLM Approaches\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.221, \"y\": 4.8}, {\"title\": \"The complementary roles of non-verbal cues for Robust Pronunciation  Assessment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.972, \"y\": 5.449}, {\"title\": \"Explaining Speech Classification Models via Word-Level Audio Segments  and Paralinguistic Features\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.938, \"y\": 3.976}, {\"title\": \"PerPLM: Personalized Fine-tuning of Pretrained Language Models via  Writer-specific Intermediate Learning and Prompts\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.7, \"y\": 3.314}, {\"title\": \"L1-aware Multilingual Mispronunciation Detection Framework\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.864, \"y\": 5.471}, {\"title\": \"Tree of Uncertain Thoughts Reasoning for Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.438, \"y\": 2.526}, {\"title\": \"Detecting ChatGPT: A Survey of the State of Detecting ChatGPT-Generated  Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.298, \"y\": 4.715}, {\"title\": \"A Conversation is Worth A Thousand Recommendations: A Survey of Holistic  Conversational Recommender Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.98, \"y\": 3.222}, {\"title\": \"Aligning Speakers: Evaluating and Visualizing Text-based Diarization  Using Efficient Multiple Sequence Alignment (Extended Version)\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.927, \"y\": 5.439}, {\"title\": \"Incorporating Class-based Language Model for Named Entity Recognition in  Factorized Neural Transducer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.041, \"y\": 5.155}, {\"title\": \"Detecting Misinformation with LLM-Predicted Credibility Signals and Weak  Supervision\", \"topic\": \"Fake News Detection\", \"x\": 4.041, \"y\": 5.529}, {\"title\": \"DBLPLink: An Entity Linker for the DBLP Scholarly Knowledge Graph\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.027, \"y\": 6.589}, {\"title\": \"Direct Text to Speech Translation System using Acoustic Units\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.563, \"y\": 5.372}, {\"title\": \"Adapted Large Language Models Can Outperform Medical Experts in Clinical  Text Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.731, \"y\": 8.0}, {\"title\": \"ChatGPT MT: Competitive for High- (but not Low-) Resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.301, \"y\": 4.3}, {\"title\": \"PromptASR for contextualized ASR with controllable style\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.918, \"y\": 5.224}, {\"title\": \"CPPF: A contextual and post-processing-free model for automatic speech  recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.153, \"y\": 5.285}, {\"title\": \"An Interactive Framework for Profiling News Media Sources\", \"topic\": \"Fake News Detection\", \"x\": 4.024, \"y\": 5.835}, {\"title\": \"Hybrid Attention-based Encoder-decoder Model for Efficient Language  Model Adaptation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.925, \"y\": 5.168}, {\"title\": \"Traveling Words: A Geometric Interpretation of Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.414, \"y\": 3.662}, {\"title\": \"In-Contextual Gender Bias Suppression for Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.382, \"y\": 4.167}, {\"title\": \"RAIN: Your Language Models Can Align Themselves without Finetuning\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.485, \"y\": 1.498}, {\"title\": \"Sight Beyond Text: Multi-Modal Training Enhances LLMs in Truthfulness  and Ethics\", \"topic\": \"Multimodal Language Models\", \"x\": 8.258, \"y\": 7.378}, {\"title\": \"Mitigating Hallucinations and Off-target Machine Translation with  Source-Contrastive and Language-Contrastive Decoding\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.259, \"y\": 1.092}, {\"title\": \"Can Whisper perform speech-based in-context learning?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.136, \"y\": 5.221}, {\"title\": \"Dynamic Causal Disentanglement Model for Dialogue Emotion Detection\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.289, \"y\": 7.713}, {\"title\": \"Cognitive Mirage: A Review of Hallucinations in Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.138, \"y\": 1.096}, {\"title\": \"Scaled Prompt-Tuning for Few-Shot Natural Language Generation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.983, \"y\": 3.04}, {\"title\": \"Simultaneous Machine Translation with Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.892, \"y\": 4.501}, {\"title\": \"VLSlice: Interactive Vision-and-Language Slice Discovery\", \"topic\": \"Multimodal Language Models\", \"x\": 8.587, \"y\": 7.62}, {\"title\": \"Benchmarking Procedural Language Understanding for Low-Resource  Languages: A Case Study on Turkish\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.019, \"y\": 4.362}, {\"title\": \"Query-Dependent Prompt Evaluation and Optimization with Offline Inverse  RL\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.381, \"y\": 3.145}, {\"title\": \"Statistical Rejection Sampling Improves Preference Optimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.288, \"y\": 1.316}, {\"title\": \"How We Define Harm Impacts Data Annotations: Explaining How Annotators  Distinguish Hateful, Offensive, and Toxic Comments\", \"topic\": \"Hate Speech Detection\", \"x\": 3.025, \"y\": 5.188}, {\"title\": \"Measuring Catastrophic Forgetting in Cross-Lingual Transfer Paradigms:  Exploring Tuning Strategies\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.381, \"y\": 4.636}, {\"title\": \"RAP-Gen: Retrieval-Augmented Patch Generation with CodeT5 for Automatic  Program Repair\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.445, \"y\": 2.205}, {\"title\": \"Content Reduction, Surprisal and Information Density Estimation for Long  Documents\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.942, \"y\": 7.423}, {\"title\": \"Kid-Whisper: Towards Bridging the Performance Gap in Automatic Speech  Recognition for Children VS. Adults\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.221, \"y\": 5.386}, {\"title\": \"Improving Robustness of Neural Inverse Text Normalization via  Data-Augmentation, Semi-Supervised Learning, and Post-Aligning Method\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.003, \"y\": 5.177}, {\"title\": \"Performance of ChatGPT-3.5 and GPT-4 on the United States Medical  Licensing Examination With and Without Distractions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.542, \"y\": 8.072}, {\"title\": \"Evaluating the Ebb and Flow: An In-depth Analysis of Question-Answering  Trends across Diverse Platforms\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.236, \"y\": 5.254}, {\"title\": \"Language Models as Black-Box Optimizers for Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.67, \"y\": 7.393}, {\"title\": \"Answering Subjective Induction Questions on Products by Summarizing  Multi-sources Multi-viewpoints Knowledge\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.019, \"y\": 5.645}, {\"title\": \"A Survey of Hallucination in Large Foundation Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.137, \"y\": 1.105}, {\"title\": \"Challenges in Annotating Datasets to Quantify Bias in Under-represented  Society\", \"topic\": \"Bias in Language Models\", \"x\": 3.468, \"y\": 4.509}, {\"title\": \"Hi Model, generating 'nice' instead of 'good' is not as bad as  generating 'rice'! Towards Context and Semantic Infused Dialogue Generation  Loss Function and Evaluation Metric\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.533, \"y\": 3.872}, {\"title\": \"Applying BioBERT to Extract Germline Gene-Disease Associations for  Building a Knowledge Graph from the Biomedical Literature\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.238, \"y\": 7.419}, {\"title\": \"Hypothesis Search: Inductive Reasoning with Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.689, \"y\": 2.953}, {\"title\": \"Large Language Model for Science: A Study on P vs. NP\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.673, \"y\": 3.227}, {\"title\": \"MAmmoTH: Building Math Generalist Models through Hybrid Instruction  Tuning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.249, \"y\": 2.741}, {\"title\": \"Incorporating Pre-trained Model Prompting in Multimodal Stock Volume  Movement Prediction\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.752, \"y\": 6.835}, {\"title\": \"ITI-GEN: Inclusive Text-to-Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.898, \"y\": 6.831}, {\"title\": \"An Empirical Study of NetOps Capability of Pre-Trained Large Language  Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.329, \"y\": 3.992}, {\"title\": \"NExT-GPT: Any-to-Any Multimodal LLM\", \"topic\": \"Multimodal Language Models\", \"x\": 8.314, \"y\": 7.291}, {\"title\": \"Black-Box Analysis: GPTs Across Time in Legal Textual Entailment Task\", \"topic\": \"Legal NLP\", \"x\": 5.276, \"y\": 5.698}, {\"title\": \"NeCo@ALQAC 2023: Legal Domain Knowledge Acquisition for Low-Resource  Languages through Data Enrichment\", \"topic\": \"Legal NLP\", \"x\": 5.392, \"y\": 5.581}, {\"title\": \"Zero-shot Learning with Minimum Instruction to Extract Social  Determinants and Family History from Clinical Notes using GPT Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.458, \"y\": 7.756}, {\"title\": \"LeBenchmark 2.0: a Standardized, Replicable and Enhanced Framework for  Self-supervised Representations of French Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.623, \"y\": 4.934}, {\"title\": \"Evaluating the Deductive Competence of Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.575, \"y\": 3.133}, {\"title\": \"Panoptic Vision-Language Feature Fields\", \"topic\": \"Multimodal Language Models\", \"x\": 8.803, \"y\": 7.093}, {\"title\": \"DoG-Instruct: Towards Premium Instruction-Tuning Data via Text-Grounded  Instruction Wrapping\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.091, \"y\": 2.291}, {\"title\": \"Multi-Modal Automatic Prosody Annotation with Contrastive Pretraining of  SSWP\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.633, \"y\": 5.667}, {\"title\": \"Experimenting with UD Adaptation of an Unsupervised Rule-based Approach  for Sentiment Analysis of Mexican Tourist Texts\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.33, \"y\": 6.717}, {\"title\": \"Analysing Cross-Lingual Transfer in Low-Resourced African Named Entity  Recognition\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.381, \"y\": 4.804}, {\"title\": \"Minuteman: Machine and Human Joining Forces in Meeting Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.541, \"y\": 6.316}, {\"title\": \"CONFLATOR: Incorporating Switching Point based Rotatory Positional  Encodings for Code-Mixed Language Modeling\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.665, \"y\": 4.932}, {\"title\": \"Detecting Natural Language Biases with Prompt-based Learning\", \"topic\": \"Bias in Language Models\", \"x\": 3.442, \"y\": 4.362}, {\"title\": \"Exploring the Law of Numbers: Evidence from China's Real Estate\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.899, \"y\": 6.751}, {\"title\": \"Quantifying and Attributing the Hallucination of Large Language Models  via Association Analysis\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.176, \"y\": 1.115}, {\"title\": \"Understanding the Impact of Post-Training Quantization on Large Language  Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.721, \"y\": 2.185}, {\"title\": \"Two is Better Than One: Answering Complex Questions by Multiple  Knowledge Sources with Generalized Links\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.644, \"y\": 5.488}, {\"title\": \"DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.852, \"y\": 3.205}, {\"title\": \"Large Language Models for Difficulty Estimation of Foreign Language  Content with Application to Language Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.998, \"y\": 4.319}, {\"title\": \"AGent: A Novel Pipeline for Automatically Creating Unanswerable  Questions\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.292, \"y\": 5.107}, {\"title\": \"An Appraisal-Based Chain-Of-Emotion Architecture for Affective Language  Model Game Agents\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.522, \"y\": 7.647}, {\"title\": \"The Effect of Alignment Objectives on Code-Switching Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.722, \"y\": 4.803}, {\"title\": \"FOLLOWUPQG: Towards Information-Seeking Follow-up Question Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.206, \"y\": 4.915}, {\"title\": \"Machine Translation Models Stand Strong in the Face of Adversarial  Attacks\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.121, \"y\": 3.009}, {\"title\": \"Multi-document Summarization: A Comparative Evaluation\", \"topic\": \"Text Summarization\", \"x\": 5.596, \"y\": 6.342}, {\"title\": \"Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect  Representations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.222, \"y\": 7.84}, {\"title\": \"Leveraging Large Language Models for Exploiting ASR Uncertainty\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.012, \"y\": 5.083}, {\"title\": \"Data Augmentation for Conversational AI\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.31, \"y\": 3.91}, {\"title\": \"Towards Better Multi-modal Keyphrase Generation via Visual Entity  Enhancement and Multi-granularity Image Noise Filtering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.262, \"y\": 7.048}, {\"title\": \"EPA: Easy Prompt Augmentation on Large Language Models via Multiple  Sources and Multiple Targets\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.579, \"y\": 3.271}, {\"title\": \"Toward Reproducing Network Research Results Using Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.698, \"y\": 3.93}, {\"title\": \"Code-Style In-Context Learning for Knowledge-Based Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.692, \"y\": 5.314}, {\"title\": \"Embedding structure matters: Comparing methods to adapt multilingual  vocabularies to new languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.333, \"y\": 4.318}, {\"title\": \"Linking Symptom Inventories using Semantic Textual Similarity\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.599, \"y\": 8.031}, {\"title\": \"Four Ways to Improve Verbo-visual Fusion for Dense 3D Visual Grounding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.818, \"y\": 7.336}, {\"title\": \"Retrieving Evidence from EHRs with LLMs: Possibilities and Challenges\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.793, \"y\": 8.181}, {\"title\": \"CSPRD: A Financial Policy Retrieval Dataset for Chinese Stock Market\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.809, \"y\": 6.725}, {\"title\": \"Beyond Static Datasets: A Deep Interaction Approach to LLM Evaluation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.139, \"y\": 3.71}, {\"title\": \"Fuzzy Fingerprinting Transformer Language-Models for Emotion Recognition  in Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.293, \"y\": 7.79}, {\"title\": \"From Sparse to Dense: GPT-4 Summarization with Chain of Density  Prompting\", \"topic\": \"Text Summarization\", \"x\": 5.541, \"y\": 6.302}, {\"title\": \"UQ at #SMM4H 2023: ALEX for Public Health Analysis with Social Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.256, \"y\": 7.319}, {\"title\": \"Don't Ignore Dual Logic Ability of LLMs while Privatizing: A  Data-Intensive Analysis in Medical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.583, \"y\": 7.851}, {\"title\": \"Knowledge-tuning Large Language Models with Structured Medical Knowledge  Bases for Reliable Response Generation in Chinese\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.889, \"y\": 7.882}, {\"title\": \"Manifold-based Verbalizer Space Re-embedding for Tuning-free  Prompt-based Classification\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.599, \"y\": 3.458}, {\"title\": \"Cross-Utterance Conditioned VAE for Speech Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.603, \"y\": 5.94}, {\"title\": \"NESTLE: a No-Code Tool for Statistical Analysis of Legal Corpus\", \"topic\": \"Legal NLP\", \"x\": 5.127, \"y\": 5.68}, {\"title\": \"Unsupervised Multi-document Summarization with Holistic Inference\", \"topic\": \"Text Summarization\", \"x\": 5.602, \"y\": 6.406}, {\"title\": \"Evaluation and Enhancement of Semantic Grounding in Large  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.702, \"y\": 7.523}, {\"title\": \"Multiple Representation Transfer from Large Language Models to  End-to-End ASR Systems\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.64, \"y\": 5.037}, {\"title\": \"TIDE: Textual Identity Detection for Evaluating and Augmenting  Classification and Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.36, \"y\": 4.267}, {\"title\": \"ConDA: Contrastive Domain Adaptation for AI-generated Text Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.076, \"y\": 5.124}, {\"title\": \"LanSER: Language-Model Supported Speech Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.184, \"y\": 7.854}, {\"title\": \"ImageBind-LLM: Multi-modality Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.347, \"y\": 7.294}, {\"title\": \"DoLa: Decoding by Contrasting Layers Improves Factuality in Large  Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.434, \"y\": 1.303}, {\"title\": \"Introducing \\\"Forecast Utterance\\\" for Conversational Data Science\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.342, \"y\": 3.89}, {\"title\": \"OpinionGPT: Modelling Explicit Biases in Instruction-Tuned LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.523, \"y\": 4.273}, {\"title\": \"USA: Universal Sentiment Analysis Model & Construction of Japanese  Sentiment Text Classification and Part of Speech Dataset\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.514, \"y\": 6.715}, {\"title\": \"Exploring an LM to generate Prolog Predicates from Mathematics Questions\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.892, \"y\": 2.647}, {\"title\": \"Evaluating ChatGPT as a Recommender System: A Rigorous Approach\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.949, \"y\": 3.085}, {\"title\": \"Supervised Learning and Large Language Model Benchmarks on Mental Health  Datasets: Cognitive Distortions and Suicidal Risks in Chinese Social Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.258, \"y\": 7.511}, {\"title\": \"From Base to Conversational: Japanese Instruction Dataset and Tuning  Large Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.204, \"y\": 2.438}, {\"title\": \"Large Language Models as Optimizers\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.313, \"y\": 3.132}, {\"title\": \"Gender-specific Machine Translation with Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 2.979, \"y\": 4.353}, {\"title\": \"GPT-InvestAR: Enhancing Stock Investment Strategies through Annual  Report Analysis with Large Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.866, \"y\": 6.874}, {\"title\": \"Everyone Deserves A Reward: Learning Customized Human Preferences\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.239, \"y\": 1.427}, {\"title\": \"On the Challenges of Building Datasets for Hate Speech Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.756, \"y\": 5.336}, {\"title\": \"Aligning Large Language Models for Clinical Tasks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.741, \"y\": 7.974}, {\"title\": \"Promoting Open-domain Dialogue Generation through Learning Pattern  Information between Contexts and Responses\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.519, \"y\": 3.93}, {\"title\": \"GRASS: Unified Generation Model for Speech-to-Semantic Tasks\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.524, \"y\": 5.382}, {\"title\": \"GPT Can Solve Mathematical Problems Without a Calculator\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.482, \"y\": 2.825}, {\"title\": \"HC3 Plus: A Semantic-Invariant Human ChatGPT Comparison Corpus\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.463, \"y\": 4.711}, {\"title\": \"Offensive Hebrew Corpus and Detection using BERT\", \"topic\": \"Hate Speech Detection\", \"x\": 2.769, \"y\": 5.405}, {\"title\": \"A Joint Study of Phrase Grounding and Task Performance in Vision and  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.667, \"y\": 7.181}, {\"title\": \"Implicit Design Choices and Their Impact on Emotion Recognition Model  Development and Evaluation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.322, \"y\": 7.642}, {\"title\": \"Zero-Resource Hallucination Prevention for Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.212, \"y\": 1.123}, {\"title\": \"Scaling Autoregressive Multi-Modal Models: Pretraining and Instruction  Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.435, \"y\": 7.302}, {\"title\": \"Cognitive Architectures for Language Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.634, \"y\": 2.779}, {\"title\": \"Weigh Your Own Words: Improving Hate Speech Counter Narrative Generation  via Attention Regularization\", \"topic\": \"Hate Speech Detection\", \"x\": 2.699, \"y\": 5.301}, {\"title\": \"PromptTTS 2: Describing and Generating Voices with Text Prompt\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.529, \"y\": 5.896}, {\"title\": \"Augmenting Black-box LLMs with Medical Textbooks for Clinical Question  Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.882, \"y\": 7.781}, {\"title\": \"Bring the Noise: Introducing Noise Robustness to Pretrained Automatic  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.092, \"y\": 5.118}, {\"title\": \"Evaluating Methods for Ground-Truth-Free Foreign Accent Conversion\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.841, \"y\": 5.445}, {\"title\": \"Leveraging Label Information for Multimodal Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.247, \"y\": 7.74}, {\"title\": \"Where are We in Event-centric Emotion Analysis? Bridging Emotion Role  Labeling and Appraisal-based Approaches\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.551, \"y\": 7.342}, {\"title\": \"An Automatic Evaluation Framework for Multi-turn Medical Consultations  Capabilities of Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.633, \"y\": 8.091}, {\"title\": \"Bilevel Scheduled Sampling for Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.573, \"y\": 3.812}, {\"title\": \"TODM: Train Once Deploy Many Efficient Supernet-Based RNN-T Compression  For On-device ASR Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.189, \"y\": 4.86}, {\"title\": \"CodeApex: A Bilingual Programming Evaluation Benchmark for Large  Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.453, \"y\": 2.606}, {\"title\": \"QuantEase: Optimization-based Quantization for Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.786, \"y\": 2.153}, {\"title\": \"ChatGPT Assisting Diagnosis of Neuro-ophthalmology Diseases Based on  Case Reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.009, \"y\": 8.28}, {\"title\": \"One Wide Feedforward is All You Need\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.892, \"y\": 3.317}, {\"title\": \"Into the Single Cell Multiverse: an End-to-End Dataset for Procedural  Knowledge Extraction in Biomedical Texts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.078, \"y\": 7.333}, {\"title\": \"An Empirical Analysis for Zero-Shot Multi-Label Classification on  COVID-19 CT Scans and Uncurated Reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.25, \"y\": 8.46}, {\"title\": \"Prompting or Fine-tuning? A Comparative Study of Large Language Models  for Taxonomy Construction\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.608, \"y\": 3.046}, {\"title\": \"MathAttack: Attacking Large Language Models Towards Math Solving Ability\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.806, \"y\": 2.824}, {\"title\": \"Donkii: Can Annotation Error Detection Methods Find Errors in  Instruction-Tuning Datasets?\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.224, \"y\": 2.311}, {\"title\": \"Fine-grained Affective Processing Capabilities Emerging from Large  Language Models\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.512, \"y\": 7.568}, {\"title\": \"Evolving linguistic divergence on polarizing social media\", \"topic\": \"Fake News Detection\", \"x\": 3.535, \"y\": 5.646}, {\"title\": \"A Comparative Analysis of Pretrained Language Models for Text-to-Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.581, \"y\": 5.592}, {\"title\": \"NumHG: A Dataset for Number-Focused Headline Generation\", \"topic\": \"Text Summarization\", \"x\": 5.532, \"y\": 6.347}, {\"title\": \"Open Sesame! Universal Black Box Jailbreaking of Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.308, \"y\": 2.331}, {\"title\": \"Text-Only Domain Adaptation for End-to-End Speech Recognition through  Down-Sampling Acoustic Representation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.969, \"y\": 5.151}, {\"title\": \"SememeASR: Boosting Performance of End-to-End Speech Recognition against  Domain and Long-Tailed Data Shift with Sememe Semantic Knowledge\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.126, \"y\": 5.218}, {\"title\": \"Benchmarking Large Language Models in Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.039, \"y\": 4.556}, {\"title\": \"Hateful Messages: A Conversational Data Set of Hate Speech produced by  Adolescents on Discord\", \"topic\": \"Hate Speech Detection\", \"x\": 2.831, \"y\": 5.386}, {\"title\": \"Zero-shot information extraction from radiological reports using ChatGPT\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.023, \"y\": 7.984}, {\"title\": \"Learning a Patent-Informed Biomedical Knowledge Graph Reveals  Technological Potential of Drug Repositioning Candidates\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.123, \"y\": 7.261}, {\"title\": \"Code Representation Pre-training with Complements from Program  Executions\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.637, \"y\": 2.432}, {\"title\": \"BDC-Adapter: Brownian Distance Covariance for Better Vision-Language  Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.666, \"y\": 7.206}, {\"title\": \"Large AI Model Empowered Multimodal Semantic Communications\", \"topic\": \"Multimodal Language Models\", \"x\": 8.201, \"y\": 7.173}, {\"title\": \"Representations Matter: Embedding Modes of Large Language Models using  Dynamic Mode Decomposition\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.157, \"y\": 1.118}, {\"title\": \"Siren's Song in the AI Ocean: A Survey on Hallucination in Large  Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.121, \"y\": 1.107}, {\"title\": \"Large Language Models for Generative Recommendation: A Survey and  Visionary Discussions\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.009, \"y\": 2.95}, {\"title\": \"MedChatZH: a Better Medical Adviser Learns from Better Instructions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.803, \"y\": 8.027}, {\"title\": \"A Study on the Implementation of Generative AI Services Using an  Enterprise Data-Based LLM Application Architecture\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.915, \"y\": 4.493}, {\"title\": \"Explainability for Large Language Models: A Survey\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.01, \"y\": 3.773}, {\"title\": \"ModelScope-Agent: Building Your Customizable Agent System with  Open-source Large Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.748, \"y\": 2.729}, {\"title\": \"Knowledge Graph Embeddings for Multi-Lingual Structured Representations  of Radiology Reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.185, \"y\": 8.45}, {\"title\": \"BLSP: Bootstrapping Language-Speech Pre-training via Behavior Alignment  of Continuation Writing\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.457, \"y\": 5.197}, {\"title\": \"Evaluating Transformer's Ability to Learn Mildly Context-Sensitive  Languages\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.53, \"y\": 3.359}, {\"title\": \"Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights,  and Duties\", \"topic\": \"Bias in Language Models\", \"x\": 4.369, \"y\": 3.828}, {\"title\": \"Bias and Fairness in Large Language Models: A Survey\", \"topic\": \"Bias in Language Models\", \"x\": 3.345, \"y\": 4.337}, {\"title\": \"Efficient RLHF: Reducing the Memory Usage of PPO\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.223, \"y\": 1.447}, {\"title\": \"Contextual Biasing of Named-Entities with Large Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.348, \"y\": 4.965}, {\"title\": \"Point-Bind & Point-LLM: Aligning Point Cloud with Multi-modality for 3D  Understanding, Generation, and Instruction Following\", \"topic\": \"Multimodal Language Models\", \"x\": 8.818, \"y\": 7.175}, {\"title\": \"Baseline Defenses for Adversarial Attacks Against Aligned Language  Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.362, \"y\": 2.815}, {\"title\": \"Learning Speech Representation From Contrastive Token-Acoustic  Pretraining\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.832, \"y\": 5.295}, {\"title\": \"BatchPrompt: Accomplish more with less\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.299, \"y\": 3.026}, {\"title\": \"Enhancing the vocal range of single-speaker singing voice synthesis with  melody-unsupervised pre-training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.591, \"y\": 5.892}, {\"title\": \"RLAIF: Scaling Reinforcement Learning from Human Feedback with AI  Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.181, \"y\": 1.482}, {\"title\": \"Detecting Suicidality in Arabic Tweets Using Machine Learning and Deep  Learning Techniques\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.134, \"y\": 7.303}, {\"title\": \"ALJP: An Arabic Legal Judgment Prediction in Personal Status Cases Using  Machine Learning Models\", \"topic\": \"Legal NLP\", \"x\": 5.001, \"y\": 5.711}, {\"title\": \"Publicly Shareable Clinical Large Language Model Built on Synthetic  Clinical Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.749, \"y\": 8.046}, {\"title\": \"JoTR: A Joint Transformer and Reinforcement Learning Framework for  Dialog Policy Learning\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.319, \"y\": 3.483}, {\"title\": \"The FruitShell French synthesis system at the Blizzard 2023 Challenge\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.737, \"y\": 5.683}, {\"title\": \"Towards Addressing the Misalignment of Object Proposal Evaluation for  Vision-Language Tasks via Semantic Grounding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.699, \"y\": 7.366}, {\"title\": \"Large Language Models for Semantic Monitoring of Corporate Disclosures:  A Case Study on Korea's Top 50 KOSPI Companies\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.122, \"y\": 6.275}, {\"title\": \"Will Sentiment Analysis Need Subculture? A New Data Augmentation  Approach\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.369, \"y\": 6.781}, {\"title\": \"QS-TTS: Towards Semi-Supervised Text-to-Speech Synthesis via  Vector-Quantized Self-Supervised Speech Representation Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.685, \"y\": 5.722}, {\"title\": \"Large language models in medicine: the potentials and pitfalls\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.509, \"y\": 7.82}, {\"title\": \"PointLLM: Empowering Large Language Models to Understand Point Clouds\", \"topic\": \"Multimodal Language Models\", \"x\": 8.938, \"y\": 7.192}, {\"title\": \"Transformers as Support Vector Machines\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.756, \"y\": 3.327}, {\"title\": \"TouchStone: Evaluating Vision-Language Models by Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.197, \"y\": 7.724}, {\"title\": \"The Gender-GAP Pipeline: A Gender-Aware Polyglot Pipeline for Gender  Characterisation in 55 Languages\", \"topic\": \"Bias in Language Models\", \"x\": 3.176, \"y\": 4.345}, {\"title\": \"Enhancing PLM Performance on Labour Market Tasks via Instruction-based  Finetuning and Prompt-tuning with Rules\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.838, \"y\": 3.053}, {\"title\": \"Ladder-of-Thought: Using Knowledge as Steps to Elevate Stance Detection\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 3.444, \"y\": 5.766}, {\"title\": \"Exploring Cross-Cultural Differences in English Hate Speech Annotations:  From Dataset Construction to Analysis\", \"topic\": \"Hate Speech Detection\", \"x\": 2.815, \"y\": 5.371}, {\"title\": \"GPT has become financially literate: Insights from financial literacy  tests of GPT and a preliminary test of how people use it as a source of  advice\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.871, \"y\": 6.84}, {\"title\": \"SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language  Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.416, \"y\": 5.331}, {\"title\": \"Using Large Language Models to Automate Category and Trend Analysis of  Scientific Articles: An Application in Ophthalmology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.115, \"y\": 8.09}, {\"title\": \"Towards Spontaneous Style Modeling with Semi-supervised Pre-training for  Conversational Text-to-Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.612, \"y\": 5.88}, {\"title\": \"Interpreting Sentiment Composition with Latent Semantic Tree\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.259, \"y\": 6.833}, {\"title\": \"Improving Mandarin Prosodic Structure Prediction with Multi-level  Contextual Information\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.61, \"y\": 5.751}, {\"title\": \"Thesis Distillation: Investigating The Impact of Bias in NLP Models on  Hate Speech Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.849, \"y\": 5.067}, {\"title\": \"Time-Varying Quasi-Closed-Phase Analysis for Accurate Formant Tracking  in Speech Signals\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.946, \"y\": 5.647}, {\"title\": \"The Smart Data Extractor, a Clinician Friendly Solution to Accelerate  and Improve the Data Collection During Clinical Trials\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.658, \"y\": 7.759}, {\"title\": \"Companion Animal Disease Diagnostics based on Literal-aware Medical  Knowledge Graph Representation Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.015, \"y\": 8.043}, {\"title\": \"Sparkles: Unlocking Chats Across Multiple Images for Multimodal  Instruction-Following Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.146, \"y\": 7.486}, {\"title\": \"BioCoder: A Benchmark for Bioinformatics Code Generation with Large  Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.465, \"y\": 2.557}, {\"title\": \"Affective Visual Dialog: A Large-Scale Benchmark for Emotional Reasoning  Based on Visually Grounded Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.4, \"y\": 7.755}, {\"title\": \"Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open  Generative Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.47, \"y\": 3.927}, {\"title\": \"AsyncET: Asynchronous Learning for Knowledge Graph Entity Typing with  Auxiliary Relations\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.064, \"y\": 6.187}, {\"title\": \"FPTQ: Fine-grained Post-Training Quantization for Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.706, \"y\": 2.106}, {\"title\": \"Finding-Aware Anatomical Tokens for Chest X-Ray Automated Reporting\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.277, \"y\": 8.62}, {\"title\": \"Peering Through Preferences: Unraveling Feedback Acquisition for  Aligning Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.049, \"y\": 1.651}, {\"title\": \"HAlf-MAsked Model for Named Entity Sentiment analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.597, \"y\": 6.544}, {\"title\": \"Cyberbullying Detection for Low-resource Languages and Dialects: Review  of the State of the Art\", \"topic\": \"Hate Speech Detection\", \"x\": 2.801, \"y\": 5.433}, {\"title\": \"Multimodal Recommender Systems in the Prediction of Disease Comorbidity\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.963, \"y\": 8.416}, {\"title\": \"Extracting Mathematical Concepts with Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.964, \"y\": 3.16}, {\"title\": \"Radiology-Llama2: Best-in-Class Large Language Model for Radiology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.092, \"y\": 8.536}, {\"title\": \"When Do Program-of-Thoughts Work for Reasoning?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.955, \"y\": 2.339}, {\"title\": \"Vulgar Remarks Detection in Chittagonian Dialect of Bangla\", \"topic\": \"Hate Speech Detection\", \"x\": 2.743, \"y\": 5.454}, {\"title\": \"KGConv, a Conversational Corpus grounded in Wikidata\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.369, \"y\": 5.232}, {\"title\": \"A Classification-Guided Approach for Adversarial Attacks against Neural  Machine Translation\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.097, \"y\": 3.031}, {\"title\": \"PronounFlow: A Hybrid Approach for Calibrating Pronouns in Sentences\", \"topic\": \"Bias in Language Models\", \"x\": 3.058, \"y\": 4.371}, {\"title\": \"Multi-party Goal Tracking with LLMs: Comparing Pre-training,  Fine-tuning, and Prompt Engineering\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.53, \"y\": 3.561}, {\"title\": \"CLIPTrans: Transferring Visual Knowledge with Pre-trained Models for  Multimodal Machine Translation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.759, \"y\": 7.336}, {\"title\": \"Evaluation and Analysis of Hallucination in Large Vision-Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.2, \"y\": 1.046}, {\"title\": \"Killing two birds with one stone: Can an audio captioning system also be  used for audio-text retrieval?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.563, \"y\": 6.02}, {\"title\": \"Adapting Text-based Dialogue State Tracker for Spoken Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.448, \"y\": 3.864}, {\"title\": \"TransPrompt v2: A Transferable Prompting Framework for Cross-task Text  Classification\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.834, \"y\": 3.524}, {\"title\": \"Robust Open-Set Spoken Language Identification and the CU MultiLang  Dataset\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.406, \"y\": 5.32}, {\"title\": \"Gender bias and stereotypes in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.453, \"y\": 4.31}, {\"title\": \"Neural approaches to spoken content embedding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.517, \"y\": 5.084}, {\"title\": \"Multiscale Contextual Learning for Speech Emotion Recognition in  Emergency Call Center Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.305, \"y\": 7.825}, {\"title\": \"Attention Visualizer Package: Revealing Word Importance for Deeper  Insight into Encoder-Only Transformer Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.676, \"y\": 3.52}, {\"title\": \"Fine-Tuning Llama 2 Large Language Models for Detecting Online Sexual  Predatory Chats and Abusive Texts\", \"topic\": \"Hate Speech Detection\", \"x\": 2.921, \"y\": 5.267}, {\"title\": \"ANER: Arabic and Arabizi Named Entity Recognition using  Transformer-Based Approach\", \"topic\": \"Named Entity Recognition\", \"x\": 7.431, \"y\": 6.818}, {\"title\": \"Challenges of GPT-3-based Conversational Agents for Healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.582, \"y\": 7.853}, {\"title\": \"Breaking the Bank with ChatGPT: Few-Shot Text Classification for Finance\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.918, \"y\": 6.845}, {\"title\": \"An Empirical Study of Consistency Regularization for End-to-End  Speech-to-Text Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.321, \"y\": 5.035}, {\"title\": \"Biomedical Entity Linking with Triple-aware Pre-Training\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.406, \"y\": 7.513}, {\"title\": \"GADePo: Graph-Assisted Declarative Pooling Transformers for  Document-Level Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.937, \"y\": 6.768}, {\"title\": \"Effect of Attention and Self-Supervised Speech Embeddings on  Non-Semantic Speech Tasks\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.155, \"y\": 7.856}, {\"title\": \"DISC-MedLLM: Bridging General Large Language Models and Real-World  Medical Consultation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.786, \"y\": 7.98}, {\"title\": \"Leveraging A Medical Knowledge Graph into Large Language Models for  Diagnosis Prediction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.615, \"y\": 8.219}, {\"title\": \"Evaluating the Robustness to Instructions of Large Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.177, \"y\": 2.336}, {\"title\": \"Goodhart's Law Applies to NLP's Explanation Benchmarks\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.912, \"y\": 3.969}, {\"title\": \"SalesBot 2.0: A Human-Like Intent-Guided Chit-Chat Dataset\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.149, \"y\": 3.789}, {\"title\": \"Empowering Cross-lingual Abilities of Instruction-tuned Large Language  Models by Translation-following demonstrations\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.154, \"y\": 4.455}, {\"title\": \"Towards Vision-Language Mechanistic Interpretability: A Causal Tracing  Tool for BLIP\", \"topic\": \"Multimodal Language Models\", \"x\": 8.438, \"y\": 7.818}, {\"title\": \"Large Language Models Streamline Automated Machine Learning for Clinical  Studies\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.691, \"y\": 8.049}, {\"title\": \"Situated Natural Language Explanations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.807, \"y\": 3.691}, {\"title\": \"MedAlign: A Clinician-Generated Dataset for Instruction Following with  Electronic Medical Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.728, \"y\": 8.018}, {\"title\": \"VoiceBank-2023: A Multi-Speaker Mandarin Speech Corpus for Constructing  Personalized TTS Systems for the Speech Impaired\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.607, \"y\": 5.63}, {\"title\": \"Translate Meanings, Not Just Words: IdiomKB's Role in Optimizing  Idiomatic Translation with Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.706, \"y\": 4.575}, {\"title\": \"Improving Knowledge Distillation for BERT Models: Loss Functions,  Mapping Methods, and Weight Tuning\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.517, \"y\": 3.767}, {\"title\": \"Solving Math Word Problem with Problem Type Classification\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.069, \"y\": 2.719}, {\"title\": \"EditSum: A Retrieve-and-Edit Framework for Source Code Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.598, \"y\": 6.25}, {\"title\": \"WellXplain: Wellness Concept Extraction and Classification in Reddit  Posts for Mental Health Analysis\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.253, \"y\": 7.481}, {\"title\": \"Training and Meta-Evaluating Machine Translation Evaluation Metrics at  the Paragraph Level\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.794, \"y\": 4.73}, {\"title\": \"LSTM-based QoE Evaluation for Web Microservices' Reputation Scoring\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.667, \"y\": 6.551}, {\"title\": \"Ngambay-French Neural Machine Translation (sba-Fr)\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.689, \"y\": 4.961}, {\"title\": \"Decoupled Structure for Improved Adaptability of End-to-End Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.164, \"y\": 5.057}, {\"title\": \"Transforming the Output of Generative Pre-trained Transformer: The  Influence of the PGI Framework on Attention Dynamics\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.635, \"y\": 3.375}, {\"title\": \"Knowledge-Driven CoT: Exploring Faithful Reasoning in LLMs for  Knowledge-intensive Question Answering\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.654, \"y\": 2.365}, {\"title\": \"Chunk, Align, Select: A Simple Long-sequence Processing Method for  Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.795, \"y\": 3.319}, {\"title\": \"How to Evaluate the Generalization of Detection? A Benchmark for  Comprehensive Open-Vocabulary Detection\", \"topic\": \"Multimodal Language Models\", \"x\": 8.695, \"y\": 7.094}, {\"title\": \"Towards a Holistic Approach: Understanding Sociodemographic Biases in  NLP Models using an Interdisciplinary Lens\", \"topic\": \"Bias in Language Models\", \"x\": 3.339, \"y\": 4.578}, {\"title\": \"Financial News Analytics Using Fine-Tuned Llama 2 GPT Model\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.726, \"y\": 6.864}, {\"title\": \"Qwen-VL: A Versatile Vision-Language Model for Understanding,  Localization, Text Reading, and Beyond\", \"topic\": \"Multimodal Language Models\", \"x\": 8.394, \"y\": 7.68}, {\"title\": \"Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language  Pretraining?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.435, \"y\": 7.513}, {\"title\": \"Large Language Models Vote: Prompting for Rare Disease Identification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.797, \"y\": 8.016}, {\"title\": \"Inducing Causal Structure for Abstractive Text Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.628, \"y\": 6.271}, {\"title\": \"Real-time Detection of AI-Generated Speech for DeepFake Voice Conversion\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.015, \"y\": 5.571}, {\"title\": \"Harnessing the Power of David against Goliath: Exploring Instruction  Data Generation without Using Closed-Source Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.047, \"y\": 2.211}, {\"title\": \"Improving Translation Faithfulness of Large Language Models via  Augmenting Instructions\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.254, \"y\": 2.388}, {\"title\": \"From Chatter to Matter: Addressing Critical Steps of Emotion Recognition  Learning in Task-oriented Dialogue\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.302, \"y\": 7.771}, {\"title\": \"PromptMRG: Diagnosis-Driven Prompts for Medical Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.055, \"y\": 8.408}, {\"title\": \"CALM : A Multi-task Benchmark for Comprehensive Assessment of Language  Model Bias\", \"topic\": \"Bias in Language Models\", \"x\": 3.471, \"y\": 4.269}, {\"title\": \"CARE: Co-Attention Network for Joint Entity and Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.879, \"y\": 6.943}, {\"title\": \"MultiPA: A Multi-task Speech Pronunciation Assessment Model for Open  Response Scenarios\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.783, \"y\": 5.429}, {\"title\": \"GPTEval: A Survey on Assessments of ChatGPT and GPT-4\", \"topic\": \"Bias in Language Models\", \"x\": 5.34, \"y\": 4.543}, {\"title\": \"Considerations for health care institutions training large language  models on electronic health records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.619, \"y\": 7.986}, {\"title\": \"With a Little Help from your own Past: Prototypical Memory Networks for  Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.025, \"y\": 7.324}, {\"title\": \"Prompt2Model: Generating Deployable Models from Natural Language  Instructions\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.186, \"y\": 3.33}, {\"title\": \"Instruction Position Matters in Sequence Generation with Large Language  Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.147, \"y\": 2.452}, {\"title\": \"InstructionGPT-4: A 200-Instruction Paradigm for Fine-Tuning MiniGPT-4\", \"topic\": \"Multimodal Language Models\", \"x\": 8.33, \"y\": 7.441}, {\"title\": \"FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base  Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.68, \"y\": 5.388}, {\"title\": \"Aligning Language Models with Offline Learning from Human Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.295, \"y\": 1.354}, {\"title\": \"CgT-GAN: CLIP-guided Text GAN for Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.077, \"y\": 7.298}, {\"title\": \"IncreLoRA: Incremental Parameter Allocation Method for  Parameter-Efficient Fine-tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.178, \"y\": 2.076}, {\"title\": \"Large Multilingual Models Pivot Zero-Shot Multimodal Learning across  Languages\", \"topic\": \"Multimodal Language Models\", \"x\": 8.662, \"y\": 6.703}, {\"title\": \"PREFER: Prompt Ensemble Learning via Feedback-Reflect-Refine\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.296, \"y\": 3.074}, {\"title\": \"From Quantity to Quality: Boosting LLM Performance with Self-Guided Data  Selection for Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.161, \"y\": 2.257}, {\"title\": \"Prompt-Based Length Controlled Generation with Reinforcement Learning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.029, \"y\": 3.249}, {\"title\": \"Knowledge-injected Prompt Learning for Chinese Biomedical Entity  Normalization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.193, \"y\": 7.892}, {\"title\": \"Reranking Passages with Coarse-to-Fine Neural Retriever Enhanced by  List-Context Information\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.602, \"y\": 5.016}, {\"title\": \"Graecia capta ferum victorem cepit. Detecting Latin Allusions to Ancient  Greek Literature\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.774, \"y\": 5.358}, {\"title\": \"Topical-Chat: Towards Knowledge-Grounded Open-Domain Conversations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.187, \"y\": 3.854}, {\"title\": \"EVE: Efficient Vision-Language Pre-training with Masked Prediction and  Modality-Aware MoE\", \"topic\": \"Multimodal Language Models\", \"x\": 8.566, \"y\": 7.259}, {\"title\": \"Audio Generation with Multiple Conditional Diffusion Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.368, \"y\": 6.053}, {\"title\": \"Cabrita: closing the gap for foreign languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.222, \"y\": 4.18}, {\"title\": \"Towards an On-device Agent for Text Rewriting\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.358, \"y\": 2.285}, {\"title\": \"Identifying depression-related topics in smartphone-collected  free-response speech recordings using an automatic speech recognition system  and a deep learning topic model\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.199, \"y\": 7.511}, {\"title\": \"Halo: Estimation and Reduction of Hallucinations in Open-Source Weak  Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.153, \"y\": 1.071}, {\"title\": \"Knowledge Graph Prompting for Multi-Document Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.78, \"y\": 5.467}, {\"title\": \"StoryBench: A Multifaceted Benchmark for Continuous Story Visualization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.935, \"y\": 7.9}, {\"title\": \"Tryage: Real-time, intelligent Routing of User Prompts to Large Language  Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.453, \"y\": 2.987}, {\"title\": \"SeamlessM4T: Massively Multilingual & Multimodal Machine Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.131, \"y\": 5.071}, {\"title\": \"BELB: a Biomedical Entity Linking Benchmark\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.513, \"y\": 7.321}, {\"title\": \"Empowering Refugee Claimants and their Lawyers: Using Machine Learning  to Examine Decision-Making in Refugee Law\", \"topic\": \"Legal NLP\", \"x\": 4.973, \"y\": 5.807}, {\"title\": \"Unsupervised Prototype Adapter for Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.702, \"y\": 7.098}, {\"title\": \"Aspect-oriented Opinion Alignment Network for Aspect-Based Sentiment  Classification\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.102, \"y\": 6.849}, {\"title\": \"Inferring gender from name: a large scale performance evaluation study\", \"topic\": \"Bias in Language Models\", \"x\": 3.267, \"y\": 4.428}, {\"title\": \"A Survey on Large Language Model based Autonomous Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.488, \"y\": 2.905}, {\"title\": \"Extracting Relational Triples Based on Graph Recursive Neural Network  via Dynamic Feedback Forest Algorithm\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.974, \"y\": 6.894}, {\"title\": \"Convoifilter: A case study of doing cocktail party speech recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.296, \"y\": 5.169}, {\"title\": \"LEAP: Efficient and Automated Test Method for NLP Software\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.158, \"y\": 3.063}, {\"title\": \"HopPG: Self-Iterative Program Generation for Multi-Hop Question  Answering over Heterogeneous Knowledge\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.731, \"y\": 5.302}, {\"title\": \"ViCo: Engaging Video Comment Generation with Human Preference Rewards\", \"topic\": \"Multimodal Language Models\", \"x\": 9.03, \"y\": 7.828}, {\"title\": \"LLaMA-Reviewer: Advancing Code Review Automation with Large Language  Models through Parameter-Efficient Fine-Tuning\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.557, \"y\": 2.448}, {\"title\": \"Anonymity at Risk? Assessing Re-Identification Capabilities of Large  Language Models\", \"topic\": \"Legal NLP\", \"x\": 5.014, \"y\": 5.488}, {\"title\": \"\\\"Guinea Pig Trials\\\" Utilizing GPT: A Novel Smart Agent-Based Modeling  Approach for Studying Firm Competition and Collusion\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.241, \"y\": 2.99}, {\"title\": \"Analyzing Transformer Dynamics as Movement through Embedding Space\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.393, \"y\": 3.641}, {\"title\": \"AgentVerse: Facilitating Multi-Agent Collaboration and Exploring  Emergent Behaviors\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.3, \"y\": 2.825}, {\"title\": \"Instruction Tuning for Large Language Models: A Survey\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.191, \"y\": 2.291}, {\"title\": \"DepreSym: A Depression Symptom Annotated Corpus and the Role of LLMs as  Assessors of Psychological Markers\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.223, \"y\": 7.514}, {\"title\": \"Refashioning Emotion Recognition Modelling: The Advent of Generalised  Large Models\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.309, \"y\": 7.559}, {\"title\": \"LibriWASN: A Data Set for Meeting Separation, Diarization, and  Recognition with Asynchronous Recording Devices\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.123, \"y\": 5.402}, {\"title\": \"BAN-PL: a Novel Polish Dataset of Banned Harmful and Offensive Content  from Wykop.pl web service\", \"topic\": \"Hate Speech Detection\", \"x\": 2.866, \"y\": 5.347}, {\"title\": \"Exploring Equation as a Better Intermediate Meaning Representation for  Numerical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.904, \"y\": 2.717}, {\"title\": \"Software Entity Recognition with Noise-Robust Learning\", \"topic\": \"Named Entity Recognition\", \"x\": 7.348, \"y\": 6.722}, {\"title\": \"An Examination of the Compositionality of Large Generative  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.285, \"y\": 7.599}, {\"title\": \"An Effective Method using Phrase Mechanism in Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.983, \"y\": 4.495}, {\"title\": \"Implicit Self-supervised Language Representation for Spoken Language  Diarization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.832, \"y\": 5.271}, {\"title\": \"Simple Baselines for Interactive Video Retrieval with Questions and  Answers\", \"topic\": \"Multimodal Language Models\", \"x\": 8.526, \"y\": 8.046}, {\"title\": \"FairMonitor: A Four-Stage Automatic Framework for Detecting Stereotypes  and Biases in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.324, \"y\": 4.338}, {\"title\": \"Algorithm of Thoughts: Enhancing Exploration of Ideas in Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.437, \"y\": 2.453}, {\"title\": \"LegalBench: A Collaboratively Built Benchmark for Measuring Legal  Reasoning in Large Language Models\", \"topic\": \"Legal NLP\", \"x\": 5.625, \"y\": 4.731}, {\"title\": \"cantnlp@LT-EDI-2023: Homophobia/Transphobia Detection in Social Media  Comments using Spatio-Temporally Retrained Language Models\", \"topic\": \"Hate Speech Detection\", \"x\": 2.831, \"y\": 5.479}, {\"title\": \"Economic Policy Uncertainty: A Review on Applications and Measurement  Methods with Focus on Text Mining Methods\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.55, \"y\": 6.681}, {\"title\": \"StableLLaVA: Enhanced Visual Instruction Tuning with Synthesized  Image-Dialogue Data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.429, \"y\": 7.366}, {\"title\": \"Indonesian Automatic Speech Recognition with XLSR-53\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.102, \"y\": 5.546}, {\"title\": \"WMFormer++: Nested Transformer for Visible Watermark Removal via Implict  Joint Learning\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.999, \"y\": 3.221}, {\"title\": \"FoodGPT: A Large Language Model in Food Testing Domain with Incremental  Pre-training and Knowledge Graph Prompt\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.016, \"y\": 5.952}, {\"title\": \"A Survey on Fairness in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.437, \"y\": 4.193}, {\"title\": \"ExpeL: LLM Agents Are Experiential Learners\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.804, \"y\": 2.315}, {\"title\": \"Bayes Risk Transducer: Transducer with Controllable Alignment Prediction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.294, \"y\": 5.074}, {\"title\": \"PACE: Improving Prompt with Actor-Critic Editing for Large Language  Model\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.358, \"y\": 3.025}, {\"title\": \"UniDoc: A Universal Large Multimodal Model for Simultaneous Text  Detection, Recognition, Spotting and Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.257, \"y\": 7.006}, {\"title\": \"An Empirical Study of CLIP for Text-based Person Search\", \"topic\": \"Multimodal Language Models\", \"x\": 9.031, \"y\": 7.159}, {\"title\": \"GameEval: Evaluating LLMs on Conversational Games\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.426, \"y\": 3.231}, {\"title\": \"Optimizing Multi-Class Text Classification: A Diverse Stacking Ensemble  Framework Utilizing Transformers\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.742, \"y\": 6.481}, {\"title\": \"Causal Intersectionality and Dual Form of Gradient Descent for  Multimodal Analysis: a Case Study on Hateful Memes\", \"topic\": \"Hate Speech Detection\", \"x\": 2.846, \"y\": 5.55}, {\"title\": \"FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for  Large Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.862, \"y\": 6.891}, {\"title\": \"Tackling Vision Language Tasks Through Learning Inner Monologues\", \"topic\": \"Multimodal Language Models\", \"x\": 8.433, \"y\": 7.453}, {\"title\": \"Data-to-text Generation for Severely Under-Resourced Languages with  GPT-3.5: A Bit of Help Needed from Google Translate\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.129, \"y\": 4.378}, {\"title\": \"BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual  Questions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.363, \"y\": 7.843}, {\"title\": \"Utilizing Semantic Textual Similarity for Clinical Survey Data Feature  Selection\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.808, \"y\": 7.915}, {\"title\": \"Inductive-bias Learning: Generating Code Models with Large Language  Model\", \"topic\": \"In-Context Learning\", \"x\": 8.158, \"y\": 3.164}, {\"title\": \"Breaking Language Barriers: A Question Answering Dataset for Hindi and  Marathi\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.588, \"y\": 5.162}, {\"title\": \"Black-box Adversarial Attacks against Dense Retrieval Models: A  Multi-view Contrastive Learning Method\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.143, \"y\": 3.013}, {\"title\": \"Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.606, \"y\": 7.468}, {\"title\": \"NaijaRC: A Multi-choice Reading Comprehension Dataset for Nigerian  Languages\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.566, \"y\": 5.245}, {\"title\": \"Graph of Thoughts: Solving Elaborate Problems with Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.556, \"y\": 2.577}, {\"title\": \"WizardMath: Empowering Mathematical Reasoning for Large Language Models  via Reinforced Evol-Instruct\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.996, \"y\": 2.836}, {\"title\": \"Artificial-Spiking Hierarchical Networks for Vision-Language  Representation Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.693, \"y\": 6.928}, {\"title\": \"TrOMR:Transformer-Based Polyphonic Optical Music Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.123, \"y\": 5.276}, {\"title\": \"KESDT: knowledge enhanced shallow and deep Transformer for detecting  adverse drug reactions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.385, \"y\": 7.707}, {\"title\": \"Lip Reading for Low-resource Languages by Learning and Combining General  Speech Knowledge and Language-specific Knowledge\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.78, \"y\": 5.451}, {\"title\": \"Advancing Relation Extraction through Language Probing with Exemplars  from Set Co-Expansion\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.995, \"y\": 6.795}, {\"title\": \"ChatGPT-HealthPrompt. Harnessing the Power of XAI in Prompt-Based  Healthcare Decision Support using ChatGPT\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.692, \"y\": 8.072}, {\"title\": \"EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.806, \"y\": 7.965}, {\"title\": \"Reinforced Self-Training (ReST) for Language Modeling\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.378, \"y\": 1.599}, {\"title\": \"End-to-End Beam Retrieval for Multi-Hop Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.88, \"y\": 5.374}, {\"title\": \"Building Emotional Support Chatbots in the Era of LLMs\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.71, \"y\": 7.8}, {\"title\": \"CMB: A Comprehensive Medical Benchmark in Chinese\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.846, \"y\": 7.937}, {\"title\": \"Factuality Detection using Machine Translation -- a Use Case for German  Clinical Text\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.687, \"y\": 7.656}, {\"title\": \"Exploring Demonstration Ensembling for In-context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.32, \"y\": 3.423}, {\"title\": \"Multimodal Analysis Of Google Bard And GPT-Vision: Experiments In Visual  Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.132, \"y\": 7.677}, {\"title\": \"Discrete Prompt Compression with Reinforcement Learning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.592, \"y\": 3.264}, {\"title\": \"PMET: Precise Model Editing in a Transformer\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.66, \"y\": 3.162}, {\"title\": \"Decoding Emotions: A comprehensive Multilingual Study of Speech Models  for Speech Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.2, \"y\": 7.831}, {\"title\": \"FineQuant: Unlocking Efficiency with Fine-Grained Weight-Only  Quantization for LLMs\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.671, \"y\": 2.17}, {\"title\": \"Answering Ambiguous Questions with a Database of Questions, Answers, and  Revisions\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.529, \"y\": 5.135}, {\"title\": \"Large Language Models for Granularized Barrett's Esophagus Diagnosis  Classification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.948, \"y\": 8.409}, {\"title\": \"BIOptimus: Pre-training an Optimal Biomedical Language Model with  Curriculum Learning for Named Entity Recognition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.401, \"y\": 7.6}, {\"title\": \"Boosting Logical Reasoning in Large Language Models through a New  Framework: The Graph of Thought\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.608, \"y\": 2.655}, {\"title\": \"Mitigating the Exposure Bias in Sentence-Level Grapheme-to-Phoneme (G2P)  Transduction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.511, \"y\": 5.285}, {\"title\": \"SummHelper: Collaborative Human-Computer Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.519, \"y\": 6.209}, {\"title\": \"Self-Deception: Reverse Penetrating the Semantic Firewall of Large  Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.292, \"y\": 2.363}, {\"title\": \"MoCoSA: Momentum Contrast for Knowledge Graph Completion with  Structure-Augmented Pre-trained Language Models\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.07, \"y\": 6.018}, {\"title\": \"ChinaTelecom System Description to VoxCeleb Speaker Recognition  Challenge 2023\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.985, \"y\": 5.704}, {\"title\": \"Enhancing Performance on Seen and Unseen Dialogue Scenarios using  Retrieval-Augmented End-to-End Task-Oriented System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.538, \"y\": 3.793}, {\"title\": \"AffectEcho: Speaker Independent and Language-Agnostic Emotion and Affect  Transfer for Speech Synthesis\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.301, \"y\": 7.831}, {\"title\": \"Sarcasm Detection in a Disaster Context\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.599, \"y\": 6.789}, {\"title\": \"AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.564, \"y\": 2.89}, {\"title\": \"Fast Training of NMT Model with Data Sorting\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.889, \"y\": 4.147}, {\"title\": \"MDDial: A Multi-turn Differential Diagnosis Dialogue Dataset with  Reliability Evaluation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.564, \"y\": 8.218}, {\"title\": \"Radio2Text: Streaming Speech Recognition Using mmWave Radio Signals\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.179, \"y\": 5.113}, {\"title\": \"DiagGPT: An LLM-based and Multi-agent Dialogue System with Automatic  Topic Management for Flexible Task-Oriented Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.398, \"y\": 3.717}, {\"title\": \"End-to-End Open Vocabulary Keyword Search With Multilingual Neural  Representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.765, \"y\": 5.068}, {\"title\": \"Solving Challenging Math Word Problems Using GPT-4 Code Interpreter with  Code-based Self-Verification\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.024, \"y\": 2.687}, {\"title\": \"Through the Lens of Core Competency: Survey on Evaluation of Large  Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.339, \"y\": 3.938}, {\"title\": \"Is it Really Negative? Evaluating Natural Language Video Localization  Performance on Multiple Reliable Videos Pool\", \"topic\": \"Multimodal Language Models\", \"x\": 8.912, \"y\": 7.809}, {\"title\": \"Link-Context Learning for Multimodal LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.374, \"y\": 7.087}, {\"title\": \"A Comprehensive Study on Knowledge Graph Embedding over Relational  Patterns Based on Rule Learning\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.017, \"y\": 6.024}, {\"title\": \"A Trustable LSTM-Autoencoder Network for Cyberbullying Detection on  Social Media Using Synthetic Data\", \"topic\": \"Hate Speech Detection\", \"x\": 2.863, \"y\": 5.49}, {\"title\": \"Emotion Embeddings $\\\\unicode{x2014}$ Learning Stable and Homogeneous  Abstractions from Heterogeneous Affective Datasets\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.316, \"y\": 7.665}, {\"title\": \"Informed Named Entity Recognition Decoding for Generative Language  Models\", \"topic\": \"Named Entity Recognition\", \"x\": 7.352, \"y\": 6.782}, {\"title\": \"DS4DH at #SMM4H 2023: Zero-Shot Adverse Drug Events Normalization using  Sentence Transformers and Reciprocal-Rank Fusion\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.303, \"y\": 7.667}, {\"title\": \"Forward-Backward Reasoning in Large Language Models for Mathematical  Verification\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.908, \"y\": 2.758}, {\"title\": \"Exploring Transfer Learning in Medical Image Segmentation using  Vision-Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.602, \"y\": 8.275}, {\"title\": \"Attention Is Not All You Need Anymore\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.82, \"y\": 3.342}, {\"title\": \"LLM-Mini-CEX: Automatic Evaluation of Large Language Model for  Diagnostic Conversation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.58, \"y\": 8.139}, {\"title\": \"VBD-MT Chinese-Vietnamese Translation Systems for VLSP 2022\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.884, \"y\": 4.716}, {\"title\": \"Improving CTC-AED model with integrated-CTC and auxiliary loss  regularization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.212, \"y\": 5.052}, {\"title\": \"Finding Stakeholder-Material Information from 10-K Reports using  Fine-Tuned BERT and LSTM Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.919, \"y\": 6.599}, {\"title\": \"SOTASTREAM: A Streaming Approach to Machine Translation Training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.327, \"y\": 4.848}, {\"title\": \"O-1: Self-training with Oracle and 1-best Hypothesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.021, \"y\": 4.981}, {\"title\": \"Playing with Words: Comparing the Vocabulary and Lexical Richness of  ChatGPT and Humans\", \"topic\": \"Bias in Language Models\", \"x\": 5.046, \"y\": 4.547}, {\"title\": \"Text Injection for Capitalization and Turn-Taking Prediction in Speech  Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.996, \"y\": 5.429}, {\"title\": \"Using Text Injection to Improve Recognition of Personal Identifiers in  Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.104, \"y\": 5.545}, {\"title\": \"Comparison between parameter-efficient techniques and full fine-tuning:  A case study on multilingual news article classification\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.948, \"y\": 2.477}, {\"title\": \"Dialogue for Prompting: a Policy-Gradient-Based Discrete Prompt  Generation for Few-shot Learning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.456, \"y\": 3.263}, {\"title\": \"Temporal Sentence Grounding in Streaming Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.908, \"y\": 7.823}, {\"title\": \"#InsTag: Instruction Tagging for Analyzing Supervised Fine-tuning of  Large Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.16, \"y\": 2.267}, {\"title\": \"Improving Audio-Visual Speech Recognition by Lip-Subword Correlation  Based Visual Pre-training and Cross-Modal Fusion Encoder\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.775, \"y\": 5.6}, {\"title\": \"Can Knowledge Graphs Simplify Text?\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.11, \"y\": 5.858}, {\"title\": \"Automated Testing and Improvement of Named Entity Recognition Systems\", \"topic\": \"Named Entity Recognition\", \"x\": 7.33, \"y\": 6.816}, {\"title\": \"Generative Interpretation\", \"topic\": \"Legal NLP\", \"x\": 5.091, \"y\": 5.573}, {\"title\": \"SpeechX: Neural Codec Language Model as a Versatile Speech Transformer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.631, \"y\": 5.76}, {\"title\": \"Diagnostic Reasoning Prompts Reveal the Potential for Large Language  Model Interpretability in Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.57, \"y\": 8.134}, {\"title\": \"An Ensemble Approach to Question Classification: Integrating Electra  Transformer, GloVe, and LSTM\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.304, \"y\": 5.438}, {\"title\": \"Token-Scaled Logit Distillation for Ternary Weight Generative Language  Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 10.057, \"y\": 2.649}, {\"title\": \"Transforming Sentiment Analysis in the Financial Domain with ChatGPT\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.685, \"y\": 6.853}, {\"title\": \"Bio-SIEVE: Exploring Instruction Tuning Large Language Models for  Systematic Review Automation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.627, \"y\": 7.361}, {\"title\": \"VisIT-Bench: A Benchmark for Vision-Language Instruction Following  Inspired by Real-World Use\", \"topic\": \"Multimodal Language Models\", \"x\": 8.332, \"y\": 7.381}, {\"title\": \"MT4CrossOIE: Multi-stage Tuning for Cross-lingual Open Information  Extraction\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.397, \"y\": 4.905}, {\"title\": \"Alternative Pseudo-Labeling for Semi-Supervised Automatic Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.99, \"y\": 5.293}, {\"title\": \"MC-DRE: Multi-Aspect Cross Integration for Drug Event/Entity Extraction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.84, \"y\": 7.683}, {\"title\": \"HyperFormer: Enhancing Entity and Relation Interaction for  Hyper-Relational Knowledge Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.073, \"y\": 6.095}, {\"title\": \"AutoConv: Automatically Generating Information-seeking Conversations  with Large Language Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.53, \"y\": 3.784}, {\"title\": \"NewsDialogues: Towards Proactive News Grounded Conversation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.297, \"y\": 3.829}, {\"title\": \"Text-to-Video: a Two-stage Framework for Zero-shot Identity-agnostic  Talking-head Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.551, \"y\": 5.94}, {\"title\": \"Demonstration-based learning for few-shot biomedical named entity  recognition under machine reading comprehension\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.728, \"y\": 7.335}, {\"title\": \"ERNetCL: A novel emotion recognition network in textual conversation  based on curriculum learning strategy\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.259, \"y\": 7.82}, {\"title\": \"ZYN: Zero-Shot Reward Models with Yes-No Questions for RLAIF\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 6.344, \"y\": 1.786}, {\"title\": \"Large Language Models to Identify Social Determinants of Health in  Electronic Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.489, \"y\": 7.859}, {\"title\": \"Bilingual Streaming ASR with Grapheme units and Auxiliary Monolingual  Loss\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.74, \"y\": 5.232}, {\"title\": \"A Large Language Model Enhanced Conversational Recommender System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.044, \"y\": 3.097}, {\"title\": \"Weakly Supervised Text Classification on Free Text Comments in  Patient-Reported Outcome Measures\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.471, \"y\": 7.73}, {\"title\": \"Assessing Guest Nationality Composition from Hotel Reviews\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.508, \"y\": 6.621}, {\"title\": \"Improving Joint Speech-Text Representations Without Alignment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.727, \"y\": 5.297}, {\"title\": \"Learning Deductive Reasoning from Synthetic Corpus based on Formal Logic\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.713, \"y\": 2.961}, {\"title\": \"Lip2Vec: Efficient and Robust Visual Speech Recognition via  Latent-to-Latent Visual to Audio Representation Mapping\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.925, \"y\": 5.563}, {\"title\": \"Improving Zero-Shot Text Matching for Financial Auditing with Large  Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.915, \"y\": 6.825}, {\"title\": \"Neural Conversation Models and How to Rein Them in: A Survey of Failures  and Fixes\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.306, \"y\": 3.599}, {\"title\": \"A Case Study on Context Encoding in Multi-Encoder based Document-Level  Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.71, \"y\": 4.32}, {\"title\": \"Multimodality and Attention Increase Alignment in Natural Language  Prediction Between Humans and Computational Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.253, \"y\": 7.247}, {\"title\": \"Large Language Models in Cryptocurrency Securities Cases: Can a GPT  Model Meaningfully Assist Lawyers?\", \"topic\": \"Legal NLP\", \"x\": 5.079, \"y\": 5.406}, {\"title\": \"PIPPA: A Partially Synthetic Conversational Dataset\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.053, \"y\": 3.743}, {\"title\": \"EXPRESSO: A Benchmark and Analysis of Discrete Expressive Speech  Resynthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.658, \"y\": 5.833}, {\"title\": \"A Preliminary Study of the Intrinsic Relationship between Complexity and  Alignment\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.156, \"y\": 2.275}, {\"title\": \"AST-MHSA : Code Summarization using Multi-Head Self-Attention\", \"topic\": \"Text Summarization\", \"x\": 5.705, \"y\": 6.252}, {\"title\": \"IIHT: Medical Report Generation with Image-to-Indicator Hierarchical  Transformer\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.202, \"y\": 8.605}, {\"title\": \"LASIGE and UNICAGE solution to the NASA LitCoin NLP Competition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.272, \"y\": 7.205}, {\"title\": \"Exploring Linguistic Similarity and Zero-Shot Learning for Multilingual  Translation of Dravidian Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.688, \"y\": 4.81}, {\"title\": \"Bringing order into the realm of Transformer-based language models for  artificial intelligence and law\", \"topic\": \"Legal NLP\", \"x\": 5.213, \"y\": 5.602}, {\"title\": \"WeaverBird: Empowering Financial Decision-Making with Large Language  Model, Knowledge Base, and Search Engine\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.908, \"y\": 6.845}, {\"title\": \"Classification of Human- and AI-Generated Texts: Investigating Features  for ChatGPT\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.335, \"y\": 4.781}, {\"title\": \"Developing an Informal-Formal Persian Corpus\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.018, \"y\": 5.404}, {\"title\": \"Investigating disaster response through social media data and the  Susceptible-Infected-Recovered (SIR) model: A case study of 2020 Western U.S.  wildfire season\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.155, \"y\": 6.616}, {\"title\": \"A Novel Self-training Approach for Low-resource Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.968, \"y\": 5.26}, {\"title\": \"Conceptualizing Machine Learning for Dynamic Information Retrieval of  Electronic Health Record Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.731, \"y\": 8.144}, {\"title\": \"Decoding Layer Saliency in Language Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.705, \"y\": 3.565}, {\"title\": \"Constructing Holistic Spatio-Temporal Scene Graph for Video Semantic  Role Labeling\", \"topic\": \"Multimodal Language Models\", \"x\": 8.888, \"y\": 7.716}, {\"title\": \"RadGraph2: Modeling Disease Progression in Radiology Reports via  Hierarchical Information Extraction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.153, \"y\": 8.54}, {\"title\": \"Performance Analysis of Transformer Based Models (BERT, ALBERT and  RoBERTa) in Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.08, \"y\": 5.756}, {\"title\": \"Extrapolating Large Language Models to Non-English by Aligning Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.258, \"y\": 4.351}, {\"title\": \"LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.516, \"y\": 3.826}, {\"title\": \"Emotion-Conditioned Text Generation through Automatic Prompt  Optimization\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.423, \"y\": 3.484}, {\"title\": \"A Bipartite Graph is All We Need for Enhancing Emotional Reasoning with  Commonsense Knowledge\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.64, \"y\": 7.573}, {\"title\": \"ADMUS: A Progressive Question Answering Framework Adaptable to Multiple  Knowledge Sources\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.617, \"y\": 5.309}, {\"title\": \"Automatically measuring speech fluency in people with aphasia: first  achievements using read-speech data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.164, \"y\": 5.642}, {\"title\": \"A Comparative Study of Open-Source Large Language Models, GPT-4 and  Claude 2: Multiple-Choice Test Taking in Nephrology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.762, \"y\": 7.993}, {\"title\": \"TBIN: Modeling Long Textual Behavior Data for CTR Prediction\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.95, \"y\": 2.951}, {\"title\": \"Sci-CoT: Leveraging Large Language Models for Enhanced Knowledge  Distillation in Small Models for Scientific QA\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.893, \"y\": 2.348}, {\"title\": \"Single-Sentence Reader: A Novel Approach for Addressing Answer Position  Bias\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.631, \"y\": 5.151}, {\"title\": \"Revisiting Disentanglement and Fusion on Modality and Context in  Conversational Multimodal Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.33, \"y\": 7.736}, {\"title\": \"Character-level NMT and language similarity\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.65, \"y\": 4.629}, {\"title\": \"Unmasking Nationality Bias: A Study of Human Perception of Nationalities  in AI-Generated Articles\", \"topic\": \"Bias in Language Models\", \"x\": 3.491, \"y\": 4.512}, {\"title\": \"Comparative Analysis of the wav2vec 2.0 Feature Extractor\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.188, \"y\": 5.343}, {\"title\": \"CLASSLA-Stanza: The Next Step for Linguistic Processing of South Slavic  Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.938, \"y\": 5.229}, {\"title\": \"OpinionConv: Conversational Product Search with Grounded Opinions\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.139, \"y\": 3.861}, {\"title\": \"Studying Socially Unacceptable Discourse Classification (SUD) through  different eyes: \\\"Are we on the same page ?\\\"\", \"topic\": \"Hate Speech Detection\", \"x\": 2.831, \"y\": 5.398}, {\"title\": \"On Monotonic Aggregation for Open-domain QA\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.589, \"y\": 5.114}, {\"title\": \"The Five-Dollar Model: Generating Game Maps and Sprites from Sentence  Embeddings\", \"topic\": \"Multimodal Language Models\", \"x\": 8.789, \"y\": 6.88}, {\"title\": \"Universal Automatic Phonetic Transcription into the International  Phonetic Alphabet\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.534, \"y\": 5.32}, {\"title\": \"CORAL: Expert-Curated medical Oncology Reports to Advance Language Model  Inference\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.731, \"y\": 8.061}, {\"title\": \"Emotionally Numb or Empathetic? Evaluating How LLMs Feel Using  EmotionBench\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.581, \"y\": 7.687}, {\"title\": \"KITLM: Domain-Specific Knowledge InTegration into Language Models for  Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.929, \"y\": 4.908}, {\"title\": \"MedMine: Examining Pre-trained Language Models on Medication Mining\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.973, \"y\": 7.921}, {\"title\": \"Negative Lexical Constraints in Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.799, \"y\": 4.363}, {\"title\": \"Mondrian: Prompt Abstraction Attack Against Large Language Models for  Cheaper API Pricing\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.342, \"y\": 2.575}, {\"title\": \"Zhongjing: Enhancing the Chinese Medical Capabilities of Large Language  Model through Expert Feedback and Real-world Multi-turn Dialogue\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.83, \"y\": 8.046}, {\"title\": \"RCMHA: Relative Convolutional Multi-Head Attention for Natural Language  Modelling\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.809, \"y\": 3.1}, {\"title\": \"Boosting Chinese ASR Error Correction with Dynamic Error Scaling  Mechanism\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.938, \"y\": 5.494}, {\"title\": \"Prompt Guided Copy Mechanism for Conversational Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.163, \"y\": 5.001}, {\"title\": \"End-to-End Evaluation for Low-Latency Simultaneous Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.468, \"y\": 5.249}, {\"title\": \"Coupling Symbolic Reasoning with Language Modeling for Efficient  Longitudinal Understanding of Unstructured Electronic Medical Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.837, \"y\": 7.971}, {\"title\": \"SciGraphQA: A Large-Scale Synthetic Multi-Turn Question-Answering  Dataset for Scientific Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.543, \"y\": 5.498}, {\"title\": \"LoRA-FA: Memory-efficient Low-rank Adaptation for Large Language Models  Fine-tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.168, \"y\": 2.127}, {\"title\": \"Dialogue Systems Can Generate Appropriate Responses without the Use of  Question Marks? -- Investigation of the Effects of Question Marks on Dialogue  Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.357, \"y\": 4.054}, {\"title\": \"Simple Rule Injection for ComplEx Embeddings\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.967, \"y\": 5.869}, {\"title\": \"SeACo-Paraformer: A Non-Autoregressive ASR System with Flexible and  Effective Hotword Customization Ability\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.212, \"y\": 5.185}, {\"title\": \"PaniniQA: Enhancing Patient Education Through Interactive Question  Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.642, \"y\": 7.974}, {\"title\": \"Analysis of the Evolution of Advanced Transformer-Based Language Models:  Experiments on Opinion Mining\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.528, \"y\": 6.73}, {\"title\": \"Investigation of Self-supervised Pre-trained Models for Classification  of Voice Quality from Speech and Neck Surface Accelerometer Signals\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.001, \"y\": 5.339}, {\"title\": \"Average-Hard Attention Transformers are Constant-Depth Uniform Threshold  Circuits\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.698, \"y\": 3.322}, {\"title\": \"Food-500 Cap: A Fine-Grained Food Caption Benchmark for Evaluating  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.502, \"y\": 7.654}, {\"title\": \"LARCH: Large Language Model-based Automatic Readme Creation with  Heuristics\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.251, \"y\": 2.543}, {\"title\": \"System-Initiated Transitions from Chit-Chat to Task-Oriented Dialogues  with Transition Info Extractor and Transition Sentence Generator\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.414, \"y\": 3.843}, {\"title\": \"Towards Scene-Text to Scene-Text Translation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.977, \"y\": 6.762}, {\"title\": \"LaDA: Latent Dialogue Action For Zero-shot Cross-lingual Neural Network  Language Modeling\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.838, \"y\": 5.028}, {\"title\": \"Textual Data Mining for Financial Fraud Detection: A Deep Learning  Approach\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.925, \"y\": 6.636}, {\"title\": \"ApproBiVT: Lead ASR Models to Generalize Better Using Approximated  Bias-Variance Tradeoff Guided Early Stopping and Checkpoint Averaging\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.287, \"y\": 5.201}, {\"title\": \"How Good Are SOTA Fake News Detectors\", \"topic\": \"Fake News Detection\", \"x\": 4.055, \"y\": 5.666}, {\"title\": \"MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities\", \"topic\": \"Multimodal Language Models\", \"x\": 8.003, \"y\": 7.555}, {\"title\": \"Adapting the NICT-JLE Corpus for Disfluency Detection Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.133, \"y\": 5.628}, {\"title\": \"Towards Generalist Foundation Model for Radiology by Leveraging  Web-scale 2D&3D Medical Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.215, \"y\": 8.508}, {\"title\": \"Legal Summarisation through LLMs: The PRODIGIT Project\", \"topic\": \"Legal NLP\", \"x\": 5.089, \"y\": 5.77}, {\"title\": \"Dataflow Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.379, \"y\": 3.821}, {\"title\": \"Redundancy Aware Multi-Reference Based Gainwise Evaluation of Extractive  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.474, \"y\": 6.201}, {\"title\": \"Efficient Monaural Speech Enhancement using Spectrum Attention Fusion\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.096, \"y\": 4.967}, {\"title\": \"Sinhala-English Parallel Word Dictionary Dataset\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.273, \"y\": 5.1}, {\"title\": \"A Survey of Spanish Clinical Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.855, \"y\": 7.924}, {\"title\": \"Emo-DNA: Emotion Decoupling and Alignment Learning for Cross-Corpus  Speech Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.186, \"y\": 7.815}, {\"title\": \"From Fake to Hyperpartisan News Detection Using Domain Adaptation\", \"topic\": \"Fake News Detection\", \"x\": 4.051, \"y\": 5.874}, {\"title\": \"Scaling Clinical Trial Matching Using Large Language Models: A Case  Study in Oncology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.736, \"y\": 7.909}, {\"title\": \"Speaker Diarization of Scripted Audiovisual Content\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.869, \"y\": 5.635}, {\"title\": \"Capturing Spectral and Long-term Contextual Information for Speech  Emotion Recognition Using Deep Learning Techniques\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.233, \"y\": 7.814}, {\"title\": \"Chinese Financial Text Emotion Mining: GCGTS -- A Character  Relationship-based Approach for Simultaneous Aspect-Opinion Pair Extraction\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.53, \"y\": 6.886}, {\"title\": \"N-gram Boosting: Improving Contextual Biasing with Normalized N-gram  Targets\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.328, \"y\": 5.059}, {\"title\": \"Causality Guided Disentanglement for Cross-Platform Hate Speech  Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.731, \"y\": 5.384}, {\"title\": \"The Unequal Opportunities of Large Language Models: Revealing  Demographic Bias through Job Recommendations\", \"topic\": \"Bias in Language Models\", \"x\": 3.476, \"y\": 4.345}, {\"title\": \"Efficient Sentiment Analysis: A Resource-Aware Evaluation of Feature  Extraction Techniques, Ensembling, and Deep Learning Models\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.544, \"y\": 6.702}, {\"title\": \"Baby Llama: knowledge distillation from an ensemble of teachers trained  on a small dataset with no performance penalty\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.483, \"y\": 3.804}, {\"title\": \"Federated Representation Learning for Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.808, \"y\": 4.923}, {\"title\": \"Bengali Fake Reviews: A Benchmark Dataset and Detection System\", \"topic\": \"Fake News Detection\", \"x\": 3.877, \"y\": 5.997}, {\"title\": \"Reasoning in Large Language Models Through Symbolic Math Word Problems\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.954, \"y\": 2.752}, {\"title\": \"Athena 2.0: Discourse and User Modeling in Open Domain Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.128, \"y\": 3.78}, {\"title\": \"ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on  Class-level Code Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.455, \"y\": 2.364}, {\"title\": \"Many-to-Many Spoken Language Translation via Unified Speech and Text  Representation Learning with Unit-to-Unit Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.415, \"y\": 5.261}, {\"title\": \"Scaling Relationship on Learning Mathematical Reasoning with Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.102, \"y\": 2.707}, {\"title\": \"Is GPT-4 a reliable rater? Evaluating Consistency in GPT-4 Text Ratings\", \"topic\": \"Bias in Language Models\", \"x\": 5.438, \"y\": 4.493}, {\"title\": \"Local Large Language Models for Complex Structured Medical Tasks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.81, \"y\": 8.209}, {\"title\": \"Baby's CoThought: Leveraging Large Language Models for Enhanced  Reasoning in Compact Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.795, \"y\": 2.309}, {\"title\": \"NBIAS: A Natural Language Processing Framework for Bias Identification  in Text\", \"topic\": \"Bias in Language Models\", \"x\": 3.353, \"y\": 4.512}, {\"title\": \"Evaluating ChatGPT text-mining of clinical records for obesity  monitoring\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.655, \"y\": 8.127}, {\"title\": \"BioBERT Based SNP-traits Associations Extraction from Biomedical  Literature\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.306, \"y\": 7.389}, {\"title\": \"Multimodal Neurons in Pretrained Text-Only Transformers\", \"topic\": \"Multimodal Language Models\", \"x\": 8.428, \"y\": 7.111}, {\"title\": \"UPB at IberLEF-2023 AuTexTification: Detection of Machine-Generated Text  using Transformer Ensembles\", \"topic\": \"AI-Generated Text Detection\", \"x\": 3.998, \"y\": 5.15}, {\"title\": \"Bio+Clinical BERT, BERT Base, and CNN Performance Comparison for  Predicting Drug-Review Satisfaction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.318, \"y\": 7.672}, {\"title\": \"DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like  Models at All Scales\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.218, \"y\": 1.597}, {\"title\": \"PerceptionCLIP: Visual Classification by Inferring and Conditioning on  Contexts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.896, \"y\": 7.165}, {\"title\": \"Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.267, \"y\": 4.715}, {\"title\": \"Evaluating Instruction-Tuned Large Language Models on Code Comprehension  and Generation\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.064, \"y\": 2.426}, {\"title\": \"Careful Whisper -- leveraging advances in automatic speech recognition  for robust and interpretable aphasia subtype classification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.151, \"y\": 5.645}, {\"title\": \"Grounded Image Text Matching with Mismatched Relation Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.738, \"y\": 7.225}, {\"title\": \"Do Multilingual Language Models Think Better in English?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.508, \"y\": 4.661}, {\"title\": \"ADS-Cap: A Framework for Accurate and Diverse Stylized Captioning with  Unpaired Stylistic Corpora\", \"topic\": \"Multimodal Language Models\", \"x\": 9.146, \"y\": 7.29}, {\"title\": \"Beyond Generic: Enhancing Image Captioning with Real-World Knowledge  using Vision-Language Pre-Training Model\", \"topic\": \"Multimodal Language Models\", \"x\": 9.008, \"y\": 7.496}, {\"title\": \"Leveraging Few-Shot Data Augmentation and Waterfall Prompting for  Response Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.529, \"y\": 3.962}, {\"title\": \"Chat Translation Error Detection for Assisting Cross-lingual  Communications\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.515, \"y\": 4.858}, {\"title\": \"SALTTS: Leveraging Self-Supervised Speech Representations for improved  Text-to-Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.778, \"y\": 5.562}, {\"title\": \"DiactTOD: Learning Generalizable Latent Dialogue Acts for Controllable  Task-Oriented Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.563, \"y\": 3.806}, {\"title\": \"Aspect based sentimental analysis for travellers' reviews\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.386, \"y\": 6.673}, {\"title\": \"GRDD: A Dataset for Greek Dialectal NLP\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.121, \"y\": 5.283}, {\"title\": \"The Bias Amplification Paradox in Text-to-Image Generation\", \"topic\": \"Bias in Language Models\", \"x\": 3.183, \"y\": 4.51}, {\"title\": \"Covid-19 Public Sentiment Analysis for Indian Tweets Classification\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 3.965, \"y\": 6.712}, {\"title\": \"Tackling Hallucinations in Neural Chart Summarization\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.169, \"y\": 1.116}, {\"title\": \"LimeAttack: Local Explainable Method for Textual Hard-Label Adversarial  Attack\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.136, \"y\": 3.01}, {\"title\": \"Making the V in Text-VQA Matter\", \"topic\": \"Multimodal Language Models\", \"x\": 8.189, \"y\": 7.958}, {\"title\": \"Adversarially Robust Neural Legal Judgement Systems\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.168, \"y\": 2.947}, {\"title\": \"MTUncertainty: Assessing the Need for Post-editing of Machine  Translation Outputs by Fine-tuning OpenAI LLMs\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.833, \"y\": 4.565}, {\"title\": \"Boosting Adverse Drug Event Normalization on Social Media:  General-Purpose Model Initialization and Biomedical Semantic Text Similarity  Benefit Zero-Shot Linking in Informal Contexts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.488, \"y\": 7.648}, {\"title\": \"Towards Semantically Enriched Embeddings for Knowledge Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.009, \"y\": 6.0}, {\"title\": \"Learning to Model the World with Language\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.815, \"y\": 2.464}, {\"title\": \"Backdooring Instruction-Tuned Large Language Models with Virtual Prompt  Injection\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.363, \"y\": 2.563}, {\"title\": \"Contrastive Learning for API Aspect Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.232, \"y\": 6.765}, {\"title\": \"Alpha-GPT: Human-AI Interactive Alpha Mining for Quantitative Investment\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.68, \"y\": 6.563}, {\"title\": \"Defense of Adversarial Ranking Attack in Text Retrieval: Benchmark and  Baseline via Detection\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.155, \"y\": 3.051}, {\"title\": \"DoDo Learning: DOmain-DemOgraphic Transfer in Language Models for  Detecting Abuse Targeted at Public Figures\", \"topic\": \"Hate Speech Detection\", \"x\": 2.797, \"y\": 5.357}, {\"title\": \"Changes in Policy Preferences in German Tweets during the COVID Pandemic\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.069, \"y\": 6.637}, {\"title\": \"Structural Transfer Learning in NL-to-Bash Semantic Parsers\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.24, \"y\": 4.815}, {\"title\": \"Lexically-Accelerated Dense Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.553, \"y\": 5.002}, {\"title\": \"Multilingual context-based pronunciation learning for Text-to-Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.564, \"y\": 5.387}, {\"title\": \"Comparing normalizing flows and diffusion models for prosody and  acoustic modelling in text-to-speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.6, \"y\": 5.907}, {\"title\": \"Improving grapheme-to-phoneme conversion by learning pronunciations from  speech recordings\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.808, \"y\": 5.422}, {\"title\": \"Text-CRS: A Generalized Certified Robustness Framework against Textual  Adversarial Attacks\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.161, \"y\": 3.032}, {\"title\": \"Noisy Self-Training with Data Augmentations for Offensive and Hate  Speech Detection Tasks\", \"topic\": \"Hate Speech Detection\", \"x\": 2.728, \"y\": 5.461}, {\"title\": \"DiffProsody: Diffusion-based Latent Prosody Generation for Expressive  Speech Synthesis with Prosody Conditional Adversarial Training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.532, \"y\": 5.919}, {\"title\": \"Transferable Decoding with Visual Entities for Zero-Shot Image  Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.996, \"y\": 7.361}, {\"title\": \"FinVis-GPT: A Multimodal Large Language Model for Financial Chart  Analysis\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.844, \"y\": 6.86}, {\"title\": \"An Effective Data Creation Pipeline to Generate High-quality Financial  Instruction Data for Large Language Model\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.865, \"y\": 6.918}, {\"title\": \"DCTM: Dilated Convolutional Transformer Model for Multimodal Engagement  Estimation in Conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.372, \"y\": 7.682}, {\"title\": \"Bridging the Gap: Exploring the Capabilities of Bridge-Architectures for  Complex Visual Reasoning Tasks\", \"topic\": \"Multimodal Language Models\", \"x\": 8.372, \"y\": 7.642}, {\"title\": \"Mispronunciation detection using self-supervised speech representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.842, \"y\": 5.258}, {\"title\": \"Question Answering with Deep Neural Networks for Semi-Structured  Heterogeneous Genealogical Knowledge Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.672, \"y\": 5.465}, {\"title\": \"Around the GLOBE: Numerical Aggregation Question-Answering on  Heterogeneous Genealogical Knowledge Graphs with Deep Neural Networks\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.609, \"y\": 5.415}, {\"title\": \"A Knowledge-enhanced Two-stage Generative Framework for Medical Dialogue  Information Extraction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.677, \"y\": 8.162}, {\"title\": \"Improving TTS for Shanghainese: Addressing Tone Sandhi via Word  Segmentation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.362, \"y\": 5.601}, {\"title\": \"SEED-Bench: Benchmarking Multimodal LLMs with Generative Comprehension\", \"topic\": \"Multimodal Language Models\", \"x\": 8.036, \"y\": 7.485}, {\"title\": \"Roll Up Your Sleeves: Working with a Collaborative and Engaging  Task-Oriented Dialogue System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.181, \"y\": 3.641}, {\"title\": \"\\u00ccr\\u00f2y\\u00ecnSpeech: A multi-purpose Yor\\u00f9b\\u00e1 Speech Corpus\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.595, \"y\": 5.545}, {\"title\": \"RoCar: A Relationship Network-based Evaluation Method to Large Language  Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.25, \"y\": 3.908}, {\"title\": \"Analysing the Resourcefulness of the Paragraph for Precedence Retrieval\", \"topic\": \"Legal NLP\", \"x\": 5.156, \"y\": 5.827}, {\"title\": \"ATESA-B\\u00c6RT: A Heterogeneous Ensemble Learning Model for Aspect-Based  Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.169, \"y\": 6.799}, {\"title\": \"Select and Augment: Enhanced Dense Retrieval Knowledge Graph  Augmentation\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.203, \"y\": 6.026}, {\"title\": \"Context-VQA: Towards Context-Aware and Purposeful Visual Question  Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.215, \"y\": 8.059}, {\"title\": \"All-for-One and One-For-All: Deep learning-based feature fusion for  Synthetic Speech Detection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.008, \"y\": 5.601}, {\"title\": \"Exploring Format Consistency for Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.175, \"y\": 2.3}, {\"title\": \"The timing bottleneck: Why timing and overlap are mission-critical for  conversational user interfaces, speech recognition and dialogue systems\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.119, \"y\": 5.456}, {\"title\": \"Minimally-Supervised Speech Synthesis with Conditional Diffusion Model  and Language Model: A Comparative Study of Semantic Coding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.566, \"y\": 5.872}, {\"title\": \"Testing the Depth of ChatGPT's Comprehension via Cross-Modal Tasks Based  on ASCII-Art: GPT3.5's Abilities in Regard to Recognizing and Generating  ASCII-Art Are Not Totally Lacking\", \"topic\": \"Multimodal Language Models\", \"x\": 8.048, \"y\": 7.793}, {\"title\": \"Cross-Modal Concept Learning and Inference for Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.693, \"y\": 7.225}, {\"title\": \"CFN-ESA: A Cross-Modal Fusion Network with Emotion-Shift Awareness for  Dialogue Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.273, \"y\": 7.796}, {\"title\": \"Investigating the Learning Behaviour of In-context Learning: A  Comparison with Supervised Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.311, \"y\": 3.3}, {\"title\": \"Towards a Fully Unsupervised Framework for Intent Induction in Customer  Support Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.988, \"y\": 4.371}, {\"title\": \"Med-HALT: Medical Domain Hallucination Test for Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.089, \"y\": 1.131}, {\"title\": \"Skeleton-of-Thought: Prompting LLMs for Efficient Parallel Generation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.678, \"y\": 2.381}, {\"title\": \"BARTPhoBEiT: Pre-trained Sequence-to-Sequence and Image Transformers  Models for Vietnamese Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.187, \"y\": 8.04}, {\"title\": \"Reasoning before Responding: Integrating Commonsense-based Causality  Explanation for Empathetic Response Generation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.643, \"y\": 7.829}, {\"title\": \"Open Problems and Fundamental Limitations of Reinforcement Learning from  Human Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.101, \"y\": 1.616}, {\"title\": \"f-Divergence Minimization for Sequence-Level Knowledge Distillation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.554, \"y\": 3.796}, {\"title\": \"VISU at WASSA 2023 Shared Task: Detecting Emotions in Reaction to News  Stories Leveraging BERT and Stacked Embeddings\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.336, \"y\": 7.654}, {\"title\": \"Distilled Feature Fields Enable Few-Shot Language-Guided Manipulation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.734, \"y\": 6.996}, {\"title\": \"Matching Patients to Clinical Trials with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.767, \"y\": 7.922}, {\"title\": \"PanGu-Coder2: Boosting Large Language Models for Code with Ranking  Feedback\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.414, \"y\": 2.371}, {\"title\": \"Cascaded Cross-Modal Transformer for Request and Complaint Detection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.789, \"y\": 5.362}, {\"title\": \"Turkish Native Language Identification\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.795, \"y\": 5.103}, {\"title\": \"Emotion4MIDI: a Lyrics-based Emotion-Labeled Symbolic Music Dataset\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.364, \"y\": 7.462}, {\"title\": \"Turning Whisper into Real-Time Transcription System\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.694, \"y\": 5.412}, {\"title\": \"Metric-Based In-context Learning: A Case Study in Text Simplification\", \"topic\": \"In-Context Learning\", \"x\": 8.348, \"y\": 3.406}, {\"title\": \"Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal  Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.272, \"y\": 2.356}, {\"title\": \"CliniDigest: A Case Study in Large Language Model Based Large-Scale  Summarization of Clinical Trial Descriptions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.625, \"y\": 7.613}, {\"title\": \"Controllable Generation of Dialogue Acts for Dialogue Systems via  Few-Shot Response Generation and Ranking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.681, \"y\": 3.838}, {\"title\": \"Towards Generalist Biomedical AI\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.192, \"y\": 8.255}, {\"title\": \"Utilizing Large Language Models for Natural Interface to Pharmacology  Databases\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.97, \"y\": 7.632}, {\"title\": \"Comparative Analysis of Libraries for the Sentimental Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.692, \"y\": 6.622}, {\"title\": \"Automatically Evaluating Opinion Prevalence in Opinion Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.241, \"y\": 6.245}, {\"title\": \"ChatGPT and Persuasive Technologies for the Management and Delivery of  Personalized Recommendations in Hotel Hospitality\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.878, \"y\": 2.99}, {\"title\": \"LOIS: Looking Out of Instance Semantics for Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.36, \"y\": 7.868}, {\"title\": \"CIF-T: A Novel CIF-based Transducer Architecture for Automatic Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.22, \"y\": 5.082}, {\"title\": \"Decoding ChatGPT: A Taxonomy of Existing Research, Current Challenges,  and Possible Future Directions\", \"topic\": \"Bias in Language Models\", \"x\": 4.967, \"y\": 4.509}, {\"title\": \"Affective Natural Language Generation of Event Descriptions through  Fine-grained Appraisal Conditions\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.544, \"y\": 7.538}, {\"title\": \"How User Language Affects Conflict Fatality Estimates in ChatGPT\", \"topic\": \"Bias in Language Models\", \"x\": 3.535, \"y\": 4.599}, {\"title\": \"Data Augmentation for Neural Machine Translation using Generative  Language Model\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.703, \"y\": 4.664}, {\"title\": \"WebArena: A Realistic Web Environment for Building Autonomous Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.588, \"y\": 2.739}, {\"title\": \"ARC-NLP at Multimodal Hate Speech Event Detection 2023: Multimodal  Methods Boosted by Ensemble Learning, Syntactical and Entity Features\", \"topic\": \"Hate Speech Detection\", \"x\": 2.816, \"y\": 5.51}, {\"title\": \"Speech representation learning: Learning bidirectional encoders with  single-view, multi-view, and multi-task methods\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.797, \"y\": 4.963}, {\"title\": \"Is GPT a Computational Model of Emotion? Detailed Analysis\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.559, \"y\": 7.568}, {\"title\": \"Combating the Curse of Multilinguality in Cross-Lingual WSD by Aligning  Sparse Contextualized Word Representations\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.252, \"y\": 4.953}, {\"title\": \"Evaluating Large Language Models for Radiology Natural Language  Processing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.759, \"y\": 8.223}, {\"title\": \"ARB: Advanced Reasoning Benchmark for Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.581, \"y\": 3.311}, {\"title\": \"Contributions to the Improvement of Question Answering Systems in the  Biomedical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.829, \"y\": 7.469}, {\"title\": \"GPT-3 Models are Few-Shot Financial Reasoners\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.888, \"y\": 6.827}, {\"title\": \"Diversity and Language Technology: How Techno-Linguistic Bias Can Cause  Epistemic Injustice\", \"topic\": \"Bias in Language Models\", \"x\": 3.581, \"y\": 4.596}, {\"title\": \"XDLM: Cross-lingual Diffusion Language Model for Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.571, \"y\": 4.642}, {\"title\": \"Analyzing Chain-of-Thought Prompting in Large Language Models via  Gradient-based Feature Attributions\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.674, \"y\": 2.422}, {\"title\": \"An Intent Taxonomy of Legal Case Retrieval\", \"topic\": \"Legal NLP\", \"x\": 5.194, \"y\": 5.784}, {\"title\": \"LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA  Composition\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.157, \"y\": 2.047}, {\"title\": \"Opinion Mining Using Population-tuned Generative Language Models\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.539, \"y\": 6.688}, {\"title\": \"Improving Primary Healthcare Workflow Using Extreme Summarization of  Scientific Literature Based on Generative AI\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.547, \"y\": 7.508}, {\"title\": \"Explaining Math Word Problem Solvers\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.094, \"y\": 2.883}, {\"title\": \"A Hybrid Machine Learning Model for Classifying Gene Mutations in Cancer  using LSTM, BiLSTM, CNN, GRU, and GloVe\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.921, \"y\": 8.194}, {\"title\": \"Comparative Analysis of Drug-GPT and ChatGPT LLMs for Healthcare  Insights: Evaluating Accuracy and Relevance in Patient and HCP Contexts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.607, \"y\": 8.075}, {\"title\": \"Making Metadata More FAIR Using Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.377, \"y\": 4.114}, {\"title\": \"LLM-Rec: Personalized Recommendation via Prompting Large Language Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.905, \"y\": 2.9}, {\"title\": \"3D-LLM: Injecting the 3D World into Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.818, \"y\": 7.15}, {\"title\": \"Wisdom of Instruction-Tuned Language Model Crowds. Exploring Model Label  Variation\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.181, \"y\": 2.497}, {\"title\": \"Enhancing image captioning with depth information using a  Transformer-based framework\", \"topic\": \"Multimodal Language Models\", \"x\": 9.051, \"y\": 7.43}, {\"title\": \"RLCD: Reinforcement Learning from Contrastive Distillation for Language  Model Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.283, \"y\": 1.436}, {\"title\": \"Rule By Example: Harnessing Logical Rules for Explainable Hate Speech  Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.772, \"y\": 5.357}, {\"title\": \"Interpretable Stereotype Identification through Reasoning\", \"topic\": \"Bias in Language Models\", \"x\": 3.535, \"y\": 4.21}, {\"title\": \"A Real-World WebAgent with Planning, Long Context Understanding, and  Program Synthesis\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.635, \"y\": 2.547}, {\"title\": \"Joint Dropout: Improving Generalizability in Low-Resource Neural Machine  Translation through Phrase Pair Variables\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.874, \"y\": 4.487}, {\"title\": \"Guidance in Radiology Report Summarization: An Empirical Evaluation and  Error Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.054, \"y\": 8.418}, {\"title\": \"Code-Switched Urdu ASR for Noisy Telephonic Environment using Data  Centric Approach with Hybrid HMM and CNN-TDNN\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.74, \"y\": 5.508}, {\"title\": \"A Model for Every User and Budget: Label-Free and Personalized  Mixed-Precision Quantization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.224, \"y\": 4.928}, {\"title\": \"Fake News Detection Through Graph-based Neural Networks: A Survey\", \"topic\": \"Fake News Detection\", \"x\": 4.009, \"y\": 5.812}, {\"title\": \"Lost In Translation: Generating Adversarial Examples Robust to  Round-Trip Translation\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.176, \"y\": 3.033}, {\"title\": \"Gradient-Based Word Substitution for Obstinate Adversarial Examples  Generation in Language Models\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.108, \"y\": 3.048}, {\"title\": \"Robust Automatic Speech Recognition via WavAugment Guided Phoneme  Adversarial Training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.258, \"y\": 5.307}, {\"title\": \"HateModerate: Testing Hate Speech Detectors against Content Moderation  Policies\", \"topic\": \"Hate Speech Detection\", \"x\": 2.824, \"y\": 5.317}, {\"title\": \"Validation of a Zero-Shot Learning Natural Language Processing Tool for  Data Abstraction from Unstructured Healthcare Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.801, \"y\": 7.942}, {\"title\": \"In-Context Learning Learns Label Relationships but Is Not Conventional  Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.502, \"y\": 3.364}, {\"title\": \"Early Prediction of Alzheimers Disease Leveraging Symptom Occurrences  from Longitudinal Electronic Health Records of US Military Veterans\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.347, \"y\": 8.27}, {\"title\": \"X-CapsNet For Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.006, \"y\": 5.854}, {\"title\": \"Milimili. Collecting Parallel Data via Crowdsourcing\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.42, \"y\": 5.079}, {\"title\": \"Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid  Essay in Education\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.266, \"y\": 4.868}, {\"title\": \"A meta learning scheme for fast accent domain expansion in Mandarin  speech recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.119, \"y\": 5.197}, {\"title\": \"Exploring the Integration of Speech Separation and Recognition with  Self-Supervised Learning Representation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.043, \"y\": 5.217}, {\"title\": \"FATRER: Full-Attention Topic Regularizer for Accurate and Robust  Conversational Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.273, \"y\": 7.745}, {\"title\": \"The Imitation Game: Detecting Human and AI-Generated Texts in the Era of  ChatGPT and BARD\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.246, \"y\": 4.709}, {\"title\": \"Identifying Misinformation on YouTube through Transcript Contextual  Analysis with Transformer Models\", \"topic\": \"Fake News Detection\", \"x\": 4.165, \"y\": 5.892}, {\"title\": \"Modality Confidence Aware Training for Robust End-to-End Spoken Language  Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.836, \"y\": 5.148}, {\"title\": \"A Zero-shot and Few-shot Study of Instruction-Finetuned Large Language  Models Applied to Clinical and Biomedical Tasks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.079, \"y\": 7.914}, {\"title\": \"FinPT: Financial Risk Prediction with Profile Tuning on Pretrained  Foundation Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.914, \"y\": 6.862}, {\"title\": \"Enhancing CLIP with GPT-4: Harnessing Visual Descriptions as Prompts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.829, \"y\": 7.378}, {\"title\": \"CausE: Towards Causal Knowledge Graph Embedding\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.982, \"y\": 6.034}, {\"title\": \"A Change of Heart: Improving Speech Emotion Recognition through  Speech-to-Text Modality Conversion\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.227, \"y\": 7.814}, {\"title\": \"Advancing Visual Grounding with Scene Knowledge: Benchmark and Method\", \"topic\": \"Multimodal Language Models\", \"x\": 8.708, \"y\": 7.438}, {\"title\": \"IndigoVX: Where Human Intelligence Meets AI for Optimal Decision Making\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.252, \"y\": 3.156}, {\"title\": \"Incorporating Human Translator Style into English-Turkish Literary  Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.557, \"y\": 5.137}, {\"title\": \"Topic Identification For Spontaneous Speech: Enriching Audio Features  With Embedded Linguistic Information\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.094, \"y\": 5.431}, {\"title\": \"Prompting Large Language Models with Speech Recognition Abilities\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.874, \"y\": 5.159}, {\"title\": \"MeetEval: A Toolkit for Computation of Word Error Rates for Meeting  Transcription Systems\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.949, \"y\": 5.242}, {\"title\": \"Is ChatGPT Involved in Texts? Measure the Polish Ratio to Detect  ChatGPT-Generated Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.404, \"y\": 4.805}, {\"title\": \"CohortGPT: An Enhanced GPT for Participant Recruitment in Clinical Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.733, \"y\": 8.065}, {\"title\": \"GIST: Generating Image-Specific Text for Fine-grained Object  Classification\", \"topic\": \"Multimodal Language Models\", \"x\": 8.841, \"y\": 7.271}, {\"title\": \"Generator-Retriever-Generator Approach for Open-Domain Question  Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.642, \"y\": 5.119}, {\"title\": \"Applying QNLP to sentiment analysis in finance\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.449, \"y\": 6.859}, {\"title\": \"UMLS-KGI-BERT: Data-Centric Knowledge Integration in Transformers for  Biomedical Entity Recognition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.338, \"y\": 7.733}, {\"title\": \"Embroid: Unsupervised Prediction Smoothing Can Improve Few-Shot  Classification\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.71, \"y\": 3.673}, {\"title\": \"Integrating Pretrained ASR and LM to Perform Sequence Generation for  Spoken Language Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.778, \"y\": 5.122}, {\"title\": \"MASR: Multi-label Aware Speech Representation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.848, \"y\": 5.158}, {\"title\": \"FigCaps-HF: A Figure-to-Caption Generative Framework and Benchmark with  Human Feedback\", \"topic\": \"Multimodal Language Models\", \"x\": 9.089, \"y\": 7.326}, {\"title\": \"Divide & Bind Your Attention for Improved Generative Semantic Nursing\", \"topic\": \"Multimodal Language Models\", \"x\": 8.886, \"y\": 6.796}, {\"title\": \"Yelp Reviews and Food Types: A Comparative Analysis of Ratings,  Sentiments, and Topics\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.719, \"y\": 6.46}, {\"title\": \"Cross-Corpus Multilingual Speech Emotion Recognition: Amharic vs. Other  Languages\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.253, \"y\": 7.726}, {\"title\": \"Meta-Transformer: A Unified Framework for Multimodal Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.168, \"y\": 7.184}, {\"title\": \"Vesper: A Compact and Effective Pretrained Model for Speech Emotion  Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.197, \"y\": 7.839}, {\"title\": \"Multi-Method Self-Training: Improving Code Generation With Text, And  Vice Versa\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.218, \"y\": 2.281}, {\"title\": \"A Deep Dive into the Disparity of Word Error Rates Across Thousands of  NPTEL MOOC Videos\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.121, \"y\": 5.57}, {\"title\": \"Gender-tuning: Empowering Fine-tuning for Debiasing Pre-trained Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.192, \"y\": 4.321}, {\"title\": \"Building Socio-culturally Inclusive Stereotype Resources with Community  Engagement\", \"topic\": \"Bias in Language Models\", \"x\": 3.437, \"y\": 4.474}, {\"title\": \"IvyGPT: InteractiVe Chinese pathwaY language model in medical domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.703, \"y\": 8.067}, {\"title\": \"Transsion TSUP's speech recognition system for ASRU 2023 MADASR  Challenge\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.073, \"y\": 5.412}, {\"title\": \"Abusing Images and Sounds for Indirect Instruction Injection in  Multi-Modal LLMs\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.39, \"y\": 2.614}, {\"title\": \"SPRINT: A Unified Toolkit for Evaluating and Demystifying Zero-shot  Neural Sparse Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.608, \"y\": 4.895}, {\"title\": \"FinGPT: Democratizing Internet-scale Data for Financial Large Language  Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.841, \"y\": 6.863}, {\"title\": \"Findings of Factify 2: Multimodal Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.148, \"y\": 5.808}, {\"title\": \"Can Instruction Fine-Tuned Language Models Identify Social Bias through  Prompting?\", \"topic\": \"Bias in Language Models\", \"x\": 3.592, \"y\": 4.154}, {\"title\": \"PharmacyGPT: The AI Pharmacist\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.645, \"y\": 7.995}, {\"title\": \"DialogStudio: Towards Richest and Most Diverse Unified Dataset  Collection for Conversational AI\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.437, \"y\": 3.995}, {\"title\": \"Challenges and Applications of Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.468, \"y\": 4.065}, {\"title\": \"Exploring Transformer Extrapolation\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.617, \"y\": 3.497}, {\"title\": \"Gradient Sparsification For Masked Fine-Tuning of Transformers\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.969, \"y\": 2.527}, {\"title\": \"An Empirical Study on Fertility Proposals Using Multi-Grained Topic  Analysis Methods\", \"topic\": \"Fake News Detection\", \"x\": 3.949, \"y\": 6.347}, {\"title\": \"Generating Mathematical Derivations with Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.997, \"y\": 2.986}, {\"title\": \"Test-takers have a say: understanding the implications of the use of AI  in language tests\", \"topic\": \"Bias in Language Models\", \"x\": 4.816, \"y\": 4.233}, {\"title\": \"On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large  Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.565, \"y\": 4.146}, {\"title\": \"ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring  Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.261, \"y\": 7.293}, {\"title\": \"A comparative analysis of SRGAN models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.866, \"y\": 6.973}, {\"title\": \"Let's ViCE! Mimicking Human Cognitive Behavior in Image Generation  Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.706, \"y\": 7.643}, {\"title\": \"Multi-Modal Discussion Transformer: Integrating Text, Images and Graph  Transformers to Detect Hate Speech on Social Media\", \"topic\": \"Hate Speech Detection\", \"x\": 2.788, \"y\": 5.409}, {\"title\": \"Linearized Relative Positional Encoding\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.637, \"y\": 3.548}, {\"title\": \"Automated Ableism: An Exploration of Explicit Disability Biases in  Sentiment and Toxicity Analysis Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.19, \"y\": 4.678}, {\"title\": \"Unveiling Gender Bias in Terms of Profession Across LLMs: Analyzing and  Addressing Sociological Implications\", \"topic\": \"Bias in Language Models\", \"x\": 3.34, \"y\": 4.397}, {\"title\": \"Attention over pre-trained Sentence Embeddings for Long Document  Classification\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.661, \"y\": 3.517}, {\"title\": \"Unleashing the Imagination of Text: A Novel Framework for Text-to-image  Person Retrieval via Exploring the Power of Words\", \"topic\": \"Multimodal Language Models\", \"x\": 8.806, \"y\": 6.926}, {\"title\": \"Zero-shot Domain-sensitive Speech Recognition with Prompt-conditioning  Fine-tuning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.982, \"y\": 5.082}, {\"title\": \"Teach model to answer questions after comprehending the document\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.665, \"y\": 5.363}, {\"title\": \"Large Language Models Perform Diagnostic Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 5.477, \"y\": 8.236}, {\"title\": \"An Integrated NPL Approach to Sentiment Analysis in Satisfaction Surveys\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.68, \"y\": 6.623}, {\"title\": \"Comparative Performance Evaluation of Large Language Models for  Extracting Molecular Interactions and Pathway Knowledge\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.165, \"y\": 7.383}, {\"title\": \"AlpaGasus: Training A Better Alpaca with Fewer Data\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.14, \"y\": 2.256}, {\"title\": \"Do Models Explain Themselves? Counterfactual Simulatability of Natural  Language Explanations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.694, \"y\": 3.595}, {\"title\": \"Multilingual Speech-to-Speech Translation into Multiple Target Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.298, \"y\": 5.244}, {\"title\": \"Retentive Network: A Successor to Transformer for Large Language Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.764, \"y\": 3.251}, {\"title\": \"Multimodal Diffusion Segmentation Model for Object Segmentation from  Manipulation Instructions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.741, \"y\": 7.054}, {\"title\": \"The Resume Paradox: Greater Language Differences, Smaller Pay Gaps\", \"topic\": \"Bias in Language Models\", \"x\": 3.201, \"y\": 4.361}, {\"title\": \"Latent Jailbreak: A Benchmark for Evaluating Text Safety and Output  Robustness of Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.422, \"y\": 2.361}, {\"title\": \"Improving End-to-End Speech Translation by Imitation-Based Knowledge  Distillation with Synthetic Transcripts\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.887, \"y\": 4.706}, {\"title\": \"Enhancing Supervised Learning with Contrastive Markings in Neural  Machine Translation Training\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.599, \"y\": 4.663}, {\"title\": \"Gender mobility in the labor market with skills-based matching models\", \"topic\": \"Bias in Language Models\", \"x\": 3.367, \"y\": 4.361}, {\"title\": \"Legal Syllogism Prompting: Teaching Large Language Models for Legal  Judgment Prediction\", \"topic\": \"Legal NLP\", \"x\": 5.23, \"y\": 5.471}, {\"title\": \"Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language  Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.737, \"y\": 3.604}, {\"title\": \"CoAD: Automatic Diagnosis through Symptom and Disease Collaborative  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.754, \"y\": 8.364}, {\"title\": \"Extending the Frontier of ChatGPT: Code Generation and Debugging\", \"topic\": \"Bias in Language Models\", \"x\": 5.262, \"y\": 4.374}, {\"title\": \"PAT: Parallel Attention Transformer for Visual Question Answering in  Vietnamese\", \"topic\": \"Multimodal Language Models\", \"x\": 8.215, \"y\": 8.018}, {\"title\": \"ivrit.ai: A Comprehensive Dataset of Hebrew Speech for AI Research and  Development\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.899, \"y\": 5.498}, {\"title\": \"BASS: Block-wise Adaptation for Speech Summarization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.574, \"y\": 4.933}, {\"title\": \"Measuring Faithfulness in Chain-of-Thought Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.518, \"y\": 2.448}, {\"title\": \"Question Decomposition Improves the Faithfulness of Model-Generated  Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.646, \"y\": 2.52}, {\"title\": \"The Potential and Pitfalls of using a Large Language Model such as  ChatGPT or GPT-4 as a Clinical Assistant\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.596, \"y\": 8.118}, {\"title\": \"Facilitating Multi-turn Emotional Support Conversation with Positive  Emotion Elicitation: A Reinforcement Learning Approach\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.525, \"y\": 7.883}, {\"title\": \"A Survey of Techniques for Optimizing Transformer Inference\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.731, \"y\": 3.295}, {\"title\": \"MinT: Boosting Generalization in Mathematical Reasoning via Multi-View  Fine-Tuning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.082, \"y\": 2.627}, {\"title\": \"SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its  Departure from Current Machine Learning\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.515, \"y\": 6.788}, {\"title\": \"Model Adaptation for ASR in low-resource Indian Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.96, \"y\": 5.308}, {\"title\": \"Deduplicating and Ranking Solution Programs for Suggesting Reference  Solutions\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.345, \"y\": 2.492}, {\"title\": \"ChatDev: Communicative Agents for Software Development\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.427, \"y\": 2.948}, {\"title\": \"A Dialogue System for Assessing Activities of Daily Living: Improving  Consistency with Grounded Knowledge\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.318, \"y\": 3.94}, {\"title\": \"Transformers are Universal Predictors\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.344, \"y\": 3.645}, {\"title\": \"Opinion mining using Double Channel CNN for Recommender System\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.607, \"y\": 6.646}, {\"title\": \"Political Sentiment Analysis of Persian Tweets Using CNN-LSTM Model\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.649, \"y\": 6.553}, {\"title\": \"CPET: Effective Parameter-Efficient Tuning for Compressed Large Language  Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.003, \"y\": 2.386}, {\"title\": \"Leveraging Large Language Models to Generate Answer Set Programs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.641, \"y\": 2.927}, {\"title\": \"Coupling Large Language Models with Logic Programming for Robust and  General Reasoning from Text\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.684, \"y\": 3.128}, {\"title\": \"Single and Multi-Speaker Cloned Voice Detection: From Perceptual to  Learned Features\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.957, \"y\": 5.592}, {\"title\": \"Othering and low status framing of immigrant cuisines in US restaurant  reviews and large language models\", \"topic\": \"Bias in Language Models\", \"x\": 3.43, \"y\": 4.748}, {\"title\": \"Sensi-BERT: Towards Sensitivity Driven Fine-Tuning for  Parameter-Efficient BERT\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.002, \"y\": 2.419}, {\"title\": \"Towards spoken dialect identification of Irish\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.699, \"y\": 5.448}, {\"title\": \"Rank Your Summaries: Enhancing Bengali Text Summarization via  Ranking-based Approach\", \"topic\": \"Text Summarization\", \"x\": 5.454, \"y\": 6.395}, {\"title\": \"A scoping review on multimodal deep learning in biomedical images and  texts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.417, \"y\": 8.373}, {\"title\": \"Mitigating Bias in Conversations: A Hate Speech Classifier and Debiaser  with Prompts\", \"topic\": \"Hate Speech Detection\", \"x\": 2.772, \"y\": 5.244}, {\"title\": \"How Different Is Stereotypical Bias Across Languages?\", \"topic\": \"Bias in Language Models\", \"x\": 3.31, \"y\": 4.489}, {\"title\": \"Similarity-based Memory Enhanced Joint Entity and Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.965, \"y\": 6.867}, {\"title\": \"Towards dialect-inclusive recognition in a low-resource language: are  balanced corpora the answer?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.847, \"y\": 5.422}, {\"title\": \"Replay to Remember: Continual Layer-Specific Fine-tuning for German  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.145, \"y\": 5.052}, {\"title\": \"Are words equally surprising in audio and audio-visual comprehension?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.467, \"y\": 7.464}, {\"title\": \"Dialogue Agents 101: A Beginner's Guide to Critical Ingredients for  Designing Effective Conversational Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.153, \"y\": 3.753}, {\"title\": \"Fairness of ChatGPT and the Role Of Explainable-Guided Prompts\", \"topic\": \"Bias in Language Models\", \"x\": 3.5, \"y\": 4.203}, {\"title\": \"Learning to Retrieve In-Context Examples for Large Language Models\", \"topic\": \"In-Context Learning\", \"x\": 8.151, \"y\": 3.393}, {\"title\": \"Large Language Models Understand and Can be Enhanced by Emotional  Stimuli\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.54, \"y\": 7.666}, {\"title\": \"Controllable Data Augmentation for Few-Shot Text Mining with  Chain-of-Thought Attribute Manipulation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.656, \"y\": 2.241}, {\"title\": \"An Analysis of Dialogue Repair in Virtual Voice Assistants\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.207, \"y\": 3.894}, {\"title\": \"Leveraging Pretrained ASR Encoders for Effective and Efficient  End-to-End Speech Intent Classification and Slot Filling\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.992, \"y\": 5.064}, {\"title\": \"Making the Most Out of the Limited Context Length: Predictive Power  Varies with Clinical Note Type and Note Section\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.553, \"y\": 8.002}, {\"title\": \"Does Collaborative Human-LM Dialogue Generation Help Information  Extraction from Human Dialogues?\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.341, \"y\": 3.892}, {\"title\": \"Data Augmentation for Machine Translation via Dependency Subtree  Swapping\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.876, \"y\": 4.736}, {\"title\": \"Electoral Agitation Data Set: The Use Case of the Polish Election\", \"topic\": \"Fake News Detection\", \"x\": 3.715, \"y\": 5.971}, {\"title\": \"mBLIP: Efficient Bootstrapping of Multilingual Vision-LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.633, \"y\": 7.13}, {\"title\": \"Adapting an ASR Foundation Model for Spoken Language Assessment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.202, \"y\": 5.398}, {\"title\": \"Personalization for BERT-based Discriminative Speech Recognition  Rescoring\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.147, \"y\": 5.176}, {\"title\": \"Tackling Fake News in Bengali: Unraveling the Impact of Summarization  vs. Augmentation on Pre-trained Language Models\", \"topic\": \"Fake News Detection\", \"x\": 3.965, \"y\": 5.851}, {\"title\": \"EFL Students' Attitudes and Contradictions in a Machine-in-the-loop  Activity System\", \"topic\": \"Bias in Language Models\", \"x\": 4.964, \"y\": 4.429}, {\"title\": \"Going Beyond Local: Global Graph-Enhanced Personalized News  Recommendations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.912, \"y\": 2.947}, {\"title\": \"Convolutional Neural Networks for Sentiment Analysis on Weibo Data: A  Natural Language Processing Approach\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.737, \"y\": 6.748}, {\"title\": \"Exploring the Integration of Large Language Models into Automatic Speech  Recognition Systems: An Empirical Study\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.945, \"y\": 5.185}, {\"title\": \"National Origin Discrimination in Deep-learning-powered Automated Resume  Screening\", \"topic\": \"Bias in Language Models\", \"x\": 3.417, \"y\": 4.423}, {\"title\": \"AutoHint: Automatic Prompt Optimization with Hint Generation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.382, \"y\": 3.251}, {\"title\": \"ACTI at EVALITA 2023: Overview of the Conspiracy Theory Identification  Task\", \"topic\": \"Fake News Detection\", \"x\": 3.854, \"y\": 5.758}, {\"title\": \"Distilling Large Language Models for Biomedical Knowledge Extraction: A  Case Study on Adverse Drug Events\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.879, \"y\": 7.572}, {\"title\": \"A Comprehensive Overview of Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.617, \"y\": 4.044}, {\"title\": \"Instruction Mining: When Data Mining Meets Large Language Model  Finetuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.198, \"y\": 2.314}, {\"title\": \"MMBench: Is Your Multi-modal Model an All-around Player?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.007, \"y\": 7.553}, {\"title\": \"SummaryMixing: A Linear-Complexity Alternative to Self-Attention for  Speech Recognition and Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.071, \"y\": 4.998}, {\"title\": \"Interpreting deep embeddings for disease progression clustering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.875, \"y\": 8.294}, {\"title\": \"Pluggable Neural Machine Translation Models via Memory-augmented  Adapters\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.861, \"y\": 4.267}, {\"title\": \"PolyLM: An Open Source Polyglot Large Language Model\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.911, \"y\": 4.27}, {\"title\": \"Self-Distilled Quantization: Achieving High Compression Rates in  Transformer-Based Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.86, \"y\": 2.345}, {\"title\": \"Relational Extraction on Wikipedia Tables using Convolutional and Memory  Networks\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.845, \"y\": 6.799}, {\"title\": \"Improved POS tagging for spontaneous, clinical speech using data  augmentation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.124, \"y\": 5.59}, {\"title\": \"Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.651, \"y\": 3.882}, {\"title\": \"Neural Machine Translation Data Generation and Augmentation using  ChatGPT\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.785, \"y\": 4.477}, {\"title\": \"ReLoRA: High-Rank Training Through Low-Rank Updates\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.263, \"y\": 2.406}, {\"title\": \"Named entity recognition using GPT for identifying comparable companies\", \"topic\": \"Named Entity Recognition\", \"x\": 7.226, \"y\": 6.692}, {\"title\": \"U-CREAT: Unsupervised Case Retrieval using Events extrAcTion\", \"topic\": \"Legal NLP\", \"x\": 5.176, \"y\": 5.815}, {\"title\": \"Better Handling Coreference Resolution in Aspect Level Sentiment  Classification by Fine-Tuning Language Models\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.233, \"y\": 6.783}, {\"title\": \"SuryaKiran at MEDIQA-Sum 2023: Leveraging LoRA for Clinical Dialogue  Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.885, \"y\": 8.006}, {\"title\": \"TIAM -- A Metric for Evaluating Alignment in Text-to-Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.986, \"y\": 6.881}, {\"title\": \"Overview of BioASQ 2023: The eleventh BioASQ challenge on Large-Scale  Biomedical Semantic Indexing and Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.874, \"y\": 7.448}, {\"title\": \"Piecing Together Clues: A Benchmark for Evaluating the Detective Skills  of Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.403, \"y\": 3.114}, {\"title\": \"Argumentative Segmentation Enhancement for Legal Summarization\", \"topic\": \"Legal NLP\", \"x\": 4.977, \"y\": 5.765}, {\"title\": \"Towards Understanding In-Context Learning with Contrastive  Demonstrations and Saliency Maps\", \"topic\": \"In-Context Learning\", \"x\": 8.381, \"y\": 3.365}, {\"title\": \"Separate-and-Aggregate: A Transformer-based Patch Refinement Model for  Knowledge Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.039, \"y\": 6.03}, {\"title\": \"Improving RNN-Transducers with Acoustic LookAhead\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.209, \"y\": 5.132}, {\"title\": \"Secrets of RLHF in Large Language Models Part I: PPO\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.099, \"y\": 1.63}, {\"title\": \"KU-DMIS-MSRA at RadSum23: Pre-trained Vision-Language Model for  Radiology Report Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.278, \"y\": 8.614}, {\"title\": \"SimpleMTOD: A Simple Language Model for Multimodal Task-Oriented  Dialogue with Symbolic Scene Representation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.066, \"y\": 7.399}, {\"title\": \"ChatGPT for Digital Forensic Investigation: The Good, The Bad, and The  Unknown\", \"topic\": \"Bias in Language Models\", \"x\": 4.973, \"y\": 4.446}, {\"title\": \"Linear Alignment of Vision-language Models for Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.096, \"y\": 7.386}, {\"title\": \"Large Language Models as General Pattern Machines\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 6.612, \"y\": 3.23}, {\"title\": \"Retrieval of phonemes and Kohonen algorithm\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.617, \"y\": 5.196}, {\"title\": \"Hate Speech Detection via Dual Contrastive Learning\", \"topic\": \"Hate Speech Detection\", \"x\": 2.728, \"y\": 5.368}, {\"title\": \"Detecting LLM-Generated Text in Computing Education: A Comparative Study  for ChatGPT Cases\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.184, \"y\": 4.667}, {\"title\": \"Improving Factuality of Abstractive Summarization via Contrastive Reward  Learning\", \"topic\": \"Text Summarization\", \"x\": 5.477, \"y\": 6.145}, {\"title\": \"Exploring Large Language Model for Graph Data Understanding in Online  Job Recommendations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.919, \"y\": 2.924}, {\"title\": \"Enhancing Biomedical Text Summarization and Question-Answering: On the  Utility of Domain-Specific Pre-Training\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.148, \"y\": 7.412}, {\"title\": \"Unmasking the giant: A comprehensive evaluation of ChatGPT's proficiency  in coding algorithms and data structures\", \"topic\": \"Bias in Language Models\", \"x\": 5.313, \"y\": 4.356}, {\"title\": \"Learning to Generate Equitable Text in Dialogue from Biased Training  Data\", \"topic\": \"Bias in Language Models\", \"x\": 3.418, \"y\": 4.258}, {\"title\": \"HistRED: A Historical Document-Level Relation Extraction Dataset\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.989, \"y\": 6.807}, {\"title\": \"Augmenters at SemEval-2023 Task 1: Enhancing CLIP in Handling  Compositionality and Ambiguity for Zero-Shot Visual WSD through Prompt  Augmentation and Text-To-Image Diffusion\", \"topic\": \"Multimodal Language Models\", \"x\": 8.692, \"y\": 6.974}, {\"title\": \"ChatGPT in the Age of Generative AI and Large Language Models: A Concise  Survey\", \"topic\": \"Bias in Language Models\", \"x\": 5.038, \"y\": 4.386}, {\"title\": \"Automatic Coding at Scale: Design and Deployment of a Nationwide System  for Normalizing Referrals in the Chilean Public Healthcare System\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.831, \"y\": 8.283}, {\"title\": \"Self-Adaptive Sampling for Efficient Video Question-Answering on  Image--Text Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.564, \"y\": 8.048}, {\"title\": \"Can Generative Large Language Models Perform ASR Error Correction?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.06, \"y\": 5.349}, {\"title\": \"Towards cross-language prosody transfer for dialog\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.346, \"y\": 5.45}, {\"title\": \"Optimal Transport Posterior Alignment for Cross-lingual Semantic Parsing\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.266, \"y\": 4.995}, {\"title\": \"Disentangling Societal Inequality from Model Biases: Gender Inequality  in Divorce Court Proceedings\", \"topic\": \"Bias in Language Models\", \"x\": 3.31, \"y\": 4.509}, {\"title\": \"A Personalized Reinforcement Learning Summarization Service for Learning  Structure from Unstructured Data\", \"topic\": \"Text Summarization\", \"x\": 5.503, \"y\": 6.205}, {\"title\": \"Bidirectional Attention as a Mixture of Continuous Word Experts\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.736, \"y\": 3.203}, {\"title\": \"Can LLMs be Good Financial Advisors?: An Initial Study in Personal  Decision Making for Optimized Outcomes\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.852, \"y\": 6.857}, {\"title\": \"Toward Interactive Dictation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.702, \"y\": 5.771}, {\"title\": \"A Stitch in Time Saves Nine: Detecting and Mitigating Hallucinations of  LLMs by Validating Low-Confidence Generation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.231, \"y\": 1.138}, {\"title\": \"On decoder-only architecture for speech-to-text and large language model  integration\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.465, \"y\": 5.122}, {\"title\": \"Answering Ambiguous Questions via Iterative Prompting\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.55, \"y\": 5.086}, {\"title\": \"Embedding Mental Health Discourse for Community Recommendation\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.333, \"y\": 7.549}, {\"title\": \"MDACE: MIMIC Documents Annotated with Code Evidence\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.868, \"y\": 8.305}, {\"title\": \"INT-FP-QSim: Mixed Precision and Formats For Large Language Models and  Vision Transformers\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.704, \"y\": 2.146}, {\"title\": \"AI-UPV at EXIST 2023 -- Sexism Characterization Using Large Language  Models Under The Learning with Disagreements Regime\", \"topic\": \"Hate Speech Detection\", \"x\": 2.863, \"y\": 5.516}, {\"title\": \"Mitigating Negative Transfer with Task Awareness for Sexism, Hate  Speech, and Toxic Language Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.833, \"y\": 5.444}, {\"title\": \"Evaluating Biased Attitude Associations of Language Models in an  Intersectional Context\", \"topic\": \"Bias in Language Models\", \"x\": 3.414, \"y\": 4.498}, {\"title\": \"Token-Level Serialized Output Training for Joint Streaming ASR and ST  Leveraging Textual Alignments\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.831, \"y\": 5.174}, {\"title\": \"BiPhone: Modeling Inter Language Phonetic Influences in Text\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.618, \"y\": 5.568}, {\"title\": \"Covering Uncommon Ground: Gap-Focused Question Generation for Answer  Assessment\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.199, \"y\": 4.916}, {\"title\": \"Gammatonegram Representation for End-to-End Dysarthric Speech Processing  Tasks: Speech Recognition, Speaker Identification, and Intelligibility  Assessment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.313, \"y\": 5.637}, {\"title\": \"Performance Comparison of Pre-trained Models for Speech-to-Text in  Turkish: Whisper-Small and Wav2Vec2-XLS-R-300M\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.856, \"y\": 5.334}, {\"title\": \"Vision Language Transformers: A Survey\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.581, \"y\": 3.701}, {\"title\": \"Focused Transformer: Contrastive Training for Context Scaling\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.748, \"y\": 3.254}, {\"title\": \"Distilling Large Vision-Language Model with Out-of-Distribution  Generalizability\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.512, \"y\": 3.862}, {\"title\": \"T-MARS: Improving Visual Representations by Circumventing Text Feature  Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.881, \"y\": 7.13}, {\"title\": \"VisKoP: Visual Knowledge oriented Programming for Interactive Knowledge  Base Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.734, \"y\": 5.67}, {\"title\": \"KoRC: Knowledge oriented Reading Comprehension Benchmark for Deep Text  Understanding\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.602, \"y\": 5.307}, {\"title\": \"A Survey on Evaluation of Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.222, \"y\": 3.934}, {\"title\": \"A Novel Site-Agnostic Multimodal Deep Learning Model to Identify  Pro-Eating Disorder Content on Social Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.181, \"y\": 7.166}, {\"title\": \"Parameter-Efficient Fine-Tuning of LLaMA for the Clinical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.022, \"y\": 7.967}, {\"title\": \"On the Cultural Gap in Text-to-Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.877, \"y\": 6.763}, {\"title\": \"The Relationship Between Speech Features Changes When You Get Depressed:  Feature Correlations for Improving Speed and Performance of Depression  Detection\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.103, \"y\": 7.534}, {\"title\": \"Contrast Is All You Need\", \"topic\": \"Legal NLP\", \"x\": 5.252, \"y\": 5.86}, {\"title\": \"NatLogAttack: A Framework for Attacking Natural Language Inference  Models with Natural Logic\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.11, \"y\": 2.978}, {\"title\": \"Enhancing LLM with Evolutionary Fine Tuning for News Summary Generation\", \"topic\": \"Text Summarization\", \"x\": 5.532, \"y\": 6.178}, {\"title\": \"Read, Look or Listen? What's Needed for Solving a Multimodal Dataset\", \"topic\": \"Multimodal Language Models\", \"x\": 8.087, \"y\": 7.895}, {\"title\": \"On-Device Constrained Self-Supervised Speech Representation Learning for  Keyword Spotting via Knowledge Distillation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.889, \"y\": 4.697}, {\"title\": \"Scaling In-Context Demonstrations with Structured Attention\", \"topic\": \"In-Context Learning\", \"x\": 8.396, \"y\": 3.35}, {\"title\": \"Learning Symbolic Rules over Abstract Meaning Representations for  Textual Reinforcement Learning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 6.03, \"y\": 2.203}, {\"title\": \"Zero-Shot Dense Video Captioning by Jointly Optimizing Text and Moment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.936, \"y\": 7.777}, {\"title\": \"Evade ChatGPT Detectors via A Single Space\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.153, \"y\": 4.626}, {\"title\": \"ODD: A Benchmark Dataset for the Natural Language Processing based  Opioid Related Aberrant Behavior Detection\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.366, \"y\": 7.825}, {\"title\": \"Several categories of Large Language Models (LLMs): A Short Survey\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.425, \"y\": 3.948}, {\"title\": \"LongNet: Scaling Transformers to 1,000,000,000 Tokens\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.806, \"y\": 3.176}, {\"title\": \"Deductive Additivity for Planning of Natural Language Proofs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.713, \"y\": 3.011}, {\"title\": \"What Matters in Training a GPT4-Style Language Model with Multimodal  Inputs?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.232, \"y\": 7.36}, {\"title\": \"External Reasoning: Towards Multi-Large-Language-Models Interchangeable  Assistance with Human Feedback\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.469, \"y\": 2.788}, {\"title\": \"OpenDelta: A Plug-and-play Library for Parameter-efficient Adaptation of  Pre-trained Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.056, \"y\": 2.218}, {\"title\": \"Utilizing ChatGPT Generated Data to Retrieve Depression Symptoms from  Social Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.175, \"y\": 7.48}, {\"title\": \"Sumformer: Universal Approximation for Efficient Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.781, \"y\": 3.319}, {\"title\": \"Generative Job Recommendations with Large Language Model\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.929, \"y\": 2.875}, {\"title\": \"Becoming self-instruct: introducing early stopping criteria for minimal  instruct tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.157, \"y\": 2.371}, {\"title\": \"Flacuna: Unleashing the Problem Solving Power of Vicuna using FLAN  Fine-Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.339, \"y\": 2.377}, {\"title\": \"Flowchase: a Mobile Application for Pronunciation Training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.966, \"y\": 5.564}, {\"title\": \"CAME: Confidence-guided Adaptive Memory Efficient Optimization\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.211, \"y\": 2.324}, {\"title\": \"Recommender Systems in the Era of Large Language Models (LLMs)\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.97, \"y\": 2.96}, {\"title\": \"EHRSHOT: An EHR Benchmark for Few-Shot Evaluation of Foundation Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.971, \"y\": 8.104}, {\"title\": \"Using Data Augmentations and VTLN to Reduce Bias in Dutch End-to-End  Speech Recognition Systems\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.163, \"y\": 5.354}, {\"title\": \"PULSAR at MEDIQA-Sum 2023: Large Language Models Augmented by Synthetic  Dialogue Convert Patient Dialogues to Medical Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.773, \"y\": 8.218}, {\"title\": \"Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge  Graphs\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.235, \"y\": 6.065}, {\"title\": \"Math Agents: Computational Infrastructure, Mathematical Embedding, and  Genomics\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.689, \"y\": 3.102}, {\"title\": \"The Inner Sentiments of a Thought\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.545, \"y\": 7.252}, {\"title\": \"Align With Purpose: Optimize Desired Properties in CTC Models with a  General Plug-and-Play Framework\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.218, \"y\": 5.013}, {\"title\": \"Dipping PLMs Sauce: Bridging Structure and Text for Effective Knowledge  Graph Completion via Conditional Soft Prompting\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.03, \"y\": 5.896}, {\"title\": \"Racial Bias Trends in the Text of US Legal Opinions\", \"topic\": \"Bias in Language Models\", \"x\": 3.449, \"y\": 4.649}, {\"title\": \"Robust Hate Speech Detection in Social Media: A Cross-Dataset Empirical  Evaluation\", \"topic\": \"Hate Speech Detection\", \"x\": 2.747, \"y\": 5.373}, {\"title\": \"Disentanglement in a GAN for Unconditional Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.676, \"y\": 5.736}, {\"title\": \"Boosting Norwegian Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.04, \"y\": 5.454}, {\"title\": \"Unified Conversational Models with System-Initiated Transitions between  Chit-Chat and Task-Oriented Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.365, \"y\": 3.83}, {\"title\": \"mPLUG-DocOwl: Modularized Multimodal Large Language Model for Document  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.053, \"y\": 7.051}, {\"title\": \"Chain of Thought Prompting Elicits Knowledge Augmentation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.725, \"y\": 2.265}, {\"title\": \"Prompt Tuning Pushes Farther, Contrastive Learning Pulls Closer: A  Two-Stage Approach to Mitigate Social Biases\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 3.66, \"y\": 3.96}, {\"title\": \"On Evaluating and Mitigating Gender Biases in Multilingual Settings\", \"topic\": \"Bias in Language Models\", \"x\": 3.232, \"y\": 4.4}, {\"title\": \"SCAT: Robust Self-supervised Contrastive Learning via Adversarial  Training for Text Classification\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.179, \"y\": 3.141}, {\"title\": \"CARE-MI: Chinese Benchmark for Misinformation Evaluation in Maternity  and Infant Care\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.835, \"y\": 7.75}, {\"title\": \"Diverse Retrieval-Augmented In-Context Learning for Dialogue State  Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.656, \"y\": 3.922}, {\"title\": \"ReactIE: Enhancing Chemical Reaction Extraction with Weak Supervision\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.72, \"y\": 7.267}, {\"title\": \"On Conditional and Compositional Language Model Differentiable Prompting\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.755, \"y\": 3.373}, {\"title\": \"Garbage in, garbage out: Zero-shot detection of crime using Large  Language Models\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.041, \"y\": 5.022}, {\"title\": \"ALBERTI, a Multilingual Domain Specific Language Model for Poetry  Analysis\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.069, \"y\": 5.084}, {\"title\": \"Implicit Memory Transformer for Computationally Efficient Simultaneous  Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.429, \"y\": 4.852}, {\"title\": \"Shiftable Context: Addressing Training-Inference Context Mismatch in  Simultaneous Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.454, \"y\": 5.113}, {\"title\": \"Semantic enrichment towards efficient speech representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.361, \"y\": 4.997}, {\"title\": \"The Evolution of Substance Use Coverage in the Philadelphia Inquirer\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.116, \"y\": 6.789}, {\"title\": \"SCITUNE: Aligning Large Language Models with Scientific Multimodal  Instructions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.211, \"y\": 7.079}, {\"title\": \"Exploring the In-context Learning Ability of Large Language Model for  Biomedical Concept Linking\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.247, \"y\": 7.619}, {\"title\": \"Iterative Zero-Shot LLM Prompting for Knowledge Graph Construction\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.894, \"y\": 5.568}, {\"title\": \"Analyzing Multiple-Choice Reading and Listening Comprehension Tests\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.236, \"y\": 5.01}, {\"title\": \"Visual Instruction Tuning with Polite Flamingo\", \"topic\": \"Multimodal Language Models\", \"x\": 8.384, \"y\": 7.338}, {\"title\": \"Towards Suicide Prevention from Bipolar Disorder with Temporal  Symptom-Aware Multitask Learning\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.23, \"y\": 7.493}, {\"title\": \"Challenges in Domain-Specific Abstractive Summarization and How to  Overcome them\", \"topic\": \"Text Summarization\", \"x\": 5.61, \"y\": 6.189}, {\"title\": \"Data-Driven Information Extraction and Enrichment of Molecular Profiling  Data for Cancer Cell Lines\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.08, \"y\": 7.494}, {\"title\": \"Node-weighted Graph Convolutional Network for Depression Detection in  Transcribed Clinical Interviews\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.138, \"y\": 7.424}, {\"title\": \"UniFine: A Unified and Fine-grained Approach for Zero-shot  Vision-Language Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.819, \"y\": 7.122}, {\"title\": \"ContextSpeech: Expressive and Efficient Text-to-Speech for Paragraph  Reading\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.563, \"y\": 5.655}, {\"title\": \"CollabKG: A Learnable Human-Machine-Cooperative Information Extraction  Toolkit for (Event) Knowledge Graph Construction\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.042, \"y\": 6.182}, {\"title\": \"Multilingual Contextual Adapters To Improve Custom Word Recognition In  Low-resource Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.298, \"y\": 5.065}, {\"title\": \"An End-to-End Multi-Module Audio Deepfake Generation System for ADD  Challenge 2023\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.705, \"y\": 5.832}, {\"title\": \"Interpretability and Transparency-Driven Detection and Transformation of  Textual Adversarial Examples (IT-DT)\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.205, \"y\": 2.974}, {\"title\": \"MedCPT: Contrastive Pre-trained Transformers with Large-scale PubMed  Search Logs for Zero-shot Biomedical Information Retrieval\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.38, \"y\": 7.886}, {\"title\": \"Conformer LLMs -- Convolution Augmented Large Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.934, \"y\": 4.921}, {\"title\": \"GenRec: Large Language Model for Generative Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.9, \"y\": 2.848}, {\"title\": \"Don't Stop Self-Supervision: Accent Adaptation of Speech Representations  via Residual Adapters\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.032, \"y\": 5.21}, {\"title\": \"A Dual-Stream Recurrence-Attention Network With Global-Local Awareness  for Emotion Recognition in Textual Dialog\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.25, \"y\": 7.798}, {\"title\": \"Understanding Counterspeech for Online Harm Mitigation\", \"topic\": \"Hate Speech Detection\", \"x\": 2.76, \"y\": 5.253}, {\"title\": \"Low-Resource Cross-Lingual Adaptive Training for Nigerian Pidgin\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.382, \"y\": 4.834}, {\"title\": \"Effective Matching of Patients to Clinical Trials using Entity  Extraction and Neural Re-ranking\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.835, \"y\": 7.784}, {\"title\": \"CephGPT-4: An Interactive Multimodal Cephalometric Measurement and  Diagnostic System with Visual Large Language Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.906, \"y\": 8.208}, {\"title\": \"Single Sequence Prediction over Reasoning Graphs for Multi-hop QA\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.837, \"y\": 5.462}, {\"title\": \"Hierarchical Pretraining for Biomedical Term Embeddings\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.157, \"y\": 7.891}, {\"title\": \"InstructEval: Systematic Evaluation of Instruction Selection Methods\", \"topic\": \"In-Context Learning\", \"x\": 8.29, \"y\": 3.266}, {\"title\": \"How far is Language Model from 100% Few-shot Named Entity Recognition in  Medical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.134, \"y\": 7.838}, {\"title\": \"The Integer Linear Programming Inference Cookbook\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.788, \"y\": 3.121}, {\"title\": \"What Do Self-Supervised Speech Models Know About Words?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.615, \"y\": 4.957}, {\"title\": \"Queer People are People First: Deconstructing Sexual Identity  Stereotypes in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.279, \"y\": 4.46}, {\"title\": \"SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen  LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.49, \"y\": 7.265}, {\"title\": \"Statler: State-Maintaining Language Models for Embodied Reasoning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.905, \"y\": 2.569}, {\"title\": \"Meta-Reasoning: Semantics-Symbol Deconstruction for Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.685, \"y\": 2.919}, {\"title\": \"Stay on topic with Classifier-Free Guidance\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.485, \"y\": 3.41}, {\"title\": \"Voting-based Multimodal Automatic Deception Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.012, \"y\": 5.76}, {\"title\": \"Towards Improving the Performance of Pre-Trained Speech Models for  Low-Resource Languages Through Lateral Inhibition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.934, \"y\": 5.186}, {\"title\": \"A New Task and Dataset on Detecting Attacks on Human Rights Defenders\", \"topic\": \"Hate Speech Detection\", \"x\": 3.195, \"y\": 5.486}, {\"title\": \"Biomedical Language Models are Robust to Sub-optimal Tokenization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.476, \"y\": 7.562}, {\"title\": \"A Cost-aware Study of Depression Language on Social Media using Topic  and Affect Contextualization\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.103, \"y\": 7.378}, {\"title\": \"Preference Ranking Optimization for Human Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.275, \"y\": 1.405}, {\"title\": \"An automated method for the ontological representation of security  directives\", \"topic\": \"Legal NLP\", \"x\": 5.47, \"y\": 5.488}, {\"title\": \"Knowledge Base Completion for Long-Tail Entities\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.086, \"y\": 6.063}, {\"title\": \"SummQA at MEDIQA-Chat 2023:In-Context Learning with GPT-4 for Medical  Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.476, \"y\": 7.923}, {\"title\": \"Prediction of COVID-19 Patients' Emergency Room Revisit using  Multi-Source Transfer Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.753, \"y\": 8.264}, {\"title\": \"Could Small Language Models Serve as Recommenders? Towards Data-centric  Cold-start Recommendations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.887, \"y\": 2.883}, {\"title\": \"LLaVAR: Enhanced Visual Instruction Tuning for Text-Rich Image  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.436, \"y\": 7.446}, {\"title\": \"Towards Grammatical Tagging for the Legal Language of Cybersecurity\", \"topic\": \"Legal NLP\", \"x\": 5.106, \"y\": 5.68}, {\"title\": \"Exploring & Exploiting High-Order Graph Structure for Sparse Knowledge  Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.028, \"y\": 5.989}, {\"title\": \"High-Quality Automatic Voice Over with Accurate Alignment: Supervision  through Self-Supervised Discrete Speech Units\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.721, \"y\": 5.635}, {\"title\": \"MEMD-ABSA: A Multi-Element Multi-Domain Dataset for Aspect-Based  Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.144, \"y\": 6.786}, {\"title\": \"UMASS_BioNLP at MEDIQA-Chat 2023: Can LLMs generate high-quality  synthetic note-oriented doctor-patient conversations?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.507, \"y\": 8.091}, {\"title\": \"Leveraging Cross-Utterance Context For ASR Decoding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.064, \"y\": 5.109}, {\"title\": \"CLIPAG: Towards Generator-Free Text-to-Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.954, \"y\": 7.127}, {\"title\": \"Stop Pre-Training: Adapt Visual-Language Models to Unseen Languages\", \"topic\": \"Multimodal Language Models\", \"x\": 8.59, \"y\": 7.288}, {\"title\": \"DialoGPS: Dialogue Path Sampling in Continuous Semantic Space for Data  Augmentation in Multi-Turn Conversations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.56, \"y\": 3.922}, {\"title\": \"Learning Multilingual Expressive Speech Representation for Prosody  Prediction without Parallel Data\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.209, \"y\": 7.847}, {\"title\": \"Automatic Speech Recognition of Non-Native Child Speech for Language  Learning Applications\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.191, \"y\": 5.496}, {\"title\": \"ZeroGen: Zero-shot Multimodal Controllable Text Generation with Multiple  Oracles\", \"topic\": \"Multimodal Language Models\", \"x\": 8.377, \"y\": 6.91}, {\"title\": \"An Efficient Sparse Inference Software Accelerator for Transformer-based  Language Models on CPUs\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.504, \"y\": 2.512}, {\"title\": \"ICSVR: Investigating Compositional and Syntactic Understanding in Video  Retrieval Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.801, \"y\": 7.882}, {\"title\": \"Pre-Training Multi-Modal Dense Retrievers for Outside-Knowledge Visual  Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.088, \"y\": 7.912}, {\"title\": \"MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep  Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.989, \"y\": 7.369}, {\"title\": \"Towards Language Models That Can See: Computer Vision Through the LENS  of Natural Language\", \"topic\": \"Multimodal Language Models\", \"x\": 8.348, \"y\": 7.507}, {\"title\": \"Multi-Site Clinical Federated Learning using Recursive and Attentive  Models and NVFlare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.826, \"y\": 8.162}, {\"title\": \"Leveraging GPT-4 for Food Effect Summarization to Enhance  Product-Specific Guidance Development via Iterative Prompting\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.559, \"y\": 7.463}, {\"title\": \"CBBQ: A Chinese Bias Benchmark Dataset Curated with Human-AI  Collaboration for Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.473, \"y\": 4.236}, {\"title\": \"SkillNet-X: A Multilingual Multitask Model with Sparsely Activated  Skills\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.459, \"y\": 4.364}, {\"title\": \"A Framework for Identifying Depression on Social Media:  MentalRiskES@IberLEF 2023\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.113, \"y\": 7.394}, {\"title\": \"Is ChatGPT a Biomedical Expert? -- Exploring the Zero-Shot Performance  of Current GPT Models in Biomedical Tasks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.854, \"y\": 7.538}, {\"title\": \"Chatlaw: A Multi-Agent Collaborative Legal Assistant with Knowledge  Graph Enhanced Mixture-of-Experts Large Language Model\", \"topic\": \"Legal NLP\", \"x\": 5.236, \"y\": 5.485}, {\"title\": \"What Sentiment and Fun Facts We Learnt Before FIFA World Cup Qatar 2022  Using Twitter and AI\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 3.925, \"y\": 6.633}, {\"title\": \"Exploring Spatial-Temporal Variations of Public Discourse on Social  Media: A Case Study on the First Wave of the Coronavirus Pandemic in Italy\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.055, \"y\": 6.673}, {\"title\": \"Accelerating Transducers through Adjacent Token Merging\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.164, \"y\": 5.108}, {\"title\": \"Sentence-to-Label Generation Framework for Multi-task Learning of  Japanese Sentence Classification and Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.334, \"y\": 6.711}, {\"title\": \"MAT: Mixed-Strategy Game of Adversarial Training in Fine-tuning\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.127, \"y\": 3.104}, {\"title\": \"Confidence-based Ensembles of End-to-End Speech Recognition Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.203, \"y\": 5.15}, {\"title\": \"FLuRKA: Fast and accurate unified Low-Rank & Kernel Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.961, \"y\": 3.25}, {\"title\": \"Next Steps for Human-Centered Generative AI: A Technical Perspective\", \"topic\": \"Bias in Language Models\", \"x\": 4.919, \"y\": 4.2}, {\"title\": \"Identity Construction in a Misogynist Incels Forum\", \"topic\": \"Hate Speech Detection\", \"x\": 2.954, \"y\": 5.21}, {\"title\": \"A Weakly Supervised Classifier and Dataset of White Supremacist Language\", \"topic\": \"Hate Speech Detection\", \"x\": 2.75, \"y\": 5.362}, {\"title\": \"SparseOptimizer: Sparsify Language Models through Moreau-Yosida  Regularization and Accelerate via Compiler Co-design\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.496, \"y\": 2.302}, {\"title\": \"Constructing Multilingual Code Search Dataset Using Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.429, \"y\": 4.496}, {\"title\": \"CamemBERT-bio: Leveraging Continual Pre-training for Cost-Effective  Models on French Biomedical Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.205, \"y\": 7.953}, {\"title\": \"Unleashing the Power of User Reviews: Exploring Airline Choices at  Catania Airport, Italy\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.651, \"y\": 6.554}, {\"title\": \"Phase Space Analysis of Cardiac Spectra\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.93, \"y\": 8.372}, {\"title\": \"Quality Estimation of Machine Translated Texts based on Direct Evidence  from Training Data\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.827, \"y\": 4.694}, {\"title\": \"SAHAAYAK 2023 -- the Multi Domain Bilingual Parallel Corpus of Sanskrit  to Hindi for Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.44, \"y\": 5.223}, {\"title\": \"Exploiting Pseudo Future Contexts for Emotion Recognition in  Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.272, \"y\": 7.79}, {\"title\": \"3D-Speaker: A Large-Scale Multi-Device, Multi-Distance, and  Multi-Dialect Corpus for Speech Representation Disentanglement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.755, \"y\": 5.232}, {\"title\": \"Gender Bias in BERT -- Measuring and Analysing Biases through Sentiment  Rating in a Realistic Downstream Classification Task\", \"topic\": \"Bias in Language Models\", \"x\": 3.218, \"y\": 4.423}, {\"title\": \"IDOL: Indicator-oriented Logic Pre-training for Logical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.77, \"y\": 2.93}, {\"title\": \"GroundNLQ @ Ego4D Natural Language Queries Challenge 2023\", \"topic\": \"Multimodal Language Models\", \"x\": 8.82, \"y\": 7.688}, {\"title\": \"MindDial: Belief Dynamics Tracking with Theory-of-Mind Modeling for  Situated Neural Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.519, \"y\": 3.686}, {\"title\": \"C-PMI: Conditional Pointwise Mutual Information for Turn-level Dialogue  Evaluation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.185, \"y\": 3.848}, {\"title\": \"Emulating Reader Behaviors for Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.027, \"y\": 5.829}, {\"title\": \"Learning to Rank in Generative Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.413, \"y\": 4.842}, {\"title\": \"Reducing the gap between streaming and non-streaming Transducer-based  ASR by adaptive two-stage knowledge distillation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.149, \"y\": 4.949}, {\"title\": \"On the Universal Adversarial Perturbations for Efficient Data-free  Adversarial Detection\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.144, \"y\": 3.008}, {\"title\": \"DSRM: Boost Textual Adversarial Training with Distribution Shift Risk  Minimization\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.126, \"y\": 3.046}, {\"title\": \"Understanding In-Context Learning via Supportive Pretraining Data\", \"topic\": \"In-Context Learning\", \"x\": 8.489, \"y\": 3.349}, {\"title\": \"WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in  Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.29, \"y\": 4.513}, {\"title\": \"FunQA: Towards Surprising Video Comprehension\", \"topic\": \"Multimodal Language Models\", \"x\": 8.551, \"y\": 8.031}, {\"title\": \"InterCode: Standardizing and Benchmarking Interactive Coding with  Execution Feedback\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.339, \"y\": 2.211}, {\"title\": \"Composing Parameter-Efficient Modules with Arithmetic Operations\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.191, \"y\": 2.351}, {\"title\": \"The Art of Embedding Fusion: Optimizing Hate Speech Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.7, \"y\": 5.358}, {\"title\": \"HonestBait: Forward References for Attractive but Faithful Headline  Generation\", \"topic\": \"Fake News Detection\", \"x\": 4.25, \"y\": 5.976}, {\"title\": \"Vietnamese multi-document summary using subgraph selection approach --  VLSP 2022 AbMuSu Shared Task\", \"topic\": \"Text Summarization\", \"x\": 5.531, \"y\": 6.509}, {\"title\": \"Kosmos-2: Grounding Multimodal Large Language Models to the World\", \"topic\": \"Multimodal Language Models\", \"x\": 8.452, \"y\": 7.261}, {\"title\": \"Label-Aware Hyperbolic Embeddings for Fine-grained Emotion  Classification\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.284, \"y\": 7.628}, {\"title\": \"A Positive-Unlabeled Metric Learning Framework for Document-Level  Relation Extraction with Incomplete Labeling\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.036, \"y\": 6.846}, {\"title\": \"Uncovering Political Hate Speech During Indian Election Campaign: A New  Low-Resource Dataset and Baselines\", \"topic\": \"Hate Speech Detection\", \"x\": 2.781, \"y\": 5.407}, {\"title\": \"Learn over Past, Evolve for Future: Forecasting Temporal Trends for Fake  News Detection\", \"topic\": \"Fake News Detection\", \"x\": 3.985, \"y\": 5.923}, {\"title\": \"Ontology Enrichment from Texts: A Biomedical Dataset for Concept  Discovery and Placement\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.13, \"y\": 7.443}, {\"title\": \"SugarCrepe: Fixing Hackable Benchmarks for Vision-Language  Compositionality\", \"topic\": \"Multimodal Language Models\", \"x\": 8.529, \"y\": 7.43}, {\"title\": \"Factorised Speaker-environment Adaptive Training of Conformer Speech  Recognition Systems\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.221, \"y\": 5.097}, {\"title\": \"Transfer Learning across Several Centuries: Machine and Historian  Integrated Method to Decipher Royal Secretary's Diary\", \"topic\": \"Named Entity Recognition\", \"x\": 7.102, \"y\": 6.65}, {\"title\": \"Exploring the Robustness of Large Language Models for Solving  Programming Problems\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.264, \"y\": 2.601}, {\"title\": \"Mitigating Hallucination in Large Multi-Modal Models via Robust  Instruction Tuning\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.531, \"y\": 1.081}, {\"title\": \"Cross-Lingual Cross-Age Group Adaptation for Low-Resource Elderly Speech  Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.149, \"y\": 7.79}, {\"title\": \"Data-Driven Approach for Formality-Sensitive Machine Translation:  Language-Specific Handling and Synthetic Data Generation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.459, \"y\": 4.835}, {\"title\": \"The Singing Voice Conversion Challenge 2023\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.806, \"y\": 5.777}, {\"title\": \"RobuT: A Systematic Study of Table QA Robustness Against Human-Annotated  Adversarial Perturbations\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.127, \"y\": 3.084}, {\"title\": \"Addressing Cold Start Problem for End-to-end Automatic Speech Scoring\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.726, \"y\": 5.08}, {\"title\": \"Visual Question Answering in Remote Sensing with Cross-Attention and  Multimodal Information Bottleneck\", \"topic\": \"Multimodal Language Models\", \"x\": 8.209, \"y\": 8.044}, {\"title\": \"Unveiling the Potential of Sentiment: Can Large Language Models Predict  Chinese Stock Price Movements?\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.634, \"y\": 6.92}, {\"title\": \"Low-Rank Prune-And-Factorize for Language Model Compression\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.59, \"y\": 2.526}, {\"title\": \"DSE-TTS: Dual Speaker Embedding for Cross-Lingual Text-to-Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.606, \"y\": 5.76}, {\"title\": \"Chain-of-Thought Prompt Distillation for Multimodal Named Entity  Recognition and Multimodal Relation Extraction\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.824, \"y\": 2.384}, {\"title\": \"Chinese Fine-Grained Financial Sentiment Analysis with Large Language  Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.733, \"y\": 6.894}, {\"title\": \"DesCo: Learning Object Recognition with Rich Language Descriptions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.734, \"y\": 7.309}, {\"title\": \"Symbolic Chain-of-Thought Distillation: Small Models Can Also \\\"Think\\\"  Step-by-Step\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.794, \"y\": 2.269}, {\"title\": \"Towards Robust Aspect-based Sentiment Analysis through  Non-counterfactual Augmentations\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.107, \"y\": 6.8}, {\"title\": \"Emotion Flip Reasoning in Multiparty Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.35, \"y\": 7.825}, {\"title\": \"Can GPT-4 Support Analysis of Textual Data in Tasks Requiring Highly  Specialized Domain Expertise?\", \"topic\": \"Legal NLP\", \"x\": 5.264, \"y\": 5.662}, {\"title\": \"Math Word Problem Solving by Generating Linguistic Variants of Problem  Statements\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.086, \"y\": 2.72}, {\"title\": \"L3Cube-MahaSent-MD: A Multi-domain Marathi Sentiment Analysis Dataset  and Transformer Models\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.402, \"y\": 6.678}, {\"title\": \"The Double Helix inside the NLP Transformer\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.499, \"y\": 3.633}, {\"title\": \"Cross-Language Speech Emotion Recognition Using Multimodal Dual  Attention Transformers\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.22, \"y\": 7.787}, {\"title\": \"The CHiME-7 DASR Challenge: Distant Meeting Transcription with Multiple  Devices in Diverse Scenarios\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.148, \"y\": 5.401}, {\"title\": \"On-Policy Distillation of Language Models: Learning from Self-Generated  Mistakes\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.526, \"y\": 3.822}, {\"title\": \"Max-Margin Token Selection in Attention Mechanism\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.791, \"y\": 3.28}, {\"title\": \"Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.645, \"y\": 5.671}, {\"title\": \"Master-ASR: Achieving Multilingual Scalability and Low-Resource  Adaptation in ASR with Modular Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.01, \"y\": 5.19}, {\"title\": \"A Survey on Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.973, \"y\": 7.358}, {\"title\": \"Knowledge-Infused Self Attention Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.64, \"y\": 3.555}, {\"title\": \"Learning Descriptive Image Captioning via Semipermeable Maximum  Likelihood Estimation\", \"topic\": \"Multimodal Language Models\", \"x\": 9.086, \"y\": 7.418}, {\"title\": \"Implementing contextual biasing in GPU decoder for online ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.419, \"y\": 5.04}, {\"title\": \"Abstractive Text Summarization for Resumes With Cutting Edge NLP  Transformers and LSTM\", \"topic\": \"Text Summarization\", \"x\": 5.729, \"y\": 6.277}, {\"title\": \"Mutually Guided Few-shot Learning for Relational Triple Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.112, \"y\": 6.669}, {\"title\": \"Towards Effective and Compact Contextual Representation for Conformer  Transducer Speech Recognition Systems\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.232, \"y\": 5.052}, {\"title\": \"Visual Adversarial Examples Jailbreak Aligned Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.223, \"y\": 2.675}, {\"title\": \"Named entity recognition in resumes\", \"topic\": \"Named Entity Recognition\", \"x\": 7.148, \"y\": 6.818}, {\"title\": \"Analysis of the Cambridge Multiple-Choice Questions Reading Dataset with  a Focus on Candidate Response Distribution\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.23, \"y\": 4.946}, {\"title\": \"Towards Explainable Evaluation Metrics for Machine Translation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.925, \"y\": 3.876}, {\"title\": \"Speech Emotion Diarization: Which Emotion Appears When?\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.148, \"y\": 7.889}, {\"title\": \"Quantizable Transformers: Removing Outliers by Helping Attention Heads  Do Nothing\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.91, \"y\": 3.22}, {\"title\": \"AudioPaLM: A Large Language Model That Can Speak and Listen\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.499, \"y\": 5.451}, {\"title\": \"Cross-lingual Cross-temporal Summarization: Dataset, Models, Evaluation\", \"topic\": \"Text Summarization\", \"x\": 5.685, \"y\": 6.315}, {\"title\": \"Implicit spoken language diarization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.835, \"y\": 5.35}, {\"title\": \"Unveiling Global Narratives: A Multilingual Twitter Dataset of News  Media on the Russo-Ukrainian Conflict\", \"topic\": \"Fake News Detection\", \"x\": 3.74, \"y\": 6.136}, {\"title\": \"Natural Language Processing in Electronic Health Records in Relation to  Healthcare Decision-making: A Systematic Review\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.459, \"y\": 7.74}, {\"title\": \"Multilingual Neural Machine Translation System for Indic to Indic  Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.809, \"y\": 4.883}, {\"title\": \"Constructing Colloquial Dataset for Persian Sentiment Analysis of Social  Microblogs\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.582, \"y\": 6.671}, {\"title\": \"Instruct-FinGPT: Financial Sentiment Analysis by Instruction Tuning of  General-Purpose Large Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.758, \"y\": 6.888}, {\"title\": \"Identifying and Extracting Rare Disease Phenotypes with Large Language  Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.819, \"y\": 8.087}, {\"title\": \"A Reference-less Quality Metric for Automatic Speech Recognition via  Contrastive-Learning of a Multi-Language Model with Self-Supervision\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.121, \"y\": 5.277}, {\"title\": \"NoRefER: a Referenceless Quality Metric for Automatic Speech Recognition  via Semi-Supervised Language Model Fine-Tuning with Contrastive Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.148, \"y\": 5.316}, {\"title\": \"Joint Prompt Optimization of Stacked LLMs using Variational Inference\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.516, \"y\": 3.028}, {\"title\": \"VisoGender: A dataset for benchmarking gender bias in image-text pronoun  resolution\", \"topic\": \"Bias in Language Models\", \"x\": 3.187, \"y\": 4.466}, {\"title\": \"Testing of Detection Tools for AI-Generated Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.236, \"y\": 4.738}, {\"title\": \"Iterated Piecewise Affine (IPA) Approximation for Language Modeling\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.464, \"y\": 3.539}, {\"title\": \"Medical ministrations through web scraping\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.578, \"y\": 7.75}, {\"title\": \"Bidirectional End-to-End Learning of Retriever-Reader Paradigm for  Entity Linking\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.047, \"y\": 6.639}, {\"title\": \"Towards Enriched Controllability for Educational Question Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.2, \"y\": 4.994}, {\"title\": \"Mixture Encoder for Joint Speech Separation and Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.175, \"y\": 5.259}, {\"title\": \"Mass-Producing Failures of Multimodal Systems with Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.879, \"y\": 7.605}, {\"title\": \"Towards Accurate Translation via Semantically Appropriate Application of  Lexical Constraints\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.726, \"y\": 4.455}, {\"title\": \"Strategies in Transfer Learning for Low-Resource Speech Synthesis: Phone  Mapping, Features Input, and Source Language Selection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.554, \"y\": 5.416}, {\"title\": \"Visual-Aware Text-to-Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.532, \"y\": 5.936}, {\"title\": \"3HAN: A Deep Neural Network for Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.042, \"y\": 5.809}, {\"title\": \"Efficient Machine Translation Corpus Generation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.871, \"y\": 4.63}, {\"title\": \"QuOTeS: Query-Oriented Technical Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.844, \"y\": 6.325}, {\"title\": \"EvolveMT: an Ensemble MT Engine Improving Itself with Usage Only\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.854, \"y\": 4.549}, {\"title\": \"A Simple and Effective Pruning Approach for Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.47, \"y\": 2.37}, {\"title\": \"Recent Advances in Direct Speech-to-text Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.464, \"y\": 5.252}, {\"title\": \"An empirical study of using radiology reports and images to improve ICU  mortality prediction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.041, \"y\": 8.495}, {\"title\": \"Improving Image Captioning Descriptiveness by Ranking and LLM-based  Fusion\", \"topic\": \"Multimodal Language Models\", \"x\": 9.019, \"y\": 7.429}, {\"title\": \"FAIR: A Causal Framework for Accurately Inferring Judgments Reversals\", \"topic\": \"Legal NLP\", \"x\": 5.053, \"y\": 5.618}, {\"title\": \"Hallucination is the last thing you need\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.088, \"y\": 1.268}, {\"title\": \"One model to rule them all: ranking Slovene summarizers\", \"topic\": \"Text Summarization\", \"x\": 5.544, \"y\": 6.315}, {\"title\": \"DEPAC: a Corpus for Depression and Anxiety Detection from Speech\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.205, \"y\": 7.498}, {\"title\": \"CATS: A Pragmatic Chinese Answer-to-Sequence Dataset with Large Scale  and High Quality\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.844, \"y\": 5.678}, {\"title\": \"Timestamped Embedding-Matching Acoustic-to-Word CTC ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.18, \"y\": 5.118}, {\"title\": \"Exploring the Performance and Efficiency of Transformer Models for NLP  on Mobile Devices\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.662, \"y\": 3.245}, {\"title\": \"On Evaluating Multilingual Compositional Generalization with Translated  Datasets\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.171, \"y\": 4.732}, {\"title\": \"Did the Models Understand Documents? Benchmarking Models for Language  Understanding in Document-Level Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.892, \"y\": 6.846}, {\"title\": \"Democratizing LLMs for Low-Resource Languages by Leveraging their  English Dominant Abilities with Linguistically-Diverse Prompts\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.28, \"y\": 4.321}, {\"title\": \"Visually grounded few-shot word learning in low-resource settings\", \"topic\": \"Multimodal Language Models\", \"x\": 8.629, \"y\": 6.817}, {\"title\": \"KiUT: Knowledge-injected U-Transformer for Radiology Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.252, \"y\": 8.628}, {\"title\": \"MSVD-Indonesian: A Benchmark for Multimodal Video-Text Tasks in  Indonesian\", \"topic\": \"Multimodal Language Models\", \"x\": 8.935, \"y\": 7.757}, {\"title\": \"Multi-pass Training and Cross-information Fusion for Low-resource  End-to-end Accented Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.214, \"y\": 5.127}, {\"title\": \"RS5M and GeoRSCLIP: A Large Scale Vision-Language Dataset and A Large  Vision-Language Model for Remote Sensing\", \"topic\": \"Multimodal Language Models\", \"x\": 8.75, \"y\": 7.522}, {\"title\": \"Evaluating the Zero-shot Robustness of Instruction-tuned Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.165, \"y\": 2.454}, {\"title\": \"A Novel Counterfactual Data Augmentation Method for Aspect-Based  Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.139, \"y\": 6.802}, {\"title\": \"GUMSum: Multi-Genre Data and Evaluation for English Abstractive  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.466, \"y\": 6.258}, {\"title\": \"HK-LegiCoST: Leveraging Non-Verbatim Transcripts for Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.338, \"y\": 5.351}, {\"title\": \"LoSparse: Structured Compression of Large Language Models based on  Low-Rank and Sparse Approximation\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.646, \"y\": 2.705}, {\"title\": \"Quilt-1M: One Million Image-Text Pairs for Histopathology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.645, \"y\": 8.367}, {\"title\": \"Sparse Modular Activation for Efficient Sequence Modeling\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.666, \"y\": 3.064}, {\"title\": \"BioREx: Improving Biomedical Relation Extraction by Leveraging  Heterogeneous Datasets\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.404, \"y\": 7.316}, {\"title\": \"Evaluating Privacy Questions From Stack Overflow: Can ChatGPT Compete?\", \"topic\": \"Bias in Language Models\", \"x\": 4.994, \"y\": 4.44}, {\"title\": \"Large Language Models are Fixated by Red Herrings: Exploring Creative  Problem Solving and Einstellung Effect using the Only Connect Wall Dataset\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.211, \"y\": 3.176}, {\"title\": \"Cross-Modal Attribute Insertions for Assessing the Robustness of  Vision-and-Language Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.207, \"y\": 7.22}, {\"title\": \"FSUIE: A Novel Fuzzy Span Mechanism for Universal Information Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.898, \"y\": 6.702}, {\"title\": \"JiuZhang 2.0: A Unified Chinese Pre-trained Language Model for  Multi-task Mathematical Problem Solving\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.47, \"y\": 2.851}, {\"title\": \"Temporal Data Meets LLM -- Explainable Financial Time Series Forecasting\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.936, \"y\": 6.647}, {\"title\": \"Comparison of L2 Korean pronunciation error patterns from five L1  backgrounds by using automatic phonetic transcription\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.923, \"y\": 5.616}, {\"title\": \"Replace and Report: NLP Assisted Radiology Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.217, \"y\": 8.611}, {\"title\": \"Gender Differences in Abuse: The Case of Dutch Politicians on Twitter\", \"topic\": \"Hate Speech Detection\", \"x\": 3.085, \"y\": 5.4}, {\"title\": \"Path to Medical AGI: Unify Domain-specific Medical LLMs with the Lowest  Cost\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.992, \"y\": 8.138}, {\"title\": \"Guiding Language Models of Code with Global Context using Monitors\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.501, \"y\": 2.36}, {\"title\": \"Cases of EFL Secondary Students' Prompt Engineering Pathways to Complete  a Writing Task with ChatGPT\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 6.994, \"y\": 3.401}, {\"title\": \"Summarization from Leaderboards to Practice: Choosing A Representation  Backbone and Ensuring Robustness\", \"topic\": \"Text Summarization\", \"x\": 5.451, \"y\": 6.298}, {\"title\": \"UniMC: A Unified Framework for Long-Term Memory Conversation via  Relevance Representation Learning\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.537, \"y\": 3.667}, {\"title\": \"Gender Bias in Transformer Models: A comprehensive survey\", \"topic\": \"Bias in Language Models\", \"x\": 3.195, \"y\": 4.405}, {\"title\": \"Evolutionary Verbalizer Search for Prompt-based Few Shot Text  Classification\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.582, \"y\": 3.439}, {\"title\": \"MOSPC: MOS Prediction Based on Pairwise Comparison\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.916, \"y\": 5.588}, {\"title\": \"Generation of Radiology Findings in Chest X-Ray by Leveraging  Collaborative Knowledge\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.24, \"y\": 8.67}, {\"title\": \"RECAP-KG: Mining Knowledge Graphs from Raw GP Notes for Remote COVID-19  Assessment in Primary Care\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.78, \"y\": 7.976}, {\"title\": \"LLMVA-GEBC: Large Language Model with Video Adapter for Generic Event  Boundary Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.926, \"y\": 7.797}, {\"title\": \"Seen to Unseen: Exploring Compositional Generalization of  Multi-Attribute Controllable Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.53, \"y\": 3.853}, {\"title\": \"FutureTOD: Teaching Future Knowledge to Pre-trained Language Model for  Task-Oriented Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.743, \"y\": 4.114}, {\"title\": \"Meta-Personalizing Vision-Language Models to Find Named Instances in  Video\", \"topic\": \"Multimodal Language Models\", \"x\": 8.814, \"y\": 7.741}, {\"title\": \"Semi-supervised Relation Extraction via Data Augmentation and  Consistency-training\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.047, \"y\": 6.809}, {\"title\": \"Differentiable Instruction Optimization for Cross-Task Generalization\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.345, \"y\": 2.337}, {\"title\": \"Investigating Prompting Techniques for Zero- and Few-Shot Visual  Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.35, \"y\": 7.926}, {\"title\": \"CML-TTS A Multilingual Dataset for Speech Synthesis in Low-Resource  Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.374, \"y\": 5.677}, {\"title\": \"ClinicalGPT: Large Language Models Finetuned with Diverse Medical Data  and Comprehensive Evaluation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.706, \"y\": 8.058}, {\"title\": \"Revealing the impact of social circumstances on the selection of cancer  therapy through natural language processing of social work notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.433, \"y\": 7.873}, {\"title\": \"Are Large Language Models Really Good Logical Reasoners? A Comprehensive  Evaluation and Beyond\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.636, \"y\": 3.099}, {\"title\": \"Sheffield's Submission to the AmericasNLP Shared Task on Machine  Translation into Indigenous Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.823, \"y\": 5.044}, {\"title\": \"Process Knowledge-infused Learning for Clinician-friendly Explanations\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.369, \"y\": 7.61}, {\"title\": \"Unlocking the Potential of User Feedback: Leveraging Large Language  Model as User Simulator to Enhance Dialogue System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.355, \"y\": 3.642}, {\"title\": \"Investigating the Utility of Surprisal from Large Language Models for  Speech Synthesis Prosody\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.419, \"y\": 5.648}, {\"title\": \"Full Parameter Fine-tuning for Large Language Models with Limited  Resources\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.108, \"y\": 2.306}, {\"title\": \"Politeness Stereotypes and Attack Vectors: Gender Stereotypes in  Japanese and Korean Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.275, \"y\": 4.374}, {\"title\": \"Reducing Computational Costs in Sentiment Analysis: Tensorized Recurrent  Networks vs. Recurrent Networks\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.542, \"y\": 6.703}, {\"title\": \"Class-Adaptive Self-Training for Relation Extraction with Incompletely  Annotated Training Data\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.128, \"y\": 6.756}, {\"title\": \"ReactGenie: A Development Framework for Complex Multimodal Interactions  Using Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.945, \"y\": 7.459}, {\"title\": \"AUGUST: an Automatic Generation Understudy for Synthesizing  Conversational Recommendation Datasets\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.2, \"y\": 3.706}, {\"title\": \"Listener Model for the PhotoBook Referential Game with CLIPScores as  Implicit Reference Chain\", \"topic\": \"Multimodal Language Models\", \"x\": 8.731, \"y\": 7.315}, {\"title\": \"Schema-learning and rebinding as mechanisms of in-context learning and  emergence\", \"topic\": \"In-Context Learning\", \"x\": 8.55, \"y\": 3.297}, {\"title\": \"Building blocks for complex tasks: Robust generative event extraction  for radiology reports under domain shifts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.168, \"y\": 8.582}, {\"title\": \"Block-State Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.762, \"y\": 3.144}, {\"title\": \"Explaining Legal Concepts with Augmented Large Language Models (GPT-4)\", \"topic\": \"Legal NLP\", \"x\": 5.097, \"y\": 5.598}, {\"title\": \"Relation-Aware Network with Attention-Based Loss for Few-Shot Knowledge  Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.104, \"y\": 6.196}, {\"title\": \"Opportunities and Challenges for ChatGPT and Large Language Models in  Biomedicine and Health\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.681, \"y\": 7.835}, {\"title\": \"PaReprop: Fast Parallelized Reversible Backpropagation\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.695, \"y\": 2.991}, {\"title\": \"Span-Selective Linear Attention Transformers for Effective and Robust  Schema-Guided Dialogue State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.471, \"y\": 3.924}, {\"title\": \"Lexical Speaker Error Correction: Leveraging Language Models for Speaker  Diarization Error Correction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.983, \"y\": 5.525}, {\"title\": \"Propagating Knowledge Updates to LMs Through Distillation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.417, \"y\": 3.814}, {\"title\": \"KoLA: Carefully Benchmarking World Knowledge of Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.452, \"y\": 3.908}, {\"title\": \"ChatGPT for Suicide Risk Assessment on Social Media: Quantitative  Evaluation of Model Performance, Potentials and Limitations\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.239, \"y\": 7.369}, {\"title\": \"Macaw-LLM: Multi-Modal Language Modeling with Image, Audio, Video, and  Text Integration\", \"topic\": \"Multimodal Language Models\", \"x\": 8.283, \"y\": 7.27}, {\"title\": \"COSA: Concatenated Sample Pretrained Vision-Language Foundation Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.719, \"y\": 7.232}, {\"title\": \"Learning by Analogy: Diverse Questions Generation in Math Word Problem\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.08, \"y\": 2.853}, {\"title\": \"Voting Booklet Bias: Stance Detection in Swiss Federal Communication\", \"topic\": \"Fake News Detection\", \"x\": 3.548, \"y\": 5.645}, {\"title\": \"Rethinking Document-Level Relation Extraction: A Reality Check\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.837, \"y\": 6.892}, {\"title\": \"Opinion Tree Parsing for Aspect-based Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.124, \"y\": 6.813}, {\"title\": \"Pushing the Limits of Unsupervised Unit Discovery for SSL Speech  Representation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.835, \"y\": 4.957}, {\"title\": \"Bridging the Gap between Decision and Logits in Decision-based Knowledge  Distillation for Pre-trained Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.517, \"y\": 3.813}, {\"title\": \"Participatory Research as a Path to Community-Informed, Gender-Fair  Machine Translation\", \"topic\": \"Bias in Language Models\", \"x\": 3.055, \"y\": 4.362}, {\"title\": \"MetricPrompt: Prompting Model as a Relevance Metric for Few-shot Text  Classification\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.724, \"y\": 3.578}, {\"title\": \"Multi-modal Hate Speech Detection using Machine Learning\", \"topic\": \"Hate Speech Detection\", \"x\": 2.734, \"y\": 5.428}, {\"title\": \"Improving Reading Comprehension Question Generation with Data  Augmentation and Overgenerate-and-rank\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.337, \"y\": 5.05}, {\"title\": \"Pragmatic Inference with a CLIP Listener for Contrastive Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.181, \"y\": 7.418}, {\"title\": \"PEACE: Cross-Platform Hate Speech Detection- A Causality-guided  Framework\", \"topic\": \"Hate Speech Detection\", \"x\": 2.713, \"y\": 5.374}, {\"title\": \"MPSA-DenseNet: A novel deep learning model for English accent  classification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.905, \"y\": 5.428}, {\"title\": \"Unified model for code-switching speech recognition and language  identification based on a concatenated tokenizer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.649, \"y\": 5.396}, {\"title\": \"Utilizing Longitudinal Chest X-Rays and Reports to Pre-Fill Radiology  Reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.214, \"y\": 8.61}, {\"title\": \"Does mBERT understand Romansh? Evaluating word embeddings using word  alignment\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.305, \"y\": 4.896}, {\"title\": \"World-to-Words: Grounded Open Vocabulary Acquisition through Fast  Mapping in Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.755, \"y\": 7.007}, {\"title\": \"When to Use Efficient Self Attention? Profiling Text, Speech and Image  Transformer Variants\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.873, \"y\": 3.304}, {\"title\": \"Radiology-GPT: A Large Language Model for Radiology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.029, \"y\": 8.43}, {\"title\": \"Improving Code-Switching and Named Entity Recognition in ASR with Speech  Editing based Data Augmentation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.068, \"y\": 5.349}, {\"title\": \"Learning Cross-lingual Mappings for Data Augmentation to Improve  Low-Resource Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.862, \"y\": 5.249}, {\"title\": \"MiniLLM: Knowledge Distillation of Large Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.499, \"y\": 3.714}, {\"title\": \"AlbMoRe: A Corpus of Movie Reviews for Sentiment Analysis in Albanian\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.632, \"y\": 6.546}, {\"title\": \"A Relaxed Optimization Approach for Adversarial Attacks against Neural  Machine Translation Models\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.116, \"y\": 2.993}, {\"title\": \"Building a Corpus for Biomedical Relation Extraction of Species Mentions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.438, \"y\": 7.283}, {\"title\": \"LiveChat: A Large-Scale Personalized Dialogue Dataset Automatically  Constructed from Live Streaming\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.131, \"y\": 3.683}, {\"title\": \"SpeechGLUE: How Well Can Self-Supervised Speech Models Capture  Linguistic Knowledge?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.79, \"y\": 4.843}, {\"title\": \"A semantically enhanced dual encoder for aspect sentiment triplet  extraction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.085, \"y\": 6.83}, {\"title\": \"Research on an improved Conformer end-to-end Speech Recognition Model  with R-Drop Structure\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.24, \"y\": 5.077}, {\"title\": \"Research on Named Entity Recognition in Improved transformer with R-Drop  structure\", \"topic\": \"Named Entity Recognition\", \"x\": 7.407, \"y\": 6.863}, {\"title\": \"Investigating the dynamics of hand and lips in French Cued Speech using  attention mechanisms and CTC-based decoding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.766, \"y\": 5.434}, {\"title\": \"Assessing the Effectiveness of GPT-3 in Detecting False Political  Statements: A Case Study on the LIAR Dataset\", \"topic\": \"Fake News Detection\", \"x\": 4.174, \"y\": 5.486}, {\"title\": \"Sociodemographic Bias in Language Models: A Survey and Forward Path\", \"topic\": \"Bias in Language Models\", \"x\": 3.365, \"y\": 4.41}, {\"title\": \"Large-scale Language Model Rescoring on Long-form Data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.892, \"y\": 5.097}, {\"title\": \"AVIS: Autonomous Visual Information Seeking with Large Language Model  Agent\", \"topic\": \"Multimodal Language Models\", \"x\": 8.221, \"y\": 7.911}, {\"title\": \"PersonaPKT: Building Personalized Dialogue Agents via  Parameter-efficient Knowledge Transfer\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.15, \"y\": 3.675}, {\"title\": \"Beyond Black Box AI-Generated Plagiarism Detection: From Sentence to  Document Level\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.264, \"y\": 4.682}, {\"title\": \"MOFI: Learning Image Representations from Noisy Entity Annotated Images\", \"topic\": \"Multimodal Language Models\", \"x\": 8.344, \"y\": 7.05}, {\"title\": \"GEmo-CLAP: Gender-Attribute-Enhanced Contrastive Language-Audio  Pretraining for Accurate Speech Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.188, \"y\": 7.863}, {\"title\": \"Adversarial Capsule Networks for Romanian Satire Detection and Sentiment  Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.51, \"y\": 6.457}, {\"title\": \"Monolingual and Cross-Lingual Knowledge Transfer for Topic  Classification\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.397, \"y\": 4.958}, {\"title\": \"A Novel Scheme to classify Read and Spontaneous Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.037, \"y\": 5.635}, {\"title\": \"StyleTTS 2: Towards Human-Level Text-to-Speech through Style Diffusion  and Adversarial Training with Large Speech Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.631, \"y\": 5.762}, {\"title\": \"Is Anisotropy Inherent to Transformers?\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.402, \"y\": 3.539}, {\"title\": \"Modality Adaption or Regularization? A Case Study on End-to-End Speech  Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.421, \"y\": 5.061}, {\"title\": \"SqueezeLLM: Dense-and-Sparse Quantization\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.709, \"y\": 2.172}, {\"title\": \"Soft Language Clustering for Multilingual Model Pre-training\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.372, \"y\": 4.541}, {\"title\": \"Question Decomposition Tree for Answering Complex Questions over  Knowledge Bases\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.588, \"y\": 5.307}, {\"title\": \"Large Language Models Sometimes Generate Purely Negatively-Reinforced  Text\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.336, \"y\": 2.834}, {\"title\": \"Improving Zero-Shot Detection of Low Prevalence Chest Pathologies using  Domain Pre-trained Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.268, \"y\": 8.469}, {\"title\": \"Detect Depression from Social Networks with Sentiment Knowledge Sharing\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.08, \"y\": 7.419}, {\"title\": \"TART: A plug-and-play Transformer module for task-agnostic reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.934, \"y\": 2.873}, {\"title\": \"Noisy Positive-Unlabeled Learning with Self-Training for Speculative  Knowledge Graph Reasoning\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.951, \"y\": 5.991}, {\"title\": \"Resources for Brewing BEIR: Reproducible Reference Models and an  Official Leaderboard\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.579, \"y\": 4.993}, {\"title\": \"Lost in Translation: Large Language Models in Non-English Content  Analysis\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.006, \"y\": 4.591}, {\"title\": \"EriBERTa: A Bilingual Pre-Trained Language Model for Clinical Natural  Language Processing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.98, \"y\": 8.049}, {\"title\": \"MFSN: Multi-perspective Fusion Search Network For Pre-training Knowledge  in Speech Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.183, \"y\": 7.805}, {\"title\": \"Valley: Video Assistant with Large Language model Enhanced abilitY\", \"topic\": \"Multimodal Language Models\", \"x\": 8.768, \"y\": 7.798}, {\"title\": \"RECAP: Retrieval-Enhanced Context-Aware Prefix Encoder for Personalized  Dialogue Response Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.491, \"y\": 4.008}, {\"title\": \"LTCR: Long-Text Chinese Rumor Detection Dataset\", \"topic\": \"Fake News Detection\", \"x\": 4.096, \"y\": 5.89}, {\"title\": \"A Survey of Vision-Language Pre-training from the Lens of Multimodal  Machine Translation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.566, \"y\": 7.479}, {\"title\": \"Prompt-based Extraction of Social Determinants of Health Using Few-shot  Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.346, \"y\": 7.806}, {\"title\": \"Measuring Sentiment Bias in Machine Translation\", \"topic\": \"Bias in Language Models\", \"x\": 3.06, \"y\": 4.498}, {\"title\": \"On the Amplification of Linguistic Bias through Unintentional  Self-reinforcement Learning by Generative Language Models -- A Perspective\", \"topic\": \"Bias in Language Models\", \"x\": 3.748, \"y\": 4.208}, {\"title\": \"Exploring Attention Mechanisms for Multimodal Emotion Recognition in an  Emergency Call Center Corpus\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.288, \"y\": 7.764}, {\"title\": \"Large Language Models as Tax Attorneys: A Case Study in Legal  Capabilities Emergence\", \"topic\": \"Legal NLP\", \"x\": 5.143, \"y\": 5.42}, {\"title\": \"weighted CapsuleNet networks for Persian multi-domain sentiment analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.52, \"y\": 6.626}, {\"title\": \"Multi-View Frequency-Attention Alternative to CNN Frontends for  Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.253, \"y\": 4.976}, {\"title\": \"Rethinking Translation Memory Augmented Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.89, \"y\": 4.343}, {\"title\": \"Learning Multilingual Sentence Representations with Cross-lingual  Consistency Regularization\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.254, \"y\": 5.13}, {\"title\": \"On the N-gram Approximation of Pre-trained Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.092, \"y\": 5.389}, {\"title\": \"Recursion of Thought: A Divide-and-Conquer Approach to Multi-Context  Reasoning with Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.638, \"y\": 2.298}, {\"title\": \"History Semantic Graph Enhanced Conversational KBQA with Temporal  Information Modeling\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.625, \"y\": 5.482}, {\"title\": \"Recurrent Attention Networks for Long-text Modeling\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.674, \"y\": 3.323}, {\"title\": \"Weakly supervised information extraction from inscrutable handwritten  document images\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.254, \"y\": 8.003}, {\"title\": \"Multimodal Audio-textual Architecture for Robust Spoken Language  Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.777, \"y\": 5.104}, {\"title\": \"A Practical Entity Linking System for Tables in Scientific Literature\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.869, \"y\": 6.553}, {\"title\": \"TrojLLM: A Black-box Trojan Prompt Attack on Large Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.405, \"y\": 2.616}, {\"title\": \"Neural Machine Translation for the Indigenous Languages of the Americas:  An Introduction\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.684, \"y\": 4.744}, {\"title\": \"A Comprehensive Survey on Applications of Transformers for Deep Learning  Tasks\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.8, \"y\": 3.396}, {\"title\": \"Impact of Experiencing Misrecognition by Teachable Agents on Learning  and Rapport\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.998, \"y\": 5.483}, {\"title\": \"Multi-Source Test-Time Adaptation as Dueling Bandits for Extractive  Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.519, \"y\": 5.132}, {\"title\": \"The Impact of ChatGPT and LLMs on Medical Imaging Stakeholders:  Perspectives and Use Cases\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.508, \"y\": 7.993}, {\"title\": \"Estimating the Uncertainty in Emotion Attributes using Deep Evidential  Regression\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.388, \"y\": 7.579}, {\"title\": \"Language Versatilists vs. Specialists: An Empirical Revisiting on  Multilingual Transfer Ability\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.184, \"y\": 4.602}, {\"title\": \"Reducing Barriers to Self-Supervised Learning: HuBERT Pre-training with  Academic Compute\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.936, \"y\": 4.854}, {\"title\": \"GKD: A General Knowledge Distillation Framework for Large-scale  Pre-trained Language Model\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.525, \"y\": 3.794}, {\"title\": \"Are Intermediate Layers and Labels Really Necessary? A General Language  Model Distillation Method\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.525, \"y\": 3.826}, {\"title\": \"A Pairing Enhancement Approach for Aspect Sentiment Triplet Extraction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.107, \"y\": 6.823}, {\"title\": \"Towards Diverse and Effective Question-Answer Pair Generation from  Children Storybooks\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.225, \"y\": 5.037}, {\"title\": \"Mimicking the Thinking Process for Emotion Recognition in Conversation  with Prompts and Paraphrasing\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.319, \"y\": 7.786}, {\"title\": \"Inductive reasoning in humans and large language models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.494, \"y\": 3.275}, {\"title\": \"AutoTAMP: Autoregressive Task and Motion Planning with LLMs as  Translators and Checkers\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.83, \"y\": 2.584}, {\"title\": \"What Can an Accent Identifier Learn? Probing Phonetic and Prosodic  Information in a Wav2vec2-based Accent Identification Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.877, \"y\": 5.336}, {\"title\": \"Medical Data Augmentation via ChatGPT: A Case Study on Medication  Identification and Medication Event Classification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.775, \"y\": 7.966}, {\"title\": \"Enhancing Low Resource NER Using Assisting Language And Transfer  Learning\", \"topic\": \"Named Entity Recognition\", \"x\": 7.548, \"y\": 6.759}, {\"title\": \"ORGAN: Observation-Guided Radiology Report Generation via Tree Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.224, \"y\": 8.6}, {\"title\": \"Boosting Language Models Reasoning with Chain-of-Knowledge Prompting\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.637, \"y\": 2.515}, {\"title\": \"OpenSR: Open-Modality Speech Recognition via Maintaining Multi-Modality  Alignment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.809, \"y\": 5.474}, {\"title\": \"Adversarial Training For Low-Resource Disfluency Correction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.251, \"y\": 5.638}, {\"title\": \"INK: Injecting kNN Knowledge in Nearest Neighbor Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.92, \"y\": 4.263}, {\"title\": \"Human-in-the-Loop through Chain-of-Thought\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.614, \"y\": 2.268}, {\"title\": \"Record Deduplication for Entity Distribution Modeling in ASR Transcripts\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.312, \"y\": 5.296}, {\"title\": \"Probing self-supervised speech models for phonetic and phonemic  information: a case study in aspiration\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.651, \"y\": 5.031}, {\"title\": \"Leveraging Large Language Models for Scalable Vector Graphics-Driven  Image Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.585, \"y\": 7.489}, {\"title\": \"Implementing BERT and fine-tuned RobertA to detect AI generated news by  ChatGPT\", \"topic\": \"Fake News Detection\", \"x\": 4.04, \"y\": 5.743}, {\"title\": \"Developing Speech Processing Pipelines for Police Accountability\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.305, \"y\": 5.262}, {\"title\": \"Trapping LLM Hallucinations Using Tagged Context Prompts\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.207, \"y\": 1.102}, {\"title\": \"Mind2Web: Towards a Generalist Agent for the Web\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.612, \"y\": 2.701}, {\"title\": \"FinGPT: Open-Source Financial Large Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.859, \"y\": 6.872}, {\"title\": \"Automated Labeling of German Chest X-Ray Radiology Reports using Deep  Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.243, \"y\": 8.496}, {\"title\": \"Leveraging text data for causal inference using electronic health  records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.553, \"y\": 7.722}, {\"title\": \"GPT-Calls: Enhancing Call Segmentation and Tagging by Generating  Synthetic Conversations via Large Language Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.368, \"y\": 4.057}, {\"title\": \"An Efficient Speech Separation Network Based on Recurrent Fusion Dilated  Convolution and Channel Attention\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.152, \"y\": 5.014}, {\"title\": \"Good, but not always Fair: An Evaluation of Gender Bias for three  commercial Machine Translation Systems\", \"topic\": \"Bias in Language Models\", \"x\": 3.055, \"y\": 4.409}, {\"title\": \"Towards a Robust Detection of Language Model Generated Text: Is ChatGPT  that Easy to Detect?\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.12, \"y\": 4.691}, {\"title\": \"Efficient Encoder-Decoder and Dual-Path Conformer for Comprehensive  Feature Learning in Speech Enhancement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.123, \"y\": 5.093}, {\"title\": \"SentiGOLD: A Large Bangla Gold Standard Multi-Domain Sentiment Analysis  Dataset and its Evaluation\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.419, \"y\": 6.551}, {\"title\": \"Towards the Exploitation of LLM-based Chatbot for Providing Legal  Support to Palestinian Cooperatives\", \"topic\": \"Legal NLP\", \"x\": 5.143, \"y\": 5.386}, {\"title\": \"Transformer-based Time-to-Event Prediction for Chronic Kidney Disease  Deterioration\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.873, \"y\": 8.322}, {\"title\": \"A Theory of Unsupervised Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.171, \"y\": 5.254}, {\"title\": \"Zero-Shot Dialogue Relation Extraction by Relating Explainable Triggers  and Relation Names\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.887, \"y\": 6.543}, {\"title\": \"Learning Emotional Representations from Imbalanced Speech Data for  Speech Emotion Recognition and Emotional Text-to-Speech\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.2, \"y\": 7.842}, {\"title\": \"COVER: A Heuristic Greedy Adversarial Attack on Prompt-based Learning in  Language Models\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.319, \"y\": 2.687}, {\"title\": \"Customizing General-Purpose Foundation Models for Medical Report  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.363, \"y\": 8.453}, {\"title\": \"Low-rank Adaptation Method for Wav2vec2-based Fake Audio Detection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.09, \"y\": 5.002}, {\"title\": \"LOST: A Mental Health Dataset of Low Self-esteem in Reddit Posts\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.173, \"y\": 7.403}, {\"title\": \"Speech-to-Text Adapter and Speech-to-Entity Retriever Augmented LLMs for  Speech Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.943, \"y\": 5.162}, {\"title\": \"Bias Against 93 Stigmatized Groups in Masked Language Models and  Downstream Sentiment Classification Tasks\", \"topic\": \"Bias in Language Models\", \"x\": 3.364, \"y\": 4.524}, {\"title\": \"Prompt Injection attack against LLM-integrated Applications\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.435, \"y\": 2.568}, {\"title\": \"MIMIC-IT: Multi-Modal In-Context Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.31, \"y\": 7.369}, {\"title\": \"Modular Visual Question Answering via Code Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.22, \"y\": 8.053}, {\"title\": \"Utterance Emotion Dynamics in Children's Poems: Emotional Changes Across  Age\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.635, \"y\": 7.511}, {\"title\": \"Latent Phrase Matching for Dysarthric Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.318, \"y\": 5.595}, {\"title\": \"Advancing Italian Biomedical Information Extraction with  Transformers-based Models: Methodological Insights and Multicenter Practical  Application\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.83, \"y\": 7.688}, {\"title\": \"KIT's Multilingual Speech Translation System for IWSLT 2023\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.341, \"y\": 5.169}, {\"title\": \"CUED at ProbSum 2023: Hierarchical Ensemble of Summarization Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.619, \"y\": 7.795}, {\"title\": \"Are fairness metric scores enough to assess discrimination biases in  machine learning?\", \"topic\": \"Bias in Language Models\", \"x\": 3.409, \"y\": 4.321}, {\"title\": \"Extensive Evaluation of Transformer-based Architectures for Adverse Drug  Events Extraction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.691, \"y\": 7.723}, {\"title\": \"Overview of the Problem List Summarization (ProbSum) 2023 Shared Task on  Summarizing Patients' Active Diagnoses and Problems from Electronic Health  Record Progress Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.586, \"y\": 8.035}, {\"title\": \"Factorized Contrastive Learning: Going Beyond Multi-view Redundancy\", \"topic\": \"Multimodal Language Models\", \"x\": 8.264, \"y\": 7.208}, {\"title\": \"PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark  for Finance\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.865, \"y\": 6.843}, {\"title\": \"Improving Long Context Document-Level Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.849, \"y\": 4.177}, {\"title\": \"RRWKV: Capturing Long-range Dependencies in RWKV\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.819, \"y\": 3.327}, {\"title\": \"On Search Strategies for Document-Level Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.794, \"y\": 4.34}, {\"title\": \"The ART of Conversation: Measuring Phonetic Convergence and Deliberate  Imitation in L2-Speech with a Siamese RNN\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.57, \"y\": 5.291}, {\"title\": \"Improving Language Model Integration for Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.956, \"y\": 4.712}, {\"title\": \"Interpretable Medical Diagnostics with Structured Data Extraction by  Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.747, \"y\": 8.147}, {\"title\": \"T3L: Translate-and-Test Transfer Learning for Cross-Lingual Text  Classification\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.482, \"y\": 4.838}, {\"title\": \"Assessing Phrase Break of ESL Speech with Pre-trained Language Models  and Large Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.455, \"y\": 5.582}, {\"title\": \"Actively Supervised Clustering for Open Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.977, \"y\": 6.749}, {\"title\": \"RE-Matching: A Fine-Grained Semantic Matching Method for Zero-Shot  Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.341, \"y\": 6.569}, {\"title\": \"Open Set Relation Extraction via Unknown-Aware Training\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.108, \"y\": 6.65}, {\"title\": \"InfoPrompt: Information-Theoretic Soft Prompt Tuning for Natural  Language Understanding\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.765, \"y\": 3.315}, {\"title\": \"Prefer to Classify: Improving Text Classifiers via Auxiliary Preference  Learning\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.524, \"y\": 1.318}, {\"title\": \"NOWJ at COLIEE 2023 -- Multi-Task and Ensemble Approaches in Legal  Information Processing\", \"topic\": \"Legal NLP\", \"x\": 5.078, \"y\": 5.75}, {\"title\": \"Expanding Scope: Adapting English Adversarial Attacks to Chinese\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.161, \"y\": 3.011}, {\"title\": \"Improving Vietnamese Legal Question--Answering System based on Automatic  Data Enrichment\", \"topic\": \"Legal NLP\", \"x\": 5.377, \"y\": 5.673}, {\"title\": \"A Review on Knowledge Graphs for Healthcare: Resources, Applications,  and Promises\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.72, \"y\": 7.796}, {\"title\": \"Absformer: Transformer-based Model for Unsupervised Multi-Document  Abstractive Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.661, \"y\": 6.402}, {\"title\": \"How Far Can Camels Go? Exploring the State of Instruction Tuning on Open  Resources\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.187, \"y\": 2.339}, {\"title\": \"Soft-prompt Tuning for Large Language Models to Evaluate Bias\", \"topic\": \"Bias in Language Models\", \"x\": 3.651, \"y\": 4.375}, {\"title\": \"Intrinsic Dimension Estimation for Robust Detection of AI-Generated  Texts\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.186, \"y\": 4.781}, {\"title\": \"ConceptBed: Evaluating Concept Learning Abilities of Text-to-Image  Diffusion Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.869, \"y\": 6.781}, {\"title\": \"Language Models Get a Gender Makeover: Mitigating Gender Bias with  Few-Shot Data Interventions\", \"topic\": \"Bias in Language Models\", \"x\": 3.207, \"y\": 4.249}, {\"title\": \"Gender, names and other mysteries: Towards the ambiguous for  gender-inclusive translation\", \"topic\": \"Bias in Language Models\", \"x\": 2.971, \"y\": 4.4}, {\"title\": \"Multi-Task Training with In-Domain Language Models for Diagnostic  Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.824, \"y\": 8.257}, {\"title\": \"Multimodal Learning Without Labeled Multimodal Data: Guarantees and  Applications\", \"topic\": \"Multimodal Language Models\", \"x\": 8.03, \"y\": 7.164}, {\"title\": \"Lenient Evaluation of Japanese Speech Recognition: Modeling Naturally  Occurring Spelling Inconsistency\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.144, \"y\": 5.538}, {\"title\": \"Evaluation of ChatGPT on Biomedical Tasks: A Zero-Shot Comparison with  Fine-Tuned Generative Transformers\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.838, \"y\": 7.468}, {\"title\": \"STEPS: A Benchmark for Order Reasoning in Sequential Tasks\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.55, \"y\": 3.078}, {\"title\": \"Zambezi Voice: A Multilingual Speech Corpus for Zambian Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.41, \"y\": 5.494}, {\"title\": \"Transfer Learning of Transformer-based Speech Recognition Models from  Czech to Slovak\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.928, \"y\": 5.366}, {\"title\": \"M$^3$IT: A Large-Scale Dataset towards Multi-Modal Multilingual  Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.306, \"y\": 7.381}, {\"title\": \"FOOCTTS: Generating Arabic Speech with Acoustic Environment for Football  Commentator\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.603, \"y\": 5.551}, {\"title\": \"Multilingual Clinical NER: Translation or Cross-lingual Transfer?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.171, \"y\": 7.778}, {\"title\": \"Label Aware Speech Representation Learning For Language Identification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.688, \"y\": 5.093}, {\"title\": \"Arabic Dysarthric Speech Recognition Using Adversarial and Signal-Based  Augmentation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.198, \"y\": 5.561}, {\"title\": \"Youku-mPLUG: A 10 Million Large-scale Chinese Video-Language Dataset for  Pre-training and Benchmarks\", \"topic\": \"Multimodal Language Models\", \"x\": 8.854, \"y\": 7.724}, {\"title\": \"Dial-MAE: ConTextual Masked Auto-Encoder for Retrieval-based Dialogue  Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.566, \"y\": 4.001}, {\"title\": \"World Models for Math Story Problems\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.001, \"y\": 2.879}, {\"title\": \"Co-evolving Graph Reasoning Network for Emotion-Cause Pair Extraction\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.391, \"y\": 7.769}, {\"title\": \"A study on the impact of Self-Supervised Learning on automatic  dysarthric speech assessment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.274, \"y\": 5.498}, {\"title\": \"Echoes from Alexandria: A Large Resource for Multilingual Book  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.662, \"y\": 6.346}, {\"title\": \"IUTEAM1 at MEDIQA-Chat 2023: Is simple fine tuning effective for  multilayer summarization of clinical conversations?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.689, \"y\": 7.991}, {\"title\": \"Personality testing of GPT-3: Limited temporal reliability, but  highlighted social desirability of GPT-3's personality instruments results\", \"topic\": \"Bias in Language Models\", \"x\": 4.68, \"y\": 4.044}, {\"title\": \"Allophant: Cross-lingual Phoneme Recognition with Articulatory  Attributes\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.491, \"y\": 5.325}, {\"title\": \"Analysis of the Fed's communication by using textual entailment model of  Zero-Shot classification\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.683, \"y\": 6.796}, {\"title\": \"Multi-microphone Automatic Speech Segmentation in Meetings Based on  Circular Harmonics Features\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.105, \"y\": 5.389}, {\"title\": \"Transfer Learning from Pre-trained Language Models Improves End-to-End  Speech Summarization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.625, \"y\": 5.157}, {\"title\": \"An ASR-Based Tutor for Learning to Read: How to Optimize Feedback to  First Graders\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.234, \"y\": 5.514}, {\"title\": \"When to Read Documents or QA History: On Unified and Selective  Open-domain QA\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.44, \"y\": 5.243}, {\"title\": \"From the One, Judge of the Whole: Typed Entailment Graph Construction  with Predicate Generation\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.046, \"y\": 5.617}, {\"title\": \"XSemPLR: Cross-Lingual Semantic Parsing in Multiple Natural Languages  and Meaning Representations\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.13, \"y\": 4.902}, {\"title\": \"Text-only Domain Adaptation using Unified Speech-Text Representation in  Transducer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.006, \"y\": 5.041}, {\"title\": \"An Empirical Analysis of Parameter-Efficient Methods for Debiasing  Pre-Trained Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.255, \"y\": 4.267}, {\"title\": \"Augmenting Reddit Posts to Determine Wellness Dimensions impacting  Mental Health\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.221, \"y\": 7.447}, {\"title\": \"Improving Fairness and Robustness in End-to-End Speech Recognition  through unsupervised clustering\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.251, \"y\": 5.247}, {\"title\": \"Sentiment Analysis in Finance: From Transformers Back to eXplainable  Lexicons (XLex)\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.72, \"y\": 6.808}, {\"title\": \"Toward More Accurate and Generalizable Evaluation Metrics for  Task-Oriented Dialogs\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.267, \"y\": 3.887}, {\"title\": \"ECQED: Emotion-Cause Quadruple Extraction in Dialogs\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.379, \"y\": 7.779}, {\"title\": \"Leveraging Explicit Procedural Instructions for Data-Efficient Action  Prediction\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.488, \"y\": 3.735}, {\"title\": \"MISGENDERED: Limits of Large Language Models in Understanding Pronouns\", \"topic\": \"Bias in Language Models\", \"x\": 3.002, \"y\": 4.423}, {\"title\": \"Deductive Verification of Chain-of-Thought Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.725, \"y\": 2.52}, {\"title\": \"Prompt Space Optimizing Few-shot Reasoning Success with Large Language  Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.324, \"y\": 3.26}, {\"title\": \"Exploring Hybrid Linguistic Features for Turkish Text Readability\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.789, \"y\": 5.423}, {\"title\": \"Towards End-to-end Speech-to-text Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.74, \"y\": 6.417}, {\"title\": \"Financial Numeric Extreme Labelling: A Dataset and Benchmarking for XBRL  Tagging\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.005, \"y\": 6.818}, {\"title\": \"Evaluating the Effectiveness of Natural Language Inference for Hate  Speech Detection in Languages with Limited Labeled Data\", \"topic\": \"Hate Speech Detection\", \"x\": 2.684, \"y\": 5.31}, {\"title\": \"On the Difference of BERT-style and CLIP-style Text Encoders\", \"topic\": \"Multimodal Language Models\", \"x\": 9.044, \"y\": 7.146}, {\"title\": \"Injecting knowledge into language generation: a case study in  auto-charting after-visit care instructions from medical dialogue\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.851, \"y\": 7.814}, {\"title\": \"\\\"A Little is Enough\\\": Few-Shot Quality Estimation based Corpus Filtering  improves Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.863, \"y\": 4.637}, {\"title\": \"Towards Adaptable and Interactive Image Captioning with Data  Augmentation and Episodic Memory\", \"topic\": \"Multimodal Language Models\", \"x\": 9.102, \"y\": 7.408}, {\"title\": \"Putting Humans in the Image Captioning Loop\", \"topic\": \"Multimodal Language Models\", \"x\": 9.084, \"y\": 7.415}, {\"title\": \"Automatic Assessment of Oral Reading Accuracy for Reading Diagnostics\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.153, \"y\": 5.553}, {\"title\": \"Large Language Models of Code Fail at Completing Code with Potential  Bugs\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.432, \"y\": 2.314}, {\"title\": \"On the Role of Attention in Prompt-tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.693, \"y\": 3.287}, {\"title\": \"Efficient and Interpretable Compressive Text Summarisation with  Unsupervised Dual-Agent Reinforcement Learning\", \"topic\": \"Text Summarization\", \"x\": 5.513, \"y\": 6.191}, {\"title\": \"TextFormer: A Query-based End-to-End Text Spotter with Mixed Supervision\", \"topic\": \"Multimodal Language Models\", \"x\": 8.516, \"y\": 6.891}, {\"title\": \"WHAT, WHEN, and HOW to Ground: Designing User Persona-Aware  Conversational Agents for Engaging Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.31, \"y\": 3.841}, {\"title\": \"shs-nlp at RadSum23: Domain-Adaptive Pre-training of Instruction-tuned  LLMs for Radiology Report Impression Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.118, \"y\": 8.485}, {\"title\": \"A Static Evaluation of Code Completion by Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.461, \"y\": 2.381}, {\"title\": \"AutoScrum: Automating Project Planning Using Large Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.893, \"y\": 2.569}, {\"title\": \"Composition and Deformance: Measuring Imageability with a Text-to-Image  Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.765, \"y\": 6.718}, {\"title\": \"RepoBench: Benchmarking Repository-Level Code Auto-Completion Systems\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.459, \"y\": 2.538}, {\"title\": \"SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight  Compression\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.708, \"y\": 2.165}, {\"title\": \"Interactive Editing for Text Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.546, \"y\": 6.123}, {\"title\": \"Semantically-Prompted Language Models Improve Visual Descriptions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.708, \"y\": 7.457}, {\"title\": \"Benchmarking Large Language Models on CMExam -- A Comprehensive Chinese  Medical Exam Dataset\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.842, \"y\": 7.747}, {\"title\": \"PokemonChat: Auditing ChatGPT for Pok\\u00e9mon Universe Knowledge\", \"topic\": \"Bias in Language Models\", \"x\": 5.248, \"y\": 4.448}, {\"title\": \"PolyVoice: Language Models for Speech to Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.458, \"y\": 5.441}, {\"title\": \"Which Argumentative Aspects of Hate Speech in Social Media can be  reliably identified?\", \"topic\": \"Hate Speech Detection\", \"x\": 2.957, \"y\": 5.268}, {\"title\": \"A Simple and Flexible Modeling for Mental Disorder Detection by Learning  from Clinical Questionnaires\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.359, \"y\": 7.507}, {\"title\": \"MidMed: Towards Mixed-Type Dialogues for Medical Consultation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.677, \"y\": 8.223}, {\"title\": \"SelfEvolve: A Code Evolution Framework via Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.234, \"y\": 2.23}, {\"title\": \"N-Shot Benchmarking of Whisper on Diverse Arabic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.918, \"y\": 5.199}, {\"title\": \"DecompX: Explaining Transformers Decisions by Propagating Token  Decomposition\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.607, \"y\": 3.488}, {\"title\": \"Text-To-KG Alignment: Comparing Current Methods on Classification Tasks\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.059, \"y\": 5.898}, {\"title\": \"Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.827, \"y\": 7.853}, {\"title\": \"Exploring the Relationship between Alignment and Cross-lingual Transfer  in Multilingual Transformers\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.387, \"y\": 4.738}, {\"title\": \"German CheXpert Chest X-ray Radiology Report Labeler\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.212, \"y\": 8.584}, {\"title\": \"Cross-Lingual Transfer with Target Language-Ready Task Adapters\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.441, \"y\": 4.793}, {\"title\": \"PULSAR: Pre-training with Extracted Healthcare Terms for Summarising  Patients' Problems and Data Augmentation with Black-box Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.703, \"y\": 8.156}, {\"title\": \"LexGPT 0.1: pre-trained GPT-J models with Pile of Law\", \"topic\": \"Legal NLP\", \"x\": 5.306, \"y\": 5.567}, {\"title\": \"End-to-End Word-Level Pronunciation Assessment with MASK Pre-training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.906, \"y\": 5.407}, {\"title\": \"BeAts: Bengali Speech Acts Recognition using Multimodal Attention Fusion\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.452, \"y\": 5.606}, {\"title\": \"Joint Pre-training and Local Re-training: Transferable Representation  Learning on Multi-source Knowledge Graphs\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.191, \"y\": 6.097}, {\"title\": \"Early Rumor Detection Using Neural Hawkes Process with a New Benchmark  Dataset\", \"topic\": \"Fake News Detection\", \"x\": 4.06, \"y\": 5.833}, {\"title\": \"A Novel Interpretable and Generalizable Re-synchronization Model for  Cued Speech based on a Multi-Cuer Corpus\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.816, \"y\": 5.483}, {\"title\": \"Cross-Lingual Transfer Learning for Phrase Break Prediction with  Multilingual Language Model\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.432, \"y\": 4.846}, {\"title\": \"Evaluation of AI Chatbots for Patient-Specific EHR Questions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.478, \"y\": 8.011}, {\"title\": \"Incorporating L2 Phonemes Using Articulatory Features for Robust Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.991, \"y\": 5.481}, {\"title\": \"RadLing: Towards Efficient Radiology Report Understanding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.215, \"y\": 8.601}, {\"title\": \"Taught by the Internet, Exploring Bias in OpenAIs GPT3\", \"topic\": \"Bias in Language Models\", \"x\": 3.319, \"y\": 4.451}, {\"title\": \"Evaluating and Improving Tool-Augmented Computation-Intensive Math  Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.729, \"y\": 2.301}, {\"title\": \"An Information-Theoretic Analysis of Self-supervised Discrete  Representations of Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.598, \"y\": 5.038}, {\"title\": \"Leverage Points in Modality Shifts: Comparing Language-only and  Multimodal Word Representations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.508, \"y\": 6.84}, {\"title\": \"Exploring the Impact of Model Scaling on Parameter-Efficient Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.966, \"y\": 2.428}, {\"title\": \"Finding the SWEET Spot: Analysis and Improvement of Adaptive Inference  in Low Resource Settings\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.232, \"y\": 2.44}, {\"title\": \"Exposing Bias in Online Communities through Large-Scale Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.28, \"y\": 4.55}, {\"title\": \"End-to-End Joint Target and Non-Target Speakers ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.135, \"y\": 5.271}, {\"title\": \"OWQ: Outlier-Aware Weight Quantization for Efficient Fine-Tuning and  Inference of Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.699, \"y\": 2.126}, {\"title\": \"A Technical Report for Polyglot-Ko: Open-Source Large-Scale Korean  Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.813, \"y\": 4.284}, {\"title\": \"Large Language Model Augmented Narrative Driven Recommendations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.924, \"y\": 2.918}, {\"title\": \"Extract and Attend: Improving Entity Translation in Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.906, \"y\": 4.414}, {\"title\": \"Fine-Tuning Language Models with Advantage-Induced Policy Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.21, \"y\": 1.45}, {\"title\": \"SpeechGen: Unlocking the Generative Power of Speech Language Models with  Prompts\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.341, \"y\": 3.271}, {\"title\": \"Word-Level Explanations for Analyzing Bias in Text-to-Image Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.265, \"y\": 4.485}, {\"title\": \"Question-Context Alignment and Answer-Context Dependencies for Effective  Answer Sentence Selection\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.683, \"y\": 5.336}, {\"title\": \"LDEB -- Label Digitization with Emotion Binarization and Machine  Learning for Emotion Recognition in Conversational Dialogues\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.26, \"y\": 7.773}, {\"title\": \"FlairNLP at SemEval-2023 Task 6b: Extraction of Legal Named Entities  from Legal Texts using Contextual String Embeddings\", \"topic\": \"Legal NLP\", \"x\": 5.115, \"y\": 5.804}, {\"title\": \"Acoustic Word Embeddings for Untranscribed Target Languages with  Continued Pretraining and Learned Pooling\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.687, \"y\": 4.978}, {\"title\": \"Advancing African-Accented Speech Recognition: Epistemic  Uncertainty-Driven Data Selection for Generalizable ASR Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.111, \"y\": 5.416}, {\"title\": \"Utilizing ChatGPT to Enhance Clinical Trial Enrollment\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.672, \"y\": 7.884}, {\"title\": \"A Conditional Generative Chatbot using Transformer Model\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.312, \"y\": 4.191}, {\"title\": \"MultiLegalPile: A 689GB Multilingual Legal Corpus\", \"topic\": \"Legal NLP\", \"x\": 5.264, \"y\": 5.542}, {\"title\": \"A Comprehensive Survey on Relation Extraction: Recent Advances and New  Frontiers\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.896, \"y\": 6.817}, {\"title\": \"Impact of translation on biomedical information extraction from  real-life clinical notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.968, \"y\": 7.717}, {\"title\": \"ACI-BENCH: a Novel Ambient Clinical Intelligence Dataset for  Benchmarking Automatic Visit Note Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.658, \"y\": 8.047}, {\"title\": \"COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive  Statements\", \"topic\": \"Hate Speech Detection\", \"x\": 2.956, \"y\": 5.048}, {\"title\": \"Efficient Spoken Language Recognition via Multilabel Classification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.788, \"y\": 5.207}, {\"title\": \"NLPositionality: Characterizing Design Biases of Datasets and Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.338, \"y\": 4.578}, {\"title\": \"Can Contextual Biasing Remain Effective with Whisper and GPT-2?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.404, \"y\": 5.07}, {\"title\": \"Simple Data Augmentation Techniques for Chinese Disease Normalization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.064, \"y\": 8.355}, {\"title\": \"Streaming Speech-to-Confusion Network Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.111, \"y\": 5.11}, {\"title\": \"Revisiting the Role of Language Priors in Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.604, \"y\": 7.526}, {\"title\": \"Improving Generalization in Task-oriented Dialogues with Workflows and  Action Plans\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.497, \"y\": 3.762}, {\"title\": \"Distilling Efficient Language-Specific Models for Cross-Lingual Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.683, \"y\": 4.754}, {\"title\": \"Learning Multi-Step Reasoning by Solving Arithmetic Tasks\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.857, \"y\": 2.504}, {\"title\": \"Fine-Grained Human Feedback Gives Better Rewards for Language Model  Training\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.18, \"y\": 1.63}, {\"title\": \"DiffusEmp: A Diffusion Model-Based Framework with Multi-Grained Control  for Empathetic Response Generation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.745, \"y\": 7.919}, {\"title\": \"EmoUS: Simulating User Emotions in Task-Oriented Dialogues\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.583, \"y\": 7.755}, {\"title\": \"Comparing a composite model versus chained models to locate a nearest  visual object\", \"topic\": \"Multimodal Language Models\", \"x\": 8.602, \"y\": 7.267}, {\"title\": \"Supervised Adversarial Contrastive Learning for Emotion Recognition in  Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.245, \"y\": 7.817}, {\"title\": \"Can LLMs like GPT-4 outperform traditional AI tools in dementia  diagnosis? Maybe, but not today\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.468, \"y\": 8.194}, {\"title\": \"Data-Efficient French Language Modeling with CamemBERTa\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.952, \"y\": 4.562}, {\"title\": \"Beta Thalassemia Carriers detection empowered federated Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.585, \"y\": 8.115}, {\"title\": \"Towards Robust FastSpeech 2 by Modelling Residual Multimodality\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.615, \"y\": 5.864}, {\"title\": \"Knowledge Graph Reasoning over Entities and Numerical Values\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.741, \"y\": 5.51}, {\"title\": \"ChatGPT for Zero-shot Dialogue State Tracking: A Solution or an  Opportunity?\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.62, \"y\": 4.018}, {\"title\": \"Leveraging Auxiliary Domain Parallel Data in Intermediate Task  Fine-tuning for Low-resource Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.68, \"y\": 4.152}, {\"title\": \"MathChat: Converse to Tackle Challenging Math Problems with LLM Agents\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.827, \"y\": 2.952}, {\"title\": \"Speech Translation with Foundation Models and Optimal Transport: UPC at  IWSLT23\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.383, \"y\": 5.215}, {\"title\": \"MetaVL: Transferring In-Context Learning Ability From Language Models to  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.613, \"y\": 7.366}, {\"title\": \"DistilXLSR: A Light Weight Cross-Lingual Speech Representation Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.654, \"y\": 4.883}, {\"title\": \"Improved Training for End-to-End Streaming Automatic Speech Recognition  Model with Punctuation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.016, \"y\": 5.16}, {\"title\": \"ChatGPT is a Remarkable Tool -- For Experts\", \"topic\": \"Bias in Language Models\", \"x\": 5.01, \"y\": 4.548}, {\"title\": \"VoteTRANS: Detecting Adversarial Text without Training by Voting on Hard  Labels of Transformations\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.15, \"y\": 3.043}, {\"title\": \"Automatic Translation of Hate Speech to Non-hate Speech in Social Media  Texts\", \"topic\": \"Hate Speech Detection\", \"x\": 2.735, \"y\": 5.406}, {\"title\": \"How Ready are Pre-trained Abstractive Models and LLMs for Legal Case  Judgement Summarization?\", \"topic\": \"Legal NLP\", \"x\": 5.077, \"y\": 5.854}, {\"title\": \"THiFLY Research at SemEval-2023 Task 7: A Multi-granularity System for  CTR-based Textual Entailment and Evidence Retrieval\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.798, \"y\": 7.641}, {\"title\": \"Responsible Task Automation: Empowering Large Language Models as  Responsible Task Automators\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.599, \"y\": 2.824}, {\"title\": \"Word Embeddings for Banking Industry\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.138, \"y\": 6.815}, {\"title\": \"Adapting an Unadaptable ASR System\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.191, \"y\": 5.273}, {\"title\": \"Learning When to Speak: Latency and Quality Trade-offs for Simultaneous  Speech-to-Speech Translation with Offline Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.441, \"y\": 5.218}, {\"title\": \"Multi-Dimensional Evaluation of Text Summarization with In-Context  Learning\", \"topic\": \"Text Summarization\", \"x\": 5.541, \"y\": 6.095}, {\"title\": \"Hybrid Long Document Summarization using C2F-FAR and ChatGPT: A  Practical Study\", \"topic\": \"Text Summarization\", \"x\": 5.566, \"y\": 6.24}, {\"title\": \"Leveraging Natural Language Processing For Public Health Screening On  YouTube: A COVID-19 Case Study\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.114, \"y\": 6.933}, {\"title\": \"Faster Causal Attention Over Large Sequences Through Sparse Flash  Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.889, \"y\": 3.145}, {\"title\": \"Diverse and Faithful Knowledge-Grounded Dialogue Generation via  Sequential Posterior Inference\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.637, \"y\": 4.069}, {\"title\": \"Did You Read the Instructions? Rethinking the Effectiveness of Task  Definitions in Instruction Learning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.247, \"y\": 2.409}, {\"title\": \"Evaluating the Capabilities of Multi-modal Reasoning Models with  Synthetic Task Data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.103, \"y\": 7.932}, {\"title\": \"Learning Transformer Programs\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.431, \"y\": 3.391}, {\"title\": \"Examining the Causal Effect of First Names on Language Models: The Case  of Social Commonsense Reasoning\", \"topic\": \"Bias in Language Models\", \"x\": 3.683, \"y\": 4.431}, {\"title\": \"Revisiting Hate Speech Benchmarks: From Data Curation to System  Deployment\", \"topic\": \"Hate Speech Detection\", \"x\": 2.767, \"y\": 5.36}, {\"title\": \"Improving the Robustness of Summarization Systems with Dual Augmentation\", \"topic\": \"Text Summarization\", \"x\": 5.649, \"y\": 6.192}, {\"title\": \"TimelineQA: A Benchmark for Question Answering over Timelines\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.431, \"y\": 5.258}, {\"title\": \"TopEx: Topic-based Explanations for Model Comparison\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.861, \"y\": 3.779}, {\"title\": \"AWQ: Activation-aware Weight Quantization for LLM Compression and  Acceleration\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.738, \"y\": 2.157}, {\"title\": \"\\\"Let's not Quote out of Context\\\": Unified Vision-Language Pretraining  for Context Assisted Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.85, \"y\": 7.44}, {\"title\": \"T2IAT: Measuring Valence and Stereotypical Biases in Text-to-Image  Generation\", \"topic\": \"Bias in Language Models\", \"x\": 3.168, \"y\": 4.538}, {\"title\": \"LLaVA-Med: Training a Large Language-and-Vision Assistant for  Biomedicine in One Day\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.564, \"y\": 8.239}, {\"title\": \"A Transformer-based representation-learning model with unified  processing of multimodal input for clinical diagnostics\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.117, \"y\": 8.437}, {\"title\": \"Adaptive Contextual Biasing for Transducer Based Streaming Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.34, \"y\": 5.058}, {\"title\": \"Birth of a Transformer: A Memory Viewpoint\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.355, \"y\": 3.487}, {\"title\": \"Interpretable Math Word Problem Solution Generation Via Step-by-step  Planning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.929, \"y\": 2.642}, {\"title\": \"In-Context Learning User Simulators for Task-Oriented Dialog Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.569, \"y\": 3.594}, {\"title\": \"Bypass Temporal Classification: Weakly Supervised Automatic Speech  Recognition with Imperfect Transcripts\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.189, \"y\": 5.35}, {\"title\": \"Enhancing the Unified Streaming and Non-streaming Model with Contrastive  Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.201, \"y\": 5.152}, {\"title\": \"How Generative Spoken Language Modeling Encodes Noisy Speech:  Investigation from Phonetics to Syntactics\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.642, \"y\": 5.158}, {\"title\": \"Automatic Glossary of Clinical Terminology: a Large-Scale Dictionary of  Biomedical Definitions Generated from Ontological Knowledge\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.931, \"y\": 7.66}, {\"title\": \"Improving Polish to English Neural Machine Translation with Transfer  Learning: Effects of Data Volume and Language Similarity\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.643, \"y\": 4.617}, {\"title\": \"Effective Structured Prompting by Meta-Learning and Representative  Verbalizer\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.689, \"y\": 3.438}, {\"title\": \"Some voices are too common: Building fair speech recognition systems  using the Common Voice dataset\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.182, \"y\": 5.444}, {\"title\": \"Chain-Of-Thought Prompting Under Streaming Batch: A Case Study\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.699, \"y\": 2.317}, {\"title\": \"The Effects of Input Type and Pronunciation Dictionary Usage in Transfer  Learning for Low-Resource Text-to-Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.631, \"y\": 5.303}, {\"title\": \"MEWL: Few-shot multimodal word learning with referential uncertainty\", \"topic\": \"Multimodal Language Models\", \"x\": 8.234, \"y\": 7.011}, {\"title\": \"Make Pre-trained Model Reversible: From Parameter to Memory Efficient  Fine-Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.016, \"y\": 2.455}, {\"title\": \"Exploring Anisotropy and Outliers in Multilingual Language Models for  Cross-Lingual Semantic Sentence Similarity\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.229, \"y\": 4.897}, {\"title\": \"How Many Answers Should I Give? An Empirical Study of Multi-Answer  Reading Comprehension\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.557, \"y\": 5.104}, {\"title\": \"Divide, Conquer, and Combine: Mixture of Semantic-Independent Experts  for Zero-Shot Dialogue State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.613, \"y\": 3.934}, {\"title\": \"End-to-end Knowledge Retrieval with Multi-modal Queries\", \"topic\": \"Multimodal Language Models\", \"x\": 7.984, \"y\": 7.297}, {\"title\": \"Uncertainty-Aware Unlikelihood Learning Improves Generative Aspect  Sentiment Quad Prediction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.109, \"y\": 6.813}, {\"title\": \"Towards hate speech detection in low-resource languages: Comparing ASR  to acoustic word embeddings on Wolof and Swahili\", \"topic\": \"Hate Speech Detection\", \"x\": 2.699, \"y\": 5.322}, {\"title\": \"BiSync: A Bilingual Editor for Synchronized Monolingual Texts\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.724, \"y\": 4.996}, {\"title\": \"Preference-grounded Token-level Guidance for Language Model Fine-tuning\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.51, \"y\": 1.452}, {\"title\": \"PV2TEA: Patching Visual Modality to Textual-Established Information  Extraction\", \"topic\": \"Multimodal Language Models\", \"x\": 8.17, \"y\": 7.032}, {\"title\": \"CapText: Large Language Model-based Caption Generation From Image  Context and Description\", \"topic\": \"Multimodal Language Models\", \"x\": 9.058, \"y\": 7.388}, {\"title\": \"AfriNames: Most ASR models \\\"butcher\\\" African Names\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.067, \"y\": 5.483}, {\"title\": \"Using Visual Cropping to Enhance Fine-Detail Question Answering of  BLIP-Family Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.269, \"y\": 7.973}, {\"title\": \"Strategies for improving low resource speech to text translation relying  on pre-trained ASR models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.567, \"y\": 5.161}, {\"title\": \"MERT: Acoustic Music Understanding Model with Large-Scale  Self-supervised Training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.841, \"y\": 5.134}, {\"title\": \"ManagerTower: Aggregating the Insights of Uni-Modal Experts for  Vision-Language Representation Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.428, \"y\": 7.31}, {\"title\": \"MetaXLR -- Mixed Language Meta Representation Transformation for  Low-resource Cross-lingual Learning based on Multi-Armed Bandit\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.548, \"y\": 4.93}, {\"title\": \"Improving CLIP Training with Language Rewrites\", \"topic\": \"Multimodal Language Models\", \"x\": 9.01, \"y\": 7.236}, {\"title\": \"Monotonic Location Attention for Length Generalization\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.703, \"y\": 3.179}, {\"title\": \"Beam Tree Recursive Cells\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.398, \"y\": 3.592}, {\"title\": \"MedNgage: A Dataset for Understanding Engagement in Patient-Nurse  Conversations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.96, \"y\": 8.014}, {\"title\": \"VILAS: Exploring the Effects of Vision and Language Context in Automatic  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.677, \"y\": 5.715}, {\"title\": \"Med-UniC: Unifying Cross-Lingual Medical Vision-Language Pre-Training by  Diminishing Bias\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.707, \"y\": 8.255}, {\"title\": \"TPDM: Selectively Removing Positional Information for Zero-shot  Translation via Token-Level Position Disentangle Module\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.815, \"y\": 4.393}, {\"title\": \"Deliberate then Generate: Enhanced Prompting Framework for Text  Generation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.23, \"y\": 3.594}, {\"title\": \"LMCap: Few-shot Multilingual Image Captioning by Retrieval Augmented  Language Model Prompting\", \"topic\": \"Multimodal Language Models\", \"x\": 8.889, \"y\": 7.411}, {\"title\": \"Attention-Based Methods For Audio Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.614, \"y\": 5.389}, {\"title\": \"AoM: Detecting Aspect-oriented Information for Multimodal Aspect-Based  Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.137, \"y\": 6.883}, {\"title\": \"Simple yet Effective Code-Switching Language Identification with  Multitask Pre-Training and Transfer Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.59, \"y\": 5.227}, {\"title\": \"Automatic Discrimination of Human and Neural Machine Translation in  Multilingual Scenarios\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.574, \"y\": 4.76}, {\"title\": \"Text-to-Speech Pipeline for Swiss German -- A comparison\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.579, \"y\": 5.717}, {\"title\": \"UKP-SQuARE: An Interactive Tool for Teaching Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.167, \"y\": 5.028}, {\"title\": \"Knowledge Base Question Answering for Space Debris Queries\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.709, \"y\": 5.357}, {\"title\": \"XPhoneBERT: A Pre-trained Multilingual Model for Phoneme Representations  for Text-to-Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.549, \"y\": 5.433}, {\"title\": \"Building Extractive Question Answering System to Support Human-AI Health  Coaching Model for Sleep Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.449, \"y\": 7.526}, {\"title\": \"Unveiling Cross Modality Bias in Visual Question Answering: A Causal  View with Possible Worlds VQA\", \"topic\": \"Multimodal Language Models\", \"x\": 8.232, \"y\": 8.026}, {\"title\": \"Adversarial Clean Label Backdoor Attacks and Defenses on Text  Classification Systems\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.163, \"y\": 2.986}, {\"title\": \"LAIT: Efficient Multi-Segment Encoding in Transformers with  Layer-Adjustable Interaction\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.858, \"y\": 3.36}, {\"title\": \"The Tag-Team Approach: Leveraging CLS and Language Tagging for Enhancing  Multilingual ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.013, \"y\": 5.38}, {\"title\": \"DC CoMix TTS: An End-to-End Expressive TTS with Discrete Code  Collaborated with Mixer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.648, \"y\": 5.836}, {\"title\": \"Zero-Shot Automatic Pronunciation Assessment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.985, \"y\": 5.431}, {\"title\": \"Large Language Models Are Not Strong Abstract Reasoners\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.644, \"y\": 3.288}, {\"title\": \"Accurate and Structured Pruning for Efficient Automatic Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.08, \"y\": 4.696}, {\"title\": \"Exploring Lottery Prompts for Pre-trained Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.477, \"y\": 3.32}, {\"title\": \"The Impact of Positional Encoding on Length Generalization in  Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.59, \"y\": 3.46}, {\"title\": \"Self-Verification Improves Few-Shot Clinical Information Extraction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.752, \"y\": 7.901}, {\"title\": \"ScoNe: Benchmarking Negation Reasoning in Language Models With  Fine-Tuning and In-Context Learning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.033, \"y\": 3.849}, {\"title\": \"Examining risks of racial biases in NLP tools for child protective  services\", \"topic\": \"Bias in Language Models\", \"x\": 3.365, \"y\": 4.525}, {\"title\": \"Contextual Vision Transformers for Robust Representation Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.711, \"y\": 7.224}, {\"title\": \"Resource-Efficient Fine-Tuning Strategies for Automatic MOS Prediction  in Text-to-Speech for Low-Resource Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.748, \"y\": 5.311}, {\"title\": \"Explaining Hate Speech Classification with Model Agnostic Methods\", \"topic\": \"Hate Speech Detection\", \"x\": 2.761, \"y\": 5.329}, {\"title\": \"Mining Themes in Clinical Notes to Identify Phenotypes and to Predict  Length of Stay in Patients admitted with Heart Failure\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.455, \"y\": 8.081}, {\"title\": \"Blockwise Parallel Transformer for Large Context Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.825, \"y\": 3.307}, {\"title\": \"Concise Answers to Complex Questions: Summarization of Long-form Answers\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.425, \"y\": 5.341}, {\"title\": \"SheetCopilot: Bringing Software Productivity to the Next Level through  Large Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 6.012, \"y\": 2.695}, {\"title\": \"Make-A-Voice: Unified Voice Synthesis With Discrete Representation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.624, \"y\": 5.87}, {\"title\": \"Jointly Reparametrized Multi-Layer Adaptation for Efficient and Private  Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.079, \"y\": 2.42}, {\"title\": \"A Stutter Seldom Comes Alone -- Cross-Corpus Stuttering Detection as a  Multi-label Problem\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.818, \"y\": 5.604}, {\"title\": \"Grammar Prompting for Domain-Specific Language Generation with Large  Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.24, \"y\": 3.438}, {\"title\": \"Towards Selection of Text-to-speech Data to Augment ASR Training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.068, \"y\": 5.433}, {\"title\": \"LANCE: Stress-testing Visual Models by Generating Language-guided  Counterfactual Images\", \"topic\": \"Multimodal Language Models\", \"x\": 8.302, \"y\": 7.897}, {\"title\": \"BLEU Meets COMET: Combining Lexical and Neural Metrics Towards Robust  Machine Translation Evaluation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.862, \"y\": 4.762}, {\"title\": \"Utilization of Multinomial Naive Bayes Algorithm and Term Frequency  Inverse Document Frequency (TF-IDF Vectorizer) in Checking the Credibility of  News Tweet in the Philippines\", \"topic\": \"Fake News Detection\", \"x\": 4.046, \"y\": 5.88}, {\"title\": \"Comparing and combining some popular NER approaches on Biomedical tasks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.425, \"y\": 7.451}, {\"title\": \"Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse  Engineering of Language at Scale\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.075, \"y\": 3.6}, {\"title\": \"Complex Query Answering on Eventuality Knowledge Graph with Implicit  Logical Constraints\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.778, \"y\": 5.493}, {\"title\": \"MiniSUPERB: Lightweight Benchmark for Self-supervised Speech Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.878, \"y\": 4.893}, {\"title\": \"Voice Conversion With Just Nearest Neighbors\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.694, \"y\": 5.627}, {\"title\": \"Chatbots put to the test in math and logic problems: A preliminary  comparison and assessment of ChatGPT-3.5, ChatGPT-4, and Google Bard\", \"topic\": \"Bias in Language Models\", \"x\": 5.154, \"y\": 4.528}, {\"title\": \"Investigating model performance in language identification: beyond  simple error statistics\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.586, \"y\": 5.439}, {\"title\": \"Fighting Bias with Bias: Promoting Model Robustness by Amplifying  Dataset Biases\", \"topic\": \"Bias in Language Models\", \"x\": 3.279, \"y\": 4.44}, {\"title\": \"Multitask learning for recognizing stress and depression in social media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.089, \"y\": 7.333}, {\"title\": \"Weakly-supervised forced alignment of disfluent speech using  phoneme-level modeling\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.222, \"y\": 5.526}, {\"title\": \"Dissecting Chain-of-Thought: Compositionality through In-Context  Filtering and Learning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.77, \"y\": 2.164}, {\"title\": \"PreQuant: A Task-agnostic Quantization Approach for Pre-trained Language  Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.674, \"y\": 2.187}, {\"title\": \"Knowledge Graph-Augmented Language Models for Knowledge-Grounded  Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.691, \"y\": 4.058}, {\"title\": \"Generate then Select: Open-ended Visual Question Answering Guided by  World Knowledge\", \"topic\": \"Multimodal Language Models\", \"x\": 8.23, \"y\": 8.07}, {\"title\": \"Graph Neural Networks for Contextual ASR with the Tree-Constrained  Pointer Generator\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.359, \"y\": 5.155}, {\"title\": \"Machine Learning Approach for Cancer Entities Association and  Classification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.99, \"y\": 7.66}, {\"title\": \"Universality and Limitations of Prompt Tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.69, \"y\": 3.334}, {\"title\": \"Scalable Performance Analysis for Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.385, \"y\": 7.567}, {\"title\": \"VSTAR: A Video-grounded Dialogue Dataset for Situated Semantic  Understanding with Scene and Topic Transitions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.657, \"y\": 7.91}, {\"title\": \"Adapting Multi-Lingual ASR Models for Handling Multiple Talkers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.974, \"y\": 5.212}, {\"title\": \"Graph Reasoning for Question Answering with Triplet Retrieval\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.81, \"y\": 5.58}, {\"title\": \"Grokking of Hierarchical Structure in Vanilla Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.266, \"y\": 3.68}, {\"title\": \"LonXplain: Lonesomeness as a Consequence of Mental Disturbance in Reddit  Posts\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.126, \"y\": 7.395}, {\"title\": \"An Annotated Dataset for Explainable Interpersonal Risk Factors of  Mental Disturbance in Social Media Posts\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.193, \"y\": 7.346}, {\"title\": \"KEYword based Sampling (KEYS) for Large Language Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.41, \"y\": 5.219}, {\"title\": \"Enhanced Chart Understanding in Vision and Language Task via Cross-modal  Pre-training on Plot Table Pairs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.997, \"y\": 7.75}, {\"title\": \"From `Snippet-lects' to Doculects and Dialects: Leveraging Neural  Representations of Speech for Placing Audio Signals in a Language Landscape\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.408, \"y\": 5.076}, {\"title\": \"Improving Generalization for Multimodal Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 3.984, \"y\": 5.857}, {\"title\": \"Building Accurate Low Latency ASR for Streaming Voice Search\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.045, \"y\": 5.225}, {\"title\": \"TreeMAN: Tree-enhanced Multimodal Attention Network for ICD Coding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.939, \"y\": 8.442}, {\"title\": \"PaLI-X: On Scaling up a Multilingual Vision and Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.357, \"y\": 7.513}, {\"title\": \"Brainformers: Trading Simplicity for Efficiency\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.811, \"y\": 3.332}, {\"title\": \"Datasets for Portuguese Legal Semantic Textual Similarity: Comparing  weak supervision and an annotation process approaches\", \"topic\": \"Legal NLP\", \"x\": 5.167, \"y\": 5.76}, {\"title\": \"Transformer Language Models Handle Word Frequency in Prediction Head\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.237, \"y\": 3.681}, {\"title\": \"Direct Preference Optimization: Your Language Model is Secretly a Reward  Model\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.343, \"y\": 1.267}, {\"title\": \"CommonAccent: Exploring Large Acoustic Pretrained Models for Accent  Classification Based on Common Voice\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.138, \"y\": 5.56}, {\"title\": \"HyperConformer: Multi-head HyperMixer for Efficient Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.234, \"y\": 4.951}, {\"title\": \"Do Language Models Know When They're Hallucinating References?\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.238, \"y\": 1.19}, {\"title\": \"A Critical Evaluation of Evaluations for Long-form Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.283, \"y\": 4.849}, {\"title\": \"Contextual Knowledge Learning For Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.702, \"y\": 3.983}, {\"title\": \"Marked Personas: Using Natural Language Prompts to Measure Stereotypes  in Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.356, \"y\": 4.349}, {\"title\": \"Leveraging Training Data in Few-Shot Prompting for Numerical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.858, \"y\": 2.402}, {\"title\": \"LM-CPPF: Paraphrasing-Guided Data Augmentation for Contrastive  Prompt-Based Few-Shot Fine-Tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.875, \"y\": 3.53}, {\"title\": \"Extrinsic Factors Affecting the Accuracy of Biomedical NER\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.345, \"y\": 7.487}, {\"title\": \"Multiscale Positive-Unlabeled Detection of AI-Generated Texts\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.119, \"y\": 4.798}, {\"title\": \"From Adversarial Arms Race to Model-centric Evaluation: Motivating a  Unified Automatic Robustness Evaluation Framework\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.275, \"y\": 3.087}, {\"title\": \"VAST: A Vision-Audio-Subtitle-Text Omni-Modality Foundation Model and  Dataset\", \"topic\": \"Multimodal Language Models\", \"x\": 8.81, \"y\": 7.766}, {\"title\": \"Medical Dialogue Generation via Dual Flow Modeling\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.589, \"y\": 8.235}, {\"title\": \"BigTranslate: Augmenting Large Language Models with Multilingual  Translation Capability over 100 Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.348, \"y\": 4.371}, {\"title\": \"Improving Textless Spoken Language Understanding with Discrete Units as  Intermediate Target\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.646, \"y\": 5.055}, {\"title\": \"Faithfulness Tests for Natural Language Explanations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.738, \"y\": 3.762}, {\"title\": \"ADAPTERMIX: Exploring the Efficacy of Mixture of Adapters for  Low-Resource TTS Adaptation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.842, \"y\": 5.223}, {\"title\": \"Abstractive Summarization as Augmentation for Document-Level Event  Detection\", \"topic\": \"Text Summarization\", \"x\": 5.653, \"y\": 6.329}, {\"title\": \"The Effects of Political Martyrdom on Election Results: The  Assassination of Abe\", \"topic\": \"Fake News Detection\", \"x\": 3.677, \"y\": 6.042}, {\"title\": \"minOffense: Inter-Agreement Hate Terms for Stable Rules, Concepts,  Transitivities, and Lattices\", \"topic\": \"Hate Speech Detection\", \"x\": 2.663, \"y\": 5.315}, {\"title\": \"LLM-QAT: Data-Free Quantization Aware Training for Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.8, \"y\": 2.206}, {\"title\": \"E-NER: Evidential Deep Learning for Trustworthy Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.335, \"y\": 6.803}, {\"title\": \"Retraining-free Customized ASR for Enharmonic Words Based on a  Named-Entity-Aware Model and Phoneme Similarity Estimation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.16, \"y\": 5.335}, {\"title\": \"Large Language Models, scientific knowledge and factuality: A systematic  analysis in antibiotic discovery\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.88, \"y\": 7.416}, {\"title\": \"ChatGPT Informed Graph Neural Network for Stock Movement Prediction\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.703, \"y\": 6.832}, {\"title\": \"Tab-CoT: Zero-shot Tabular Chain of Thought\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.652, \"y\": 2.391}, {\"title\": \"Semantic Segmentation with Bidirectional Language Models Improves  Long-form ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.57, \"y\": 5.341}, {\"title\": \"RASR2: The RWTH ASR Toolkit for Generic Sequence-to-sequence Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.121, \"y\": 5.219}, {\"title\": \"Generating EDU Extracts for Plan-Guided Summary Re-Ranking\", \"topic\": \"Text Summarization\", \"x\": 5.651, \"y\": 6.226}, {\"title\": \"Understanding Breast Cancer Survival: Using Causality and Language  Models on Multi-omics Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.809, \"y\": 7.647}, {\"title\": \"Mitigating Label Biases for In-context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.232, \"y\": 3.365}, {\"title\": \"Reliable and Interpretable Drift Detection in Streams of Short Texts\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 6.643, \"y\": 4.459}, {\"title\": \"Breaking Language Barriers with a LEAP: Learning Strategies for Polyglot  LLMs\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.933, \"y\": 4.313}, {\"title\": \"Range-Based Equal Error Rate for Spoof Localization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.172, \"y\": 5.336}, {\"title\": \"Investigating Pre-trained Audio Encoders in the Low-Resource Condition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.81, \"y\": 5.145}, {\"title\": \"FuseCap: Leveraging Large Language Models for Enriched Fused Image  Captions\", \"topic\": \"Multimodal Language Models\", \"x\": 9.051, \"y\": 7.482}, {\"title\": \"Knowledge-Augmented Reasoning Distillation for Small Language Models in  Knowledge-Intensive Tasks\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.082, \"y\": 2.35}, {\"title\": \"KoSBi: A Dataset for Mitigating Social Bias Risks Towards Safer Large  Language Model Application\", \"topic\": \"Bias in Language Models\", \"x\": 3.513, \"y\": 4.248}, {\"title\": \"HaVQA: A Dataset for Visual Question Answering and Multimodal Research  in Hausa Language\", \"topic\": \"Multimodal Language Models\", \"x\": 8.072, \"y\": 8.01}, {\"title\": \"Evaluating GPT-3 Generated Explanations for Hateful Content Moderation\", \"topic\": \"Hate Speech Detection\", \"x\": 2.765, \"y\": 5.23}, {\"title\": \"RuSentNE-2023: Evaluating Entity-Oriented Sentiment Analysis on Russian  News Texts\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.598, \"y\": 6.392}, {\"title\": \"Decoding the Underlying Meaning of Multimodal Hateful Memes\", \"topic\": \"Hate Speech Detection\", \"x\": 2.85, \"y\": 5.609}, {\"title\": \"Stochastic Bridges as Effective Regularizers for Parameter-Efficient  Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.883, \"y\": 2.39}, {\"title\": \"ConaCLIP: Exploring Distillation of Fully-Connected Knowledge  Interaction Graph for Lightweight Text-Image Retrieval\", \"topic\": \"Multimodal Language Models\", \"x\": 8.683, \"y\": 7.141}, {\"title\": \"KAFA: Rethinking Image Ad Understanding with Knowledge-Augmented Feature  Adaptation of Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.501, \"y\": 7.382}, {\"title\": \"Reward Collapse in Aligning Large Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.234, \"y\": 1.714}, {\"title\": \"Diagnosing Transformers: Illuminating Feature Spaces for Clinical  Decision-Making\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.169, \"y\": 8.328}, {\"title\": \"Translatotron 3: Speech to Speech Translation with Monolingual Data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.469, \"y\": 5.324}, {\"title\": \"Non-Sequential Graph Script Induction via Multimedia Grounding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.589, \"y\": 7.589}, {\"title\": \"Learning from Children: Improving Image-Caption Pretraining via  Curriculum\", \"topic\": \"Multimodal Language Models\", \"x\": 8.978, \"y\": 7.44}, {\"title\": \"A Two-Stage Decoder for Efficient ICD Coding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.943, \"y\": 8.457}, {\"title\": \"PuMer: Pruning and Merging Tokens for Efficient Vision Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.813, \"y\": 7.351}, {\"title\": \"MeetingBank: A Benchmark Dataset for Meeting Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.626, \"y\": 6.286}, {\"title\": \"CIF-PT: Bridging Speech and Text Representations for Spoken Language  Understanding via Continuous Integrate-and-Fire Pre-Training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.53, \"y\": 5.189}, {\"title\": \"FACTUAL: A Benchmark for Faithful and Consistent Textual Scene Graph  Parsing\", \"topic\": \"Multimodal Language Models\", \"x\": 8.792, \"y\": 7.416}, {\"title\": \"FERMAT: An Alternative to Accuracy for Numerical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.737, \"y\": 2.866}, {\"title\": \"Financial misstatement detection: a realistic evaluation\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.912, \"y\": 6.719}, {\"title\": \"CrossGET: Cross-Guided Ensemble of Tokens for Accelerating  Vision-Language Transformers\", \"topic\": \"Multimodal Language Models\", \"x\": 8.666, \"y\": 7.275}, {\"title\": \"Measuring Your ASTE Models in The Wild: A Diversified Multi-domain  Dataset For Aspect Sentiment Triplet Extraction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.129, \"y\": 6.817}, {\"title\": \"A Unified Framework for Slot based Response Generation in a Multimodal  Dialogue System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.672, \"y\": 3.951}, {\"title\": \"Understanding Emotion Valence is a Joint Deep Learning Task\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.33, \"y\": 7.747}, {\"title\": \"A Practical Toolkit for Multilingual Question and Answer Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.335, \"y\": 5.095}, {\"title\": \"Exploring Better Text Image Translation with Multimodal Codebook\", \"topic\": \"Multimodal Language Models\", \"x\": 8.57, \"y\": 6.79}, {\"title\": \"Enhancing Translation for Indigenous Languages: Experiments with  Multilingual Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.763, \"y\": 4.927}, {\"title\": \"Parallel Corpus for Indigenous Language Translation: Spanish-Mazatec and  Spanish-Mixtec\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.749, \"y\": 5.002}, {\"title\": \"Answering Unanswered Questions through Semantic Reformulations in Spoken  QA\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.336, \"y\": 4.996}, {\"title\": \"SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex  Interactive Tasks\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.953, \"y\": 2.547}, {\"title\": \"MPCHAT: Towards Multimodal Persona-Grounded Conversation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.054, \"y\": 3.999}, {\"title\": \"An Investigation of Evaluation Metrics for Automated Medical Note  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.603, \"y\": 7.885}, {\"title\": \"DNA-GPT: Divergent N-Gram Analysis for Training-Free Detection of  GPT-Generated Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.088, \"y\": 4.742}, {\"title\": \"CTC-based Non-autoregressive Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.758, \"y\": 4.922}, {\"title\": \"Bridging the Granularity Gap for Acoustic Modeling\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.99, \"y\": 5.051}, {\"title\": \"Complementary and Integrative Health Lexicon (CIHLex) and Entity  Recognition in the Literature\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.12, \"y\": 7.63}, {\"title\": \"Disambiguated Lexically Constrained Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.879, \"y\": 4.385}, {\"title\": \"Fine-Tuning Language Models with Just Forward Passes\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.975, \"y\": 2.3}, {\"title\": \"Why Does Zero-Shot Cross-Lingual Generation Fail? An Explanation and a  Solution\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.523, \"y\": 4.707}, {\"title\": \"Chain-of-Thought Hub: A Continuous Effort to Measure Large Language  Models' Reasoning Performance\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.64, \"y\": 2.48}, {\"title\": \"External Language Model Integration for Factorized Neural Transducers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.958, \"y\": 4.921}, {\"title\": \"Improved Instruction Ordering in Recipe-Grounded Conversation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.65, \"y\": 3.912}, {\"title\": \"CODET: A Benchmark for Contrastive Dialectal Evaluation of Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.692, \"y\": 4.658}, {\"title\": \"Large Language Models Can be Lazy Learners: Analyze Shortcuts in  In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.158, \"y\": 3.409}, {\"title\": \"Generating Images with Multimodal Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.384, \"y\": 7.202}, {\"title\": \"Coping with low data availability for social media crisis message  categorisation\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.194, \"y\": 6.815}, {\"title\": \"Large language models improve Alzheimer's disease diagnosis using  multi-modality data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.364, \"y\": 8.335}, {\"title\": \"On the Copying Problem of Unsupervised NMT: A Training Schedule with a  Language Discriminator Loss\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.96, \"y\": 4.44}, {\"title\": \"DeepSI: Interactive Deep Learning for Semantic Interaction\", \"topic\": \"Multimodal Language Models\", \"x\": 8.422, \"y\": 7.549}, {\"title\": \"From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language  Models\", \"topic\": \"Hate Speech Detection\", \"x\": 2.843, \"y\": 5.281}, {\"title\": \"Improving accuracy of GPT-3/4 results on biomedical data using a  retrieval-augmented language model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.877, \"y\": 7.815}, {\"title\": \"BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained  Transformer for Vision, Language, and Multimodal Tasks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.506, \"y\": 8.26}, {\"title\": \"LLMs and the Abstraction and Reasoning Corpus: Successes, Failures, and  the Importance of Object-based Representations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.718, \"y\": 3.102}, {\"title\": \"Stereotypes and Smut: The (Mis)representation of Non-cisgender  Identities by Text-to-Image Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.184, \"y\": 4.549}, {\"title\": \"Mindstorms in Natural Language-Based Societies of Mind\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.37, \"y\": 2.918}, {\"title\": \"Counterfactuals of Counterfactuals: a back-translation-inspired approach  to analyse counterfactual editors\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.61, \"y\": 3.9}, {\"title\": \"Exploiting Abstract Meaning Representation for Open-Domain Question  Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.829, \"y\": 5.595}, {\"title\": \"RFiD: Towards Rational Fusion-in-Decoder for Open-Domain Question  Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.683, \"y\": 5.209}, {\"title\": \"How Powerful are Decoder-Only Transformer Neural Models?\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.447, \"y\": 3.391}, {\"title\": \"Diable: Efficient Dialogue State Tracking as Operations on Tables\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.556, \"y\": 3.857}, {\"title\": \"Commonsense Knowledge Graph Completion Via Contrastive Pretraining and  Node Clustering\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.228, \"y\": 5.986}, {\"title\": \"Zero-shot Visual Question Answering with Language Model Feedback\", \"topic\": \"Multimodal Language Models\", \"x\": 8.268, \"y\": 8.034}, {\"title\": \"An Empirical Comparison of LM-based Question and Answer Generation  Methods\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.45, \"y\": 4.935}, {\"title\": \"Evaluating Open-Domain Dialogues in Latent Space with Next Sentence  Prediction and Mutual Information\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.621, \"y\": 3.891}, {\"title\": \"DisfluencyFixer: A tool to enhance Language Learning through Speech To  Speech Disfluency Correction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.167, \"y\": 5.647}, {\"title\": \"Learning to Imagine: Visually-Augmented Natural Language Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.729, \"y\": 6.971}, {\"title\": \"Finspector: A Human-Centered Visual Inspection Tool for Exploring and  Comparing Biases among Foundation Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.233, \"y\": 4.398}, {\"title\": \"Gender Lost In Translation: How Bridging The Gap Between Languages  Affects Gender Bias in Zero-Shot Multilingual Translation\", \"topic\": \"Bias in Language Models\", \"x\": 2.986, \"y\": 4.392}, {\"title\": \"A Neural State-Space Model Approach to Efficient Speech Separation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.2, \"y\": 5.015}, {\"title\": \"A Study on Knowledge Distillation from Weak Teacher for Scaling Up  Pre-trained Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.558, \"y\": 3.864}, {\"title\": \"Inter-connection: Effective Connection between Pre-trained Encoder and  Decoder for Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.535, \"y\": 5.046}, {\"title\": \"MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of  Thought Prompting\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.611, \"y\": 2.36}, {\"title\": \"UMSE: Unified Multi-scenario Summarization Evaluation\", \"topic\": \"Text Summarization\", \"x\": 5.563, \"y\": 6.203}, {\"title\": \"Playing repeated games with Large Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.323, \"y\": 2.984}, {\"title\": \"Randomized Positional Encodings Boost Length Generalization of  Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.602, \"y\": 3.448}, {\"title\": \"Free Lunch: Robust Cross-Lingual Transfer via Model Checkpoint Averaging\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.451, \"y\": 4.641}, {\"title\": \"KNSE: A Knowledge-aware Natural Language Inference Framework for  Dialogue Symptom Status Recognition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.439, \"y\": 8.146}, {\"title\": \"Domain Aligned Prefix Averaging for Domain Generalization in Abstractive  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.59, \"y\": 6.322}, {\"title\": \"GenQ: Automated Question Generation to Support Caregivers While Reading  Stories with Children\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.203, \"y\": 4.971}, {\"title\": \"Do GPTs Produce Less Literal Translations?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.607, \"y\": 4.624}, {\"title\": \"Schema-Guided User Satisfaction Modeling for Task-Oriented Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.416, \"y\": 3.733}, {\"title\": \"Calibration of Transformer-based Models for Identifying Stress and  Depression in Social Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.129, \"y\": 7.422}, {\"title\": \"Incorporating Distributions of Discourse Structure for Long Document  Abstractive Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.696, \"y\": 6.166}, {\"title\": \"Towards a Common Understanding of Contributing Factors for Cross-Lingual  Transfer in Multilingual Language Models: A Review\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.327, \"y\": 4.706}, {\"title\": \"Distinguishing Human Generated Text From ChatGPT Generated Text Using  Machine Learning\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.301, \"y\": 4.777}, {\"title\": \"Leveraging Domain Knowledge for Inclusive and Bias-aware Humanitarian  Response Entry Classification\", \"topic\": \"Bias in Language Models\", \"x\": 3.474, \"y\": 4.581}, {\"title\": \"Parameter-Efficient Fine-Tuning without Introducing New Latency\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.012, \"y\": 2.3}, {\"title\": \"Automatic Emotion Experiencer Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.406, \"y\": 7.455}, {\"title\": \"Code-Switched Text Synthesis in Unseen Language Pairs\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.635, \"y\": 4.823}, {\"title\": \"DKAF: KB Arbitration for Learning Task-Oriented Dialog Systems with  Dialog-KB Inconsistencies\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.629, \"y\": 3.542}, {\"title\": \"Score-balanced Loss for Multi-aspect Pronunciation Assessment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.185, \"y\": 5.491}, {\"title\": \"GDA: Generative Data Augmentation Techniques for Relation Extraction  Tasks\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.005, \"y\": 6.746}, {\"title\": \"AdaPlanner: Adaptive Planning from Feedback with Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.951, \"y\": 2.57}, {\"title\": \"Are Fairy Tales Fair? Analyzing Gender Bias in Temporal Narrative Event  Chains of Children's Fairy Tales\", \"topic\": \"Bias in Language Models\", \"x\": 3.248, \"y\": 4.419}, {\"title\": \"Zero is Not Hero Yet: Benchmarking Zero-Shot Performance of LLMs for  Financial Tasks\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.885, \"y\": 6.826}, {\"title\": \"Evaluation of Question Generation Needs More References\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.11, \"y\": 4.976}, {\"title\": \"Efficient Detection of LLM-generated Texts with a Bayesian Surrogate  Model\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.067, \"y\": 4.713}, {\"title\": \"Bridging the Domain Gaps in Context Representations for k-Nearest  Neighbor Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.955, \"y\": 4.273}, {\"title\": \"Neural Architecture Search for Parameter-Efficient Fine-tuning of Large  Pre-trained Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.159, \"y\": 2.467}, {\"title\": \"Beyond Chain-of-Thought, Effective Graph-of-Thought Reasoning in  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.577, \"y\": 2.429}, {\"title\": \"Nichelle and Nancy: The Influence of Demographic Attributes and  Tokenization Length on First Name Biases\", \"topic\": \"Bias in Language Models\", \"x\": 3.592, \"y\": 4.338}, {\"title\": \"Neural Task Synthesis for Visual Programming\", \"topic\": \"Multimodal Language Models\", \"x\": 8.461, \"y\": 7.569}, {\"title\": \"CONA: A novel CONtext-Aware instruction paradigm for communication using  large language model\", \"topic\": \"In-Context Learning\", \"x\": 8.361, \"y\": 3.316}, {\"title\": \"Prototype-Based Interpretability for Legal Citation Prediction\", \"topic\": \"Legal NLP\", \"x\": 5.133, \"y\": 5.757}, {\"title\": \"Don't Retrain, Just Rewrite: Countering Adversarial Perturbations by  Rewriting Text\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.143, \"y\": 3.047}, {\"title\": \"Neural Machine Translation for Mathematical Formulae\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.744, \"y\": 4.397}, {\"title\": \"Ghost in the Minecraft: Generally Capable Agents for Open-World  Environments via Large Language Models with Text-based Knowledge and Memory\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.687, \"y\": 2.522}, {\"title\": \"IndicTrans2: Towards High-Quality and Accessible Machine Translation  Models for all 22 Scheduled Indian Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.58, \"y\": 5.115}, {\"title\": \"Landmark Attention: Random-Access Infinite Context Length for  Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.82, \"y\": 3.046}, {\"title\": \"Transformative Effects of ChatGPT on Modern Education: Emerging Era of  AI Chatbots\", \"topic\": \"Bias in Language Models\", \"x\": 4.931, \"y\": 4.476}, {\"title\": \"Unified Modeling of Multi-Talker Overlapped Speech Recognition and  Diarization with a Sidecar Separator\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.072, \"y\": 5.261}, {\"title\": \"Uncovering and Categorizing Social Biases in Text-to-SQL\", \"topic\": \"Bias in Language Models\", \"x\": 3.251, \"y\": 4.472}, {\"title\": \"Surface-Based Retrieval Reduces Perplexity of Retrieval-Augmented  Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.391, \"y\": 4.842}, {\"title\": \"Scan and Snap: Understanding Training Dynamics and Token Composition in  1-layer Transformer\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.662, \"y\": 3.417}, {\"title\": \"Abstractive Summary Generation for the Urdu Language\", \"topic\": \"Text Summarization\", \"x\": 5.617, \"y\": 6.367}, {\"title\": \"Revisiting Non-Autoregressive Translation at Scale\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.038, \"y\": 4.146}, {\"title\": \"A Survey on ChatGPT: AI-Generated Contents, Challenges, and Solutions\", \"topic\": \"Bias in Language Models\", \"x\": 4.853, \"y\": 4.459}, {\"title\": \"VioLA: Unified Codec Language Models for Speech Recognition, Synthesis,  and Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.279, \"y\": 5.427}, {\"title\": \"Multijugate Dual Learning for Low-Resource Task-Oriented Dialogue System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.574, \"y\": 3.875}, {\"title\": \"ChatBridge: Bridging Modalities with Large Language Model as a Language  Catalyst\", \"topic\": \"Multimodal Language Models\", \"x\": 8.192, \"y\": 7.397}, {\"title\": \"End-to-End Simultaneous Speech Translation with Differentiable  Segmentation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.491, \"y\": 5.18}, {\"title\": \"ASR and Emotional Speech: A Word-Level Investigation of the Mutual  Impact of Speech and Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.174, \"y\": 7.869}, {\"title\": \"Fake News Detection and Behavioral Analysis: Case of COVID-19\", \"topic\": \"Fake News Detection\", \"x\": 3.962, \"y\": 5.964}, {\"title\": \"What about em? How Commercial Machine Translation Fails to Handle  (Neo-)Pronouns\", \"topic\": \"Bias in Language Models\", \"x\": 2.917, \"y\": 4.38}, {\"title\": \"Role-Play with Large Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.035, \"y\": 3.33}, {\"title\": \"Visually grounded few-shot word acquisition with fewer shots\", \"topic\": \"Multimodal Language Models\", \"x\": 8.77, \"y\": 6.964}, {\"title\": \"BUCA: A Binary Classification Approach to Unsupervised Commonsense  Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.556, \"y\": 5.401}, {\"title\": \"Response Generation in Longitudinal Dialogues: Which Knowledge  Representation Helps?\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.455, \"y\": 3.903}, {\"title\": \"MTCue: Learning Zero-Shot Control of Extra-Textual Attributes by  Leveraging Unstructured Context in Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.895, \"y\": 4.536}, {\"title\": \"Collective Knowledge Graph Completion with Mutual Knowledge Distillation\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.1, \"y\": 6.022}, {\"title\": \"CSS: A Large-scale Cross-schema Chinese Text-to-SQL Medical Dataset\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.091, \"y\": 7.705}, {\"title\": \"Jointprop: Joint Semi-supervised Learning for Entity and Relation  Extraction with Heterogeneous Graph-based Propagation\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.008, \"y\": 6.826}, {\"title\": \"Sequential Integrated Gradients: a simple but effective method for  explaining language models\", \"topic\": \"In-Context Learning\", \"x\": 8.601, \"y\": 3.289}, {\"title\": \"Self-contradictory Hallucinations of Large Language Models: Evaluation,  Detection and Mitigation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.308, \"y\": 1.401}, {\"title\": \"Svarah: Evaluating English ASR Systems on Indian Accents\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.942, \"y\": 5.632}, {\"title\": \"UniTRec: A Unified Text-to-Text Transformer and Joint Contrastive  Learning Framework for Text-based Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.92, \"y\": 2.843}, {\"title\": \"Multilingual Text-to-Speech Synthesis for Turkic Languages Using  Transliteration\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.409, \"y\": 5.599}, {\"title\": \"Towards Higher Pareto Frontier in Multilingual Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.789, \"y\": 4.433}, {\"title\": \"PandaGPT: One Model To Instruction-Follow Them All\", \"topic\": \"Multimodal Language Models\", \"x\": 8.266, \"y\": 7.469}, {\"title\": \"Zero-shot Approach to Overcome Perturbation Sensitivity of Prompts\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.394, \"y\": 3.579}, {\"title\": \"RewriteLM: An Instruction-Tuned Large Language Model for Text Rewriting\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.067, \"y\": 2.452}, {\"title\": \"Betray Oneself: A Novel Audio DeepFake Detection Model via  Mono-to-Stereo Conversion\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.817, \"y\": 5.788}, {\"title\": \"BookGPT: A General Framework for Book Recommendation Empowered by Large  Language Model\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.914, \"y\": 2.935}, {\"title\": \"Mixture-of-Expert Conformer for Streaming Multilingual ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.036, \"y\": 5.069}, {\"title\": \"Text-Augmented Open Knowledge Graph Completion via Pre-Trained Language  Models\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.966, \"y\": 5.857}, {\"title\": \"How do humans perceive adversarial text? A reality check on the validity  and naturalness of word-based adversarial attacks\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.161, \"y\": 3.056}, {\"title\": \"Harnessing the Power of Large Language Models for Natural Language to  First-Order Logic Translation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.704, \"y\": 2.746}, {\"title\": \"Automated Refugee Case Analysis: An NLP Pipeline for Supporting Legal  Practitioners\", \"topic\": \"Legal NLP\", \"x\": 5.085, \"y\": 5.748}, {\"title\": \"Large Language Models are Few-Shot Health Learners\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.425, \"y\": 7.96}, {\"title\": \"Exploring Automatically Perturbed Natural Language Explanations in  Relation Extraction\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.834, \"y\": 3.786}, {\"title\": \"Large Language Models for User Interest Journeys\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.943, \"y\": 2.913}, {\"title\": \"Towards Revealing the Mystery behind Chain of Thought: A Theoretical  Perspective\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.74, \"y\": 2.201}, {\"title\": \"Textless Low-Resource Speech-to-Speech Translation With Unit Language  Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.458, \"y\": 5.267}, {\"title\": \"AV-TranSpeech: Audio-Visual Robust Speech-to-Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.569, \"y\": 5.481}, {\"title\": \"Comparing Humans and Models on a Similar Scale: Towards Cognitive Gender  Bias Evaluation in Coreference Resolution\", \"topic\": \"Bias in Language Models\", \"x\": 3.589, \"y\": 4.262}, {\"title\": \"Vistaar: Diverse Benchmarks and Training Sets for Indian Language ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.986, \"y\": 5.476}, {\"title\": \"Uncovering and Quantifying Social Biases in Code Generation\", \"topic\": \"Bias in Language Models\", \"x\": 3.277, \"y\": 4.394}, {\"title\": \"ASPER: Answer Set Programming Enhanced Neural Network Models for Joint  Entity-Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.056, \"y\": 6.849}, {\"title\": \"Learning Answer Generation using Supervision from Automatic Question  Answering Evaluators\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.267, \"y\": 4.952}, {\"title\": \"Measuring and Mitigating Constraint Violations of In-Context Learning  for Utterance-to-API Semantic Parsing\", \"topic\": \"In-Context Learning\", \"x\": 8.229, \"y\": 3.536}, {\"title\": \"Visual Programming for Text-to-Image Generation and Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.549, \"y\": 7.457}, {\"title\": \"Enhancing Retrieval-Augmented Large Language Models with Iterative  Retrieval-Generation Synergy\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.141, \"y\": 4.761}, {\"title\": \"Testing the General Deductive Reasoning Capacity of Large Language  Models Using OOD Examples\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.651, \"y\": 3.127}, {\"title\": \"Spoken Question Answering and Speech Continuation Using  Spectrogram-Powered LLM\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.286, \"y\": 5.347}, {\"title\": \"Boosting Cross-lingual Transferability in Multilingual Models via  In-Context Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.29, \"y\": 4.642}, {\"title\": \"SAIL: Search-Augmented Instruction Learning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.208, \"y\": 2.441}, {\"title\": \"Neural Summarization of Electronic Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.66, \"y\": 8.058}, {\"title\": \"Towards Adaptive Prefix Tuning for Parameter-Efficient Language Model  Fine-tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.873, \"y\": 2.597}, {\"title\": \"The Role of Output Vocabulary in T2T LMs for SPARQL Semantic Parsing\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.951, \"y\": 5.364}, {\"title\": \"Fourier Transformer: Fast Long Range Modeling by Removing Sequence  Redundancy with FFT Operator\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.955, \"y\": 3.225}, {\"title\": \"Referral Augmentation for Zero-Shot Information Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.53, \"y\": 5.155}, {\"title\": \"Pento-DIARef: A Diagnostic Dataset for Learning the Incremental  Algorithm for Referring Expression Generation from Examples\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.447, \"y\": 8.514}, {\"title\": \"Eliciting the Translation Ability of Large Language Models via  Multilingual Finetuning with Translation Instructions\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.351, \"y\": 4.208}, {\"title\": \"Visually-Situated Natural Language Understanding with Contrastive  Reading Model and Frozen Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.308, \"y\": 7.136}, {\"title\": \"HuatuoGPT, towards Taming Language Model to Be a Doctor\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.594, \"y\": 8.172}, {\"title\": \"Have LLMs Advanced Enough? A Challenging Problem Solving Benchmark For  Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.527, \"y\": 3.195}, {\"title\": \"Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs  without Fine-tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.952, \"y\": 2.466}, {\"title\": \"AutoPlan: Automatic Planning of Interactive Decision-Making Tasks With  Large Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.801, \"y\": 2.422}, {\"title\": \"Lawyer LLaMA Technical Report\", \"topic\": \"Legal NLP\", \"x\": 5.29, \"y\": 5.408}, {\"title\": \"Reasoning over Hierarchical Question Decomposition Tree for Explainable  Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.601, \"y\": 5.416}, {\"title\": \"Ghostbuster: Detecting Text Ghostwritten by Large Language Models\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.227, \"y\": 4.645}, {\"title\": \"Is Summary Useful or Not? An Extrinsic Human Evaluation of Text  Summaries on Downstream Tasks\", \"topic\": \"Text Summarization\", \"x\": 5.527, \"y\": 6.262}, {\"title\": \"Self-ICL: Zero-Shot In-Context Learning with Self-Generated  Demonstrations\", \"topic\": \"In-Context Learning\", \"x\": 8.226, \"y\": 3.447}, {\"title\": \"How to Distill your BERT: An Empirical Study on the Impact of Weight  Initialisation and Distillation Objectives\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.548, \"y\": 3.796}, {\"title\": \"ImageNetVC: Zero- and Few-Shot Visual Commonsense Evaluation on 1000  ImageNet Categories\", \"topic\": \"Multimodal Language Models\", \"x\": 8.513, \"y\": 7.692}, {\"title\": \"Dior-CVAE: Pre-trained Language Models and Diffusion Priors for  Variational Dialog Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.663, \"y\": 4.033}, {\"title\": \"An Efficient Multilingual Language Model Compression through Vocabulary  Trimming\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.416, \"y\": 4.311}, {\"title\": \"Calc-X and Calcformers: Empowering Arithmetical Chain-of-Thought through  Interaction with Symbolic Systems\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.153, \"y\": 2.648}, {\"title\": \"Injecting Knowledge into Biomedical Pre-trained Models via Polymorphism  and Synonymous Substitution\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.443, \"y\": 7.675}, {\"title\": \"Sentiment Analysis in the Era of Large Language Models: A Reality Check\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.492, \"y\": 6.634}, {\"title\": \"LLMDet: A Third Party Large Language Models Generated Text Detection  Tool\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.083, \"y\": 4.619}, {\"title\": \"The Art of SOCRATIC QUESTIONING: Recursive Thinking with Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.585, \"y\": 2.264}, {\"title\": \"An Examination of the Robustness of Reference-Free Image Captioning  Evaluation Metrics\", \"topic\": \"Multimodal Language Models\", \"x\": 9.088, \"y\": 7.429}, {\"title\": \"Enabling and Analyzing How to Efficiently Extract Information from  Hybrid Long Documents with LLMs\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.964, \"y\": 6.843}, {\"title\": \"RefGPT: Dialogue Generation of GPT, by GPT, and for GPT\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.576, \"y\": 3.92}, {\"title\": \"Reasoning with Language Model is Planning with World Model\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.358, \"y\": 2.716}, {\"title\": \"MuLER: Detailed and Scalable Reference-based Evaluation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.763, \"y\": 4.791}, {\"title\": \"Improving Empathetic Dialogue Generation by Dynamically Infusing  Commonsense Knowledge\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.651, \"y\": 7.889}, {\"title\": \"IdealGPT: Iteratively Decomposing Vision and Language Reasoning via  Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.499, \"y\": 7.707}, {\"title\": \"Improving Factuality of Abstractive Summarization without Sacrificing  Summary Quality\", \"topic\": \"Text Summarization\", \"x\": 5.513, \"y\": 6.174}, {\"title\": \"OverPrompt: Enhancing ChatGPT through Efficient In-Context Learning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.673, \"y\": 3.33}, {\"title\": \"Tricking LLMs into Disobedience: Formalizing, Analyzing, and Detecting  Jailbreaks\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.336, \"y\": 2.255}, {\"title\": \"Detecting Multidimensional Political Incivility on Social Media\", \"topic\": \"Fake News Detection\", \"x\": 3.442, \"y\": 5.65}, {\"title\": \"Cross-lingual Data Augmentation for Document-grounded Dialog Systems in  Low Resource Languages\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.775, \"y\": 3.922}, {\"title\": \"GRACE: Discriminator-Guided Chain-of-Thought Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.727, \"y\": 2.221}, {\"title\": \"Universal Self-Adaptive Prompting\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.343, \"y\": 3.316}, {\"title\": \"Frugal Prompting for Dialog Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.074, \"y\": 3.208}, {\"title\": \"PURR: Efficiently Editing Language Model Hallucinations by Denoising  Language Model Corruptions\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.3, \"y\": 1.158}, {\"title\": \"Coverage-based Example Selection for In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.186, \"y\": 3.372}, {\"title\": \"M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box  Machine-Generated Text Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.015, \"y\": 4.869}, {\"title\": \"Text encoders bottleneck compositionality in contrastive vision-language  models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.972, \"y\": 7.264}, {\"title\": \"InterFormer: Interactive Local and Global Features Fusion for Automatic  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.249, \"y\": 5.083}, {\"title\": \"Dynamic Clue Bottlenecks: Towards Interpretable-by-Design Visual  Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.23, \"y\": 7.996}, {\"title\": \"Leveraging GPT-4 for Automatic Translation Post-Editing\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.732, \"y\": 4.418}, {\"title\": \"Improving Probability-based Prompt Selection Through Unified Evaluation  and Analysis\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.351, \"y\": 3.277}, {\"title\": \"BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual  Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.328, \"y\": 4.727}, {\"title\": \"Meta-learning For Vision-and-language Cross-lingual Transfer\", \"topic\": \"Multimodal Language Models\", \"x\": 8.655, \"y\": 7.022}, {\"title\": \"Exploring Sentiment Analysis Techniques in Natural Language Processing:  A Comprehensive Review\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.588, \"y\": 6.601}, {\"title\": \"PaCE: Unified Multi-modal Dialogue Pre-training with Progressive and  Compositional Experts\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.625, \"y\": 4.144}, {\"title\": \"ComSL: A Composite Speech-Language Model for End-to-End Speech-to-Text  Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.354, \"y\": 5.222}, {\"title\": \"SummIt: Iterative Text Summarization via ChatGPT\", \"topic\": \"Text Summarization\", \"x\": 5.534, \"y\": 6.254}, {\"title\": \"Machine Reading Comprehension using Case-based Reasoning\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.532, \"y\": 5.29}, {\"title\": \"AWESOME: GPU Memory-constrained Long Document Summarization using Memory  Mechanism and Global Salient Content\", \"topic\": \"Text Summarization\", \"x\": 5.595, \"y\": 6.305}, {\"title\": \"Estimating Large Language Model Capabilities without Labeled Test Data\", \"topic\": \"In-Context Learning\", \"x\": 8.1, \"y\": 3.504}, {\"title\": \"Anthropomorphization of AI: Opportunities and Risks\", \"topic\": \"Bias in Language Models\", \"x\": 4.574, \"y\": 3.858}, {\"title\": \"UniChart: A Universal Vision-language Pretrained Model for Chart  Comprehension and Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.894, \"y\": 7.789}, {\"title\": \"Bi-Drop: Enhancing Fine-tuning Generalization via Synchronous sub-net  Estimation and Optimization\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.028, \"y\": 2.568}, {\"title\": \"Trusting Your Evidence: Hallucinate Less with Context-aware Decoding\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.373, \"y\": 1.321}, {\"title\": \"In-Context Demonstration Selection with Cross Entropy Difference\", \"topic\": \"In-Context Learning\", \"x\": 8.273, \"y\": 3.37}, {\"title\": \"I Spy a Metaphor: Large Language Models and Diffusion Models Co-Create  Visual Metaphors\", \"topic\": \"Multimodal Language Models\", \"x\": 8.653, \"y\": 7.07}, {\"title\": \"CuRIAM: Corpus re Interpretation and Metalanguage in U.S. Supreme Court  Opinions\", \"topic\": \"Legal NLP\", \"x\": 5.165, \"y\": 5.743}, {\"title\": \"Leftover Lunch: Advantage-based Offline Reinforcement Learning for  Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.236, \"y\": 1.491}, {\"title\": \"Gender Biases in Automatic Evaluation Metrics for Image Captioning\", \"topic\": \"Bias in Language Models\", \"x\": 3.144, \"y\": 4.391}, {\"title\": \"ExpertPrompting: Instructing Large Language Models to be Distinguished  Experts\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.054, \"y\": 3.087}, {\"title\": \"Segmented Recurrent Transformer: An Efficient Sequence-to-Sequence Model\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.955, \"y\": 3.361}, {\"title\": \"TACR: A Table-alignment-based Cell-selection and Reasoning Model for  Hybrid Question-Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.631, \"y\": 5.365}, {\"title\": \"GRILL: Grounded Vision-language Pre-training via Aligning Text and Image  Regions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.721, \"y\": 7.305}, {\"title\": \"Denoising Bottleneck with Mutual Information Maximization for Video  Multimodal Fusion\", \"topic\": \"Multimodal Language Models\", \"x\": 8.405, \"y\": 7.501}, {\"title\": \"Scientific Opinion Summarization: Paper Meta-review Generation Dataset,  Methods, and Evaluation\", \"topic\": \"Text Summarization\", \"x\": 5.353, \"y\": 6.226}, {\"title\": \"CMOT: Cross-modal Mixup via Optimal Transport for Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.323, \"y\": 5.294}, {\"title\": \"Exploring Affordance and Situated Meaning in Image Captions: A  Multimodal Analysis\", \"topic\": \"Multimodal Language Models\", \"x\": 8.605, \"y\": 7.287}, {\"title\": \"This Land is {Your, My} Land: Evaluating Geopolitical Biases in Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.654, \"y\": 4.373}, {\"title\": \"Voices of Her: Analyzing Gender Differences in the AI Publication World\", \"topic\": \"Bias in Language Models\", \"x\": 3.283, \"y\": 4.464}, {\"title\": \"RE$^2$: Region-Aware Relation Extraction from Visually Rich Documents\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.04, \"y\": 6.808}, {\"title\": \"Evaluating OpenAI's Whisper ASR for Punctuation Prediction and Topic  Modeling of life histories of the Museum of the Person\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.158, \"y\": 5.489}, {\"title\": \"Parameter-Efficient Language Model Tuning with Active Learning in  Low-Resource Settings\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.934, \"y\": 2.422}, {\"title\": \"Detecting and Mitigating Indirect Stereotypes in Word Embeddings\", \"topic\": \"Bias in Language Models\", \"x\": 3.254, \"y\": 4.519}, {\"title\": \"All Roads Lead to Rome? Exploring the Invariance of Transformers'  Representations\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.409, \"y\": 3.581}, {\"title\": \"Sources of Hallucination by Large Language Models on Inference Tasks\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.255, \"y\": 1.214}, {\"title\": \"On the Transferability of Whisper-based Representations for  \\\"In-the-Wild\\\" Cross-Task Downstream Speech Applications\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.085, \"y\": 5.003}, {\"title\": \"Cascaded Beam Search: Plug-and-Play Terminology-Forcing For Neural  Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.981, \"y\": 4.316}, {\"title\": \"How to Choose How to Choose Your Chatbot: A Massively Multi-System  MultiReference Data Set for Dialog Metric Evaluation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.021, \"y\": 3.67}, {\"title\": \"RetICL: Sequential Retrieval of In-Context Examples with Reinforcement  Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.157, \"y\": 3.33}, {\"title\": \"Self-Polish: Enhance Reasoning in Large Language Models via Problem  Refinement\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.713, \"y\": 2.467}, {\"title\": \"Do prompt positions really matter?\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.371, \"y\": 3.266}, {\"title\": \"FOCUS: Effective Embedding Initialization for Monolingual Specialization  of Multilingual Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.35, \"y\": 4.347}, {\"title\": \"CGCE: A Chinese Generative Chat Evaluation Benchmark for General and  Financial Domains\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.622, \"y\": 4.979}, {\"title\": \"Run Like a Girl! Sports-Related Gender Bias in Language and Vision\", \"topic\": \"Bias in Language Models\", \"x\": 3.222, \"y\": 4.372}, {\"title\": \"Domain-Expanded ASTE: Rethinking Generalization in Aspect Sentiment  Triplet Extraction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.116, \"y\": 6.83}, {\"title\": \"Automatic Model Selection with Large Language Models for Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.683, \"y\": 2.362}, {\"title\": \"DirecT2V: Large Language Models are Frame-Level Directors for Zero-Shot  Text-to-Video Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 9.002, \"y\": 7.507}, {\"title\": \"Dynosaur: A Dynamic Growth Paradigm for Instruction-Tuning Data Curation\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.291, \"y\": 2.353}, {\"title\": \"Ties Matter: Meta-Evaluating Modern Metrics with Pairwise Accuracy and  Tie Calibration\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.767, \"y\": 4.719}, {\"title\": \"ChatCoT: Tool-Augmented Chain-of-Thought Reasoning on Chat-based Large  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.487, \"y\": 2.436}, {\"title\": \"Navigating Prompt Complexity for Zero-Shot Classification: A Study of  Large Language Models in Computational Social Science\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.164, \"y\": 3.592}, {\"title\": \"Evaluation of African American Language Bias in Natural Language  Generation\", \"topic\": \"Bias in Language Models\", \"x\": 3.389, \"y\": 4.395}, {\"title\": \"LLM-powered Data Augmentation for Enhanced Cross-lingual Performance\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.062, \"y\": 4.246}, {\"title\": \"Query Rewriting for Retrieval-Augmented Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.217, \"y\": 4.587}, {\"title\": \"Weakly-Supervised Learning of Visual Relations in Multimodal Pretraining\", \"topic\": \"Multimodal Language Models\", \"x\": 8.456, \"y\": 7.154}, {\"title\": \"Multilingual Pixel Representations for Translation and Effective  Cross-lingual Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.392, \"y\": 4.929}, {\"title\": \"Language Models with Rationality\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.372, \"y\": 2.768}, {\"title\": \"Modeling Empathic Similarity in Personal Narratives\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.718, \"y\": 7.86}, {\"title\": \"Revisiting Machine Translation for Cross-lingual Classification\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.562, \"y\": 4.778}, {\"title\": \"On Learning to Summarize with Large Language Models as References\", \"topic\": \"Text Summarization\", \"x\": 5.605, \"y\": 6.139}, {\"title\": \"HOP, UNION, GENERATE: Explainable Multi-hop Reasoning without Rationale  Supervision\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.44, \"y\": 5.357}, {\"title\": \"Multilingual Large Language Models Are Not (Yet) Code-Switchers\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.092, \"y\": 4.443}, {\"title\": \"Exploring Representational Disparities Between Multilingual and  Bilingual Translation Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.207, \"y\": 4.85}, {\"title\": \"ManiTweet: A New Benchmark for Identifying Manipulation of News on  Social Media\", \"topic\": \"Fake News Detection\", \"x\": 4.03, \"y\": 5.929}, {\"title\": \"mmT5: Modular Multilingual Pre-Training Solves Source Language  Hallucinations\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.516, \"y\": 4.803}, {\"title\": \"Exploring Chain-of-Thought Style Prompting for Text-to-SQL\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.744, \"y\": 2.294}, {\"title\": \"Towards Graph-hop Retrieval and Reasoning in Complex Question Answering  over Textual Database\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.781, \"y\": 5.591}, {\"title\": \"Fine-tuned LLMs Know More, Hallucinate Less with Few-Shot  Sequence-to-Sequence Semantic Parsing over Wikidata\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.835, \"y\": 5.326}, {\"title\": \"Accessing Higher Dimensions for Unsupervised Word Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.674, \"y\": 4.912}, {\"title\": \"Beyond Shared Vocabulary: Increasing Representational Word Similarities  across Languages for Multilingual Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.565, \"y\": 4.902}, {\"title\": \"In-Context Probing: Toward Building Robust Classifiers via Probing Large  Language Models\", \"topic\": \"In-Context Learning\", \"x\": 8.366, \"y\": 3.424}, {\"title\": \"Label Words are Anchors: An Information Flow Perspective for  Understanding In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.391, \"y\": 3.271}, {\"title\": \"Dr.ICL: Demonstration-Retrieved In-context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.25, \"y\": 3.379}, {\"title\": \"To Copy Rather Than Memorize: A Vertical Learning Paradigm for Knowledge  Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.089, \"y\": 6.042}, {\"title\": \"When Does Monolingual Data Help Multilingual Translation: The Role of  Domain and Model Scale\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.646, \"y\": 4.57}, {\"title\": \"BM25 Query Augmentation Learned End-to-End\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.426, \"y\": 5.023}, {\"title\": \"How to Solve Few-Shot Abusive Content Detection Using the Data We  Actually Have\", \"topic\": \"Hate Speech Detection\", \"x\": 2.747, \"y\": 5.466}, {\"title\": \"Disentangled Variational Autoencoder for Emotion Recognition in  Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.268, \"y\": 7.806}, {\"title\": \"One-stop Training of Multiple Capacity Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.671, \"y\": 4.452}, {\"title\": \"Can Language Models Understand Physical Concepts?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.506, \"y\": 7.513}, {\"title\": \"Rethinking Speech Recognition with A Multimodal Perspective via Acoustic  and Semantic Cooperative Decoding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.13, \"y\": 5.227}, {\"title\": \"The CoT Collection: Improving Zero-shot and Few-shot Learning of  Language Models via Chain-of-Thought Fine-Tuning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.969, \"y\": 2.207}, {\"title\": \"Improving speech translation by fusing speech and text\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.116, \"y\": 5.221}, {\"title\": \"Target-Agnostic Gender-Aware Contrastive Learning for Mitigating Bias in  Multilingual Machine Translation\", \"topic\": \"Bias in Language Models\", \"x\": 3.009, \"y\": 4.393}, {\"title\": \"When your Cousin has the Right Connections: Unsupervised Bilingual  Lexicon Induction for Related Data-Imbalanced Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.388, \"y\": 4.859}, {\"title\": \"IfQA: A Dataset for Open-domain Question Answering under Counterfactual  Presuppositions\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.385, \"y\": 5.196}, {\"title\": \"When Does Aggregating Multiple Skills with Multi-Task Learning Work? A  Case Study in Financial NLP\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.068, \"y\": 6.669}, {\"title\": \"S\\u0101mayik: A Benchmark and Dataset for English-Sanskrit Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.564, \"y\": 5.208}, {\"title\": \"Condensing Multilingual Knowledge with Lightweight Language-Specific  Modules\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.579, \"y\": 4.486}, {\"title\": \"Make a Choice! Knowledge Base Question Answering with In-Context  Learning\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.591, \"y\": 5.356}, {\"title\": \"Robust Prompt Optimization for Large Language Models Against  Distribution Shifts\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.33, \"y\": 3.188}, {\"title\": \"DetectLLM: Leveraging Log Rank Information for Zero-Shot Detection of  Machine-Generated Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.082, \"y\": 4.764}, {\"title\": \"EfficientSpeech: An On-Device Text to Speech Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.777, \"y\": 5.739}, {\"title\": \"Let's Think Frame by Frame with VIP: A Video Infilling and Prediction  Dataset for Evaluating Video Chain-of-Thought\", \"topic\": \"Multimodal Language Models\", \"x\": 8.728, \"y\": 7.945}, {\"title\": \"PaD: Program-aided Distillation Can Teach Small Models Reasoning Better  than Chain-of-thought Fine-tuning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.036, \"y\": 2.355}, {\"title\": \"A Trip Towards Fairness: Bias and De-Biasing in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.347, \"y\": 4.188}, {\"title\": \"Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.305, \"y\": 2.225}, {\"title\": \"Revealing User Familiarity Bias in Task-Oriented Dialogue via  Interactive Evaluation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.253, \"y\": 3.708}, {\"title\": \"Global Structure Knowledge-Guided Relation Extraction Method for  Visually-Rich Document\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.043, \"y\": 6.82}, {\"title\": \"ZET-Speech: Zero-shot adaptive Emotion-controllable Text-to-Speech  Synthesis with Diffusion and Style-based Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.613, \"y\": 6.016}, {\"title\": \"\\\"Is the Pope Catholic?\\\" Applying Chain-of-Thought Reasoning to  Understanding Conversational Implicatures\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.576, \"y\": 2.416}, {\"title\": \"Detecting automatically the layout of clinical documents to enhance the  performances of downstream natural language processing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.726, \"y\": 7.725}, {\"title\": \"Coarse-to-Fine Contrastive Learning in Image-Text-Graph Space for  Improved Vision-Language Compositionality\", \"topic\": \"Multimodal Language Models\", \"x\": 8.59, \"y\": 6.982}, {\"title\": \"Asking Clarification Questions to Handle Ambiguity in Open-Domain QA\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.333, \"y\": 4.843}, {\"title\": \"Towards Zero-shot Relation Extraction in Web Mining: A Multimodal  Approach with Relative XML Path\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.962, \"y\": 6.727}, {\"title\": \"Personalized Predictive ASR for Latency Reduction in Voice Assistants\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.229, \"y\": 5.203}, {\"title\": \"Images in Language Space: Exploring the Suitability of Large Language  Models for Vision & Language Tasks\", \"topic\": \"Multimodal Language Models\", \"x\": 8.389, \"y\": 7.573}, {\"title\": \"Counterspeeches up my sleeve! Intent Distribution Learning and  Persistent Fusion for Intent-Conditioned Counterspeech Generation\", \"topic\": \"Hate Speech Detection\", \"x\": 2.713, \"y\": 5.314}, {\"title\": \"Concept-aware Training Improves In-context Learning Ability of Language  Models\", \"topic\": \"In-Context Learning\", \"x\": 8.326, \"y\": 3.432}, {\"title\": \"Challenges in Context-Aware Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.811, \"y\": 4.319}, {\"title\": \"Goal-Driven Explainable Clustering via Language Descriptions\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.901, \"y\": 3.916}, {\"title\": \"TeCS: A Dataset and Benchmark for Tense Consistency of Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.883, \"y\": 4.7}, {\"title\": \"i-Code Studio: A Configurable and Composable Framework for Integrative  AI\", \"topic\": \"Multimodal Language Models\", \"x\": 8.261, \"y\": 7.213}, {\"title\": \"Aligning Large Language Models through Synthetic Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.276, \"y\": 1.402}, {\"title\": \"Discrete Prompt Optimization via Constrained Generation for Zero-shot  Re-ranker\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.416, \"y\": 3.425}, {\"title\": \"Conversational Recommendation as Retrieval: A Simple, Strong Baseline\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.919, \"y\": 3.043}, {\"title\": \"ChatGPT-EDSS: Empathetic Dialogue Speech Synthesis Trained from  ChatGPT-derived Context Word Embeddings\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.516, \"y\": 7.93}, {\"title\": \"Continual Dialogue State Tracking via Example-Guided Question Answering\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.746, \"y\": 3.875}, {\"title\": \"Exploring Self-supervised Logic-enhanced Training for Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.76, \"y\": 2.91}, {\"title\": \"BA-SOT: Boundary-Aware Serialized Output Training for Multi-Talker ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.155, \"y\": 5.139}, {\"title\": \"CALLS: Japanese Empathetic Dialogue Speech Corpus of Complaint Handling  and Attentive Listening in Customer Center\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.449, \"y\": 7.839}, {\"title\": \"Using Textual Interface to Align External Knowledge for End-to-End  Task-Oriented Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.546, \"y\": 3.917}, {\"title\": \"MemeCap: A Dataset for Captioning and Interpreting Memes\", \"topic\": \"Multimodal Language Models\", \"x\": 8.862, \"y\": 7.576}, {\"title\": \"UNIMO-3: Multi-granularity Interaction for Vision-Language  Representation Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.475, \"y\": 7.333}, {\"title\": \"Abstractive Text Summarization Using the BRIO Training Paradigm\", \"topic\": \"Text Summarization\", \"x\": 5.575, \"y\": 6.328}, {\"title\": \"Automated Metrics for Medical Multi-Document Summarization Disagree with  Human Evaluations\", \"topic\": \"Text Summarization\", \"x\": 5.454, \"y\": 6.302}, {\"title\": \"Training Priors Predict Text-To-Image Model Performance\", \"topic\": \"Multimodal Language Models\", \"x\": 8.798, \"y\": 6.842}, {\"title\": \"mPLM-Sim: Better Cross-Lingual Similarity and Transfer in Multilingual  Pretrained Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.429, \"y\": 4.765}, {\"title\": \"Towards Legally Enforceable Hate Speech Detection for Public Forums\", \"topic\": \"Hate Speech Detection\", \"x\": 2.752, \"y\": 5.313}, {\"title\": \"Prompt-Based Monte-Carlo Tree Search for Goal-Oriented Dialogue Policy  Planning\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.512, \"y\": 3.436}, {\"title\": \"ChatGPT as your Personal Data Scientist\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.315, \"y\": 3.71}, {\"title\": \"Cross-lingual Knowledge Transfer and Iterative Pseudo-labeling for  Low-Resource Speech Recognition with Transducers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.034, \"y\": 5.342}, {\"title\": \"Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.91, \"y\": 4.196}, {\"title\": \"Regex-augmented Domain Transfer Topic Classification based on a  Pre-trained Language Model: An application in Financial Domain\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.05, \"y\": 6.824}, {\"title\": \"Detecting and Mitigating Hallucinations in Multilingual Summarisation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.135, \"y\": 1.114}, {\"title\": \"InstructAlign: High-and-Low Resource Language Alignment via Continual  Crosslingual Instruction Tuning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.337, \"y\": 4.325}, {\"title\": \"Prompting and Evaluating Large Language Models for Proactive Dialogues:  Clarification, Target-guided, and Non-collaboration\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.527, \"y\": 3.527}, {\"title\": \"Understanding Programs by Exploiting (Fuzzing) Test Cases\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.42, \"y\": 2.332}, {\"title\": \"Query Structure Modeling for Inductive Logical Reasoning Over Knowledge  Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.925, \"y\": 5.451}, {\"title\": \"Cross-Attention is Not Enough: Incongruity-Aware Dynamic Hierarchical  Fusion for Multimodal Affect Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.117, \"y\": 7.636}, {\"title\": \"Translation and Fusion Improves Zero-shot Cross-lingual Information  Extraction\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.367, \"y\": 4.966}, {\"title\": \"Latent Positional Information is in the Self-Attention Variance of  Transformer Language Models Without Positional Embeddings\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.362, \"y\": 3.658}, {\"title\": \"ReWOO: Decoupling Reasoning from Observations for Efficient Augmented  Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.85, \"y\": 2.734}, {\"title\": \"How Fragile is Relation Extraction under Entity Replacements?\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.896, \"y\": 6.77}, {\"title\": \"How Language Model Hallucinations Can Snowball\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.127, \"y\": 1.161}, {\"title\": \"Open-world Semi-supervised Generalized Relation Discovery Aligned in a  Real-world Setting\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.009, \"y\": 6.773}, {\"title\": \"Transfer-Free Data-Efficient Multilingual Slot Labeling\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.413, \"y\": 4.927}, {\"title\": \"A Study of Generative Large Language Model for Medical Research and  Healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.673, \"y\": 8.06}, {\"title\": \"Scaling Speech Technology to 1,000+ Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.9, \"y\": 5.264}, {\"title\": \"Neural Machine Translation for Code Generation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.718, \"y\": 4.354}, {\"title\": \"Automatic Readability Assessment for Closely Related Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.931, \"y\": 5.173}, {\"title\": \"Clembench: Using Game Play to Evaluate Chat-Optimized Language Models as  Conversational Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.425, \"y\": 3.106}, {\"title\": \"VISIT: Visualizing and Interpreting the Semantic Information Flow of  Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.526, \"y\": 3.557}, {\"title\": \"Element-aware Summarization with Large Language Models: Expert-aligned  Evaluation and Chain-of-Thought Method\", \"topic\": \"Text Summarization\", \"x\": 5.565, \"y\": 6.209}, {\"title\": \"Modular Domain Adaptation for Conformer-Based Streaming ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.274, \"y\": 4.99}, {\"title\": \"Text Generation with Speech Synthesis for ASR Data Augmentation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.868, \"y\": 5.627}, {\"title\": \"BioDEX: Large-Scale Biomedical Adverse Drug Event Extraction for  Real-World Pharmacovigilance\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.55, \"y\": 7.783}, {\"title\": \"Language-Agnostic Bias Detection in Language Models with Bias Probing\", \"topic\": \"Bias in Language Models\", \"x\": 3.4, \"y\": 4.39}, {\"title\": \"Measuring Inductive Biases of In-Context Learning with Underspecified  Demonstrations\", \"topic\": \"In-Context Learning\", \"x\": 8.434, \"y\": 3.388}, {\"title\": \"DiffusionNER: Boundary Diffusion for Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.42, \"y\": 6.828}, {\"title\": \"Investigating the Role of Feed-Forward Networks in Transformers Using  Parallel Attention and Feed-Forward Net Design\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.781, \"y\": 3.332}, {\"title\": \"AlpacaFarm: A Simulation Framework for Methods that Learn from Human  Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.408, \"y\": 1.789}, {\"title\": \"Fairness of ChatGPT\", \"topic\": \"Bias in Language Models\", \"x\": 3.545, \"y\": 4.177}, {\"title\": \"How do languages influence each other? Studying cross-lingual data  sharing during LM fine-tuning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.115, \"y\": 4.499}, {\"title\": \"Evaluating ChatGPT's Performance for Multilingual and Emoji-based Hate  Speech Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.7, \"y\": 5.339}, {\"title\": \"Let GPT be a Math Tutor: Teaching Math Word Problem Solvers with  Customized Exercise Generation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.967, \"y\": 2.858}, {\"title\": \"Enhance Reasoning Ability of Visual-Language Models via Large Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.357, \"y\": 7.813}, {\"title\": \"MAGE: Machine-generated Text Detection in the Wild\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.055, \"y\": 4.767}, {\"title\": \"SPARSEFIT: Few-shot Prompting with Sparse Fine-tuning for Jointly  Generating Predictions and Natural Language Explanations\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.492, \"y\": 3.255}, {\"title\": \"Preconditioned Visual Language Inference with Weak Supervision\", \"topic\": \"Multimodal Language Models\", \"x\": 8.392, \"y\": 7.686}, {\"title\": \"Multi-Task Instruction Tuning of LLaMa for Specific Scenarios: A  Preliminary Study on Writing Assistance\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.154, \"y\": 2.355}, {\"title\": \"Improving Isochronous Machine Translation with Target Factors and  Auxiliary Counters\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.333, \"y\": 5.095}, {\"title\": \"Knowledge-Retrieval Task-Oriented Dialog Systems with Semi-Supervision\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.778, \"y\": 4.075}, {\"title\": \"Multilingual Holistic Bias: Extending Descriptors and Patterns to Unveil  Demographic Biases in Languages at Scale\", \"topic\": \"Bias in Language Models\", \"x\": 3.229, \"y\": 4.514}, {\"title\": \"SEAHORSE: A Multilingual, Multifaceted Dataset for Summarization  Evaluation\", \"topic\": \"Text Summarization\", \"x\": 5.636, \"y\": 6.298}, {\"title\": \"Taxonomy Expansion for Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.218, \"y\": 6.899}, {\"title\": \"Teaching Probabilistic Logical Reasoning to Transformers\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.769, \"y\": 2.87}, {\"title\": \"Better Sampling of Negatives for Distantly Supervised Named Entity  Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.362, \"y\": 6.751}, {\"title\": \"Extrapolating Multilingual Understanding Models as Multilingual  Generators\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.786, \"y\": 4.609}, {\"title\": \"EMNS /Imz/ Corpus: An emotive single-speaker dataset for narrative  storytelling in games, television and graphic novels\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.268, \"y\": 7.818}, {\"title\": \"Partial Annotation Learning for Biomedical Entity Recognition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.507, \"y\": 7.396}, {\"title\": \"Rethinking the Evaluation for Conversational Recommendation in the Era  of Large Language Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.03, \"y\": 3.124}, {\"title\": \"Debiased Automatic Speech Recognition for Dysarthric Speech via Sample  Reweighting with Sample Affinity Test\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.341, \"y\": 5.524}, {\"title\": \"Cognitive network science reveals bias in GPT-3, ChatGPT, and GPT-4  mirroring math anxiety in high-school students\", \"topic\": \"Bias in Language Models\", \"x\": 3.527, \"y\": 4.304}, {\"title\": \"Observations on LLMs for Telecom Domain: Capabilities and Limitations\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.382, \"y\": 3.989}, {\"title\": \"Improved Compositional Generalization by Generating Demonstrations for  Meta-Learning\", \"topic\": \"In-Context Learning\", \"x\": 7.943, \"y\": 3.509}, {\"title\": \"Should We Attend More or Less? Modulating Attention for Fairness\", \"topic\": \"Bias in Language Models\", \"x\": 3.321, \"y\": 4.267}, {\"title\": \"InheritSumm: A General, Versatile and Compact Summarizer by Distilling  from GPT\", \"topic\": \"Text Summarization\", \"x\": 5.582, \"y\": 6.266}, {\"title\": \"An Abstract Specification of VoxML as an Annotation Language\", \"topic\": \"Multimodal Language Models\", \"x\": 8.623, \"y\": 7.35}, {\"title\": \"Machine-Created Universal Language for Cross-lingual Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.491, \"y\": 4.887}, {\"title\": \"Distilling Robustness into Natural Language Inference Models with  Domain-Targeted Augmentation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.462, \"y\": 3.846}, {\"title\": \"Biomedical Named Entity Recognition via Dictionary-based Synonym  Generalization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.378, \"y\": 7.563}, {\"title\": \"Federated Learning of Medical Concepts Embedding using BEHRT\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.047, \"y\": 8.165}, {\"title\": \"RWKV: Reinventing RNNs for the Transformer Era\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.82, \"y\": 3.281}, {\"title\": \"Automated stance detection in complex topics and small languages: the  challenging case of immigration in polarizing news media\", \"topic\": \"Fake News Detection\", \"x\": 3.451, \"y\": 5.876}, {\"title\": \"SpokenWOZ: A Large-Scale Speech-Text Benchmark for Spoken Task-Oriented  Dialogue Agents\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.47, \"y\": 3.724}, {\"title\": \"Nearest Neighbor Machine Translation is Meta-Optimizer on Output  Projection Layer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.842, \"y\": 4.285}, {\"title\": \"Iterative Forward Tuning Boosts In-Context Learning in Language Models\", \"topic\": \"In-Context Learning\", \"x\": 8.269, \"y\": 3.253}, {\"title\": \"3D Rotation and Translation for Hyperbolic Knowledge Graph Embedding\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.277, \"y\": 6.034}, {\"title\": \"Textually Pretrained Speech Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.772, \"y\": 5.35}, {\"title\": \"MaNtLE: Model-agnostic Natural Language Explainer\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.827, \"y\": 3.817}, {\"title\": \"ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist  Examination\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.897, \"y\": 7.784}, {\"title\": \"Exploring Speaker-Related Information in Spoken Language Understanding  for Better Speaker Diarization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.816, \"y\": 5.659}, {\"title\": \"EnCore: Fine-Grained Entity Typing by Pre-Training Entity Encoders on  Coreference Chains\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.371, \"y\": 6.623}, {\"title\": \"Meta-in-context learning in large language models\", \"topic\": \"In-Context Learning\", \"x\": 8.656, \"y\": 3.305}, {\"title\": \"Non-Autoregressive Document-Level Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.109, \"y\": 4.513}, {\"title\": \"Lion: Adversarial Distillation of Proprietary Large Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.507, \"y\": 3.835}, {\"title\": \"Enhancing Coherence of Extractive Summarization with Multitask Learning\", \"topic\": \"Text Summarization\", \"x\": 5.738, \"y\": 6.23}, {\"title\": \"CopyNE: Better Contextual ASR by Copying Named Entities\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.296, \"y\": 5.081}, {\"title\": \"On Bias and Fairness in NLP: Investigating the Impact of Bias and  Debiasing in Language Models on the Fairness of Toxicity Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.098, \"y\": 4.264}, {\"title\": \"Crosslingual Transfer Learning for Low-Resource Languages Based on  Multilingual Colexification Graphs\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.393, \"y\": 4.938}, {\"title\": \"Investigating Agency of LLMs in Human-AI Collaboration Tasks\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.284, \"y\": 2.958}, {\"title\": \"Zero-Shot End-to-End Spoken Language Understanding via Cross-Modal  Selective Self-Training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.277, \"y\": 5.131}, {\"title\": \"Mitigating Data Imbalance and Representation Degeneration in  Multilingual Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.785, \"y\": 4.571}, {\"title\": \"Towards Robust Personalized Dialogue Generation via Order-Insensitive  Representation Regularization\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.351, \"y\": 3.807}, {\"title\": \"Evaluating Pragmatic Abilities of Image Captioners on A3DS\", \"topic\": \"Multimodal Language Models\", \"x\": 9.066, \"y\": 7.579}, {\"title\": \"D$^2$TV: Dual Knowledge Distillation and Target-oriented Vision Modeling  for Many-to-Many Multimodal Summarization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.212, \"y\": 7.359}, {\"title\": \"Explaining Emergent In-Context Learning as Kernel Regression\", \"topic\": \"In-Context Learning\", \"x\": 8.608, \"y\": 3.315}, {\"title\": \"Kanbun-LM: Reading and Translating Classical Chinese in Japanese Methods  by Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.372, \"y\": 4.768}, {\"title\": \"This Prompt is Measuring <MASK>: Evaluating Bias Evaluation in Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.312, \"y\": 4.436}, {\"title\": \"GNCformer Enhanced Self-attention for Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.247, \"y\": 5.033}, {\"title\": \"The Best of Both Worlds: Combining Human and Machine Translations for  Multilingual Semantic Parsing with Active Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.583, \"y\": 4.753}, {\"title\": \"Towards Explainable In-the-Wild Video Quality Assessment: A Database and  a Language-Prompted Approach\", \"topic\": \"Multimodal Language Models\", \"x\": 8.616, \"y\": 7.993}, {\"title\": \"Cross-lingual Transfer Can Worsen Bias in Sentiment Analysis\", \"topic\": \"Bias in Language Models\", \"x\": 3.295, \"y\": 4.545}, {\"title\": \"FIT: Far-reaching Interleaved Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.894, \"y\": 3.291}, {\"title\": \"Finding the Pillars of Strength for Multi-Head Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.909, \"y\": 3.173}, {\"title\": \"G3Detector: General GPT-Generated Text Detector\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.073, \"y\": 4.66}, {\"title\": \"Exploring Energy-based Language Models with Different Architectures and  Training Methods for Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.616, \"y\": 4.965}, {\"title\": \"Duplex Diffusion Models Improve Speech-to-Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.558, \"y\": 5.737}, {\"title\": \"MvP: Multi-view Prompting Improves Aspect Sentiment Tuple Prediction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.133, \"y\": 6.884}, {\"title\": \"Keeping Up with the Language Models: Robustness-Bias Interplay in NLI  Data and Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.386, \"y\": 4.324}, {\"title\": \"PrOnto: Language Model Evaluations for 859 Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.484, \"y\": 4.773}, {\"title\": \"Comparison of Multilingual Self-Supervised and Weakly-Supervised Speech  Pre-Training for Adaptation to Unseen Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.777, \"y\": 4.981}, {\"title\": \"Modeling User Satisfaction Dynamics in Dialogue via Hawkes Process\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.32, \"y\": 3.74}, {\"title\": \"Hystoc: Obtaining word confidences for fusion of end-to-end ASR systems\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.193, \"y\": 5.25}, {\"title\": \"Understanding the Effect of Data Augmentation on Knowledge Distillation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.558, \"y\": 3.802}, {\"title\": \"A Symbolic Framework for Evaluating Mathematical Reasoning and  Generalisation with Transformers\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.33, \"y\": 2.975}, {\"title\": \"Explaining How Transformers Use Context to Build Predictions\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.233, \"y\": 3.627}, {\"title\": \"Multilingual Simplification of Medical Texts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.166, \"y\": 7.735}, {\"title\": \"DPIC: Decoupling Prompt and Intrinsic Characteristics for LLM Generated  Text Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.149, \"y\": 4.78}, {\"title\": \"Multi-Head State Space Model for Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.146, \"y\": 4.903}, {\"title\": \"Fair Without Leveling Down: A New Intersectional Fairness Definition\", \"topic\": \"Bias in Language Models\", \"x\": 3.469, \"y\": 4.234}, {\"title\": \"Contextualized End-to-End Speech Recognition with Contextual Phrase  Prediction Network\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.392, \"y\": 5.037}, {\"title\": \"Augmenting Autotelic Agents with Large Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.804, \"y\": 2.38}, {\"title\": \"A Confidence-based Partial Label Learning Model for Crowd-Annotated  Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.296, \"y\": 6.842}, {\"title\": \"Is Translation Helpful? An Empirical Analysis of Cross-Lingual Transfer  in Low-Resource Dialog Generation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.634, \"y\": 4.773}, {\"title\": \"Continually Improving Extractive QA via Human Feedback\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.075, \"y\": 4.914}, {\"title\": \"Self-supervised Predictive Coding Models Encode Speaker and Phonetic  Information in Orthogonal Subspaces\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.67, \"y\": 5.06}, {\"title\": \"Infor-Coef: Information Bottleneck-based Dynamic Token Downsampling for  Compact and Efficient language model\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.558, \"y\": 2.615}, {\"title\": \"BiasAsker: Measuring the Bias in Conversational AI System\", \"topic\": \"Bias in Language Models\", \"x\": 3.401, \"y\": 4.282}, {\"title\": \"EM Pre-training for Multi-party Dialogue Response Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.439, \"y\": 4.085}, {\"title\": \"SHINE: Syntax-augmented Hierarchical Interactive Encoder for Zero-shot  Cross-lingual Information Extraction\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.454, \"y\": 5.146}, {\"title\": \"Measuring Intersectional Biases in Historical Documents\", \"topic\": \"Bias in Language Models\", \"x\": 3.416, \"y\": 4.73}, {\"title\": \"Machine Translation by Projecting Text into the Same  Phonetic-Orthographic Space Using a Common Encoding\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.791, \"y\": 4.988}, {\"title\": \"Task-agnostic Distillation of Encoder-Decoder Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.477, \"y\": 3.786}, {\"title\": \"i-Code V2: An Autoregressive Generation Framework over Vision, Language,  and Speech Data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.553, \"y\": 7.233}, {\"title\": \"Sentence Embedder Guided Utterance Encoder (SEGUE) for Spoken Language  Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.808, \"y\": 4.909}, {\"title\": \"Logic-LM: Empowering Large Language Models with Symbolic Solvers for  Faithful Logical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.671, \"y\": 2.806}, {\"title\": \"Lifelong Language Pretraining with Distribution-Specialized Experts\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.821, \"y\": 2.448}, {\"title\": \"Autoregressive Modeling with Lookahead Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.664, \"y\": 3.386}, {\"title\": \"Self-supervised representations in speech-based depression detection\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.183, \"y\": 7.495}, {\"title\": \"Cross2StrA: Unpaired Cross-lingual Image Captioning with Cross-lingual  Cross-modal Structure-pivoted Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 9.022, \"y\": 7.157}, {\"title\": \"Constructing Code-mixed Universal Dependency Forest for Unbiased  Cross-lingual Relation Extraction\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.367, \"y\": 4.844}, {\"title\": \"SEntFiN 1.0: Entity-Aware Sentiment Analysis for Financial News\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.697, \"y\": 6.819}, {\"title\": \"Scene Graph as Pivoting: Inference-time Image-free Unsupervised  Multimodal Machine Translation with Visual Scene Hallucination\", \"topic\": \"Multimodal Language Models\", \"x\": 8.588, \"y\": 7.045}, {\"title\": \"Brain encoding models based on multimodal transformers can transfer  across language and vision\", \"topic\": \"Multimodal Language Models\", \"x\": 8.242, \"y\": 7.07}, {\"title\": \"A Measure of Explanatory Effectiveness\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.394, \"y\": 3.616}, {\"title\": \"Dynamic Transformers Provide a False Sense of Efficiency\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.15, \"y\": 3.005}, {\"title\": \"Self-Distillation with Meta Learning for Knowledge Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.193, \"y\": 6.025}, {\"title\": \"Pointwise Mutual Information Based Metric and Decoding Strategy for  Faithful Generation in Document Grounded Dialogs\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.635, \"y\": 4.094}, {\"title\": \"Glot500: Scaling Multilingual Corpora and Language Models to 500  Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.006, \"y\": 4.269}, {\"title\": \"LogiCoT: Logical Chain-of-Thought Instruction-Tuning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.745, \"y\": 2.665}, {\"title\": \"Hedges in Bidirectional Translations of Publicity-Oriented Documents\", \"topic\": \"Fake News Detection\", \"x\": 3.734, \"y\": 5.695}, {\"title\": \"Lifting the Curse of Capacity Gap in Distilling Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.408, \"y\": 3.615}, {\"title\": \"EE-TTS: Emphatic Expressive TTS with Linguistic Information\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.425, \"y\": 5.993}, {\"title\": \"\\\"What do others think?\\\": Task-Oriented Conversational Modeling with  Subjective Knowledge\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.331, \"y\": 3.731}, {\"title\": \"UP5: Unbiased Foundation Model for Fairness-aware Recommendation\", \"topic\": \"Bias in Language Models\", \"x\": 3.438, \"y\": 4.2}, {\"title\": \"Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer in  Prompt Tuning\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.75, \"y\": 4.063}, {\"title\": \"DisCo: Distilled Student Models Co-training for Semi-supervised Text  Mining\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.521, \"y\": 3.881}, {\"title\": \"Accurate Knowledge Distillation with n-best Reranking\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.571, \"y\": 3.912}, {\"title\": \"CDJUR-BR -- A Golden Collection of Legal Document from Brazilian Justice  with Fine-Grained Named Entities\", \"topic\": \"Legal NLP\", \"x\": 5.119, \"y\": 5.755}, {\"title\": \"Clinical Camel: An Open Expert-Level Medical Language Model with  Dialogue-Based Knowledge Encoding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.651, \"y\": 8.049}, {\"title\": \"XuanYuan 2.0: A Large Chinese Financial Chat Model with Hundreds of  Billions Parameters\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.894, \"y\": 6.845}, {\"title\": \"Evaluation of medium-large Language Models at zero-shot closed book  generative question answering\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.394, \"y\": 4.145}, {\"title\": \"A Weak Supervision Approach for Few-Shot Aspect Based Sentiment\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.12, \"y\": 6.827}, {\"title\": \"Eye-SpatialNet: Spatial Information Extraction from Ophthalmology Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.184, \"y\": 8.228}, {\"title\": \"Any-to-Any Generation via Composable Diffusion\", \"topic\": \"Multimodal Language Models\", \"x\": 8.57, \"y\": 7.075}, {\"title\": \"SeeGULL: A Stereotype Benchmark with Broad Geo-Cultural Coverage  Leveraging Generative Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.368, \"y\": 4.377}, {\"title\": \"Appraising the Potential Uses and Harms of LLMs for Medical Systematic  Reviews\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.484, \"y\": 7.437}, {\"title\": \"Pseudo-Label Training and Model Inertia in Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.97, \"y\": 4.351}, {\"title\": \"Cue-CoT: Chain-of-thought Prompting for Responding to In-depth Dialogue  Questions with LLMs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.608, \"y\": 2.406}, {\"title\": \"Prompting with Pseudo-Code Instructions\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.234, \"y\": 2.929}, {\"title\": \"Cross-Lingual Supervision improves Large Language Models Pre-training\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.395, \"y\": 4.506}, {\"title\": \"Enhancing Vision-Language Pre-Training with Jointly Learned Questioner  and Dense Captioner\", \"topic\": \"Multimodal Language Models\", \"x\": 8.311, \"y\": 7.815}, {\"title\": \"Generating Visual Spatial Description via Holistic 3D Scene  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.713, \"y\": 7.359}, {\"title\": \"HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large  Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.113, \"y\": 1.049}, {\"title\": \"HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination  and Omission Detection in Machine Translation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.15, \"y\": 1.046}, {\"title\": \"A New Benchmark of Aphasia Speech Recognition and Detection Based on  E-Branchformer and Multi-task Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.078, \"y\": 5.671}, {\"title\": \"S$^3$HQA: A Three-Stage Approach for Multi-hop Text-Table Hybrid  Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.598, \"y\": 5.398}, {\"title\": \"Surgical-VQLA: Transformer with Gated Vision-Language Embedding for  Visual Question Localized-Answering in Robotic Surgery\", \"topic\": \"Multimodal Language Models\", \"x\": 8.108, \"y\": 8.029}, {\"title\": \"Sensing of inspiration events from speech: comparison of deep learning  and linguistic methods\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.088, \"y\": 5.464}, {\"title\": \"MParrotTTS: Multilingual Multi-speaker Text to Speech Synthesis in Low  Resource Setting\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.576, \"y\": 5.688}, {\"title\": \"Bias Beyond English: Counterfactual Tests for Bias in Sentiment Analysis  in Four Languages\", \"topic\": \"Bias in Language Models\", \"x\": 3.249, \"y\": 4.563}, {\"title\": \"Searching by Code: a New SearchBySnippet Dataset and SnippeR Retrieval  Model for Searching by Code Snippets\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.528, \"y\": 2.51}, {\"title\": \"Speech-Text Dialog Pre-training for Spoken Dialog Understanding with  Explicit Cross-Modal Alignment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.391, \"y\": 5.437}, {\"title\": \"Language-universal phonetic encoder for low-resource speech recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.989, \"y\": 5.3}, {\"title\": \"Language-Universal Phonetic Representation in Multilingual Speech  Pretraining for Low-Resource Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.764, \"y\": 5.104}, {\"title\": \"Blank-regularized CTC for Frame Skipping in Neural Transducer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.162, \"y\": 5.006}, {\"title\": \"Viewing Knowledge Transfer in Multilingual Machine Translation Through a  Representational Lens\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.548, \"y\": 4.777}, {\"title\": \"PlugMed: Improving Specificity in Patient-Centered Medical Dialogue  Generation using In-Context Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.747, \"y\": 8.173}, {\"title\": \"A Topic-aware Summarization Framework with Different Modal Side  Information\", \"topic\": \"Text Summarization\", \"x\": 5.402, \"y\": 6.421}, {\"title\": \"RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by  Reversing Chain-of-Thought\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.687, \"y\": 2.377}, {\"title\": \"TreePrompt: Learning to Compose Tree Prompts for Explainable Visual  Grounding\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.556, \"y\": 3.471}, {\"title\": \"Enhancing Personalized Dialogue Generation with Contrastive Latent  Variables: Combining Sparse and Dense Persona\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.172, \"y\": 3.708}, {\"title\": \"Self-Agreement: A Framework for Fine-tuning Language Models to Find  Agreement among Diverse Opinions\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.42, \"y\": 1.832}, {\"title\": \"Shattering the Agent-Environment Interface for Fine-Tuning Inclusive  Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.155, \"y\": 1.676}, {\"title\": \"Analyzing and Reducing the Performance Gap in Cross-Lingual Transfer  with Fine-tuning Slow and Fast\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.39, \"y\": 4.505}, {\"title\": \"Phonetic and Prosody-aware Self-supervised Learning Approach for  Non-native Fluency Scoring\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.961, \"y\": 5.358}, {\"title\": \"Syllable Discovery and Cross-Lingual Generalization in a Visually  Grounded, Self-Supervised Speech Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.617, \"y\": 5.029}, {\"title\": \"TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 6.903, \"y\": 3.31}, {\"title\": \"DUB: Discrete Unit Back-translation for Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.383, \"y\": 5.307}, {\"title\": \"AlignAtt: Using Attention-based Audio-Translation Alignments as a Guide  for Simultaneous Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.299, \"y\": 5.211}, {\"title\": \"Fast-StrucTexT: An Efficient Hourglass Transformer with Modality-guided  Dynamic Token Merge for Document Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.043, \"y\": 7.14}, {\"title\": \"Unsupervised ASR via Cross-Lingual Pseudo-Labeling\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.099, \"y\": 5.238}, {\"title\": \"AutoTrial: Prompting Language Models for Clinical Trial Design\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.776, \"y\": 7.814}, {\"title\": \"Unsupervised Domain-agnostic Fake News Detection using Multi-modal Weak  Signals\", \"topic\": \"Fake News Detection\", \"x\": 4.004, \"y\": 5.836}, {\"title\": \"In the Name of Fairness: Assessing the Bias in Clinical Record  De-identification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.337, \"y\": 7.674}, {\"title\": \"Towards the Automatic Generation of Conversational Interfaces to  Facilitate the Exploration of Tabular Data\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.221, \"y\": 3.943}, {\"title\": \"CHBias: Bias Evaluation and Mitigation of Chinese Conversational  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.411, \"y\": 4.11}, {\"title\": \"Reasoning Implicit Sentiment with Chain-of-Thought Prompting\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.551, \"y\": 2.387}, {\"title\": \"Comparing Biases and the Impact of Multilingual Training across Multiple  Languages\", \"topic\": \"Bias in Language Models\", \"x\": 3.29, \"y\": 4.563}, {\"title\": \"Recent Trends in Unsupervised Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.617, \"y\": 6.441}, {\"title\": \"ONE-PEACE: Exploring One General Representation Model Toward Unlimited  Modalities\", \"topic\": \"Multimodal Language Models\", \"x\": 8.231, \"y\": 7.197}, {\"title\": \"Aligning Instruction Tasks Unlocks Large Language Models as Zero-Shot  Relation Extractors\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.154, \"y\": 2.291}, {\"title\": \"Discourse Centric Evaluation of Machine Translation with a Densely  Annotated Parallel Corpus\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.706, \"y\": 4.642}, {\"title\": \"Exploiting Biased Models to De-bias Text: A Gender-Fair Rewriting Model\", \"topic\": \"Bias in Language Models\", \"x\": 3.049, \"y\": 4.331}, {\"title\": \"LLMScore: Unveiling the Power of Large Language Models in Text-to-Image  Synthesis Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.877, \"y\": 7.056}, {\"title\": \"Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot  Task Generalization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.91, \"y\": 5.27}, {\"title\": \"A Comparative Study on E-Branchformer vs Conformer in Speech  Recognition, Translation, and Understanding Tasks\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.25, \"y\": 5.014}, {\"title\": \"Self-supervised Fine-tuning for Improved Content Representations by  Speaker-invariant Clustering\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.88, \"y\": 5.109}, {\"title\": \"Trading Syntax Trees for Wordpieces: Target-oriented Opinion Words  Extraction with Wordpieces and Aspect Enhancement\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.144, \"y\": 6.858}, {\"title\": \"Silver Syntax Pre-training for Cross-Domain Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.028, \"y\": 6.745}, {\"title\": \"FunASR: A Fundamental End-to-End Speech Recognition Toolkit\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.215, \"y\": 5.308}, {\"title\": \"Making More of Little Data: Improving Low-Resource Automatic Speech  Recognition Using Data Augmentation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.982, \"y\": 5.488}, {\"title\": \"On the Off-Target Problem of Zero-Shot Multilingual Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.773, \"y\": 4.535}, {\"title\": \"Weakly-Supervised Visual-Textual Grounding with Semantic Prior  Refinement\", \"topic\": \"Multimodal Language Models\", \"x\": 8.596, \"y\": 7.187}, {\"title\": \"Take a Break in the Middle: Investigating Subgoals towards Hierarchical  Script Generation\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.988, \"y\": 2.47}, {\"title\": \"Advancing Full-Text Search Lemmatization Techniques with Paradigm  Retrieval from OpenCorpora\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.489, \"y\": 5.06}, {\"title\": \"A Lexical-aware Non-autoregressive Transformer-based ASR Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.144, \"y\": 5.158}, {\"title\": \"Ahead-of-Time P-Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.05, \"y\": 2.351}, {\"title\": \"Diffusion-Based Speech Enhancement with Joint Generative and Predictive  Decoders\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.852, \"y\": 5.647}, {\"title\": \"Analyzing Norm Violations in Live-Stream Chat\", \"topic\": \"Hate Speech Detection\", \"x\": 3.044, \"y\": 5.257}, {\"title\": \"Flatness-Aware Prompt Selection Improves Accuracy and Sample Efficiency\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.47, \"y\": 3.298}, {\"title\": \"RMSSinger: Realistic-Music-Score based Singing Voice Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.526, \"y\": 5.986}, {\"title\": \"Paxion: Patching Action Knowledge in Video-Language Foundation Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.854, \"y\": 7.767}, {\"title\": \"Accurate and Reliable Confidence Estimation Based on Non-Autoregressive  End-to-End Speech Recognition System\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.237, \"y\": 5.169}, {\"title\": \"A unified front-end framework for English text-to-speech synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.518, \"y\": 5.703}, {\"title\": \"Speech Separation based on Contrastive Learning and Deep Modularization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.981, \"y\": 5.2}, {\"title\": \"ZeroPrompt: Streaming Acoustic Encoders are Zero-Shot Masked LMs\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.095, \"y\": 5.157}, {\"title\": \"Language Models Meet World Models: Embodied Experiences Enhance Language  Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.822, \"y\": 2.474}, {\"title\": \"ML-SUPERB: Multilingual Speech Universal PERformance Benchmark\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.677, \"y\": 5.162}, {\"title\": \"Tree of Thoughts: Deliberate Problem Solving with Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.45, \"y\": 2.519}, {\"title\": \"Instruction Tuned Models are Quick Learners\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.346, \"y\": 2.453}, {\"title\": \"HaSa: Hardness and Structure-Aware Contrastive Knowledge Graph Embedding\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.115, \"y\": 6.052}, {\"title\": \"Compress, Then Prompt: Improving Accuracy-Efficiency Trade-off of LLM  Inference with Transferable Prompt\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.711, \"y\": 3.219}, {\"title\": \"Bring More Attention to Syntactic Symmetry for Automatic Postediting of  High-Quality Machine Translations\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.898, \"y\": 4.718}, {\"title\": \"Scalable and Safe Remediation of Defective Actions in Self-Learning  Conversational Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.204, \"y\": 3.452}, {\"title\": \"ChatGPT Perpetuates Gender Bias in Machine Translation and Ignores  Non-Gendered Pronouns: Findings across Bengali and Five other Low-Resource  Languages\", \"topic\": \"Bias in Language Models\", \"x\": 3.053, \"y\": 4.45}, {\"title\": \"SLiC-HF: Sequence Likelihood Calibration with Human Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.208, \"y\": 1.417}, {\"title\": \"BAD: BiAs Detection for Large Language Models in the context of  candidate screening\", \"topic\": \"Bias in Language Models\", \"x\": 3.448, \"y\": 4.406}, {\"title\": \"PaLM 2 Technical Report\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 8.596, \"y\": 3.928}, {\"title\": \"What You See is What You Read? Improving Text-Image Alignment Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.834, \"y\": 7.152}, {\"title\": \"Elaborative Simplification as Implicit Questions Under Discussion\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.29, \"y\": 5.095}, {\"title\": \"Logit-Based Ensemble Distribution Distillation for Robust Autoregressive  Sequence Uncertainties\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.543, \"y\": 3.853}, {\"title\": \"Evaluating Object Hallucination in Large Vision-Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.244, \"y\": 1.011}, {\"title\": \"Interactive Learning of Hierarchical Tasks from Dialog with GPT\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.513, \"y\": 3.705}, {\"title\": \"Controllable Speaking Styles Using a Large Language Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.429, \"y\": 5.841}, {\"title\": \"UniEX: An Effective and Efficient Framework for Unified Information  Extraction via a Span-extractive Perspective\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.887, \"y\": 6.671}, {\"title\": \"Boosting Local Spectro-Temporal Features for Speech Analysis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.036, \"y\": 5.506}, {\"title\": \"Searching for Needles in a Haystack: On the Role of Incidental  Bilingualism in PaLM's Translation Capability\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.343, \"y\": 4.572}, {\"title\": \"A quantitative study of NLP approaches to question difficulty estimation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.41, \"y\": 5.029}, {\"title\": \"Language Model Tokenizers Introduce Unfairness Between Languages\", \"topic\": \"Bias in Language Models\", \"x\": 3.385, \"y\": 4.244}, {\"title\": \"Shielded Representations: Protecting Sensitive Attributes Through  Iterative Gradient-Based Projection\", \"topic\": \"Bias in Language Models\", \"x\": 3.283, \"y\": 4.151}, {\"title\": \"Variable-length Neural Interlingua Representations for Zero-shot Neural  Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.894, \"y\": 4.497}, {\"title\": \"Knowledge-enhanced Mixed-initiative Dialogue System for Emotional  Support Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.57, \"y\": 7.881}, {\"title\": \"Pragmatic Reasoning in Structured Signaling Games\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.497, \"y\": 2.921}, {\"title\": \"Large Language Models Leverage External Knowledge to Extend Clinical  Insight Beyond Language Boundaries\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.794, \"y\": 7.996}, {\"title\": \"Improving Language Model Negotiation with Self-Play and In-Context  Learning from AI Feedback\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.284, \"y\": 2.999}, {\"title\": \"Use of a Taxonomy of Empathetic Response Intents to Control and  Interpret Empathy in Neural Chatbots\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.615, \"y\": 7.882}, {\"title\": \"Probing the Role of Positional Information in Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.503, \"y\": 7.563}, {\"title\": \"When Gradient Descent Meets Derivative-Free Optimization: A Match Made  in Black-Box Scenario\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.765, \"y\": 2.993}, {\"title\": \"AD-KD: Attribution-Driven Knowledge Distillation for Language Model  Compression\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.601, \"y\": 3.864}, {\"title\": \"EfficientSCI: Densely Connected Network with Space-time Factorization  for Large-scale Video Snapshot Compressive Imaging\", \"topic\": \"Multimodal Language Models\", \"x\": 8.954, \"y\": 7.79}, {\"title\": \"DinoSR: Self-Distillation and Online Clustering for Self-supervised  Speech Representation Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.811, \"y\": 4.802}, {\"title\": \"Reprompting: Automated Chain-of-Thought Prompt Inference Through Gibbs  Sampling\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.701, \"y\": 2.294}, {\"title\": \"\\\"I'm fully who I am\\\": Towards Centering Transgender and Non-Binary  Voices to Measure Biases in Open Language Generation\", \"topic\": \"Bias in Language Models\", \"x\": 3.224, \"y\": 4.431}, {\"title\": \"Balancing Lexical and Semantic Quality in Abstractive Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.47, \"y\": 6.16}, {\"title\": \"The Jaseci Programming Paradigm and Runtime Stack: Building Scale-out  Production Applications Easy and Fast\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.283, \"y\": 2.515}, {\"title\": \"Explaining black box text modules in natural language with language  models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.079, \"y\": 3.77}, {\"title\": \"Smaller Language Models are Better Black-box Machine-Generated Text  Detectors\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.066, \"y\": 4.747}, {\"title\": \"Knowledge Graph Completion Models are Few-shot Learners: An Empirical  Study of Relation Labeling in E-commerce with LLMs\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.007, \"y\": 5.748}, {\"title\": \"Understanding of Normal and Abnormal Hearts by Phase Space Analysis and  Convolutional Neural Networks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.804, \"y\": 8.297}, {\"title\": \"Application-Agnostic Language Modeling for On-Device ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.086, \"y\": 5.271}, {\"title\": \"A Video Is Worth 4096 Tokens: Verbalize Videos To Understand Them In  Zero Shot\", \"topic\": \"Multimodal Language Models\", \"x\": 8.911, \"y\": 7.857}, {\"title\": \"Clinical Note Owns its Hierarchy: Multi-Level Hypergraph Neural Networks  for Patient-Level Representation Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.814, \"y\": 8.271}, {\"title\": \"What In-Context Learning \\\"Learns\\\" In-Context: Disentangling Task  Recognition and Task Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.491, \"y\": 3.323}, {\"title\": \"SatLM: Satisfiability-Aided Language Models Using Declarative Prompting\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.625, \"y\": 2.847}, {\"title\": \"The Interpreter Understands Your Meaning: End-to-end Spoken Language  Understanding Aided by Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.242, \"y\": 5.04}, {\"title\": \"Tailoring Instructions to Student's Learning Levels Boosts Knowledge  Distillation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.552, \"y\": 3.838}, {\"title\": \"Towards Expert-Level Medical Question Answering with Large Language  Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.832, \"y\": 7.809}, {\"title\": \"Bidirectional Generative Framework for Cross-domain Aspect-based  Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.127, \"y\": 6.803}, {\"title\": \"About Evaluation of F1 Score for RECENT Relation Extraction System\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.868, \"y\": 6.843}, {\"title\": \"A Preliminary Analysis on the Code Generation Capabilities of GPT-3.5  and Bard AI Models for Java Functions\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.379, \"y\": 2.673}, {\"title\": \"Multi-modal Visual Understanding with Prompts for Semantic Information  Disentanglement of Image\", \"topic\": \"Multimodal Language Models\", \"x\": 8.166, \"y\": 7.383}, {\"title\": \"Hybrid and Collaborative Passage Reranking\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.522, \"y\": 5.056}, {\"title\": \"Exploring the Impact of Layer Normalization for Zero-shot Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.795, \"y\": 4.234}, {\"title\": \"Adversarial Word Dilution as Text Data Augmentation in Low-Resource  Regime\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.122, \"y\": 3.117}, {\"title\": \"On the Origins of Bias in NLP through the Lens of the Jim Code\", \"topic\": \"Bias in Language Models\", \"x\": 3.367, \"y\": 4.478}, {\"title\": \"xPQA: Cross-Lingual Product Question Answering across 12 Languages\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.596, \"y\": 5.204}, {\"title\": \"Maybe Only 0.5% Data is Needed: A Preliminary Exploration of Low  Training Data Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.405, \"y\": 2.398}, {\"title\": \"Towards Unifying Multi-Lingual and Cross-Lingual Summarization\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.169, \"y\": 4.961}, {\"title\": \"Towards Speech Dialogue Translation Mediating Speakers of Different  Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.319, \"y\": 5.307}, {\"title\": \"Easy-to-Hard Learning for Information Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.893, \"y\": 6.683}, {\"title\": \"Adversarial Speaker Disentanglement Using Unannotated External Data for  Self-supervised Representation Based Voice Conversion\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.716, \"y\": 5.488}, {\"title\": \"Progressive Translation: Improving Domain Robustness of Neural Machine  Translation with Intermediate Sequences\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.872, \"y\": 4.328}, {\"title\": \"Dual-Alignment Pre-training for Cross-lingual Sentence Embedding\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.295, \"y\": 4.927}, {\"title\": \"Is a Video worth $n\\\\times n$ Images? A Highly Efficient Approach to  Transformer-based Video Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.626, \"y\": 7.985}, {\"title\": \"Weight-Inherited Distillation for Task-Agnostic BERT Compression\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.55, \"y\": 3.816}, {\"title\": \"SGP-TOD: Building Task Bots Effortlessly via Schema-Guided LLM Prompting\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.521, \"y\": 3.77}, {\"title\": \"OOD-Speech: A Large Bengali Speech Recognition Dataset for  Out-of-Distribution Benchmarking\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.793, \"y\": 5.506}, {\"title\": \"Small Models are Valuable Plug-ins for Large Language Models\", \"topic\": \"In-Context Learning\", \"x\": 8.565, \"y\": 3.153}, {\"title\": \"Large Language Models are Zero-Shot Rankers for Recommender Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.996, \"y\": 2.873}, {\"title\": \"PMIndiaSum: Multilingual and Cross-lingual Headline Summarization for  Languages in India\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.231, \"y\": 5.298}, {\"title\": \"Exploring In-Context Learning Capabilities of Foundation Models for  Generating Knowledge Graphs from Text\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.032, \"y\": 5.873}, {\"title\": \"Measuring Cross-Lingual Transferability of Multilingual Transformers on  Sentence Classification\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.416, \"y\": 4.77}, {\"title\": \"Comparing Variation in Tokenizer Outputs Using a Series of Problematic  and Challenging Biomedical Sentences\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.298, \"y\": 7.44}, {\"title\": \"Question-Answering System Extracts Information on Injection Drug Use  from Clinical Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.698, \"y\": 7.804}, {\"title\": \"Sensitivity and Robustness of Large Language Models to Prompt Template  in Japanese Text Classification Tasks\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.137, \"y\": 3.297}, {\"title\": \"Back Translation for Speech-to-text Translation Without Transcripts\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.492, \"y\": 5.251}, {\"title\": \"Understanding and Bridging the Modality Gap for Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.291, \"y\": 5.174}, {\"title\": \"Schema-adaptable Knowledge Graph Construction\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.996, \"y\": 5.985}, {\"title\": \"Emotion Recognition based on Psychological Components in Guided  Narratives for Emotion Regulation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.442, \"y\": 7.543}, {\"title\": \"Measuring Consistency in Text-based Financial Forecasting Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.856, \"y\": 6.794}, {\"title\": \"A Hierarchical Encoding-Decoding Scheme for Abstractive Multi-document  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.775, \"y\": 6.42}, {\"title\": \"MeeQA: Natural Questions in Meeting Transcripts\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.41, \"y\": 5.275}, {\"title\": \"Taxi1500: A Multilingual Dataset for Text Classification in 1500  Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.203, \"y\": 5.058}, {\"title\": \"EMBRACE: Evaluation and Modifications for Boosting RACE\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.344, \"y\": 5.017}, {\"title\": \"Legal Extractive Summarization of U.S. Court Opinions\", \"topic\": \"Legal NLP\", \"x\": 5.078, \"y\": 5.87}, {\"title\": \"SuperDialseg: A Large-scale Dataset for Supervised Dialogue Segmentation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.358, \"y\": 4.241}, {\"title\": \"KEPR: Knowledge Enhancement and Plausibility Ranking for Generative  Commonsense Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.504, \"y\": 5.18}, {\"title\": \"\\\"Nothing Abnormal\\\": Disambiguating Medical Reports via Contrastive  Knowledge Infusion\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.264, \"y\": 8.329}, {\"title\": \"Large Language Model Guided Tree-of-Thought\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.365, \"y\": 2.545}, {\"title\": \"Parameter-Efficient Fine-Tuning with Layer Pruning on Free-Text  Sequence-to-Sequence Modeling\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.04, \"y\": 2.272}, {\"title\": \"From Pretraining Data to Language Models to Downstream Tasks: Tracking  the Trails of Political Biases Leading to Unfair NLP Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.365, \"y\": 4.484}, {\"title\": \"DeepFilterNet: Perceptually Motivated Real-Time Speech Enhancement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.107, \"y\": 5.318}, {\"title\": \"Learning to Generalize for Cross-domain QA\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.601, \"y\": 5.029}, {\"title\": \"Croatian Film Review Dataset (Cro-FiReDa): A Sentiment Annotated Dataset  of Film Reviews\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.558, \"y\": 6.585}, {\"title\": \"Distinguish Before Answer: Generating Contrastive Explanation as  Knowledge for Commonsense Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.402, \"y\": 5.228}, {\"title\": \"Self-supervised Neural Factor Analysis for Disentangling Utterance-level  Speech Representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.8, \"y\": 5.02}, {\"title\": \"Towards Understanding and Improving Knowledge Distillation for Neural  Machine Translation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.543, \"y\": 3.837}, {\"title\": \"Make Prompt-based Black-Box Tuning Colorful: Boosting Model  Generalization from Three Orthogonal Perspectives\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.708, \"y\": 3.264}, {\"title\": \"Improving End-to-End SLU performance with Prosodic Attention and  Distillation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.924, \"y\": 5.082}, {\"title\": \"Semantic-aware Dynamic Retrospective-Prospective Reasoning for  Event-level Video Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.555, \"y\": 7.982}, {\"title\": \"Reconstruct Before Summarize: An Efficient Two-Step Framework for  Condensing and Summarizing Meeting Transcripts\", \"topic\": \"Text Summarization\", \"x\": 5.606, \"y\": 6.259}, {\"title\": \"Trillion Dollar Words: A New Financial Dataset, Task & Market Analysis\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.781, \"y\": 6.826}, {\"title\": \"GPT-Sentinel: Distinguishing Human and ChatGPT Generated Content\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.243, \"y\": 4.747}, {\"title\": \"Leveraging Large Language Models in Conversational Recommender Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.04, \"y\": 3.082}, {\"title\": \"RC3: Regularized Contrastive Cross-lingual Cross-modal Pre-training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.658, \"y\": 7.05}, {\"title\": \"On the Hidden Mystery of OCR in Large Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.134, \"y\": 7.427}, {\"title\": \"Improving Small Language Models on PubMedQA via Generative Data  Augmentation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.931, \"y\": 7.761}, {\"title\": \"Constructing Holistic Measures for Social Biases in Masked Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.338, \"y\": 4.454}, {\"title\": \"HPE:Answering Complex Questions over Text by Hybrid Question Parsing and  Execution\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.722, \"y\": 5.351}, {\"title\": \"Using Language Models to Detect Alarming Student Responses\", \"topic\": \"Hate Speech Detection\", \"x\": 3.112, \"y\": 5.394}, {\"title\": \"Text2Cohort: Facilitating Intuitive Access to Biomedical Data with  Natural Language Cohort Discovery\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.972, \"y\": 7.614}, {\"title\": \"PALR: Personalization Aware LLMs for Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.981, \"y\": 2.953}, {\"title\": \"What are the Desired Characteristics of Calibration Sets? Identifying  Correlates on Long Form Scientific Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.412, \"y\": 6.134}, {\"title\": \"Is ChatGPT Fair for Recommendation? Evaluating Fairness in Large  Language Model Recommendation\", \"topic\": \"Bias in Language Models\", \"x\": 3.453, \"y\": 4.217}, {\"title\": \"Measuring Progress in Fine-grained Vision-and-Language Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.662, \"y\": 7.414}, {\"title\": \"LeXFiles and LegalLAMA: Facilitating English Multinational Legal  Language Model Development\", \"topic\": \"Legal NLP\", \"x\": 5.229, \"y\": 5.507}, {\"title\": \"A Comprehensive Analysis of Adapter Efficiency\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.984, \"y\": 2.605}, {\"title\": \"ArtGPT-4: Towards Artistic-understanding Large Vision-Language Models  with Enhanced Adapter\", \"topic\": \"Multimodal Language Models\", \"x\": 8.099, \"y\": 7.698}, {\"title\": \"Perturbation-based QE: An Explainable, Unsupervised Word-level Quality  Estimation Method for Blackbox Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.904, \"y\": 4.523}, {\"title\": \"Improving Cascaded Unsupervised Speech Translation with Denoising  Back-translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.367, \"y\": 5.268}, {\"title\": \"Two-in-One: A Model Hijacking Attack Against Text Generation Models\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.182, \"y\": 2.974}, {\"title\": \"Synergistic Interplay between Search and Large Language Models for  Information Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.115, \"y\": 4.562}, {\"title\": \"Investigating the Sensitivity of Automatic Speech Recognition Systems to  Phonetic Variation in L2 Englishes\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.053, \"y\": 5.483}, {\"title\": \"Improving the Quality of Neural Machine Translation Through Proper  Translation of Name Entities\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.845, \"y\": 4.483}, {\"title\": \"Towards Versatile and Efficient Visual Knowledge Integration into  Pre-trained Language Models with Cross-Modal Adapters\", \"topic\": \"Multimodal Language Models\", \"x\": 8.517, \"y\": 7.364}, {\"title\": \"MedGPTEval: A Dataset and Benchmark to Evaluate Responses of Large  Language Models in Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.676, \"y\": 8.062}, {\"title\": \"Improving Zero-shot Multilingual Neural Machine Translation by  Leveraging Cross-lingual Consistency Regularization\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.688, \"y\": 4.707}, {\"title\": \"Open-WikiTable: Dataset for Open Domain Question Answering with Complex  Reasoning over Table\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.61, \"y\": 5.35}, {\"title\": \"Gaussian Prior Reinforcement Learning for Nested Named Entity  Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.388, \"y\": 6.726}, {\"title\": \"IMAGINATOR: Pre-Trained Image+Text Joint Embeddings using Word-Level  Grounding of Images\", \"topic\": \"Multimodal Language Models\", \"x\": 8.578, \"y\": 6.965}, {\"title\": \"Better speech synthesis through scaling\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.519, \"y\": 5.964}, {\"title\": \"Masked Audio Text Encoders are Effective Multi-Modal Rescorers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.068, \"y\": 5.165}, {\"title\": \"OneCAD: One Classifier for All image Datasets using multimodal learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.313, \"y\": 7.238}, {\"title\": \"Musketeer: Joint Training for Multi-task Vision Language Model with Task  Explanation Prompts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.366, \"y\": 7.423}, {\"title\": \"A General-Purpose Multilingual Document Encoder\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.283, \"y\": 4.936}, {\"title\": \"Region-Aware Pretraining for Open-Vocabulary Object Detection with  Vision Transformers\", \"topic\": \"Multimodal Language Models\", \"x\": 8.773, \"y\": 7.134}, {\"title\": \"Learning the Visualness of Text Using Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.73, \"y\": 7.016}, {\"title\": \"Recommendation as Instruction Following: A Large Language Model  Empowered Recommendation Approach\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.897, \"y\": 2.881}, {\"title\": \"Self-Chained Image-Language Model for Video Localization and Question  Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.805, \"y\": 7.964}, {\"title\": \"Active Retrieval Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.133, \"y\": 4.514}, {\"title\": \"CoMoSpeech: One-Step Speech and Singing Voice Synthesis via Consistency  Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.548, \"y\": 5.944}, {\"title\": \"AfriQA: Cross-lingual Open-Retrieval Question Answering for African  Languages\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.578, \"y\": 5.376}, {\"title\": \"THUIR@COLIEE 2023: More Parameters and Legal Knowledge for Legal Case  Entailment\", \"topic\": \"Legal NLP\", \"x\": 5.175, \"y\": 5.721}, {\"title\": \"THUIR@COLIEE 2023: Incorporating Structural Knowledge into Pre-trained  Language Models for Legal Case Retrieval\", \"topic\": \"Legal NLP\", \"x\": 5.181, \"y\": 5.765}, {\"title\": \"Detecting Idiomatic Multiword Expressions in Clinical Terminology using  Definition-Based Representation Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.12, \"y\": 7.815}, {\"title\": \"PROM: A Phrase-level Copying Mechanism with Pre-training for Abstractive  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.553, \"y\": 6.282}, {\"title\": \"When the Majority is Wrong: Modeling Annotator Disagreement for  Subjective Tasks\", \"topic\": \"Hate Speech Detection\", \"x\": 3.031, \"y\": 5.376}, {\"title\": \"Improving Continual Relation Extraction by Distinguishing Analogous  Semantics\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.046, \"y\": 6.713}, {\"title\": \"Structured Chain-of-Thought Prompting for Code Generation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.781, \"y\": 2.447}, {\"title\": \"BanglaBook: A Large-scale Bangla Dataset for Sentiment Analysis from  Book Reviews\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.496, \"y\": 6.468}, {\"title\": \"SemEval-2023 Task 2: Fine-grained Multilingual Named Entity Recognition  (MultiCoNER 2)\", \"topic\": \"Named Entity Recognition\", \"x\": 7.424, \"y\": 6.765}, {\"title\": \"Chain-of-Dictionary Prompting Elicits Translation in Large Language  Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.503, \"y\": 4.281}, {\"title\": \"How to Index Item IDs for Recommendation Foundation Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.924, \"y\": 2.864}, {\"title\": \"ONCE: Boosting Content-based Recommendation with Both Open- and  Closed-source Large Language Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.969, \"y\": 2.873}, {\"title\": \"Long-Tailed Question Answering in an Open World\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.555, \"y\": 5.204}, {\"title\": \"Randomized Smoothing with Masked Inference for Adversarially Robust Text  Classifications\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.175, \"y\": 3.123}, {\"title\": \"ChatGPT-Like Large-Scale Foundation Models for Prognostics and Health  Management: A Survey and Roadmaps\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.729, \"y\": 7.818}, {\"title\": \"Mispronunciation Detection of Basic Quranic Recitation Rules using Deep  Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.811, \"y\": 5.416}, {\"title\": \"A Method to Automate the Discharge Summary Hospital Course for Neurology  Patients\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.682, \"y\": 8.026}, {\"title\": \"Quran Recitation Recognition using End-to-End Deep Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.806, \"y\": 5.405}, {\"title\": \"Beyond Negativity: Re-Analysis and Follow-Up Experiments on Hope Speech  Detection\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.033, \"y\": 7.198}, {\"title\": \"LACoS-BLOOM: Low-rank Adaptation with Contrastive objective on 8 bits  Siamese-BLOOM\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.212, \"y\": 2.131}, {\"title\": \"VideoChat: Chat-Centric Video Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.801, \"y\": 7.889}, {\"title\": \"Korean Named Entity Recognition Based on Language-Specific Features\", \"topic\": \"Named Entity Recognition\", \"x\": 7.445, \"y\": 6.768}, {\"title\": \"Summarizing, Simplifying, and Synthesizing Medical Evidence Using GPT-3  (with Varying Success)\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.698, \"y\": 7.265}, {\"title\": \"Large language models in biomedical natural language processing:  benchmarks, baselines, and recommendations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.962, \"y\": 7.515}, {\"title\": \"PAI at SemEval-2023 Task 2: A Universal System for Named Entity  Recognition with External Entity Information\", \"topic\": \"Named Entity Recognition\", \"x\": 7.407, \"y\": 6.85}, {\"title\": \"Talking with Machines: A Comprehensive Survey of Emergent Dialogue  Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.148, \"y\": 3.869}, {\"title\": \"Generating medically-accurate summaries of patient-provider dialogue: A  multi-stage approach using large language models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.592, \"y\": 7.983}, {\"title\": \"Humans are Still Better than ChatGPT: Case of the IEEEXtreme Competition\", \"topic\": \"Bias in Language Models\", \"x\": 5.246, \"y\": 4.401}, {\"title\": \"Interpretable Multimodal Misinformation Detection with Logic Reasoning\", \"topic\": \"Fake News Detection\", \"x\": 4.048, \"y\": 5.937}, {\"title\": \"Are ChatGPT and GPT-4 General-Purpose Solvers for Financial Text  Analytics? A Study on Several Typical Tasks\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.888, \"y\": 6.812}, {\"title\": \"A Review of Vision-Language Models and their Performance on the Hateful  Memes Challenge\", \"topic\": \"Hate Speech Detection\", \"x\": 2.861, \"y\": 5.615}, {\"title\": \"Representation Learning for Person or Entity-centric Knowledge Graphs:  An Application in Healthcare\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.902, \"y\": 6.267}, {\"title\": \"Fine-tuning Language Models with Generative Adversarial Reward Modelling\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.236, \"y\": 1.59}, {\"title\": \"The Case Records of ChatGPT: Language Models and Complex Clinical  Questions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.637, \"y\": 8.168}, {\"title\": \"Exploiting Pseudo Image Captions for Multimodal Summarization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.602, \"y\": 7.024}, {\"title\": \"MAUPQA: Massive Automatically-created Polish Question Answering Dataset\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.504, \"y\": 5.327}, {\"title\": \"Large Language Models Need Holistically Thought in Medical  Conversational QA\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.639, \"y\": 7.942}, {\"title\": \"CaseEncoder: A Knowledge-enhanced Pre-trained Model for Legal Case  Encoding\", \"topic\": \"Legal NLP\", \"x\": 5.145, \"y\": 5.801}, {\"title\": \"Explainable Recommender with Geometric Information Bottleneck\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.87, \"y\": 2.975}, {\"title\": \"Detection of depression on social networks using transformers and  ensembles\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.135, \"y\": 7.366}, {\"title\": \"Structured Sentiment Analysis as Transition-based Dependency Parsing\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.129, \"y\": 6.824}, {\"title\": \"The Perfect Victim: Computational Analysis of Judicial Attitudes towards  Victims of Sexual Violence\", \"topic\": \"Hate Speech Detection\", \"x\": 2.954, \"y\": 5.382}, {\"title\": \"Boosting Zero-shot Cross-lingual Retrieval by Training on Artificially  Code-Switched Data\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.253, \"y\": 4.886}, {\"title\": \"Dialogue Planning via Brownian Bridge Stochastic Process for  Goal-directed Proactive Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.445, \"y\": 3.695}, {\"title\": \"VCSUM: A Versatile Chinese Meeting Summarization Dataset\", \"topic\": \"Text Summarization\", \"x\": 5.5, \"y\": 6.414}, {\"title\": \"Robust Acoustic and Semantic Contextual Biasing in Neural Transducers  for Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.266, \"y\": 5.087}, {\"title\": \"Attack Named Entity Recognition by Entity Boundary Interference\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.047, \"y\": 2.934}, {\"title\": \"StarCoder: may the source be with you!\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.571, \"y\": 2.546}, {\"title\": \"Multi-Teacher Knowledge Distillation For Text Image Machine Translation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.445, \"y\": 3.97}, {\"title\": \"CharSpan: Utilizing Lexical Similarity to Enable Zero-Shot Machine  Translation for Extremely Low-resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.546, \"y\": 4.851}, {\"title\": \"QVoice: Arabic Speech Pronunciation Learning Application\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.699, \"y\": 5.49}, {\"title\": \"Exploration of Language Dependency for Japanese Self-Supervised Speech  Representation Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.63, \"y\": 5.07}, {\"title\": \"MoT: Memory-of-Thought Enables ChatGPT to Self-Improve\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.557, \"y\": 2.396}, {\"title\": \"Summarization with Precise Length Control\", \"topic\": \"Text Summarization\", \"x\": 5.706, \"y\": 6.08}, {\"title\": \"Effective Medical Code Prediction via Label Internal Alignment\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.937, \"y\": 8.345}, {\"title\": \"Read, Diagnose and Chat: Towards Explainable and Interactive  LLMs-Augmented Depression Detection in Social Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.183, \"y\": 7.494}, {\"title\": \"Multi-Task End-to-End Training Improves Conversational Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.975, \"y\": 3.084}, {\"title\": \"Do Not Blindly Imitate the Teacher: Using Perturbed Loss for Knowledge  Distillation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.568, \"y\": 3.803}, {\"title\": \"ComputeGPT: A computational chat model for numerical problems\", \"topic\": \"Bias in Language Models\", \"x\": 5.266, \"y\": 4.392}, {\"title\": \"Revisiting Relation Extraction in the era of Large Language Models\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.959, \"y\": 6.7}, {\"title\": \"GersteinLab at MEDIQA-Chat 2023: Clinical Note Summarization from  Doctor-Patient Conversations through Fine-tuning and In-context Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.577, \"y\": 8.022}, {\"title\": \"NeuroComparatives: Neuro-Symbolic Distillation of Comparative Knowledge\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.33, \"y\": 3.761}, {\"title\": \"Joint Moment Retrieval and Highlight Detection Via Natural Language  Queries\", \"topic\": \"Multimodal Language Models\", \"x\": 8.871, \"y\": 7.851}, {\"title\": \"What Do Patients Say About Their Disease Symptoms? Deep Multilabel Text  Classification With Human-in-the-Loop Curation for Automatic Labeling of  Patient Self Reports of Problems\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.268, \"y\": 7.948}, {\"title\": \"The Current State of Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.588, \"y\": 6.342}, {\"title\": \"How Do In-Context Examples Affect Compositional Generalization?\", \"topic\": \"In-Context Learning\", \"x\": 8.467, \"y\": 3.397}, {\"title\": \"Learning Summary-Worthy Visual Representation for Abstractive  Summarization in Video\", \"topic\": \"Multimodal Language Models\", \"x\": 8.788, \"y\": 7.733}, {\"title\": \"MultiModal-GPT: A Vision and Language Model for Dialogue with Humans\", \"topic\": \"Multimodal Language Models\", \"x\": 8.152, \"y\": 7.387}, {\"title\": \"ChatGPT: Vision and Challenges\", \"topic\": \"Bias in Language Models\", \"x\": 4.816, \"y\": 4.351}, {\"title\": \"Toeplitz Neural Network for Sequence Modeling\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.804, \"y\": 3.365}, {\"title\": \"SkillQG: Learning to Generate Question for Reading Comprehension  Assessment\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.25, \"y\": 5.071}, {\"title\": \"DEnsity: Open-domain Dialogue Evaluation Metric using Density Estimation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.323, \"y\": 3.886}, {\"title\": \"Enhancing Continual Relation Extraction via Classifier Decomposition\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.035, \"y\": 6.729}, {\"title\": \"Cone: Unsupervised Contrastive Opinion Extraction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.22, \"y\": 6.796}, {\"title\": \"Code Execution with Pre-trained Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.749, \"y\": 2.612}, {\"title\": \"HiFi: High-Information Attention Heads Hold for Parameter-Efficient  Model Adaptation\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.063, \"y\": 2.36}, {\"title\": \"Boosting Radiology Report Generation by Infusing Comparison Prior\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.242, \"y\": 8.613}, {\"title\": \"Toward Adversarial Training on Contextualized Language Representation\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.149, \"y\": 3.013}, {\"title\": \"Non-Autoregressive Math Word Problem Solver with Unified Tree Structure\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.147, \"y\": 2.779}, {\"title\": \"Prompted LLMs as Chatbot Modules for Long Open-domain Conversation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.386, \"y\": 3.427}, {\"title\": \"A Multi-Modal Context Reasoning Approach for Conditional Inference on  Joint Textual and Visual Clues\", \"topic\": \"Multimodal Language Models\", \"x\": 8.193, \"y\": 7.449}, {\"title\": \"Sparks of Artificial General Recommender (AGR): Early Experiments with  ChatGPT\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.882, \"y\": 3.254}, {\"title\": \"Target-Side Augmentation for Document-Level Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.867, \"y\": 4.552}, {\"title\": \"AlignSTS: Speech-to-Singing Conversion via Cross-Modal Alignment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.584, \"y\": 5.836}, {\"title\": \"Improving Cross-Task Generalization with Step-by-Step Instructions\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.099, \"y\": 2.333}, {\"title\": \"Unlocking Practical Applications in Legal Domain: Evaluation of GPT for  Zero-Shot Semantic Annotation of Legal Texts\", \"topic\": \"Legal NLP\", \"x\": 5.198, \"y\": 5.641}, {\"title\": \"Language Models Don't Always Say What They Think: Unfaithful  Explanations in Chain-of-Thought Prompting\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.53, \"y\": 2.35}, {\"title\": \"Empowering Language Model with Guided Knowledge Fusion for Biomedical  Document Re-ranking\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.169, \"y\": 7.576}, {\"title\": \"Unified Demonstration Retriever for In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.35, \"y\": 3.592}, {\"title\": \"Learning Robust Self-attention Features for Speech Emotion Recognition  with Label-adaptive Mixup\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.111, \"y\": 7.899}, {\"title\": \"HIORE: Leveraging High-order Interactions for Unified Entity Relation  Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.9, \"y\": 6.878}, {\"title\": \"Vcc: Scaling Transformers to 128K Tokens or More by Prioritizing  Important Tokens\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.86, \"y\": 3.074}, {\"title\": \"Leveraging Synthetic Targets for Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.851, \"y\": 4.535}, {\"title\": \"Cross-Modal Retrieval for Motion and Text via DopTriple Loss\", \"topic\": \"Multimodal Language Models\", \"x\": 9.059, \"y\": 7.208}, {\"title\": \"OpenViVQA: Task, Dataset, and Multimodal Fusion Models for Visual  Question Answering in Vietnamese\", \"topic\": \"Multimodal Language Models\", \"x\": 8.165, \"y\": 8.009}, {\"title\": \"UIT-OpenViIC: A Novel Benchmark for Evaluating Image Captioning in  Vietnamese\", \"topic\": \"Multimodal Language Models\", \"x\": 8.858, \"y\": 7.657}, {\"title\": \"X-LLM: Bootstrapping Advanced Large Language Models by Treating  Multi-Modalities as Foreign Languages\", \"topic\": \"Multimodal Language Models\", \"x\": 8.262, \"y\": 7.219}, {\"title\": \"Rhetorical Role Labeling of Legal Documents using Transformers and Graph  Neural Networks\", \"topic\": \"Legal NLP\", \"x\": 5.133, \"y\": 5.796}, {\"title\": \"Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning  by Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.678, \"y\": 2.497}, {\"title\": \"Self-Edit: Fault-Aware Code Editor for Code Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.433, \"y\": 2.258}, {\"title\": \"SANTA: Separate Strategies for Inaccurate and Incomplete Annotation  Noise in Distantly-Supervised Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.374, \"y\": 6.686}, {\"title\": \"The Best Defense is Attack: Repairing Semantics in Textual Adversarial  Examples\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.112, \"y\": 3.027}, {\"title\": \"Refining the Responses of LLMs by Themselves\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.078, \"y\": 2.929}, {\"title\": \"NER-to-MRC: Named-Entity Recognition Completely Solving as Machine  Reading Comprehension\", \"topic\": \"Named Entity Recognition\", \"x\": 7.354, \"y\": 6.778}, {\"title\": \"Residual Prompt Tuning: Improving Prompt Tuning with Residual  Reparameterization\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.738, \"y\": 3.254}, {\"title\": \"Structure-CLIP: Towards Scene Graph Knowledge to Enhance Multi-modal  Structured Representations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.671, \"y\": 7.313}, {\"title\": \"HateMM: A Multi-Modal Dataset for Hate Video Classification\", \"topic\": \"Hate Speech Detection\", \"x\": 2.7, \"y\": 5.382}, {\"title\": \"Fairness in Image Search: A Study of Occupational Stereotyping in Image  Retrieval and its Debiasing\", \"topic\": \"Bias in Language Models\", \"x\": 3.341, \"y\": 4.328}, {\"title\": \"Train Global, Tailor Local: Minimalist Multilingual Translation into  Endangered Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.576, \"y\": 4.725}, {\"title\": \"Large Language Models in Sport Science & Medicine: Opportunities, Risks  and Considerations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.514, \"y\": 7.627}, {\"title\": \"CLaC at SemEval-2023 Task 2: Comparing Span-Prediction and  Sequence-Labeling approaches for NER\", \"topic\": \"Named Entity Recognition\", \"x\": 7.371, \"y\": 6.826}, {\"title\": \"Transformer Working Memory Enables Regular Language Reasoning and  Natural Language Length Extrapolation\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.771, \"y\": 3.356}, {\"title\": \"Harnessing the Power of BERT in the Turkish Clinical Domain: Pretraining  Approaches for Limited Data Scenarios\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.223, \"y\": 8.008}, {\"title\": \"Otter: A Multi-Modal Model with In-Context Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.32, \"y\": 7.225}, {\"title\": \"Large Language Models in Ambulatory Devices for Home Health Diagnostics:  A case study of Sickle Cell Anemia Management\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.441, \"y\": 8.106}, {\"title\": \"DAMO-NLP at SemEval-2023 Task 2: A Unified Retrieval-augmented System  for Multilingual Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.427, \"y\": 6.748}, {\"title\": \"A Suite of Generative Tasks for Multi-Level Multimodal Webpage  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.136, \"y\": 7.242}, {\"title\": \"Predicting COVID-19 and pneumonia complications from admission texts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.685, \"y\": 8.251}, {\"title\": \"Retrieval Augmented Chest X-Ray Report Generation using OpenAI GPT  models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.21, \"y\": 8.602}, {\"title\": \"White-Box Multi-Objective Adversarial Attack on Dialogue Generation\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.207, \"y\": 2.994}, {\"title\": \"Jointly Extracting Interventions, Outcomes, and Findings from RCT  Reports with LLMs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.77, \"y\": 7.671}, {\"title\": \"The Role of Data Curation in Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.102, \"y\": 7.391}, {\"title\": \"NLI4CT: Multi-Evidence Natural Language Inference for Clinical Trial  Reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.625, \"y\": 7.623}, {\"title\": \"Implications of Multi-Word Expressions on English to Bharti Braille  Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.646, \"y\": 5.181}, {\"title\": \"The MuSe 2023 Multimodal Sentiment Analysis Challenge: Mimicked  Emotions, Cross-Cultural Humour, and Personalisation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.324, \"y\": 7.37}, {\"title\": \"From Parse-Execute to Parse-Execute-Refine: Improving Semantic Parser  for Complex Question Answering over Knowledge Base\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.809, \"y\": 5.421}, {\"title\": \"Improved Logical Reasoning of Language Models via Differentiable  Symbolic Programming\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.644, \"y\": 2.821}, {\"title\": \"LLM-RM at SemEval-2023 Task 2: Multilingual Complex NER using  XLM-RoBERTa\", \"topic\": \"Named Entity Recognition\", \"x\": 7.445, \"y\": 6.724}, {\"title\": \"Open Information Extraction via Chunks\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.873, \"y\": 6.688}, {\"title\": \"TransESC: Smoothing Emotional Support Conversation via Turn-Level State  Transition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.356, \"y\": 7.855}, {\"title\": \"Low-Resource Multi-Granularity Academic Function Recognition Based on  Multiple Prompt Knowledge\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.722, \"y\": 3.432}, {\"title\": \"Verify-and-Edit: A Knowledge-Enhanced Chain-of-Thought Framework\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.639, \"y\": 2.291}, {\"title\": \"Rescue Conversations from Dead-ends: Efficient Exploration for  Task-oriented Dialogue Policy Optimization\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.419, \"y\": 3.489}, {\"title\": \"VicunaNER: Zero/Few-shot Named Entity Recognition using Vicuna\", \"topic\": \"Named Entity Recognition\", \"x\": 7.389, \"y\": 6.749}, {\"title\": \"Neuromodulation Gated Transformer\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.871, \"y\": 3.258}, {\"title\": \"AttentionViz: A Global View of Transformer Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.692, \"y\": 3.464}, {\"title\": \"Investigating Lexical Sharing in Multilingual Machine Translation for  Indian Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.557, \"y\": 4.889}, {\"title\": \"VideoOFA: Two-Stage Pre-Training for Video-to-Text Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.966, \"y\": 7.77}, {\"title\": \"Employing Hybrid Deep Neural Networks on Dari Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.141, \"y\": 5.403}, {\"title\": \"The Role of Global and Local Context in Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.393, \"y\": 6.783}, {\"title\": \"Analysis of Visual Question Answering Algorithms with attention model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.189, \"y\": 8.06}, {\"title\": \"Are Human Explanations Always Helpful? Towards Objective Evaluation of  Human Natural Language Explanations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.784, \"y\": 3.846}, {\"title\": \"Hybrid Transducer and Attention based Encoder-Decoder Modeling for  Speech-to-Text Tasks\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.92, \"y\": 5.067}, {\"title\": \"Modeling What-to-ask and How-to-ask for Answer-unaware Conversational  Question Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.27, \"y\": 4.966}, {\"title\": \"Personalize Segment Anything Model with One Shot\", \"topic\": \"Multimodal Language Models\", \"x\": 8.771, \"y\": 7.054}, {\"title\": \"Principle-Driven Self-Alignment of Language Models from Scratch with  Minimal Human Supervision\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.52, \"y\": 1.609}, {\"title\": \"NatCS: Eliciting Natural Customer Support Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.201, \"y\": 3.934}, {\"title\": \"SemEval-2023 Task 7: Multi-Evidence Natural Language Inference for  Clinical Trial Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.701, \"y\": 7.666}, {\"title\": \"Conversational Semantic Parsing using Dynamic Context Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.983, \"y\": 5.534}, {\"title\": \"End-to-end spoken language understanding using joint CTC loss and  self-supervised, pretrained acoustic encoders\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.676, \"y\": 5.046}, {\"title\": \"Automatic Prompt Optimization with \\\"Gradient Descent\\\" and Beam Search\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.387, \"y\": 3.231}, {\"title\": \"An automatically discovered chain-of-thought prompt generalizes to novel  models and datasets\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.745, \"y\": 2.296}, {\"title\": \"Semantic Space Grounded Weighted Decoding for Multi-Attribute  Controllable Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.508, \"y\": 3.926}, {\"title\": \"Multi-grained Hypergraph Interest Modeling for Conversational  Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.957, \"y\": 3.059}, {\"title\": \"BranchNorm: Robustly Scaling Extremely Deep Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.76, \"y\": 3.239}, {\"title\": \"Unified Model Learning for Various Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.869, \"y\": 4.495}, {\"title\": \"The Politics of Language Choice: How the Russian-Ukrainian War  Influences Ukrainians' Language Use on Twitter\", \"topic\": \"Fake News Detection\", \"x\": 3.681, \"y\": 5.929}, {\"title\": \"A Survey on Proactive Dialogue Systems: Problems, Methods, and Prospects\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.17, \"y\": 3.681}, {\"title\": \"An Asynchronous Updating Reinforcement Learning Framework for  Task-oriented Dialog System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.514, \"y\": 3.426}, {\"title\": \"SI-LSTM: Speaker Hybrid Long-short Term Memory and Cross Modal Attention  for Emotion Recognition in Conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.255, \"y\": 7.787}, {\"title\": \"Learning Language-Specific Layers for Multilingual Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.663, \"y\": 4.5}, {\"title\": \"Towards Weakly-Supervised Hate Speech Classification Across Datasets\", \"topic\": \"Hate Speech Detection\", \"x\": 2.695, \"y\": 5.393}, {\"title\": \"A framework for the emergence and analysis of language in social  learning agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.444, \"y\": 2.799}, {\"title\": \"How to Enhance Causal Discrimination of Utterances: A Case on Affective  Reasoning\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.476, \"y\": 7.651}, {\"title\": \"Re$^3$Dial: Retrieve, Reorganize and Rescale Dialogue Corpus for  Long-Turn Open-Domain Dialogue Pre-training\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.573, \"y\": 3.68}, {\"title\": \"Analyzing Hong Kong's Legal Judgments from a Computational Linguistics  point-of-view\", \"topic\": \"Legal NLP\", \"x\": 5.049, \"y\": 5.741}, {\"title\": \"FormNetV2: Multimodal Graph Contrastive Learning for Form Document  Information Extraction\", \"topic\": \"Multimodal Language Models\", \"x\": 8.011, \"y\": 7.038}, {\"title\": \"ANetQA: A Large-scale Benchmark for Fine-grained Compositional Reasoning  over Untrimmed Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.631, \"y\": 8.01}, {\"title\": \"Black-box Prompt Tuning with Subspace Learning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.693, \"y\": 3.314}, {\"title\": \"Task-Optimized Adapters for an End-to-End Task-Oriented Dialogue System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.524, \"y\": 3.767}, {\"title\": \"PTP: Boosting Stability and Performance of Prompt Tuning with  Perturbation-Based Regularizer\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.655, \"y\": 3.216}, {\"title\": \"Plan, Eliminate, and Track -- Language Models are Good Teachers for  Embodied Agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.88, \"y\": 2.36}, {\"title\": \"Approximating CKY with Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.297, \"y\": 3.714}, {\"title\": \"PeaCoK: Persona Commonsense Knowledge for Consistent and Engaging  Narratives\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.058, \"y\": 3.77}, {\"title\": \"Entity-Based Evaluation of Political Bias in Automatic Summarization\", \"topic\": \"Fake News Detection\", \"x\": 3.731, \"y\": 5.5}, {\"title\": \"Visual Chain of Thought: Bridging Logical Gaps with Multimodal  Infillings\", \"topic\": \"Multimodal Language Models\", \"x\": 8.096, \"y\": 7.731}, {\"title\": \"Distilling Step-by-Step! Outperforming Larger Language Models with Less  Training Data and Smaller Model Sizes\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.275, \"y\": 3.628}, {\"title\": \"Evaluating the Efficacy of Length-Controllable Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.832, \"y\": 4.798}, {\"title\": \"M2-CTTS: End-to-End Multi-scale Multi-modal Conversational  Text-to-Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.577, \"y\": 5.803}, {\"title\": \"A Neural Divide-and-Conquer Reasoning Framework for Image Retrieval from  Linguistically Complex Text\", \"topic\": \"Multimodal Language Models\", \"x\": 8.384, \"y\": 7.423}, {\"title\": \"End-to-end Training and Decoding for Pivot-based Cascaded Translation  Model\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.86, \"y\": 4.589}, {\"title\": \"AttenWalker: Unsupervised Long-Document Question Answering via  Attention-based Graph Walking\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.768, \"y\": 5.465}, {\"title\": \"WangLab at MEDIQA-Chat 2023: Clinical Note Generation from  Doctor-Patient Conversations using Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.557, \"y\": 8.024}, {\"title\": \"Identifying the Correlation Between Language Distance and Cross-Lingual  Transfer in a Multilingual Representation Space\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.286, \"y\": 4.796}, {\"title\": \"Pay More Attention to Relation Exploration for Knowledge Base Question  Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.757, \"y\": 5.499}, {\"title\": \"GPT-RE: In-context Learning for Relation Extraction using Large Language  Models\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.028, \"y\": 6.609}, {\"title\": \"Background Knowledge Grounding for Readable, Relevant, and Factual  Biomedical Lay Summaries\", \"topic\": \"Text Summarization\", \"x\": 5.581, \"y\": 6.266}, {\"title\": \"Response-conditioned Turn-taking Prediction\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.524, \"y\": 3.829}, {\"title\": \"A Systematic Study of Knowledge Distillation for Natural Language  Generation with Pseudo-Target Training\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.522, \"y\": 3.808}, {\"title\": \"Analysing the Impact of Audio Quality on the Use of Naturalistic  Long-Form Recordings for Infant-Directed Speech Research\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.797, \"y\": 5.462}, {\"title\": \"NorQuAD: Norwegian Question Answering Dataset\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.455, \"y\": 5.241}, {\"title\": \"Can LMs Generalize to Future Data? An Empirical Analysis on Text  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.647, \"y\": 6.302}, {\"title\": \"Can Large Language Models Be an Alternative to Human Evaluations?\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.013, \"y\": 3.858}, {\"title\": \"CiteCaseLAW: Citation Worthiness Detection in Caselaw for Legal  Assistive Writing\", \"topic\": \"Legal NLP\", \"x\": 5.273, \"y\": 5.764}, {\"title\": \"SCOTT: Self-Consistent Chain-of-Thought Distillation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.809, \"y\": 2.334}, {\"title\": \"Towards Imperceptible Document Manipulations against Neural Ranking  Models\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.154, \"y\": 3.069}, {\"title\": \"Multimodal Procedural Planning via Dual Text-Image Prompting\", \"topic\": \"Multimodal Language Models\", \"x\": 8.105, \"y\": 7.481}, {\"title\": \"Automated Code generation for Information Technology Tasks in YAML  through Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.349, \"y\": 2.536}, {\"title\": \"Few-shot In-context Learning for Knowledge Base Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.683, \"y\": 5.353}, {\"title\": \"DiffuSum: Generation Enhanced Extractive Summarization with Diffusion\", \"topic\": \"Text Summarization\", \"x\": 5.578, \"y\": 6.26}, {\"title\": \"Stance Detection: A Practical Guide to Classifying Political Beliefs in  Text\", \"topic\": \"Fake News Detection\", \"x\": 3.515, \"y\": 5.834}, {\"title\": \"Don't Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.924, \"y\": 3.37}, {\"title\": \"Stars Are All You Need: A Distantly Supervised Pyramid Network for  Unified Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.217, \"y\": 6.777}, {\"title\": \"Distill or Annotate? Cost-Efficient Fine-Tuning of Compact Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.319, \"y\": 3.633}, {\"title\": \"TMR: Text-to-Motion Retrieval Using Contrastive 3D Human Motion  Synthesis\", \"topic\": \"Multimodal Language Models\", \"x\": 9.134, \"y\": 6.946}, {\"title\": \"Unlimiformer: Long-Range Transformers with Unlimited Length Input\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.808, \"y\": 3.314}, {\"title\": \"A Study on the Integration of Pipeline and E2E SLU systems for Spoken  Semantic Parsing toward STOP Quality Challenge\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.692, \"y\": 5.167}, {\"title\": \"How to Unleash the Power of Large Language Models for Few-shot Relation  Extraction?\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.977, \"y\": 6.61}, {\"title\": \"FIREBALL: A Dataset of Dungeons and Dragons Actual-Play with Structured  Game State Information\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.439, \"y\": 3.227}, {\"title\": \"Shared Latent Space by Both Languages in Non-Autoregressive Neural  Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.996, \"y\": 4.526}, {\"title\": \"Summarizing Multiple Documents with Conversational Structure for  Meta-Review Generation\", \"topic\": \"Text Summarization\", \"x\": 5.439, \"y\": 6.246}, {\"title\": \"Multimodal Neural Databases\", \"topic\": \"Multimodal Language Models\", \"x\": 8.036, \"y\": 7.308}, {\"title\": \"Parameter-Efficient Cross-lingual Transfer of Vision and Language Models  via Translation-based Alignment\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.413, \"y\": 4.993}, {\"title\": \"Sentiment Perception Adversarial Attacks on Neural Machine Translation  Systems\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.08, \"y\": 2.96}, {\"title\": \"Turning Flowchart into Dialog: Augmenting Flowchart-grounded  Troubleshooting Dialogs via Synthetic Data Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.419, \"y\": 3.898}, {\"title\": \"Improving Cancer Hallmark Classification with BERT-based Deep Learning  Approach\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.994, \"y\": 7.899}, {\"title\": \"VPGTrans: Transfer Visual Prompt Generator across LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.625, \"y\": 7.368}, {\"title\": \"The Role of Summarization in Generative Agents: A Preliminary  Perspective\", \"topic\": \"Text Summarization\", \"x\": 5.49, \"y\": 6.197}, {\"title\": \"MultiLegalSBD: A Multilingual Legal Sentence Boundary Detection Dataset\", \"topic\": \"Legal NLP\", \"x\": 5.241, \"y\": 5.721}, {\"title\": \"Is Your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of  Large Language Models for Code Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.351, \"y\": 2.391}, {\"title\": \"The Pipeline System of ASR and NLU with MLM-based Data Augmentation  toward STOP Low-resource Challenge\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.018, \"y\": 5.222}, {\"title\": \"Think Rationally about What You See: Continuous Rationale Extraction for  Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.075, \"y\": 6.601}, {\"title\": \"Lessons Learned in ATCO2: 5000 hours of Air Traffic Control  Communications for Robust Automatic Speech Recognition and Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.162, \"y\": 5.502}, {\"title\": \"RadAdapt: Radiology Report Summarization via Lightweight Domain  Adaptation of Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.134, \"y\": 8.535}, {\"title\": \"Evaluating statistical language models as pragmatic reasoners\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.888, \"y\": 3.536}, {\"title\": \"Deception Detection with Feature-Augmentation by soft Domain Transfer\", \"topic\": \"Fake News Detection\", \"x\": 3.971, \"y\": 5.842}, {\"title\": \"CryCeleb: A Speaker Verification Dataset Based on Infant Cry Sounds\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.993, \"y\": 5.753}, {\"title\": \"Large Linguistic Models: Analyzing theoretical linguistic abilities of  LLMs\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.685, \"y\": 3.787}, {\"title\": \"Poisoning Language Models During Instruction Tuning\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.383, \"y\": 2.547}, {\"title\": \"Learning to Reason and Memorize with Self-Notes\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.795, \"y\": 2.291}, {\"title\": \"Self-Evaluation Guided Beam Search for Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.658, \"y\": 2.346}, {\"title\": \"Low-Resourced Machine Translation for Senegalese Wolof Language\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.561, \"y\": 4.98}, {\"title\": \"Reliable Gradient-free and Likelihood-free Prompt Tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.702, \"y\": 3.214}, {\"title\": \"Multimodal Graph Transformer for Multimodal Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.035, \"y\": 7.646}, {\"title\": \"Sensitive Data Detection with High-Throughput Machine Learning Models in  Electrical Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.675, \"y\": 8.081}, {\"title\": \"Working Memory Capacity of ChatGPT: An Empirical Study\", \"topic\": \"Bias in Language Models\", \"x\": 5.337, \"y\": 4.319}, {\"title\": \"Building a Non-native Speech Corpus Featuring Chinese-English Bilingual  Children: Compilation and Rationale\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.384, \"y\": 5.361}, {\"title\": \"Beyond Classification: Financial Reasoning in State-of-the-Art Language  Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.894, \"y\": 6.808}, {\"title\": \"LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.31, \"y\": 7.587}, {\"title\": \"Empirical Analysis of the Strengths and Weaknesses of PEFT Techniques  for LLMs\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.89, \"y\": 2.367}, {\"title\": \"Interpreting Vision and Language Generative Models with Semantic Visual  Priors\", \"topic\": \"Multimodal Language Models\", \"x\": 8.569, \"y\": 7.477}, {\"title\": \"An Empirical Study of Multimodal Model Merging\", \"topic\": \"Multimodal Language Models\", \"x\": 8.226, \"y\": 7.156}, {\"title\": \"HQP: A Human-Annotated Dataset for Detecting Online Propaganda\", \"topic\": \"Fake News Detection\", \"x\": 3.808, \"y\": 5.596}, {\"title\": \"ResiDual: Transformer with Dual Residual Connections\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.785, \"y\": 3.347}, {\"title\": \"RexUIE: A Recursive Method with Explicit Schema Instructor for Universal  Information Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.833, \"y\": 6.682}, {\"title\": \"FlowTransformer: A Transformer Framework for Flow-based Network  Intrusion Detection Systems\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.717, \"y\": 3.404}, {\"title\": \"Towards autonomous system: flexible modular production system enhanced  with large language model agents\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.712, \"y\": 2.772}, {\"title\": \"Antisemitic Messages? A Guide to High-Quality Annotation and a Labeled  Dataset of Tweets\", \"topic\": \"Hate Speech Detection\", \"x\": 2.823, \"y\": 5.397}, {\"title\": \"Deep Transfer Learning for Automatic Speech Recognition: Towards Better  Generalization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.205, \"y\": 5.4}, {\"title\": \"Understanding Shared Speech-Text Representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.642, \"y\": 5.178}, {\"title\": \"PMC-LLaMA: Towards Building Open-source Language Models for Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.899, \"y\": 8.003}, {\"title\": \"Analyzing Vietnamese Legal Questions Using Deep Neural Networks with  Biaffine Classifiers\", \"topic\": \"Legal NLP\", \"x\": 5.271, \"y\": 5.762}, {\"title\": \"ViMQ: A Vietnamese Medical Question Dataset for Healthcare Dialogue  System Development\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.949, \"y\": 7.613}, {\"title\": \"LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale  Instructions\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.438, \"y\": 2.478}, {\"title\": \"CONSCENDI: A Contrastive and Scenario-Guided Distillation Approach to  Guardrail Models for Virtual Assistants\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.222, \"y\": 3.463}, {\"title\": \"ICE-Score: Instructing Large Language Models to Evaluate Code\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.329, \"y\": 2.585}, {\"title\": \"Entity-Level Sentiment Analysis (ELSA): An exploratory task survey\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.382, \"y\": 6.659}, {\"title\": \"Large Language Models are Strong Zero-Shot Retriever\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.259, \"y\": 4.753}, {\"title\": \"mPLUG-Owl: Modularization Empowers Large Language Models with  Multimodality\", \"topic\": \"Multimodal Language Models\", \"x\": 8.197, \"y\": 7.345}, {\"title\": \"DataComp: In search of the next generation of multimodal datasets\", \"topic\": \"Multimodal Language Models\", \"x\": 8.337, \"y\": 7.271}, {\"title\": \"ChatLog: Carefully Evaluating the Evolution of ChatGPT Across Time\", \"topic\": \"Bias in Language Models\", \"x\": 5.316, \"y\": 4.677}, {\"title\": \"Learning Human-Human Interactions in Images from Weak Textual  Supervision\", \"topic\": \"Multimodal Language Models\", \"x\": 8.778, \"y\": 7.387}, {\"title\": \"Origin Tracing and Detecting of LLMs\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.076, \"y\": 4.592}, {\"title\": \"Understanding the Impact of Culture in Assessing Helpfulness of Online  Reviews\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.767, \"y\": 6.296}, {\"title\": \"BactInt: A domain driven transfer learning approach and a corpus for  extracting inter-bacterial interactions from biomedical text\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.326, \"y\": 7.402}, {\"title\": \"Retrieval-based Knowledge Augmented Vision Language Pre-training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.468, \"y\": 7.541}, {\"title\": \"MasonNLP+ at SemEval-2023 Task 8: Extracting Medical Questions,  Experiences and Claims from Social Media using Knowledge-Augmented  Pre-trained Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.263, \"y\": 7.632}, {\"title\": \"Multi-Party Chat: Conversational Agents in Group Settings with Humans  and Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.175, \"y\": 3.705}, {\"title\": \"Evaluation of GPT-3.5 and GPT-4 for supporting real-world information  needs in healthcare delivery\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.483, \"y\": 8.069}, {\"title\": \"Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.34, \"y\": 4.071}, {\"title\": \"HeySQuAD: A Spoken Question Answering Dataset\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.185, \"y\": 4.983}, {\"title\": \"Using Implicit Feedback to Improve Question Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.177, \"y\": 5.019}, {\"title\": \"A Symmetric Dual Encoding Dense Retrieval Framework for  Knowledge-Intensive Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.068, \"y\": 7.888}, {\"title\": \"From Association to Generation: Text-only Captioning by Unsupervised  Cross-modal Mapping\", \"topic\": \"Multimodal Language Models\", \"x\": 8.966, \"y\": 7.356}, {\"title\": \"Exploring the Curious Case of Code Prompts\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.154, \"y\": 3.143}, {\"title\": \"Sebis at SemEval-2023 Task 7: A Joint System for Natural Language  Inference and Evidence Retrieval from Clinical Trial Reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.613, \"y\": 7.695}, {\"title\": \"LAST: Scalable Lattice-Based Speech Modelling in JAX\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.983, \"y\": 4.625}, {\"title\": \"Intent Induction from Conversations for Task-Oriented Dialogue Track at  DSTC 11\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.363, \"y\": 3.839}, {\"title\": \"Escaping the sentence-level paradigm in machine translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.819, \"y\": 4.398}, {\"title\": \"Out-of-distribution Evidence-aware Fake News Detection via Dual  Adversarial Debiasing\", \"topic\": \"Fake News Detection\", \"x\": 3.97, \"y\": 5.834}, {\"title\": \"State Spaces Aren't Enough: Machine Translation Needs Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.773, \"y\": 3.709}, {\"title\": \"PUNR: Pre-training with User Behavior Modeling for News Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.949, \"y\": 2.919}, {\"title\": \"Explain like I am BM25: Interpreting a Dense Model's Ranked-List with a  Sparse Approximation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.461, \"y\": 4.744}, {\"title\": \"PEFT-Ref: A Modular Reference Architecture and Typology for  Parameter-Efficient Finetuning Techniques\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.953, \"y\": 2.358}, {\"title\": \"Extreme Classification for Answer Type Prediction in Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.722, \"y\": 5.728}, {\"title\": \"Better Question-Answering Models on a Budget\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.168, \"y\": 2.015}, {\"title\": \"AMR Parsing with Instruction Fine-tuned Pre-trained Language Models\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.441, \"y\": 2.38}, {\"title\": \"Enriching Source Code with Contextual Data for Code Completion Models:  An Empirical Study\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.658, \"y\": 2.476}, {\"title\": \"PAXQA: Generating Cross-lingual Question Answering Examples at Training  Scale\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.508, \"y\": 5.175}, {\"title\": \"Generating Post-hoc Explanations for Skip-gram-based Node Embeddings by  Identifying Important Nodes with Bridgeness\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.143, \"y\": 5.926}, {\"title\": \"Benchmarking ChatGPT-4 on ACR Radiation Oncology In-Training (TXIT) Exam  and Red Journal Gray Zone Cases: Potentials and Challenges for AI-Assisted  Medical Education and Decision Making in Radiation Oncology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.752, \"y\": 8.229}, {\"title\": \"Text-to-Audio Generation using Instruction-Tuned LLM and Latent  Diffusion Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.443, \"y\": 5.923}, {\"title\": \"NAIST-SIC-Aligned: an Aligned English-Japanese Simultaneous  Interpretation Corpus\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.887, \"y\": 4.917}, {\"title\": \"Studying the Impact of Semi-Cooperative Drivers on Overall Highway Flow\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.254, \"y\": 2.904}, {\"title\": \"IslamicPCQA: A Dataset for Persian Multi-hop Complex Question Answering  in Islamic Text Resources\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.472, \"y\": 5.33}, {\"title\": \"Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in  Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.695, \"y\": 2.424}, {\"title\": \"Differentiate ChatGPT-generated and Human-written Medical Texts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.502, \"y\": 7.828}, {\"title\": \"Divide and Prompt: Chain of Thought Prompting for Text-to-SQL\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.741, \"y\": 2.481}, {\"title\": \"L3Cube-IndicSBERT: A simple approach for learning cross-lingual sentence  representations using multilingual BERT\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.249, \"y\": 5.085}, {\"title\": \"SAILER: Structure-aware Pre-trained Language Model for Legal Case  Retrieval\", \"topic\": \"Legal NLP\", \"x\": 5.115, \"y\": 5.773}, {\"title\": \"\\\"I'm\\\" Lost in Translation: Pronoun Missteps in Crowdsourced Data Sets\", \"topic\": \"Bias in Language Models\", \"x\": 2.997, \"y\": 4.377}, {\"title\": \"Transcending the \\\"Male Code\\\": Implicit Masculine Biases in NLP Contexts\", \"topic\": \"Bias in Language Models\", \"x\": 3.148, \"y\": 4.393}, {\"title\": \"On the Identification of the Energy related Issues from the App Reviews\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.736, \"y\": 6.557}, {\"title\": \"Generative AI Perceptions: A Survey to Measure the Perceptions of  Faculty, Staff, and Students on Generative AI Tools in Academia\", \"topic\": \"Bias in Language Models\", \"x\": 4.959, \"y\": 4.433}, {\"title\": \"A Group-Specific Approach to NLP for Hate Speech Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.743, \"y\": 5.372}, {\"title\": \"Inducing anxiety in large language models increases exploration and bias\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.838, \"y\": 7.582}, {\"title\": \"ChatABL: Abductive Learning via Natural Language Interaction with  ChatGPT\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.687, \"y\": 2.866}, {\"title\": \"BERT Based Clinical Knowledge Extraction for Biomedical Knowledge Graph  Construction and Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.013, \"y\": 7.645}, {\"title\": \"LEIA: Linguistic Embeddings for the Identification of Affect\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.435, \"y\": 7.425}, {\"title\": \"Which Factors Predict the Chat Experience of a Natural Language  Generation Dialogue Service?\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.275, \"y\": 3.769}, {\"title\": \"ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.679, \"y\": 2.516}, {\"title\": \"IXA/Cogcomp at SemEval-2023 Task 2: Context-enriched Multilingual Named  Entity Recognition using Knowledge Bases\", \"topic\": \"Named Entity Recognition\", \"x\": 7.432, \"y\": 6.741}, {\"title\": \"\\\"HOT\\\" ChatGPT: The promise of ChatGPT in detecting and discriminating  hateful, offensive, and toxic comments on social media\", \"topic\": \"Hate Speech Detection\", \"x\": 2.981, \"y\": 5.188}, {\"title\": \"Emotional Expression Detection in Spoken Language Employing Machine  Learning Algorithms\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.269, \"y\": 7.818}, {\"title\": \"\\\"Can We Detect Substance Use Disorder?\\\": Knowledge and Time Aware  Classification on Social Media from Darkweb\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.323, \"y\": 7.296}, {\"title\": \"GPT-NER: Named Entity Recognition via Large Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 7.306, \"y\": 6.786}, {\"title\": \"Spaiche: Extending State-of-the-Art ASR Models to Swiss German Dialects\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.197, \"y\": 5.378}, {\"title\": \"DropDim: A Regularization Method for Transformer Networks\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.794, \"y\": 3.199}, {\"title\": \"Improving Speech Translation by Cross-Modal Multi-Grained Contrastive  Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.306, \"y\": 5.16}, {\"title\": \"Decouple Non-parametric Knowledge Distillation For End-to-end Speech  Translation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.62, \"y\": 4.09}, {\"title\": \"Exploring Paracrawl for Document-level Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.747, \"y\": 4.547}, {\"title\": \"OLISIA: a Cascade System for Spoken Dialogue State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.535, \"y\": 3.82}, {\"title\": \"Analyzing FOMC Minutes: Accuracy and Constraints of Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.657, \"y\": 6.789}, {\"title\": \"Does Manipulating Tokenization Aid Cross-Lingual Transfer? A Study on  POS Tagging for Non-Standardized Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.265, \"y\": 4.735}, {\"title\": \"On the Independence of Association Bias and Empirical Fairness in  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.357, \"y\": 4.31}, {\"title\": \"Is Cross-modal Information Retrieval Possible without Training?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.324, \"y\": 6.836}, {\"title\": \"Radar de Parit\\u00e9: An NLP system to measure gender representation in  French news stories\", \"topic\": \"Bias in Language Models\", \"x\": 3.099, \"y\": 4.748}, {\"title\": \"Low-resource Bilingual Dialect Lexicon Induction with Large Language  Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.29, \"y\": 4.767}, {\"title\": \"The eBible Corpus: Data and Model Benchmarks for Bible Translation for  Low-Resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.693, \"y\": 4.755}, {\"title\": \"Affective social anthropomorphic intelligent system\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.514, \"y\": 7.851}, {\"title\": \"A Comparison of Semi-Supervised Learning Techniques for Streaming ASR at  Scale\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.154, \"y\": 5.158}, {\"title\": \"Chameleon: Plug-and-Play Compositional Reasoning with Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.363, \"y\": 2.766}, {\"title\": \"Scaling Transformer to 1M tokens and beyond with RMT\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.718, \"y\": 3.228}, {\"title\": \"GeneGPT: Augmenting Large Language Models with Domain Tools for Improved  Access to Biomedical Information\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.239, \"y\": 7.418}, {\"title\": \"MPMQA: Multimodal Question Answering on Product Manuals\", \"topic\": \"Multimodal Language Models\", \"x\": 7.902, \"y\": 7.795}, {\"title\": \"BRENT: Bidirectional Retrieval Enhanced Norwegian Transformer\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.121, \"y\": 4.71}, {\"title\": \"CB-Conformer: Contextual biasing Conformer for biased word recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.312, \"y\": 5.074}, {\"title\": \"Is ChatGPT Equipped with Emotional Dialogue Capabilities?\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.567, \"y\": 7.656}, {\"title\": \"On the Robustness of Aspect-based Sentiment Analysis: Rethinking Model,  Data, and Training\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.09, \"y\": 6.834}, {\"title\": \"SemEval 2023 Task 6: LegalEval - Understanding Legal Texts\", \"topic\": \"Legal NLP\", \"x\": 5.056, \"y\": 5.766}, {\"title\": \"Emotion fusion for mental illness detection from social media: A survey\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.153, \"y\": 7.402}, {\"title\": \"TieFake: Title-Text Similarity and Emotion-Aware Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 3.948, \"y\": 5.983}, {\"title\": \"How to Do Things with Deep Learning Code\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.419, \"y\": 2.663}, {\"title\": \"An Empirical Study of Leveraging Knowledge Distillation for Compressing  Multilingual Neural Machine Translation Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.436, \"y\": 3.836}, {\"title\": \"Token Imbalance Adaptation for Radiology Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.242, \"y\": 8.646}, {\"title\": \"Outlier Suppression+: Accurate quantization of large language models by  equivalent and optimal shifting and scaling\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.797, \"y\": 2.169}, {\"title\": \"Exploring the Trade-Offs: Unified Large Language Models vs Local  Fine-Tuned Models for Highly-Specific Radiology NLI Task\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.9, \"y\": 8.227}, {\"title\": \"NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot  Speech and Singing Synthesizers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.603, \"y\": 5.932}, {\"title\": \"CodeKGC: Code Language Model for Generative Knowledge Graph Construction\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.999, \"y\": 5.672}, {\"title\": \"A Biomedical Entity Extraction Pipeline for Oncology Health Records in  Portuguese\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.009, \"y\": 7.686}, {\"title\": \"MER 2023: Multi-label Learning, Modality Robustness, and Semi-Supervised  Learning\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.235, \"y\": 7.625}, {\"title\": \"Enhancing Textbooks with Visuals from the Web for Improved Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.592, \"y\": 6.996}, {\"title\": \"Romanization-based Large-scale Adaptation of Multilingual Language  Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.359, \"y\": 4.483}, {\"title\": \"Approximate Nearest Neighbour Phrase Mining for Contextual Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.342, \"y\": 5.055}, {\"title\": \"Transfer to a Low-Resource Language via Close Relatives: The Case Study  on Faroese\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.451, \"y\": 4.873}, {\"title\": \"Speaker Profiling in Multiparty Conversations\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.051, \"y\": 3.861}, {\"title\": \"A Survey for Biomedical Text Summarization: From Pre-trained to Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.696, \"y\": 7.295}, {\"title\": \"CancerGPT: Few-shot Drug Pair Synergy Prediction using Large Pre-trained  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.264, \"y\": 7.948}, {\"title\": \"Comparative study on Judgment Text Classification for Transformer Based  Models\", \"topic\": \"Legal NLP\", \"x\": 5.095, \"y\": 5.81}, {\"title\": \"Classification of US Supreme Court Cases using BERT-Based Techniques\", \"topic\": \"Legal NLP\", \"x\": 5.12, \"y\": 5.778}, {\"title\": \"Effectiveness of Debiasing Techniques: An Indigenous Qualitative  Analysis\", \"topic\": \"Bias in Language Models\", \"x\": 3.401, \"y\": 4.362}, {\"title\": \"Visual Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.386, \"y\": 7.478}, {\"title\": \"DisCo-CLIP: A Distributed Contrastive Loss for Memory Efficient CLIP  Training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.957, \"y\": 7.096}, {\"title\": \"Learning to Compress Prompts with Gist Tokens\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.798, \"y\": 3.226}, {\"title\": \"LongForm: Effective Instruction Tuning with Reverse Instructions\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.114, \"y\": 2.337}, {\"title\": \"Improving Autoregressive NLP Tasks via Modular Linearized Attention\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.919, \"y\": 3.234}, {\"title\": \"An Iterative Optimizing Framework for Radiology Report Summarization  with ChatGPT\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.079, \"y\": 8.536}, {\"title\": \"VALOR: Vision-Audio-Language Omni-Perception Pretraining Model and  Dataset\", \"topic\": \"Multimodal Language Models\", \"x\": 8.578, \"y\": 7.419}, {\"title\": \"Use of social media and Natural Language Processing (NLP) in natural  hazard research\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.179, \"y\": 6.725}, {\"title\": \"Interactive and Explainable Region-guided Radiology Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.233, \"y\": 8.643}, {\"title\": \"Context-Dependent Embedding Utterance Representations for Emotion  Recognition in Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.299, \"y\": 7.78}, {\"title\": \"VECO 2.0: Cross-lingual Language Model Pre-training with  Multi-granularity Contrastive Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.353, \"y\": 4.957}, {\"title\": \"Political corpus creation through automatic speech recognition on EU  debates\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.145, \"y\": 5.623}, {\"title\": \"An Empirical Study of Multitask Learning to Improve Open Domain Dialogue  Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.559, \"y\": 3.818}, {\"title\": \"A Comparative Study between Full-Parameter and LoRA-based Fine-Tuning on  Chinese Instruction Data for Instruction Following Large Language Model\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.473, \"y\": 2.45}, {\"title\": \"Low-code LLM: Graphical User Interface over Large Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.771, \"y\": 2.74}, {\"title\": \"From Zero to Hero: Examining the Power of Symbolic Tasks in Instruction  Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.277, \"y\": 2.305}, {\"title\": \"Chinese Open Instruction Generalist: A Preliminary Release\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.262, \"y\": 2.398}, {\"title\": \"Sabi\\u00e1: Portuguese Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.113, \"y\": 4.283}, {\"title\": \"Neural Machine Translation For Low Resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.811, \"y\": 4.46}, {\"title\": \"ChatPLUG: Open-Domain Generative Dialogue System with Internet-Augmented  Instruction Tuning for Digital Human\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.571, \"y\": 4.078}, {\"title\": \"EasyNER: A Customizable Easy-to-Use Pipeline for Deep Learning- and  Dictionary-based Named Entity Recognition from Medical Text\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.323, \"y\": 7.503}, {\"title\": \"It's All in the Embedding! Fake News Detection Using Document Embeddings\", \"topic\": \"Fake News Detection\", \"x\": 3.96, \"y\": 5.717}, {\"title\": \"MisRoB\\u00c6RTa: Transformers versus Misinformation\", \"topic\": \"Fake News Detection\", \"x\": 4.02, \"y\": 5.846}, {\"title\": \"Fairness in AI and Its Long-Term Implications on Society\", \"topic\": \"Bias in Language Models\", \"x\": 3.807, \"y\": 4.205}, {\"title\": \"Solving Math Word Problems by Combining Language Models With Symbolic  Solvers\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.05, \"y\": 2.773}, {\"title\": \"Interpretable Detection of Out-of-Context Misinformation with  Neural-Symbolic-Enhanced Large Multimodal Model\", \"topic\": \"Fake News Detection\", \"x\": 4.108, \"y\": 5.968}, {\"title\": \"Evaluation of Speaker Anonymization on Emotional Speech\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.239, \"y\": 7.841}, {\"title\": \"Can ChatGPT Forecast Stock Price Movements? Return Predictability and  Large Language Models\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.643, \"y\": 6.839}, {\"title\": \"A CTC Alignment-based Non-autoregressive Transformer for End-to-end  Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.08, \"y\": 5.102}, {\"title\": \"Medical Question Summarization with Entity-driven Contrastive Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.978, \"y\": 7.572}, {\"title\": \"Improving Patient Pre-screening for Clinical Trials: Assisting  Physicians with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.728, \"y\": 7.989}, {\"title\": \"Mapping of attention mechanisms to a generalized Potts model\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.747, \"y\": 3.382}, {\"title\": \"ChatGPT: Applications, Opportunities, and Threats\", \"topic\": \"Bias in Language Models\", \"x\": 5.007, \"y\": 4.579}, {\"title\": \"Just Tell Me: Prompt Engineering in Business Process Management\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.192, \"y\": 3.319}, {\"title\": \"OPI at SemEval 2023 Task 1: Image-Text Embeddings and Multimodal  Information Retrieval for Visual Word Sense Disambiguation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.454, \"y\": 7.309}, {\"title\": \"Task-oriented Document-Grounded Dialog Systems by HLTPR@RWTH for DSTC9  and DSTC10\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.587, \"y\": 3.895}, {\"title\": \"MedAlpaca -- An Open-Source Collection of Medical Conversational AI  Models and Training Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.789, \"y\": 7.992}, {\"title\": \"Dialogue Games for Benchmarking Language Understanding: Motivation,  Taxonomy, Strategy\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.427, \"y\": 3.224}, {\"title\": \"HuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.878, \"y\": 7.986}, {\"title\": \"Multimodal C4: An Open, Billion-scale Corpus of Images Interleaved with  Text\", \"topic\": \"Multimodal Language Models\", \"x\": 8.346, \"y\": 7.162}, {\"title\": \"HCAM -- Hierarchical Cross Attention Model for Multi-modal Emotion  Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.231, \"y\": 7.808}, {\"title\": \"Evaluation of Social Biases in Recent Large Pre-Trained Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.312, \"y\": 4.365}, {\"title\": \"On the Opportunities and Challenges of Foundation Models for Geospatial  Artificial Intelligence\", \"topic\": \"Multimodal Language Models\", \"x\": 7.956, \"y\": 7.122}, {\"title\": \"Efficient Sequence Transduction by Jointly Predicting Tokens and  Durations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.098, \"y\": 4.87}, {\"title\": \"RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.249, \"y\": 1.452}, {\"title\": \"Verbs in Action: Improving verb understanding in video-language models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.885, \"y\": 7.88}, {\"title\": \"Diagnostic Benchmark and Iterative Inpainting for Layout-Guided Image  Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.65, \"y\": 6.75}, {\"title\": \"PGTask: Introducing the Task of Profile Generation from Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.204, \"y\": 3.73}, {\"title\": \"Exploring the State of the Art in Legal QA Systems\", \"topic\": \"Legal NLP\", \"x\": 5.396, \"y\": 5.613}, {\"title\": \"Are LLMs All You Need for Task-Oriented Dialogue?\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.616, \"y\": 3.662}, {\"title\": \"PDFVQA: A New Dataset for Real-World VQA on PDF Documents\", \"topic\": \"Multimodal Language Models\", \"x\": 7.848, \"y\": 7.795}, {\"title\": \"SpectFormer: Frequency and Attention is what you need in a Vision  Transformer\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.906, \"y\": 3.386}, {\"title\": \"LeafAI: query generator for clinical cohort discovery rivaling a human  programmer\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.778, \"y\": 7.775}, {\"title\": \"Using Large Language Models for (De-)Formalization and Natural  Argumentation Exercises for Beginner's Students\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.168, \"y\": 3.083}, {\"title\": \"LINGO : Visually Debiasing Natural Language Instructions to Support Task  Diversity\", \"topic\": \"Bias in Language Models\", \"x\": 3.27, \"y\": 4.529}, {\"title\": \"Textual Explanations for Automated Commentary Driving\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.752, \"y\": 3.833}, {\"title\": \"HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented  Prompting\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.251, \"y\": 7.813}, {\"title\": \"Boosted Prompt Ensembles for Large Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.289, \"y\": 3.271}, {\"title\": \"ReDWINE: A Clinical Datamart with Text Analytical Capabilities to  Facilitate Rehabilitation Research\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.734, \"y\": 7.759}, {\"title\": \"Learning Homographic Disambiguation Representation for Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.527, \"y\": 4.801}, {\"title\": \"Measuring Gender Bias in West Slavic Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.182, \"y\": 4.498}, {\"title\": \"Measuring Normative and Descriptive Biases in Language Models Using  Census Data\", \"topic\": \"Bias in Language Models\", \"x\": 3.406, \"y\": 4.382}, {\"title\": \"Global Prompt Cell: A Portable Control Module for Effective Prompt  Tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.686, \"y\": 3.303}, {\"title\": \"Distinguishing ChatGPT(-3.5, -4)-generated and human-written papers  through Japanese stylometric analysis\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.353, \"y\": 4.808}, {\"title\": \"MoMo: A shared encoder Model for text, image and multi-Modal  representations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.46, \"y\": 7.201}, {\"title\": \"Improving Items and Contexts Understanding with Descriptive Graph for  Conversational Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.948, \"y\": 3.029}, {\"title\": \"ELVIS: Empowering Locality of Vision Language Pre-training with  Intra-modal Similarity\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.455, \"y\": 8.51}, {\"title\": \"RRHF: Rank Responses to Align Language Models with Human Feedback  without tears\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.23, \"y\": 1.46}, {\"title\": \"An Entity-based Claim Extraction Pipeline for Real-world Biomedical  Fact-checking\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.975, \"y\": 7.317}, {\"title\": \"Approximating Online Human Evaluation of Social Chatbots with Prompting\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.088, \"y\": 3.59}, {\"title\": \"LBMT team at VLSP2022-Abmusu: Hybrid method with text correlation and  generative models for Vietnamese multi-document summarization\", \"topic\": \"Text Summarization\", \"x\": 5.612, \"y\": 6.402}, {\"title\": \"Teaching Large Language Models to Self-Debug\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.14, \"y\": 2.309}, {\"title\": \"FashionSAP: Symbols and Attributes Prompt for Fine-grained Fashion  Vision-Language Pre-training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.544, \"y\": 6.884}, {\"title\": \"What Food Do We Tweet about on a Rainy Day?\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.048, \"y\": 6.577}, {\"title\": \"Towards an Understanding and Explanation for Mixed-Initiative Artificial  Scientific Text Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.298, \"y\": 4.751}, {\"title\": \"Sim-T: Simplify the Transformer Network by Multiplexing Technique for  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.083, \"y\": 4.83}, {\"title\": \"DISTO: Evaluating Textual Distractors for Multi-Choice Questions using  Negative Sampling based Approach\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.242, \"y\": 4.882}, {\"title\": \"Generative Knowledge Selection for Knowledge-Grounded Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.74, \"y\": 4.07}, {\"title\": \"On the Possibilities of AI-Generated Text Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.135, \"y\": 4.727}, {\"title\": \"Prompt Pre-Training with Twenty-Thousand Classes for Open-Vocabulary  Visual Recognition\", \"topic\": \"Multimodal Language Models\", \"x\": 8.615, \"y\": 6.924}, {\"title\": \"Transfer Learning for Low-Resource Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.496, \"y\": 6.575}, {\"title\": \"Multilingual Machine Translation with Large Language Models: Empirical  Results and Analysis\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.47, \"y\": 4.339}, {\"title\": \"Enhancing Speech-to-Speech Translation with Multiple TTS Targets\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.378, \"y\": 5.295}, {\"title\": \"ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.306, \"y\": 5.228}, {\"title\": \"UATTA-EB: Uncertainty-Aware Test-Time Augmented Ensemble of BERTs for  Classifying Common Mental Illnesses on Social Media Posts\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.221, \"y\": 7.428}, {\"title\": \"Oh, Jeez! or Uh-huh? A Listener-aware Backchannel Predictor on ASR  Transcriptions\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.903, \"y\": 5.346}, {\"title\": \"Modeling Speaker-Listener Interaction for Backchannel Prediction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.758, \"y\": 5.324}, {\"title\": \"The Wall Street Neophyte: A Zero-Shot Analysis of ChatGPT Over  MultiModal Stock Movement Prediction Challenges\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.64, \"y\": 6.833}, {\"title\": \"Are Large Language Models Ready for Healthcare? A Comparative Study on  Clinical Language Understanding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.712, \"y\": 7.982}, {\"title\": \"A Preliminary Evaluation of ChatGPT for Zero-shot Dialogue Understanding\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.567, \"y\": 4.339}, {\"title\": \"Editable User Profiles for Controllable Text Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.885, \"y\": 3.013}, {\"title\": \"RISC: Generating Realistic Synthetic Bilingual Insurance Contract\", \"topic\": \"Legal NLP\", \"x\": 5.467, \"y\": 5.829}, {\"title\": \"Extractive Summarization via ChatGPT for Faithful Summary Generation\", \"topic\": \"Text Summarization\", \"x\": 5.507, \"y\": 6.074}, {\"title\": \"Similarity-Aware Multimodal Prompt Learning for Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.032, \"y\": 5.962}, {\"title\": \"Can ChatGPT and Bard Generate Aligned Assessment Items? A Reliability  Analysis against Human Performance\", \"topic\": \"Bias in Language Models\", \"x\": 5.087, \"y\": 4.598}, {\"title\": \"An investigation of speaker independent phrase break models in  End-to-End TTS systems\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.497, \"y\": 5.639}, {\"title\": \"Hi Sheldon! Creating Deep Personalized Characters from TV Shows\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.052, \"y\": 3.787}, {\"title\": \"Multi-class Categorization of Reasons behind Mental Disturbance in Long  Texts\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.205, \"y\": 7.413}, {\"title\": \"Interpretable Multi Labeled Bengali Toxic Comments Classification using  Deep Learning\", \"topic\": \"Hate Speech Detection\", \"x\": 2.924, \"y\": 5.231}, {\"title\": \"Bipol: A Novel Multi-Axes Bias Evaluation Metric with Explainability for  NLP\", \"topic\": \"Bias in Language Models\", \"x\": 3.176, \"y\": 4.571}, {\"title\": \"WikiGoldSK: Annotated Dataset, Baselines and Few-Shot Learning  Experiments for Slovak Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.386, \"y\": 6.694}, {\"title\": \"MphayaNER: Named Entity Recognition for Tshivenda\", \"topic\": \"Named Entity Recognition\", \"x\": 7.391, \"y\": 6.819}, {\"title\": \"An Empirical Study and Improvement for Speech Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.212, \"y\": 7.729}, {\"title\": \"Why think step by step? Reasoning emerges from the locality of  experience\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.765, \"y\": 2.447}, {\"title\": \"Should ChatGPT be Biased? Challenges and Risks of Bias in Large Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.795, \"y\": 4.279}, {\"title\": \"Gated Mechanism Enhanced Multi-Task Learning for Dialog Routing\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.575, \"y\": 3.716}, {\"title\": \"On the Importance of Contrastive Loss in Multimodal Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.495, \"y\": 6.978}, {\"title\": \"Revisiting Automated Prompting: Are We Actually Doing Better?\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.375, \"y\": 3.184}, {\"title\": \"ArmanTTS single-speaker Persian dataset\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.353, \"y\": 5.648}, {\"title\": \"Profiling the news spreading barriers using news headlines\", \"topic\": \"Fake News Detection\", \"x\": 4.026, \"y\": 5.895}, {\"title\": \"GEMINI: Controlling the Sentence-level Writing Style for Abstractive  Text Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.656, \"y\": 6.099}, {\"title\": \"Linking Representations with Multimodal Contrastive Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.558, \"y\": 7.004}, {\"title\": \"Using LSTM and GRU With a New Dataset for Named Entity Recognition in  the Arabic Language\", \"topic\": \"Named Entity Recognition\", \"x\": 7.401, \"y\": 6.844}, {\"title\": \"Deep Learning for Opinion Mining and Topic Classification of Course  Reviews\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.554, \"y\": 6.654}, {\"title\": \"ChatGPT-Crawler: Find out if ChatGPT really knows what it's talking  about\", \"topic\": \"Bias in Language Models\", \"x\": 5.095, \"y\": 4.579}, {\"title\": \"Instruction Tuning with GPT-4\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.065, \"y\": 2.372}, {\"title\": \"Large language models effectively leverage document-level context for  literary translation, but critical errors persist\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.664, \"y\": 4.452}, {\"title\": \"On the Pareto Front of Multilingual Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.77, \"y\": 4.467}, {\"title\": \"Bridging the Language Gap: Knowledge Injected Multilingual Question  Answering\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.185, \"y\": 4.765}, {\"title\": \"Zero-Shot Next-Item Recommendation using Large Pretrained Language  Models\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.894, \"y\": 2.89}, {\"title\": \"Evaluating the Robustness of Machine Reading Comprehension Models to Low  Resource Entity Renaming\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.445, \"y\": 5.058}, {\"title\": \"Natural Language Robot Programming: NLP integrated with autonomous  robotic grasping\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.915, \"y\": 2.598}, {\"title\": \"SpanRE: Entities and Overlapping Relations Extraction Based on Spans and  Entity Attention\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.947, \"y\": 6.816}, {\"title\": \"Affect as a proxy for literary mood\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.601, \"y\": 7.319}, {\"title\": \"Automatic ICD-10 Code Association: A Challenging Task on French Clinical  Texts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.952, \"y\": 8.433}, {\"title\": \"GPT detectors are biased against non-native English writers\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.216, \"y\": 4.686}, {\"title\": \"Context-Aware Classification of Legal Document Pages\", \"topic\": \"Legal NLP\", \"x\": 5.383, \"y\": 5.914}, {\"title\": \"Application of Transformers based methods in Electronic Medical Records:  A Systematic Literature Review\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.521, \"y\": 7.45}, {\"title\": \"To Asymmetry and Beyond: Structured Pruning of Sequence to Sequence  Models for Improved Inference Efficiency\", \"topic\": \"Text Summarization\", \"x\": 9.626, \"y\": 2.507}, {\"title\": \"Human-like Summarization Evaluation with ChatGPT\", \"topic\": \"Text Summarization\", \"x\": 5.403, \"y\": 6.124}, {\"title\": \"Evaluation of ChatGPT Family of Models for Biomedical Reasoning and  Classification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.706, \"y\": 7.714}, {\"title\": \"On the Impact of Voice Anonymization on Speech Diagnostic Applications:  a Case Study on COVID-19 Detection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 4.782, \"y\": 7.92}, {\"title\": \"Geotechnical Parrot Tales (GPT): Harnessing Large Language Models in  geotechnical engineering\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.134, \"y\": 3.384}, {\"title\": \"Scalable and Accurate Self-supervised Multimodal Representation Learning  without Aligned Video and Text Data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.976, \"y\": 7.418}, {\"title\": \"Effective Theory of Transformers at Initialization\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.746, \"y\": 3.353}, {\"title\": \"Dialogue-Contextualized Re-ranking for Medical History-Taking\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.537, \"y\": 8.01}, {\"title\": \"LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of  Large Language Models\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.995, \"y\": 2.415}, {\"title\": \"REFINER: Reasoning Feedback on Intermediate Representations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.657, \"y\": 2.424}, {\"title\": \"Sociocultural knowledge is needed for selection of shots in hate speech  detection tasks\", \"topic\": \"Hate Speech Detection\", \"x\": 2.768, \"y\": 5.362}, {\"title\": \"Cross-Domain Image Captioning with Discriminative Finetuning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.082, \"y\": 7.384}, {\"title\": \"An interpretability framework for Similar case matching\", \"topic\": \"Legal NLP\", \"x\": 5.175, \"y\": 5.757}, {\"title\": \"One Small Step for Generative AI, One Giant Leap for AGI: A Complete  Survey on ChatGPT in AIGC Era\", \"topic\": \"Bias in Language Models\", \"x\": 5.081, \"y\": 4.389}, {\"title\": \"A Unified Contrastive Transfer Framework with Propagation Structure for  Boosting Low-Resource Rumor Detection\", \"topic\": \"Fake News Detection\", \"x\": 3.971, \"y\": 5.913}, {\"title\": \"To ChatGPT, or not to ChatGPT: That is the question!\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.399, \"y\": 4.655}, {\"title\": \"The StatCan Dialogue Dataset: Retrieving Data Tables through  Conversations with Genuine Intents\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.241, \"y\": 4.109}, {\"title\": \"A Simple and Effective Method of Cross-Lingual Plagiarism Detection\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.149, \"y\": 4.986}, {\"title\": \"Grand Challenge On Detecting Cheapfakes\", \"topic\": \"Fake News Detection\", \"x\": 4.143, \"y\": 5.852}, {\"title\": \"PEACH: Pre-Training Sequence-to-Sequence Multilingual Models for  Translation with Semi-Supervised Pseudo-Parallel Document Generation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.828, \"y\": 4.782}, {\"title\": \"Hate Speech Targets Detection in Parler using BERT\", \"topic\": \"Hate Speech Detection\", \"x\": 2.687, \"y\": 5.436}, {\"title\": \"DoctorGLM: Fine-tuning your Chinese Doctor is not a Herculean Task\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.668, \"y\": 8.137}, {\"title\": \"RPTQ: Reorder-based Post-training Quantization for Large Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.673, \"y\": 2.127}, {\"title\": \"Simple Yet Effective Neural Ranking and Reranking Baselines for  Cross-Lingual Information Retrieval\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.095, \"y\": 4.831}, {\"title\": \"Does Human Collaboration Enhance the Accuracy of Identifying  LLM-Generated Deepfake Texts?\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.301, \"y\": 4.713}, {\"title\": \"DrBERT: A Robust Pre-trained Model in French for Biomedical and Clinical  domains\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.14, \"y\": 7.957}, {\"title\": \"Enhancing Clinical Evidence Recommendation with Multi-Channel  Heterogeneous Learning on Evidence Graphs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.899, \"y\": 7.722}, {\"title\": \"Detection of Homophobia & Transphobia in Dravidian Languages: Exploring  Deep Learning Methods\", \"topic\": \"Hate Speech Detection\", \"x\": 2.746, \"y\": 5.553}, {\"title\": \"LAHM : Large Annotated Dataset for Multi-Domain and Multilingual Hate  Speech Identification\", \"topic\": \"Hate Speech Detection\", \"x\": 2.781, \"y\": 5.398}, {\"title\": \"Dialog-to-Actions: Building Task-Oriented Dialogue System via  Action-Level Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.496, \"y\": 3.7}, {\"title\": \"Spam-T5: Benchmarking Large Language Models for Few-Shot Email Spam  Detection\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.054, \"y\": 4.778}, {\"title\": \"AUDIT: Audio Editing by Following Instructions with Latent Diffusion  Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.471, \"y\": 6.062}, {\"title\": \"Towards Integration of Discriminability and Robustness for  Document-Level Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.968, \"y\": 6.793}, {\"title\": \"Benchmarking Faithfulness: Towards Accurate Natural Language  Explanations in Vision-Language Tasks\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.869, \"y\": 3.81}, {\"title\": \"Multi-Modal Perceiver Language Model for Outcome Prediction in Emergency  Department\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.936, \"y\": 8.423}, {\"title\": \"Dual-Attention Neural Transducers for Efficient Wake Word Spotting in  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.28, \"y\": 5.002}, {\"title\": \"Multilingual Word Error Rate Estimation: e-WER3\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.983, \"y\": 5.472}, {\"title\": \"Eight Things to Know about Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.447, \"y\": 3.942}, {\"title\": \"PK-Chat: Pointer Network Guided Knowledge Driven Generative Dialogue  Model\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.53, \"y\": 4.105}, {\"title\": \"Semi-supervised Neural Machine Translation with Consistency  Regularization for Low-Resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.95, \"y\": 4.543}, {\"title\": \"Better Language Models of Code through Self-Improvement\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.582, \"y\": 2.431}, {\"title\": \"LLMMaps -- A Visual Metaphor for Stratified Evaluation of Large Language  Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.004, \"y\": 3.88}, {\"title\": \"When Crowd Meets Persona: Creating a Large-Scale Open-Domain Persona  Dialogue Corpus\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.163, \"y\": 3.813}, {\"title\": \"Evaluating Large Language Models on a Highly-specialized Topic,  Radiation Oncology Physics\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.87, \"y\": 8.183}, {\"title\": \"Inductive Relation Prediction from Relational Paths and Context with  Hierarchical Transformers\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.084, \"y\": 6.173}, {\"title\": \"FCC: Fusing Conversation History and Candidate Provenance for Contextual  Response Ranking in Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.681, \"y\": 3.993}, {\"title\": \"Lego-Features: Exporting modular encoder features for streaming and  deliberation ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.037, \"y\": 5.077}, {\"title\": \"Practical Conformer: Optimizing size, speed and flops of Conformer for  on-Device and cloud ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.269, \"y\": 4.968}, {\"title\": \"Extracting Thyroid Nodules Characteristics from Ultrasound Reports Using  Transformer-based Natural Language Processing Methods\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.669, \"y\": 8.111}, {\"title\": \"Dense Sparse Retrieval: Using Sparse Language Models for Inference  Efficient Dense Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.619, \"y\": 4.866}, {\"title\": \"Identifying Symptoms of Delirium from Clinical Narratives Using Natural  Language Processing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.06, \"y\": 7.858}, {\"title\": \"Self-Supervised Multimodal Learning: A Survey\", \"topic\": \"Multimodal Language Models\", \"x\": 8.017, \"y\": 7.256}, {\"title\": \"Quick Dense Retrievers Consume KALE: Post Training Kullback Leibler  Alignment of Embeddings for Asymmetrical dual encoders\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.633, \"y\": 4.965}, {\"title\": \"CQSumDP: A ChatGPT-Annotated Resource for Query-Focused Abstractive  Summarization Based on Debatepedia\", \"topic\": \"Text Summarization\", \"x\": 5.524, \"y\": 5.957}, {\"title\": \"Can AI Chatbots Pass the Fundamentals of Engineering (FE) and Principles  and Practice of Engineering (PE) Structural Exams?\", \"topic\": \"Bias in Language Models\", \"x\": 5.157, \"y\": 4.479}, {\"title\": \"UKP-SQuARE v3: A Platform for Multi-Agent QA Research\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.374, \"y\": 5.137}, {\"title\": \"The Edinburgh International Accents of English Corpus: Towards the  Democratization of English ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.979, \"y\": 5.582}, {\"title\": \"No Place to Hide: Dual Deep Interaction Channel Network for Fake News  Detection based on Data Augmentation\", \"topic\": \"Fake News Detection\", \"x\": 3.956, \"y\": 5.907}, {\"title\": \"Evaluating GPT-4 and ChatGPT on Japanese Medical Licensing Examinations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.624, \"y\": 7.821}, {\"title\": \"Exploiting Multilingualism in Low-resource Neural Machine Translation  via Adversarial Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.819, \"y\": 4.614}, {\"title\": \"$\\\\varepsilon$ K\\u00da <MASK>: Integrating Yor\\u00f9b\\u00e1 cultural greetings  into machine translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.895, \"y\": 4.765}, {\"title\": \"Cross-Cultural Transfer Learning for Chinese Offensive Language  Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.824, \"y\": 5.293}, {\"title\": \"Selective Knowledge Distillation for Non-Autoregressive Neural Machine  Translation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.434, \"y\": 4.029}, {\"title\": \"Learning Procedure-aware Video Representation from Instructional Videos  and Their Narrations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.924, \"y\": 7.727}, {\"title\": \"Zero-shot Referring Image Segmentation with Global-Local Context  Features\", \"topic\": \"Multimodal Language Models\", \"x\": 8.85, \"y\": 7.147}, {\"title\": \"GPT-4 can pass the Korean National Licensing Examination for Korean  Medicine Doctors\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.701, \"y\": 8.028}, {\"title\": \"Dialog act guided contextual adapter for personalized speech recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.217, \"y\": 5.041}, {\"title\": \"CAMEL: Communicative Agents for \\\"Mind\\\" Exploration of Large Language  Model Society\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.145, \"y\": 3.049}, {\"title\": \"Evaluation of GPT and BERT-based models on identifying protein-protein  interactions in biomedical text\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.471, \"y\": 7.353}, {\"title\": \"Task Oriented Conversational Modelling With Subjective Knowledge\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.641, \"y\": 4.006}, {\"title\": \"Fine-Tuning BERT with Character-Level Noise for Zero-Shot Transfer to  Dialects and Closely-Related Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.302, \"y\": 4.671}, {\"title\": \"Unsupervised Word Segmentation Using Temporal Gradient Pseudo-Labels\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.743, \"y\": 5.047}, {\"title\": \"Going Beyond Nouns With Vision & Language Models Using Synthetic Data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.631, \"y\": 7.375}, {\"title\": \"Elastic Weight Removal for Faithful and Abstractive Dialogue Generation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.278, \"y\": 1.196}, {\"title\": \"BloombergGPT: A Large Language Model for Finance\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.846, \"y\": 6.907}, {\"title\": \"P-Transformer: A Prompt-based Multimodal Transformer Architecture For  Medical Tabular Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.977, \"y\": 8.376}, {\"title\": \"Social Biases through the Text-to-Image Generation Lens\", \"topic\": \"Bias in Language Models\", \"x\": 3.299, \"y\": 4.488}, {\"title\": \"TLAG: An Informative Trigger and Label-Aware Knowledge Guided Model for  Dialogue-based Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.613, \"y\": 6.439}, {\"title\": \"QUADRo: Dataset and Models for QUestion-Answer Database Retrieval\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.632, \"y\": 5.289}, {\"title\": \"DERA: Enhancing Large Language Model Completions with Dialog-Enabled  Resolving Agents\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.563, \"y\": 8.186}, {\"title\": \"How do decoding algorithms distribute information in dialogue responses?\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.54, \"y\": 3.995}, {\"title\": \"Adapting to the Low-Resource Double-Bind: Investigating Low-Compute  Methods on Low-Resource African Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.34, \"y\": 4.748}, {\"title\": \"ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding with  GPT and Prototype Guidance\", \"topic\": \"Multimodal Language Models\", \"x\": 8.785, \"y\": 7.351}, {\"title\": \"End-to-End $n$-ary Relation Extraction for Combination Drug Therapies\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.261, \"y\": 7.5}, {\"title\": \"MaMMUT: A Simple Architecture for Joint Learning for MultiModal Tasks\", \"topic\": \"Multimodal Language Models\", \"x\": 8.515, \"y\": 7.269}, {\"title\": \"Using Semantic Similarity and Text Embedding to Measure the Social Media  Echo of Strategic Communications\", \"topic\": \"Fake News Detection\", \"x\": 3.637, \"y\": 5.717}, {\"title\": \"AraSpot: Arabic Spoken Command Spotting\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.82, \"y\": 5.444}, {\"title\": \"Reference-less Analysis of Context Specificity in Translation with  Personalised Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.672, \"y\": 4.261}, {\"title\": \"LMExplainer: a Knowledge-Enhanced Explainer for Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.935, \"y\": 3.731}, {\"title\": \"Multimodal Image-Text Matching Improves Retrieval-based Chest X-Ray  Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.241, \"y\": 8.646}, {\"title\": \"Improving Large Language Models for Clinical Named Entity Recognition  via Prompt Engineering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.972, \"y\": 7.971}, {\"title\": \"Hierarchical Video-Moment Retrieval and Step-Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.922, \"y\": 7.854}, {\"title\": \"A \\\"Perspectival\\\" Mirror of the Elephant: Investigating Language Bias on  Google, ChatGPT, YouTube, and Wikipedia\", \"topic\": \"Bias in Language Models\", \"x\": 3.49, \"y\": 4.708}, {\"title\": \"Zero-Shot Generalizable End-to-End Task-Oriented Dialog System using  Context Summarization and Domain Schema\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.628, \"y\": 3.801}, {\"title\": \"Towards Countering Essentialism through Social Bias Reasoning\", \"topic\": \"Bias in Language Models\", \"x\": 3.216, \"y\": 4.733}, {\"title\": \"Hallucinations in Large Multilingual Translation Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.161, \"y\": 1.064}, {\"title\": \"Soft-prompt tuning to predict lung cancer using primary care free-text  Dutch medical notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.016, \"y\": 8.343}, {\"title\": \"How can Deep Learning Retrieve the Write-Missing Additional Diagnosis  from Chinese Electronic Medical Record For DRG\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.864, \"y\": 8.38}, {\"title\": \"Evaluation of ChatGPT for NLP-based Mental Health Applications\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.351, \"y\": 7.585}, {\"title\": \"Comparative Analysis of CHATGPT and the evolution of language models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.097, \"y\": 4.065}, {\"title\": \"Model and Evaluation: Towards Fairness in Multilingual Text  Classification\", \"topic\": \"Bias in Language Models\", \"x\": 3.334, \"y\": 4.308}, {\"title\": \"Pre-training Transformers for Knowledge Graph Completion\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.116, \"y\": 6.037}, {\"title\": \"Joint embedding in Hierarchical distance and semantic representation  learning for link prediction\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.127, \"y\": 6.078}, {\"title\": \"Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.883, \"y\": 2.424}, {\"title\": \"Unlocking the Potential of ChatGPT: A Comprehensive Exploration of its  Applications, Advantages, Limitations, and Future Directions in Natural  Language Processing\", \"topic\": \"Bias in Language Models\", \"x\": 4.992, \"y\": 4.538}, {\"title\": \"Zero-shot Model Diagnosis\", \"topic\": \"Multimodal Language Models\", \"x\": 8.482, \"y\": 7.729}, {\"title\": \"TextMI: Textualize Multimodal Information for Integrating Non-verbal  Cues in Pre-trained Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.25, \"y\": 7.129}, {\"title\": \"Bilex Rx: Lexical Data Augmentation for Massively Multilingual Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.686, \"y\": 4.718}, {\"title\": \"Zero-Shot Composed Image Retrieval with Textual Inversion\", \"topic\": \"Multimodal Language Models\", \"x\": 8.745, \"y\": 7.089}, {\"title\": \"Troika: Multi-Path Cross-Modal Traction for Compositional Zero-Shot  Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.626, \"y\": 7.119}, {\"title\": \"CoCon: A Data Set on Combined Contextualized Research Artifact Use\", \"topic\": \"Text Summarization\", \"x\": 5.859, \"y\": 6.27}, {\"title\": \"Evaluating self-attention interpretability through human-grounded  experimental protocol\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.741, \"y\": 3.517}, {\"title\": \"Cross-utterance ASR Rescoring with Graph-based Label Propagation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.193, \"y\": 5.347}, {\"title\": \"An ontology-aided, natural language-based approach for multi-constraint  BIM model querying\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.892, \"y\": 5.453}, {\"title\": \"Curriculum Learning for Compositional Visual Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.383, \"y\": 7.894}, {\"title\": \"unarXive 2022: All arXiv Publications Pre-Processed for NLP, Including  Structured Full-Text and Citation Network\", \"topic\": \"Text Summarization\", \"x\": 5.946, \"y\": 6.207}, {\"title\": \"Adapting Pretrained Language Models for Solving Tabular Prediction  Problems in the Electronic Health Record\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.836, \"y\": 8.218}, {\"title\": \"Meeting Action Item Detection with Regularized Context Modeling\", \"topic\": \"Text Summarization\", \"x\": 5.767, \"y\": 6.347}, {\"title\": \"WinCLIP: Zero-/Few-Shot Anomaly Classification and Segmentation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.836, \"y\": 7.078}, {\"title\": \"Exploring the Impact of Instruction Data Scaling on Large Language  Models: An Empirical Study on Real-World Use Cases\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.257, \"y\": 2.452}, {\"title\": \"GOAL: A Challenging Knowledge-grounded Video Captioning Benchmark for  Real-time Soccer Commentary Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.946, \"y\": 7.848}, {\"title\": \"Farspredict: A benchmark dataset for link prediction\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.0, \"y\": 5.988}, {\"title\": \"Automatic Generation of Multiple-Choice Questions\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.253, \"y\": 5.106}, {\"title\": \"Chat-REC: Towards Interactive and Explainable LLMs-Augmented Recommender  System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.931, \"y\": 3.034}, {\"title\": \"Depression detection in social media posts using affective and social  norm features\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.085, \"y\": 7.337}, {\"title\": \"Lay Text Summarisation Using Natural Language Processing: A Narrative  Literature Review\", \"topic\": \"Text Summarization\", \"x\": 5.563, \"y\": 6.387}, {\"title\": \"ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model  Meta-AI (LLaMA) Using Medical Domain Knowledge\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.543, \"y\": 8.091}, {\"title\": \"SPEC: Summary Preference Decomposition for Low-Resource Abstractive  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.581, \"y\": 6.257}, {\"title\": \"PromptORE -- A Novel Approach Towards Fully Unsupervised Relation  Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.962, \"y\": 6.811}, {\"title\": \"$k$NN Prompting: Beyond-Context Learning with Calibration-Free Nearest  Neighbor Inference\", \"topic\": \"In-Context Learning\", \"x\": 8.14, \"y\": 3.333}, {\"title\": \"Personalizing Task-oriented Dialog Systems via Zero-shot Generalizable  Reward Function\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.459, \"y\": 3.727}, {\"title\": \"Large Language Models for Healthcare Data Augmentation: An Example on  Patient-Trial Matching\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.593, \"y\": 7.868}, {\"title\": \"Natural language processing to automatically extract the presence and  severity of esophagitis in notes of patients undergoing radiotherapy\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.469, \"y\": 8.002}, {\"title\": \"Prompting Multilingual Large Language Models to Generate Code-Mixed  Texts: The Case of South East Asian Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.149, \"y\": 4.494}, {\"title\": \"A Deliberation-based Joint Acoustic and Text Decoder\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.24, \"y\": 5.173}, {\"title\": \"Learning and Verification of Task Structure in Instructional Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.94, \"y\": 7.713}, {\"title\": \"CoBIT: A Contrastive Bi-directional Image-Text Generation Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.799, \"y\": 7.165}, {\"title\": \"Development and validation of a natural language processing algorithm to  pseudonymize documents in the context of a clinical data warehouse\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.562, \"y\": 7.855}, {\"title\": \"ChatGPT for Shaping the Future of Dentistry: The Potential of  Multi-Modal Large Language Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.884, \"y\": 8.002}, {\"title\": \"DBLP-QuAD: A Question Answering Dataset over the DBLP Scholarly  Knowledge Graph\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.533, \"y\": 5.519}, {\"title\": \"GETT-QA: Graph Embedding based T2T Transformer for Knowledge Graph  Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.727, \"y\": 5.635}, {\"title\": \"Visual-Language Prompt Tuning with Knowledge-guided Context Optimization\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.721, \"y\": 3.388}, {\"title\": \"Fairness-guided Few-shot Prompting for Large Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.694, \"y\": 3.392}, {\"title\": \"Judicial Intelligent Assistant System: Extracting Events from Divorce  Cases to Detect Disputes for the Judge\", \"topic\": \"Legal NLP\", \"x\": 5.131, \"y\": 5.799}, {\"title\": \"Beyond Universal Transformer: block reusing with adaptor in Transformer  for automatic speech recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.211, \"y\": 5.187}, {\"title\": \"SPeC: A Soft Prompt-Based Calibration on Performance Variability of  Large Language Model in Clinical Notes Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.686, \"y\": 8.041}, {\"title\": \"Enhancing Unsupervised Speech Recognition with Diffusion GANs\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.252, \"y\": 5.507}, {\"title\": \"Are LLMs the Master of All Trades? : Exploring Domain-Agnostic Reasoning  Skills of LLMs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.47, \"y\": 3.241}, {\"title\": \"Towards Understanding the Generalization of Medical Text-to-SQL Models  and Datasets\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.844, \"y\": 7.869}, {\"title\": \"Improving Transformer Performance for French Clinical Notes  Classification Using Mixture of Experts on a Limited Dataset\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.905, \"y\": 8.064}, {\"title\": \"Selective Data Augmentation for Robust Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.297, \"y\": 5.083}, {\"title\": \"Salient Span Masking for Temporal Understanding\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.613, \"y\": 5.677}, {\"title\": \"Integrating Image Features with Convolutional Sequence-to-sequence  Network for Multilingual Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.181, \"y\": 8.059}, {\"title\": \"Can We Identify Stance Without Target Arguments? A Study for Rumour  Stance Classification\", \"topic\": \"Fake News Detection\", \"x\": 3.566, \"y\": 5.804}, {\"title\": \"RepoCoder: Repository-Level Code Completion Through Iterative Retrieval  and Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.513, \"y\": 2.409}, {\"title\": \"Mining Clinical Notes for Physical Rehabilitation Exercise Information:  Natural Language Processing Algorithm Development and Validation Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.439, \"y\": 7.902}, {\"title\": \"GrapeQA: GRaph Augmentation and Pruning to Enhance Question-Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.815, \"y\": 5.568}, {\"title\": \"Self-supervised Meta-Prompt Learning with Meta-Gradient Regularization  for Few-shot Generalization\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.815, \"y\": 3.543}, {\"title\": \"Exploring Turkish Speech Recognition via Hybrid CTC/Attention  Architecture and Multi-feature Fusion Network\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.185, \"y\": 5.149}, {\"title\": \"MAGVLT: Masked Generative Vision-and-Language Transformer\", \"topic\": \"Multimodal Language Models\", \"x\": 8.782, \"y\": 7.104}, {\"title\": \"Understand Legal Documents with Contextualized Large Language Models\", \"topic\": \"Legal NLP\", \"x\": 5.132, \"y\": 5.707}, {\"title\": \"Positive-Augmented Contrastive Learning for Image and Video Captioning  Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 9.111, \"y\": 7.419}, {\"title\": \"VideoXum: Cross-modal Visual and Textural Summarization of Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.928, \"y\": 7.857}, {\"title\": \"Is BERT Blind? Exploring the Effect of Vision-and-Language Pretraining  on Visual Language Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.576, \"y\": 7.447}, {\"title\": \"Wearing Masks Implies Refuting Trump?: Towards Target-specific User  Stance Prediction across Events in COVID-19 and US Election 2020\", \"topic\": \"Fake News Detection\", \"x\": 3.598, \"y\": 6.058}, {\"title\": \"Logical Reasoning over Natural Language as Knowledge Representation: A  Survey\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.645, \"y\": 3.12}, {\"title\": \"ChatGPT and a New Academic Reality: Artificial Intelligence-Written  Research Papers and the Ethics of the Large Language Models in Scholarly  Publishing\", \"topic\": \"Bias in Language Models\", \"x\": 4.91, \"y\": 4.587}, {\"title\": \"The Open-domain Paradox for Chatbots: Common Ground as the Basis for  Human-like Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.168, \"y\": 3.79}, {\"title\": \"Heterogeneous-Branch Collaborative Learning for Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.683, \"y\": 3.928}, {\"title\": \"eP-ALM: Efficient Perceptual Augmentation of Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.447, \"y\": 7.248}, {\"title\": \"MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action\", \"topic\": \"Multimodal Language Models\", \"x\": 8.129, \"y\": 7.631}, {\"title\": \"Reflexion: Language Agents with Verbal Reinforcement Learning\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 5.989, \"y\": 2.133}, {\"title\": \"EVA-02: A Visual Representation for Neon Genesis\", \"topic\": \"Multimodal Language Models\", \"x\": 8.903, \"y\": 7.176}, {\"title\": \"Leveraging Foundation Models for Clinical Text Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.754, \"y\": 7.685}, {\"title\": \"Learning Semantic Text Similarity to rank Hypernyms of Financial Terms\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.108, \"y\": 6.853}, {\"title\": \"Capabilities of GPT-4 on Medical Challenge Problems\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.728, \"y\": 8.091}, {\"title\": \"Multimodal Shannon Game with Images\", \"topic\": \"Multimodal Language Models\", \"x\": 8.334, \"y\": 7.555}, {\"title\": \"DocRED-FE: A Document-Level Fine-Grained Entity And Relation Extraction  Dataset\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.906, \"y\": 6.826}, {\"title\": \"Cocktail HuBERT: Generalized Self-Supervised Pre-training for Mixture  and Single-Source Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.797, \"y\": 4.813}, {\"title\": \"EmotionIC: emotional inertia and contagion-driven dependency modeling  for emotion recognition in conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.296, \"y\": 7.796}, {\"title\": \"DeID-GPT: Zero-shot Medical Text De-Identification by GPT-4\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.864, \"y\": 7.814}, {\"title\": \"Translate your gibberish: black-box adversarial attack on machine  translation systems\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.106, \"y\": 3.002}, {\"title\": \"Towards Reliable Neural Machine Translation with Consistency-Aware  Meta-Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.876, \"y\": 4.428}, {\"title\": \"Code-Switching Text Generation and Injection in Mandarin-English ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.634, \"y\": 5.409}, {\"title\": \"On-the-fly Text Retrieval for End-to-End ASR Adaptation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.072, \"y\": 5.263}, {\"title\": \"Exploring Representation Learning for Small-Footprint Keyword Spotting\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.725, \"y\": 5.055}, {\"title\": \"Relate auditory speech to EEG by shallow-deep attention-based network\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.91, \"y\": 5.172}, {\"title\": \"Unsupervised Cross-Domain Rumor Detection with Contrastive Learning and  Cross-Attention\", \"topic\": \"Fake News Detection\", \"x\": 4.015, \"y\": 5.888}, {\"title\": \"Multi-task Transformer with Relation-attention and Type-attention for  Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.276, \"y\": 6.872}, {\"title\": \"Retrieving Multimodal Information for Augmented Generation: A Survey\", \"topic\": \"Multimodal Language Models\", \"x\": 8.026, \"y\": 7.367}, {\"title\": \"PheME: A deep ensemble framework for improving phenotype prediction from  multi-modal data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.876, \"y\": 8.309}, {\"title\": \"FVQA 2.0: Introducing Adversarial Samples into Fact-based Visual  Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.178, \"y\": 8.088}, {\"title\": \"Extracting Incidents, Effects, and Requested Advice from MeToo Posts\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.164, \"y\": 7.303}, {\"title\": \"PACO: Provocation Involving Action, Culture, and Oppression\", \"topic\": \"Hate Speech Detection\", \"x\": 3.039, \"y\": 5.513}, {\"title\": \"AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.142, \"y\": 2.096}, {\"title\": \"A Deep Learning System for Domain-specific Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.234, \"y\": 5.358}, {\"title\": \"NoisyHate: Benchmarking Content Moderation Machine Learning Models with  Human-Written Perturbations Online\", \"topic\": \"Hate Speech Detection\", \"x\": 2.925, \"y\": 5.167}, {\"title\": \"A Graph-Guided Reasoning Approach for Open-ended Commonsense Question  Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.659, \"y\": 5.475}, {\"title\": \"Powerful and Extensible WFST Framework for RNN-Transducer Losses\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.067, \"y\": 4.651}, {\"title\": \"An Empirical Study of Pre-trained Language Models in Simple Knowledge  Graph Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.871, \"y\": 5.283}, {\"title\": \"Revisiting Automatic Question Summarization Evaluation in the Biomedical  Domain\", \"topic\": \"Text Summarization\", \"x\": 5.527, \"y\": 6.3}, {\"title\": \"On the rise of fear speech in online social media\", \"topic\": \"Hate Speech Detection\", \"x\": 2.967, \"y\": 5.463}, {\"title\": \"Conversational Tree Search: A New Hybrid Dialog Task\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.487, \"y\": 3.619}, {\"title\": \"Investigating the Role of Attribute Context in Vision-Language Models  for Object Recognition and Detection\", \"topic\": \"Multimodal Language Models\", \"x\": 8.746, \"y\": 7.192}, {\"title\": \"More Robust Schema-Guided Dialogue State Tracking via Tree-Based  Paraphrase Ranking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.566, \"y\": 3.854}, {\"title\": \"Transformers and Ensemble methods: A solution for Hate Speech Detection  in Arabic languages\", \"topic\": \"Hate Speech Detection\", \"x\": 2.824, \"y\": 5.516}, {\"title\": \"CoLT5: Faster Long-Range Transformers with Conditional Computation\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.833, \"y\": 3.312}, {\"title\": \"Learning towards Selective Data Augmentation for Dialogue Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.502, \"y\": 3.947}, {\"title\": \"Neural Architecture Search for Effective Teacher-Student Knowledge  Transfer in Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.478, \"y\": 3.87}, {\"title\": \"MultiModal Bias: Introducing a Framework for Stereotypical Bias  Assessment beyond Gender and Race in Vision Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.24, \"y\": 4.479}, {\"title\": \"Jump to Conclusions: Short-Cutting Transformers With Linear  Transformations\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.542, \"y\": 3.398}, {\"title\": \"Towards the Scalable Evaluation of Cooperativeness in Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.238, \"y\": 2.897}, {\"title\": \"The Scope of In-Context Learning for the Extraction of Medical Temporal  Constraints\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.976, \"y\": 8.088}, {\"title\": \"BanglaCoNER: Towards Robust Bangla Complex Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.391, \"y\": 6.898}, {\"title\": \"How well do Large Language Models perform in Arithmetic tasks?\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.304, \"y\": 2.812}, {\"title\": \"A Short Survey of Viewing Large Language Models in Legal Aspect\", \"topic\": \"Legal NLP\", \"x\": 5.222, \"y\": 5.455}, {\"title\": \"Patch-Prompt Aligned Bayesian Prompt Tuning for Vision-Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.797, \"y\": 3.465}, {\"title\": \"Translating Radiology Reports into Plain Language using ChatGPT and  GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.868, \"y\": 8.377}, {\"title\": \"A Picture is Worth a Thousand Words: Language Models Plan from Pixels\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 6.048, \"y\": 2.62}, {\"title\": \"Cross-domain Sentiment Classification in Spanish\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.509, \"y\": 6.553}, {\"title\": \"PRESTO: A Multilingual Dataset for Parsing Realistic Task-Oriented  Dialogs\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.52, \"y\": 3.948}, {\"title\": \"Applying unsupervised keyphrase methods on concepts extracted from  discharge sheets\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.687, \"y\": 7.766}, {\"title\": \"SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for  Generative Large Language Models\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.293, \"y\": 1.313}, {\"title\": \"Understanding Post-hoc Explainers: The Case of Anchors\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.946, \"y\": 3.884}, {\"title\": \"UPRISE: Universal Prompt Retrieval for Improving Zero-Shot Evaluation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.314, \"y\": 3.476}, {\"title\": \"A Cross-institutional Evaluation on Breast Cancer Phenotyping NLP  Algorithms on Electronic Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.83, \"y\": 7.959}, {\"title\": \"PR-MCS: Perturbation Robust Metric for MultiLingual Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.969, \"y\": 7.35}, {\"title\": \"Reevaluating Data Partitioning for Emotion Detection in EmoWOZ\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.26, \"y\": 7.802}, {\"title\": \"Cross-speaker Emotion Transfer by Manipulating Speech Style Latents\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.259, \"y\": 7.904}, {\"title\": \"ZeroQuant-V2: Exploring Post-training Quantization in LLMs from  Comprehensive Study to Low Rank Compensation\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.745, \"y\": 2.126}, {\"title\": \"Rediscovery of CNN's Versatility for Text-based Encoding of Raw  Electronic Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.971, \"y\": 8.28}, {\"title\": \"Attention-likelihood relationship in transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.425, \"y\": 3.322}, {\"title\": \"Chat with the Environment: Interactive Multimodal Perception Using Large  Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 8.354, \"y\": 6.995}, {\"title\": \"Clinical Concept and Relation Extraction Using Prompt-based Machine  Reading Comprehension\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.881, \"y\": 7.733}, {\"title\": \"Contextualized Medication Information Extraction Using Transformer-based  Deep Learning Architectures\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.719, \"y\": 7.811}, {\"title\": \"MEDBERT.de: A Comprehensive German BERT Model for the Medical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.167, \"y\": 7.919}, {\"title\": \"Learning Cross-lingual Visual Speech Representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.507, \"y\": 5.284}, {\"title\": \"Progress Note Understanding -- Assessment and Plan Reasoning: Overview  of the 2022 N2C2 Track 3 Shared Task\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.313, \"y\": 7.824}, {\"title\": \"OptBA: Optimizing Hyperparameters with the Bees Algorithm for Improved  Medical Text Classification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.744, \"y\": 8.089}, {\"title\": \"A Theory of Emergent In-Context Learning as Implicit Structure Induction\", \"topic\": \"In-Context Learning\", \"x\": 8.546, \"y\": 3.421}, {\"title\": \"Improving Accented Speech Recognition with Multi-Domain Training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.243, \"y\": 5.363}, {\"title\": \"Adapting Offline Speech Translation Models for Streaming with  Future-Aware Distillation and Inference\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.737, \"y\": 5.184}, {\"title\": \"The Learnability of In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.514, \"y\": 3.416}, {\"title\": \"X-ReCoSa: Multi-Scale Context Aggregation For Multi-Turn Dialogue  Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.511, \"y\": 3.876}, {\"title\": \"Controllable Prosody Generation With Partial Inputs\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.559, \"y\": 5.881}, {\"title\": \"Efficient Image-Text Retrieval via Keyword-Guided Pre-Screening\", \"topic\": \"Multimodal Language Models\", \"x\": 8.354, \"y\": 6.887}, {\"title\": \"Good Neighbors Are All You Need for Chinese Grapheme-to-Phoneme  Conversion\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.611, \"y\": 5.569}, {\"title\": \"Improving Prosody for Cross-Speaker Style Transfer by Semi-Supervised  Style Extractor and Hierarchical Modeling in Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.725, \"y\": 5.844}, {\"title\": \"Dual-Attention Model for Aspect-Level Sentiment Classification\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.076, \"y\": 6.893}, {\"title\": \"Dynamic Alignment Mask CTC: Improved Mask-CTC with Aligned Cross Entropy\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.189, \"y\": 5.03}, {\"title\": \"QI-TTS: Questioning Intonation Control for Emotional Speech Synthesis\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.34, \"y\": 7.911}, {\"title\": \"I3D: Transformer architectures with input-dependent dynamic depth for  speech recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.143, \"y\": 4.896}, {\"title\": \"Exploring ChatGPT's Ability to Rank Content: A Preliminary Study on  Consistency with Human Preferences\", \"topic\": \"Bias in Language Models\", \"x\": 5.017, \"y\": 4.678}, {\"title\": \"Input-length-shortening and text generation via attention values\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.772, \"y\": 3.316}, {\"title\": \"Transformer-based approaches to Sentiment Detection\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.695, \"y\": 6.733}, {\"title\": \"Breaking Common Sense: WHOOPS! A Vision-and-Language Benchmark of  Synthetic and Compositional Images\", \"topic\": \"Multimodal Language Models\", \"x\": 8.528, \"y\": 7.766}, {\"title\": \"Large Language Models in the Workplace: A Case Study on Prompt  Engineering for Job Type Classification\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.228, \"y\": 3.417}, {\"title\": \"Generating multiple-choice questions for medical question answering with  distractors and cue-masking\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.062, \"y\": 7.623}, {\"title\": \"Addressing Biases in the Texts using an End-to-End Pipeline Approach\", \"topic\": \"Bias in Language Models\", \"x\": 3.174, \"y\": 4.214}, {\"title\": \"A Human Subject Study of Named Entity Recognition (NER) in  Conversational Music Recommendation Queries\", \"topic\": \"Named Entity Recognition\", \"x\": 7.35, \"y\": 6.861}, {\"title\": \"Contextually-rich human affect perception using multimodal scene  information\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.33, \"y\": 7.675}, {\"title\": \"MetaTroll: Few-shot Detection of State-Sponsored Trolls with Transformer  Adapters\", \"topic\": \"Fake News Detection\", \"x\": 4.067, \"y\": 5.908}, {\"title\": \"The System Description of dun_oscar team for The ICPR MSR Challenge\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.096, \"y\": 5.632}, {\"title\": \"Robust Contrastive Language-Image Pre-training against Data Poisoning  and Backdoor Attacks\", \"topic\": \"Multimodal Language Models\", \"x\": 9.061, \"y\": 7.231}, {\"title\": \"Learning Transductions and Alignments with RNN Seq2seq Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.273, \"y\": 3.567}, {\"title\": \"Neural Diarization with Non-autoregressive Intermediate Attractors\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.091, \"y\": 5.136}, {\"title\": \"Improving the Diproche CNL through Autoformalization via Large Language  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.174, \"y\": 2.893}, {\"title\": \"Fuzzy Alignments in Directed Acyclic Graph for Non-Autoregressive  Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.03, \"y\": 4.645}, {\"title\": \"Improving the Intent Classification accuracy in Noisy Environment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.871, \"y\": 5.172}, {\"title\": \"Towards General Purpose Medical AI: Continual Learning Medical  Foundation Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.185, \"y\": 8.114}, {\"title\": \"Compressed Heterogeneous Graph for Abstractive Multi-Document  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.98, \"y\": 6.555}, {\"title\": \"Transcription free filler word detection with Neural semi-CRFs\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.265, \"y\": 5.098}, {\"title\": \"Stabilizing Transformer Training by Preventing Attention Entropy  Collapse\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.833, \"y\": 3.272}, {\"title\": \"AUTODIAL: Efficient Asynchronous Task-Oriented Dialogue Model\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.467, \"y\": 3.682}, {\"title\": \"Generating Query Focused Summaries without Fine-tuning the  Transformer-based Pre-trained Models\", \"topic\": \"Text Summarization\", \"x\": 5.758, \"y\": 5.991}, {\"title\": \"Is In-hospital Meta-information Useful for Abstractive Discharge Summary  Generation?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.668, \"y\": 8.0}, {\"title\": \"Robust Knowledge Distillation from RNN-T Models With Noisy Training  Labels Using Full-Sum Loss\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.567, \"y\": 3.872}, {\"title\": \"MIXPGD: Hybrid Adversarial Training for Speech Recognition Systems\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 11.184, \"y\": 5.407}, {\"title\": \"Clinical BERTScore: An Improved Measure of Automatic Speech Recognition  Performance in Clinical Settings\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.782, \"y\": 7.976}, {\"title\": \"Detection of Abuse in Financial Transaction Descriptions Using Machine  Learning\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.874, \"y\": 6.551}, {\"title\": \"MuLTI: Efficient Video-and-Language Understanding with Text-Guided  MultiWay-Sampler and Multiple Choice Modeling\", \"topic\": \"Multimodal Language Models\", \"x\": 8.651, \"y\": 7.702}, {\"title\": \"Logic Against Bias: Textual Entailment Mitigates Stereotypical Sentence  Reasoning\", \"topic\": \"Bias in Language Models\", \"x\": 3.327, \"y\": 4.448}, {\"title\": \"Types of Approaches, Applications and Challenges in the Development of  Sentiment Analysis Systems\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.642, \"y\": 6.588}, {\"title\": \"Refined Vision-Language Modeling for Fine-grained Multi-modal  Pre-training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.633, \"y\": 7.313}, {\"title\": \"MixSpeech: Cross-Modality Self-Learning with Audio-Visual Stream Mixup  for Visual Speech Translation and Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.633, \"y\": 5.653}, {\"title\": \"Dynamic Stashing Quantization for Efficient Transformer Training\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.782, \"y\": 2.332}, {\"title\": \"Text-to-ECG: 12-Lead Electrocardiogram Synthesis conditioned on Clinical  Text Reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.914, \"y\": 8.317}, {\"title\": \"Improving Video Retrieval by Adaptive Margin\", \"topic\": \"Multimodal Language Models\", \"x\": 8.859, \"y\": 7.747}, {\"title\": \"Learning the Legibility of Visual Text Perturbations\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.147, \"y\": 2.979}, {\"title\": \"ICL-D3IE: In-Context Learning with Diverse Demonstrations Updating for  Document Information Extraction\", \"topic\": \"In-Context Learning\", \"x\": 8.237, \"y\": 3.465}, {\"title\": \"Unsupervised Language agnostic WER Standardization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.187, \"y\": 5.461}, {\"title\": \"Multi-Stage Coarse-to-Fine Contrastive Learning for Conversation Intent  Induction\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.841, \"y\": 4.101}, {\"title\": \"BeamAttack: Generating High-quality Textual Adversarial Examples through  Beam Search and Mixed Semantic Spaces\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.122, \"y\": 3.023}, {\"title\": \"Let's Get Personal: Personal Questions Improve SocialBot Performance in  the Alexa Prize\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.059, \"y\": 3.86}, {\"title\": \"FaceChat: An Emotion-Aware Face-to-face Dialogue Framework\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.588, \"y\": 7.792}, {\"title\": \"Extending the Pre-Training of BLOOM for Improved Support of Traditional  Chinese: Models, Methods and Results\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.035, \"y\": 4.416}, {\"title\": \"ChatGPT Participates in a Computer Science Exam\", \"topic\": \"Bias in Language Models\", \"x\": 5.263, \"y\": 4.52}, {\"title\": \"Automatic Detection of Industry Sectors in Legal Articles Using Machine  Learning Approaches\", \"topic\": \"Legal NLP\", \"x\": 5.18, \"y\": 5.861}, {\"title\": \"Sample Efficient Multimodal Semantic Augmentation for Incremental  Summarization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.787, \"y\": 7.77}, {\"title\": \"Does Synthetic Data Generation of LLMs Help Clinical Text Mining?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.754, \"y\": 7.926}, {\"title\": \"Do Prosody Transfer Models Transfer Prosody?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.503, \"y\": 5.645}, {\"title\": \"How Do Transformers Learn Topic Structure: Towards a Mechanistic  Understanding\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.526, \"y\": 3.542}, {\"title\": \"A Comprehensive Survey of AI-Generated Content (AIGC): A History of  Generative AI from GAN to ChatGPT\", \"topic\": \"Bias in Language Models\", \"x\": 4.982, \"y\": 4.499}, {\"title\": \"Gradient-Free Structured Pruning with Unlabeled Data\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.587, \"y\": 2.492}, {\"title\": \"Abstract Visual Reasoning Enabled by Language\", \"topic\": \"Multimodal Language Models\", \"x\": 8.393, \"y\": 7.586}, {\"title\": \"Automatically Summarizing Evidence from Clinical Trials: A Prototype  Highlighting Current Challenges\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.632, \"y\": 7.637}, {\"title\": \"Describe me an Aucklet: Generating Grounded Perceptual Category  Descriptions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.631, \"y\": 6.919}, {\"title\": \"Making a Computational Attorney\", \"topic\": \"Legal NLP\", \"x\": 5.097, \"y\": 5.615}, {\"title\": \"ELODIN: Naming Concepts in Embedding Spaces\", \"topic\": \"Multimodal Language Models\", \"x\": 8.85, \"y\": 6.835}, {\"title\": \"GATE: A Challenge Set for Gender-Ambiguous Translation Examples\", \"topic\": \"Bias in Language Models\", \"x\": 2.987, \"y\": 4.384}, {\"title\": \"Speak Foreign Languages with Your Own Voice: Cross-Lingual Neural Codec  Language Modeling\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.452, \"y\": 5.503}, {\"title\": \"Document-level Relation Extraction with Cross-sentence Reasoning Graph\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.865, \"y\": 6.803}, {\"title\": \"Larger language models do in-context learning differently\", \"topic\": \"In-Context Learning\", \"x\": 8.45, \"y\": 3.301}, {\"title\": \"Exploring the Feasibility of ChatGPT for Event Extraction\", \"topic\": \"Text Summarization\", \"x\": 6.118, \"y\": 6.221}, {\"title\": \"German BERT Model for Legal Named Entity Recognition\", \"topic\": \"Legal NLP\", \"x\": 5.227, \"y\": 5.833}, {\"title\": \"Stylometric Detection of AI-Generated Text in Twitter Timelines\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.173, \"y\": 4.915}, {\"title\": \"CoTEVer: Chain of Thought Prompting Annotation Toolkit for Explanation  Verification\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.612, \"y\": 2.405}, {\"title\": \"Towards Interpretable and Efficient Automatic Reference-Based  Summarization Evaluation\", \"topic\": \"Text Summarization\", \"x\": 5.506, \"y\": 6.263}, {\"title\": \"ADELT: Transpilation Between Deep Learning Frameworks\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.118, \"y\": 3.055}, {\"title\": \"Multi-resolution Interpretation and Diagnostics Tool for Natural  Language Classifiers\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.917, \"y\": 3.964}, {\"title\": \"wav2vec and its current potential to Automatic Speech Recognition in  German for the usage in Digital History: A comparative assessment of  available ASR-technologies for the use in cultural heritage contexts\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.193, \"y\": 5.491}, {\"title\": \"Depression Detection Using Digital Traces on Social Media: A  Knowledge-aware Deep Learning Approach\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.225, \"y\": 7.481}, {\"title\": \"AmQA: Amharic Question Answering Dataset\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.462, \"y\": 5.309}, {\"title\": \"Neighborhood Contrastive Transformer for Change Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.064, \"y\": 7.164}, {\"title\": \"IFAN: An Explainability-Focused Interaction Framework for Humans and NLP  Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.732, \"y\": 3.898}, {\"title\": \"DeCap: Decoding CLIP Latents for Zero-Shot Captioning via Text-Only  Training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.95, \"y\": 7.403}, {\"title\": \"HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware  Attention\", \"topic\": \"Multimodal Language Models\", \"x\": 8.943, \"y\": 7.186}, {\"title\": \"GlobalNER: Incorporating Non-local Information into Named Entity  Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.361, \"y\": 6.775}, {\"title\": \"OpenICL: An Open-Source Framework for In-context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.149, \"y\": 3.445}, {\"title\": \"Dynamic Prompting: A Unified Framework for Prompt Tuning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.684, \"y\": 3.366}, {\"title\": \"Multitask Prompt Tuning Enables Parameter-Efficient Transfer Learning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.854, \"y\": 3.352}, {\"title\": \"Contrastive variational information bottleneck for aspect-based  sentiment analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.078, \"y\": 6.858}, {\"title\": \"Model-Agnostic Meta-Learning for Natural Language Understanding Tasks in  Finance\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.868, \"y\": 6.827}, {\"title\": \"FQP 2.0: Industry Trend Analysis via Hierarchical Financial Data\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.691, \"y\": 6.826}, {\"title\": \"Mining both Commonality and Specificity from Multiple Documents for  Multi-Document Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.556, \"y\": 6.344}, {\"title\": \"Knowledge-Based Counterfactual Queries for Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.222, \"y\": 7.999}, {\"title\": \"FinXABSA: Explainable Finance through Aspect-Based Sentiment Analysis\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.678, \"y\": 6.834}, {\"title\": \"Model-Agnostic Meta-Learning for Multilingual Hate Speech Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.742, \"y\": 5.367}, {\"title\": \"Self-tuning hyper-parameters for unsupervised cross-lingual tokenization\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.415, \"y\": 4.482}, {\"title\": \"The Contribution of Knowledge in Visiolinguistic Learning: A Survey on  Tasks and Challenges\", \"topic\": \"Multimodal Language Models\", \"x\": 8.147, \"y\": 7.487}, {\"title\": \"RweetMiner: Automatic identification and categorization of help requests  on twitter during disasters\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.215, \"y\": 6.614}, {\"title\": \"DiTTO: A Feature Representation Imitation Approach for Improving  Cross-Lingual Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.434, \"y\": 4.85}, {\"title\": \"MathPrompter: Mathematical Reasoning using Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.032, \"y\": 2.729}, {\"title\": \"Learning to reason over visual objects\", \"topic\": \"Multimodal Language Models\", \"x\": 8.46, \"y\": 7.649}, {\"title\": \"Domain Specific Question Answering Over Knowledge Graphs Using Logical  Programming and Large Language Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.712, \"y\": 5.439}, {\"title\": \"Pre-trained Model Representations and their Robustness against Noise for  Speech Emotion Analysis\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.192, \"y\": 7.852}, {\"title\": \"Investigating the Translation Performance of a Large Multilingual  Language Model: the Case of BLOOM\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.547, \"y\": 4.601}, {\"title\": \"Prophet: Prompting Large Language Models with Complementary Answer  Heuristics for Knowledge-based Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.23, \"y\": 8.004}, {\"title\": \"PAGE: A Position-Aware Graph-Based Model for Emotion Cause Entailment in  Conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.394, \"y\": 7.789}, {\"title\": \"Exploiting Language Relatedness in Machine Translation Through Domain  Adaptation Techniques\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.708, \"y\": 4.549}, {\"title\": \"DWFormer: Dynamic Window transFormer for Speech Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.222, \"y\": 7.827}, {\"title\": \"Structure Pretraining and Prompt Tuning for Knowledge Graph Transfer\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.017, \"y\": 5.885}, {\"title\": \"End-to-End Speech Recognition: A Survey\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.121, \"y\": 5.181}, {\"title\": \"APIContext2Com: Code Comment Generation by Incorporating Pre-Defined API  Documentation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.527, \"y\": 2.418}, {\"title\": \"CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a  Context Synergized Hyperbolic Network\", \"topic\": \"Hate Speech Detection\", \"x\": 2.743, \"y\": 5.37}, {\"title\": \"Letz Translate: Low-Resource Machine Translation for Luxembourgish\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.671, \"y\": 4.619}, {\"title\": \"Matching-based Term Semantics Pre-training for Spoken Patient Query  Understanding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.212, \"y\": 7.957}, {\"title\": \"Synthetic Misinformers: Generating and Combating Multimodal  Misinformation\", \"topic\": \"Fake News Detection\", \"x\": 4.121, \"y\": 5.929}, {\"title\": \"CTRLStruct: Dialogue Structure Learning for Open-Domain Response  Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.643, \"y\": 4.011}, {\"title\": \"LiteG2P: A fast, light and high accuracy model for grapheme-to-phoneme  conversion\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.036, \"y\": 5.137}, {\"title\": \"LANDMARK: Language-guided Representation Enhancement Framework for Scene  Graph Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.68, \"y\": 7.233}, {\"title\": \"Targeted Adversarial Attacks against Neural Machine Translation\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.15, \"y\": 2.993}, {\"title\": \"Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.997, \"y\": 5.242}, {\"title\": \"Less is More: Mitigate Spurious Correlations for Open-Domain Dialogue  Response Generation Models by Causal Discovery\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.7, \"y\": 4.044}, {\"title\": \"Leveraging Large Text Corpora for End-to-End Speech Summarization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.604, \"y\": 5.387}, {\"title\": \"Rethinking the Reasonability of the Test Set for Simultaneous Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.907, \"y\": 4.731}, {\"title\": \"Soft Prompt Guided Joint Learning for Cross-Domain Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.107, \"y\": 6.836}, {\"title\": \"Synthetic Cross-accent Data Augmentation for Automatic Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.098, \"y\": 5.444}, {\"title\": \"Building High-accuracy Multilingual ASR with Gated Language Experts and  Curriculum Training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.904, \"y\": 5.157}, {\"title\": \"SpeechPrompt v2: Prompt Tuning for Speech Classification Tasks\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.711, \"y\": 3.326}, {\"title\": \"A Systematic Analysis of Vocabulary and BPE Settings for Optimal  Fine-tuning of NMT: A Case Study of In-domain Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.568, \"y\": 4.167}, {\"title\": \"ToxVis: Enabling Interpretability of Implicit vs. Explicit Toxicity  Detection Models with Interactive Visualization\", \"topic\": \"Hate Speech Detection\", \"x\": 2.81, \"y\": 5.234}, {\"title\": \"ParrotTTS: Text-to-Speech synthesis by exploiting self-supervised  representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.591, \"y\": 5.636}, {\"title\": \"MuAViC: A Multilingual Audio-Visual Corpus for Robust Speech Recognition  and Robust Speech-to-Text Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.366, \"y\": 5.555}, {\"title\": \"A Universal Question-Answering Platform for Knowledge Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.653, \"y\": 5.462}, {\"title\": \"N-best T5: Robust ASR Error Correction using Multiple Input Hypotheses  and Constrained Decoding Space\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.236, \"y\": 5.343}, {\"title\": \"Domain-adapted large language models for classifying nuclear medicine  reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.1, \"y\": 8.506}, {\"title\": \"Modeling Multiple User Interests using Hierarchical Knowledge for  Conversational Recommender System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.936, \"y\": 3.003}, {\"title\": \"Coarse-to-Fine Covid-19 Segmentation via Vision-Language Alignment\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.255, \"y\": 8.52}, {\"title\": \"Hidden Markov Transformer for Simultaneous Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.979, \"y\": 4.555}, {\"title\": \"Frauds Bargain Attack: Generating Adversarial Text Samples via Word  Manipulation Process\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.12, \"y\": 3.024}, {\"title\": \"Almanac: Retrieval-Augmented Language Models for Clinical Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.69, \"y\": 7.911}, {\"title\": \"Deep learning for COVID-19 topic modelling via Twitter: Alpha, Delta and  Omicron\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.132, \"y\": 6.789}, {\"title\": \"EvoPrompting: Language Models for Code-Level Neural Architecture Search\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.574, \"y\": 2.98}, {\"title\": \"Automatically Classifying Emotions based on Text: A Comparative  Exploration of Different Datasets\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.49, \"y\": 7.361}, {\"title\": \"Self-training through Classifier Disagreement for Cross-Domain Opinion  Target Extraction\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.164, \"y\": 6.797}, {\"title\": \"Investigating the Effectiveness of Task-Agnostic Prefix Prompt for  Instruction Following\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.397, \"y\": 3.109}, {\"title\": \"Synthesizing Mixed-type Electronic Health Records using Diffusion Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.817, \"y\": 8.08}, {\"title\": \"The 2022 NIST Language Recognition Evaluation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.996, \"y\": 5.507}, {\"title\": \"Language-Universal Adapter Learning with Knowledge Distillation for  End-to-End Multilingual Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.041, \"y\": 5.179}, {\"title\": \"Automatic Heteronym Resolution Pipeline Using RAD-TTS Aligners\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.877, \"y\": 5.506}, {\"title\": \"GLM-Dialog: Noise-tolerant Pre-training for Knowledge-grounded Dialogue  Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.546, \"y\": 3.785}, {\"title\": \"UniFLG: Unified Facial Landmark Generator from Text or Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.452, \"y\": 5.892}, {\"title\": \"Augmented Transformers with Adaptive n-grams Embedding for Multilingual  Scene Text Recognition\", \"topic\": \"Multimodal Language Models\", \"x\": 8.771, \"y\": 6.61}, {\"title\": \"Are Character-level Translations Worth the Wait? Comparing ByT5 and mT5  for Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.69, \"y\": 4.55}, {\"title\": \"Reward Design with Language Models\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.132, \"y\": 1.789}, {\"title\": \"Vid2Seq: Large-Scale Pretraining of a Visual Language Model for Dense  Video Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.908, \"y\": 7.789}, {\"title\": \"Language Is Not All You Need: Aligning Perception with Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.295, \"y\": 7.337}, {\"title\": \"Text-only domain adaptation for end-to-end ASR using integrated  text-to-mel-spectrogram generator\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.016, \"y\": 5.296}, {\"title\": \"Multimodal Speech Recognition for Language-Guided Embodied Agents\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.802, \"y\": 5.511}, {\"title\": \"Quantifying Valence and Arousal in Text with Multilingual Pre-trained  Transformers\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.429, \"y\": 7.448}, {\"title\": \"Full Stack Optimization of Transformer Inference: a Survey\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.722, \"y\": 3.207}, {\"title\": \"Let's have a chat! A Conversation with ChatGPT: Technology,  Applications, and Limitations\", \"topic\": \"Bias in Language Models\", \"x\": 4.916, \"y\": 4.432}, {\"title\": \"MoLE : Mixture of Language Experts for Multi-Lingual Automatic Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.924, \"y\": 5.038}, {\"title\": \"SpeechFormer++: A Hierarchical Efficient Framework for Paralinguistic  Speech Processing\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.183, \"y\": 5.144}, {\"title\": \"Using Auxiliary Tasks In Multimodal Fusion Of Wav2vec 2.0 And BERT For  Multimodal Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.277, \"y\": 7.725}, {\"title\": \"Duration-aware pause insertion using pre-trained language model for  multi-speaker text-to-speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.626, \"y\": 5.604}, {\"title\": \"Evaluation of Automatically Constructed Word Meaning Explanations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.946, \"y\": 3.828}, {\"title\": \"Orca: A Few-shot Benchmark for Chinese Conversational Machine Reading  Comprehension\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.831, \"y\": 5.019}, {\"title\": \"kNN-BOX: A Unified Framework for Nearest Neighbor Generation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.936, \"y\": 4.302}, {\"title\": \"Improving Medical Speech-to-Text Accuracy with Vision-Language  Pre-training Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.605, \"y\": 8.312}, {\"title\": \"TOT: Topology-Aware Optimal Transport For Multimodal Hate Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.838, \"y\": 5.572}, {\"title\": \"Finding Support Examples for In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.272, \"y\": 3.4}, {\"title\": \"Changes in Commuter Behavior from COVID-19 Lockdowns in the Atlanta  Metropolitan Area\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.132, \"y\": 6.763}, {\"title\": \"A low latency attention module for streaming self-supervised speech  representation learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.928, \"y\": 4.827}, {\"title\": \"Tweets Under the Rubble: Detection of Messages Calling for Help in  Earthquake Disaster\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.212, \"y\": 6.641}, {\"title\": \"Efficient Ensemble for Multimodal Punctuation Restoration using  Time-Delay Neural Network\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.685, \"y\": 5.381}, {\"title\": \"Multi-Modality in Music: Predicting Emotion in Music from High-Level  Audio Features and Lyrics\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.387, \"y\": 7.553}, {\"title\": \"Speech Corpora Divergence Based Unsupervised Data Selection for ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.039, \"y\": 5.354}, {\"title\": \"CLICKER: Attention-Based Cross-Lingual Commonsense Knowledge Transfer\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.296, \"y\": 4.737}, {\"title\": \"MetaAID 2.0: An Extensible Framework for Developing Metaverse  Applications via Human-controllable Pre-trained Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.113, \"y\": 7.144}, {\"title\": \"STACC: Code Comment Classification using SentenceTransformers\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.553, \"y\": 2.435}, {\"title\": \"Toward Fairness in Text Generation via Mutual Information Minimization  based on Importance Sampling\", \"topic\": \"Bias in Language Models\", \"x\": 3.347, \"y\": 4.259}, {\"title\": \"Abstractive Text Summarization using Attentive GRU based Encoder-Decoder\", \"topic\": \"Text Summarization\", \"x\": 5.629, \"y\": 6.353}, {\"title\": \"An Analysis of Abstractive Text Summarization Using Pre-trained Models\", \"topic\": \"Text Summarization\", \"x\": 5.574, \"y\": 6.33}, {\"title\": \"Sequential Query Encoding For Complex Query Answering on Knowledge  Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.832, \"y\": 5.472}, {\"title\": \"HADES: Homologous Automated Document Exploration and Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.952, \"y\": 6.203}, {\"title\": \"Cross-modal Contrastive Learning for Multimodal Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 4.011, \"y\": 5.947}, {\"title\": \"SynGen: A Syntactic Plug-and-play Module for Generative Aspect-based  Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.1, \"y\": 6.844}, {\"title\": \"Choice Fusion as Knowledge for Zero-Shot Dialogue State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.7, \"y\": 3.951}, {\"title\": \"Jointly Optimizing Translations and Speech Timing to Improve Isochrony  in Automatic Dubbing\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.489, \"y\": 5.423}, {\"title\": \"Locale Encoding For Scalable Multilingual Keyword Spotting Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.637, \"y\": 5.081}, {\"title\": \"Robust language-based mental health assessments in time and space  through social media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.244, \"y\": 7.444}, {\"title\": \"Pre-Finetuning for Few-Shot Emotional Speech Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 10.108, \"y\": 5.099}, {\"title\": \"LaSER: Language-Specific Event Recommendation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.028, \"y\": 2.869}, {\"title\": \"Phone and speaker spatial organization in self-supervised speech  representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.674, \"y\": 4.996}, {\"title\": \"Improving Massively Multilingual ASR With Auxiliary CTC Objectives\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.972, \"y\": 5.092}, {\"title\": \"Automatic Prompt Augmentation and Selection with Chain-of-Thought from  Labeled Data\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.6, \"y\": 2.351}, {\"title\": \"Cross-Lingual Transfer of Cognitive Processing Complexity\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.216, \"y\": 4.798}, {\"title\": \"Language Models are Few-shot Learners for Prognostic Prediction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.057, \"y\": 8.084}, {\"title\": \"Modelling Temporal Document Sequences for Clinical ICD Coding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.879, \"y\": 8.335}, {\"title\": \"In-Depth Look at Word Filling Societal Bias Measures\", \"topic\": \"Bias in Language Models\", \"x\": 3.382, \"y\": 4.386}, {\"title\": \"Fairness in Language Models Beyond English: Gaps and Challenges\", \"topic\": \"Bias in Language Models\", \"x\": 3.435, \"y\": 4.24}, {\"title\": \"Time-aware Multiway Adaptive Fusion Network for Temporal Knowledge Graph  Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.609, \"y\": 5.558}, {\"title\": \"ProofNet: Autoformalizing and Formally Proving Undergraduate-Level  Mathematics\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.22, \"y\": 2.971}, {\"title\": \"Emotion Prediction Oriented method with Multiple Supervisions for  Emotion-Cause Pair Extraction\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.412, \"y\": 7.742}, {\"title\": \"Factual Consistency Oriented Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.347, \"y\": 5.366}, {\"title\": \"Dr ChatGPT, tell me what I want to hear: How prompt knowledge impacts  health answer correctness\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.591, \"y\": 7.544}, {\"title\": \"CHiLL: Zero-shot Custom Interpretable Feature Extraction from Clinical  Notes with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.696, \"y\": 8.171}, {\"title\": \"Active Prompting with Chain-of-Thought for Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.585, \"y\": 2.513}, {\"title\": \"A Neural Span-Based Continual Named Entity Recognition Model\", \"topic\": \"Named Entity Recognition\", \"x\": 7.399, \"y\": 6.667}, {\"title\": \"MCWDST: a Minimum-Cost Weighted Directed Spanning Tree Algorithm for  Real-Time Fake News Mitigation in Social Media\", \"topic\": \"Fake News Detection\", \"x\": 3.987, \"y\": 5.946}, {\"title\": \"HL Dataset: Visually-grounded Description of Scenes, Actions and  Rationales\", \"topic\": \"Multimodal Language Models\", \"x\": 8.888, \"y\": 7.527}, {\"title\": \"Simple and Scalable Nearest Neighbor Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.975, \"y\": 4.275}, {\"title\": \"Not what you've signed up for: Compromising Real-World LLM-Integrated  Applications with Indirect Prompt Injection\", \"topic\": \"Jailbreak Attacks on LLMs\", \"x\": 3.407, \"y\": 2.635}, {\"title\": \"KHAN: Knowledge-Aware Hierarchical Attention Networks for Accurate  Political Stance Prediction\", \"topic\": \"Fake News Detection\", \"x\": 3.505, \"y\": 5.832}, {\"title\": \"Deep learning model for Mongolian Citizens Feedback Analysis using Word  Vector Embeddings\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.57, \"y\": 6.57}, {\"title\": \"ProsAudit, a prosodic benchmark for self-supervised speech models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.547, \"y\": 5.211}, {\"title\": \"Evaluating Automatic Speech Recognition in an Incremental Setting\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.194, \"y\": 5.51}, {\"title\": \"Generative Sentiment Transfer via Adaptive Masking\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.352, \"y\": 6.871}, {\"title\": \"Exploring Social Media for Early Detection of Depression in COVID-19  Patients\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.192, \"y\": 7.299}, {\"title\": \"Metric-oriented Speech Enhancement using Diffusion Probabilistic Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.833, \"y\": 5.664}, {\"title\": \"Coarse-to-Fine Knowledge Selection for Document Grounded Dialogs\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.652, \"y\": 4.0}, {\"title\": \"FiTs: Fine-grained Two-stage Training for Knowledge-aware Question  Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.708, \"y\": 5.311}, {\"title\": \"Empathetic Response Generation via Emotion Cause Transition Graph\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.594, \"y\": 7.852}, {\"title\": \"MUTANT: A Multi-sentential Code-mixed Hinglish Dataset\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.474, \"y\": 4.868}, {\"title\": \"EVJVQA Challenge: Multilingual Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.11, \"y\": 7.986}, {\"title\": \"Can Pre-trained Vision and Language Models Answer Visual  Information-Seeking Questions?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.142, \"y\": 7.942}, {\"title\": \"How Does In-Context Learning Help Prompt Tuning?\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.792, \"y\": 3.268}, {\"title\": \"Guiding Large Language Models via Directional Stimulus Prompting\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 6.878, \"y\": 3.088}, {\"title\": \"Impact of Subword Pooling Strategy on Cross-lingual Event Detection\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.344, \"y\": 4.835}, {\"title\": \"Topic-switch adapted Japanese Dialogue System based on PLATO-2\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.277, \"y\": 3.942}, {\"title\": \"MADI: Inter-domain Matching and Intra-domain Discrimination for  Cross-domain Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.018, \"y\": 5.069}, {\"title\": \"Improving Contextual Spelling Correction by External Acoustics Attention  and Semantic Aware Data Augmentation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.321, \"y\": 5.154}, {\"title\": \"UML: A Universal Monolingual Output Layer for Multilingual ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.803, \"y\": 5.187}, {\"title\": \"GTRL: An Entity Group-Aware Temporal Knowledge Graph Representation  Learning Method\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.811, \"y\": 6.012}, {\"title\": \"In-context Example Selection with Influences\", \"topic\": \"In-Context Learning\", \"x\": 8.267, \"y\": 3.387}, {\"title\": \"Efficient CTC Regularization via Coarse Labels for End-to-End Speech  Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.045, \"y\": 5.041}, {\"title\": \"Hyena Hierarchy: Towards Larger Convolutional Language Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.963, \"y\": 3.129}, {\"title\": \"ChatGPT: Jack of all trades, master of none\", \"topic\": \"Bias in Language Models\", \"x\": 5.144, \"y\": 4.542}, {\"title\": \"Parallel Sentence-Level Explanation Generation for Real-World  Low-Resource Scenarios\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.053, \"y\": 3.884}, {\"title\": \"Generic Dependency Modeling for Multi-Party Conversation\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.676, \"y\": 3.605}, {\"title\": \"Tell Model Where to Attend: Improving Interpretability of Aspect-Based  Sentiment Classification via Small Explanation Annotations\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.086, \"y\": 6.815}, {\"title\": \"KG-ECO: Knowledge Graph Enhanced Entity Correction for Query Rewriting\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.078, \"y\": 5.885}, {\"title\": \"Time to Embrace Natural Language Processing (NLP)-based Digital  Pathology: Benchmarking NLP- and Convolutional Neural Network-based Deep  Learning Pipelines\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.927, \"y\": 8.156}, {\"title\": \"Deep Transformers without Shortcuts: Modifying Self-attention for  Faithful Signal Propagation\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.803, \"y\": 3.273}, {\"title\": \"Learning Deep Semantics for Test Completion\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.514, \"y\": 2.479}, {\"title\": \"Towards Measuring and Scoring Speaker Diarization Fairness\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.887, \"y\": 5.652}, {\"title\": \"A Sidecar Separator Can Convert a Single-Talker Speech Recognition  System to a Multi-Talker One\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.146, \"y\": 5.253}, {\"title\": \"90% F1 Score in Relational Triple Extraction: Is it Real ?\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.909, \"y\": 6.792}, {\"title\": \"Mental Health Coping Stories on Social Media: A Causal-Inference Study  of Papageno Effect\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.178, \"y\": 7.41}, {\"title\": \"Can discrete information extraction prompts generalize across language  models?\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.224, \"y\": 3.265}, {\"title\": \"Knowledge-aware Bayesian Co-attention for Multimodal Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.27, \"y\": 7.718}, {\"title\": \"STOA-VLP: Spatial-Temporal Modeling of Object and Action for  Video-Language Pre-training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.891, \"y\": 7.783}, {\"title\": \"Emphasizing Unseen Words: New Vocabulary Acquisition for End-to-End  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.096, \"y\": 5.202}, {\"title\": \"Intent Identification and Entity Extraction for Healthcare Queries in  Indic Languages\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.926, \"y\": 7.724}, {\"title\": \"HomoDistil: Homotopic Task-Agnostic Distillation of Pre-trained  Transformers\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.495, \"y\": 3.774}, {\"title\": \"Multilingual Content Moderation: A Case Study on Reddit\", \"topic\": \"Hate Speech Detection\", \"x\": 2.961, \"y\": 5.282}, {\"title\": \"Language-Specific Representation of Emotion-Concept Knowledge Causally  Supports Emotion Inference\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.49, \"y\": 7.518}, {\"title\": \"SanskritShala: A Neural Sanskrit NLP Toolkit with Web-Based Interface  for Pedagogical and Annotation Purposes\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.016, \"y\": 5.377}, {\"title\": \"Video-Text Retrieval by Supervised Sparse Multi-Grained Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.865, \"y\": 7.779}, {\"title\": \"Uncertainty-Aware Reward-based Deep Reinforcement Learning for Intent  Analysis of Social Media Information\", \"topic\": \"Fake News Detection\", \"x\": 4.059, \"y\": 5.915}, {\"title\": \"BBT-Fin: Comprehensive Construction of Chinese Financial Domain  Pre-trained Language Model, Corpus and Benchmark\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.955, \"y\": 6.883}, {\"title\": \"Zero and Few-Shot Localization of Task-Oriented Dialogue Agents with a  Distilled Representation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.661, \"y\": 3.878}, {\"title\": \"Speaker and Language Change Detection using Wav2vec2 and Whisper\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.144, \"y\": 5.45}, {\"title\": \"BERT is not The Count: Learning to Match Mathematical Statements with  Proofs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.197, \"y\": 3.17}, {\"title\": \"Front-End Adapter: Adapting Front-End Input of Speech based  Self-Supervised Learning for Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.067, \"y\": 4.97}, {\"title\": \"Transformadores: Fundamentos teoricos y Aplicaciones\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.659, \"y\": 3.455}, {\"title\": \"Scalable Prompt Generation for Semi-supervised Learning with Language  Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.583, \"y\": 3.562}, {\"title\": \"How Good Are GPT Models at Machine Translation? A Comprehensive  Evaluation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.634, \"y\": 4.49}, {\"title\": \"RETVec: Resilient and Efficient Text Vectorizer\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.161, \"y\": 3.051}, {\"title\": \"Bounding the Capabilities of Large Language Models in Open Text  Generation with Prompt Constraints\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.221, \"y\": 3.542}, {\"title\": \"Unsupervised Task Graph Generation from Instructional Video Transcripts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.796, \"y\": 7.574}, {\"title\": \"CK-Transformer: Commonsense Knowledge Enhanced Transformers for  Referring Expression Comprehension\", \"topic\": \"Multimodal Language Models\", \"x\": 8.125, \"y\": 7.377}, {\"title\": \"Handling the Alignment for Wake Word Detection: A Comparison Between  Alignment-Based, Alignment-Free and Hybrid Approaches\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.015, \"y\": 5.265}, {\"title\": \"Deep Implicit Distribution Alignment Networks for Cross-Corpus Speech  Emotion Recognition\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.229, \"y\": 7.811}, {\"title\": \"Massively Multilingual Shallow Fusion with Large Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.922, \"y\": 5.103}, {\"title\": \"Natural Response Generation for Chinese Reading Comprehension\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.319, \"y\": 4.966}, {\"title\": \"Hate Speech and Offensive Language Detection using an Emotion-aware  Shared Encoder\", \"topic\": \"Hate Speech Detection\", \"x\": 2.748, \"y\": 5.441}, {\"title\": \"Multimodal Propaganda Processing\", \"topic\": \"Fake News Detection\", \"x\": 3.934, \"y\": 5.744}, {\"title\": \"DREEAM: Guiding Attention with Evidence for Improving Document-Level  Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.883, \"y\": 6.832}, {\"title\": \"Multimodal Subtask Graph Generation from Instructional Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.679, \"y\": 7.518}, {\"title\": \"Conformers are All You Need for Visual Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.12, \"y\": 5.302}, {\"title\": \"InstructABSA: Instruction Learning for Aspect Based Sentiment Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.128, \"y\": 6.813}, {\"title\": \"E2E Spoken Entity Extraction for Virtual Agents\", \"topic\": \"Named Entity Recognition\", \"x\": 7.388, \"y\": 6.835}, {\"title\": \"What A Situated Language-Using Agent Must be Able to Do: A Top-Down  Analysis\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.31, \"y\": 3.216}, {\"title\": \"JEIT: Joint End-to-End Model and Internal Language Model Training for  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.051, \"y\": 5.076}, {\"title\": \"Pretraining Language Models with Human Preferences\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.453, \"y\": 1.567}, {\"title\": \"Learning with Rejection for Abstractive Text Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.555, \"y\": 6.23}, {\"title\": \"LEVER: Learning to Verify Language-to-Code Generation with Execution\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.382, \"y\": 2.371}, {\"title\": \"Stabilising and accelerating light gated recurrent units for automatic  speech recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.174, \"y\": 5.168}, {\"title\": \"Dynamic Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.333, \"y\": 6.804}, {\"title\": \"Efficiency 360: Efficient Vision Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.793, \"y\": 3.374}, {\"title\": \"NUAA-QMUL-AIIT at Memotion 3: Multi-modal Fusion with  Squeeze-and-Excitation for Internet Meme Emotion Analysis\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.252, \"y\": 7.483}, {\"title\": \"Retrieval-augmented Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.974, \"y\": 7.49}, {\"title\": \"Improving Spoken Language Identification with Map-Mix\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.547, \"y\": 5.204}, {\"title\": \"Dialogue State Distillation Network with Inter-slot Contrastive Learning  for Dialogue State Tracking\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.645, \"y\": 3.891}, {\"title\": \"Aligning Language Models with Preferences through f-divergence  Minimization\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.298, \"y\": 1.357}, {\"title\": \"Empirical Investigation of Neural Symbolic Reasoning Strategies\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.839, \"y\": 2.404}, {\"title\": \"Learning to Initialize: Can Meta Learning Improve Cross-task  Generalization in Prompt Tuning?\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.818, \"y\": 3.398}, {\"title\": \"PAAPLoss: A Phonetic-Aligned Acoustic Parameter Loss for Speech  Enhancement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.014, \"y\": 5.477}, {\"title\": \"Product Question Answering in E-Commerce: A Survey\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.355, \"y\": 5.196}, {\"title\": \"Do We Still Need Clinical Language Models?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.886, \"y\": 7.992}, {\"title\": \"TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.059, \"y\": 5.433}, {\"title\": \"Exploring the Limits of ChatGPT for Query or Aspect-based Text  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.493, \"y\": 6.019}, {\"title\": \"Document Flattening: Beyond Concatenating Context for Document-Level  Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.867, \"y\": 4.253}, {\"title\": \"Generalization algorithm of multimodal pre-training model based on  graph-text self-supervised training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.471, \"y\": 7.09}, {\"title\": \"\\u00c0-la-carte Prompt Tuning (APT): Combining Distinct Data Via Composable  Prompting\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.689, \"y\": 3.312}, {\"title\": \"Tree-Based Representation and Generation of Natural and Mathematical  Language\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.333, \"y\": 3.069}, {\"title\": \"Meeting the Needs of Low-Resource Languages: The Value of Automatic  Alignments via Pretrained Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.404, \"y\": 4.954}, {\"title\": \"BiasTestGPT: Using ChatGPT for Social Bias Testing of Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.419, \"y\": 4.304}, {\"title\": \"ScatterShot: Interactive In-context Example Curation for Text  Transformation\", \"topic\": \"In-Context Learning\", \"x\": 8.242, \"y\": 3.403}, {\"title\": \"READIN: A Chinese Multi-Task Benchmark with Realistic and Diverse Input  Noises\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.661, \"y\": 5.505}, {\"title\": \"A Friendly Face: Do Text-to-Image Systems Rely on Stereotypes when the  Input is Under-Specified?\", \"topic\": \"Bias in Language Models\", \"x\": 3.314, \"y\": 4.498}, {\"title\": \"Modeling Complex Event Scenarios via Simple Entity-focused Questions\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.268, \"y\": 5.456}, {\"title\": \"Generation of Highlights from Research Papers Using Pointer-Generator  Networks and SciBERT Embeddings\", \"topic\": \"Text Summarization\", \"x\": 5.878, \"y\": 6.338}, {\"title\": \"SwitchPrompt: Learning Domain-Specific Gated Soft Prompts for  Classification in Low-Resource Domains\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.83, \"y\": 3.473}, {\"title\": \"BLIAM: Literature-based Data Synthesis for Synergistic Drug Combination  Prediction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.36, \"y\": 7.66}, {\"title\": \"PK-ICR: Persona-Knowledge Interactive Context Retrieval for Grounded  Dialogue\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.536, \"y\": 4.052}, {\"title\": \"UniAdapter: Unified Parameter-Efficient Transfer Learning for  Cross-modal Modeling\", \"topic\": \"Multimodal Language Models\", \"x\": 8.382, \"y\": 7.008}, {\"title\": \"Gradient-Based Automated Iterative Recovery for Parameter-Efficient  Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.787, \"y\": 2.425}, {\"title\": \"A Study on ReLU and Softmax in Transformer\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.844, \"y\": 3.324}, {\"title\": \"Encoding Sentence Position in Context-Aware Neural Machine Translation  with Concatenation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.757, \"y\": 4.282}, {\"title\": \"Joint Span Segmentation and Rhetorical Role Labeling with Data  Augmentation for Legal Documents\", \"topic\": \"Legal NLP\", \"x\": 5.092, \"y\": 5.779}, {\"title\": \"Paparazzi: A Deep Dive into the Capabilities of Language and Vision  Models for Grounding Viewpoint Descriptions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.825, \"y\": 7.372}, {\"title\": \"Parameter-efficient Modularised Bias Mitigation via AdapterFusion\", \"topic\": \"Bias in Language Models\", \"x\": 3.305, \"y\": 4.304}, {\"title\": \"Distinguishability Calibration to In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.342, \"y\": 3.465}, {\"title\": \"NNKGC: Improving Knowledge Graph Completion with Node Neighborhoods\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.021, \"y\": 6.062}, {\"title\": \"Emotion Detection in Unfix-length-Context Conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.28, \"y\": 7.783}, {\"title\": \"ASR Bundestag: A Large-Scale political debate dataset in German\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.105, \"y\": 5.528}, {\"title\": \"LiT Tuned Models for Efficient Species Detection\", \"topic\": \"Multimodal Language Models\", \"x\": 8.579, \"y\": 6.977}, {\"title\": \"Analyzing the Effectiveness of the Underlying Reasoning Tasks in  Multi-hop Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.811, \"y\": 5.467}, {\"title\": \"TextDefense: Adversarial Text Detection based on Word Importance Entropy\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.139, \"y\": 3.045}, {\"title\": \"AIDA: Legal Judgment Predictions for Non-Professional Fact Descriptions  via Partial-and-Imbalanced Domain Adaptation\", \"topic\": \"Legal NLP\", \"x\": 5.049, \"y\": 5.833}, {\"title\": \"\\\"Why is this misleading?\\\": Detecting News Headline Hallucinations with  Explanations\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.062, \"y\": 1.11}, {\"title\": \"Transformer models: an introduction and catalog\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.493, \"y\": 3.585}, {\"title\": \"A Brief Report on LawGPT 1.0: A Virtual Legal Assistant Based on GPT-3\", \"topic\": \"Legal NLP\", \"x\": 5.23, \"y\": 5.537}, {\"title\": \"Fair Enough: Standardizing Evaluation and Model Selection for Fairness  Research in NLP\", \"topic\": \"Bias in Language Models\", \"x\": 3.465, \"y\": 4.215}, {\"title\": \"Compositional Exemplars for In-context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.247, \"y\": 3.393}, {\"title\": \"Counter-GAP: Counterfactual Bias Evaluation through Gendered Ambiguous  Pronouns\", \"topic\": \"Bias in Language Models\", \"x\": 3.17, \"y\": 4.387}, {\"title\": \"Explaining text classifiers through progressive neighborhood  approximation with realistic samples\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.983, \"y\": 3.976}, {\"title\": \"Dialectograms: Machine Learning Differences between Discursive  Communities\", \"topic\": \"Fake News Detection\", \"x\": 3.546, \"y\": 5.551}, {\"title\": \"Evaluating the Robustness of Discrete Prompts\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.28, \"y\": 3.311}, {\"title\": \"Differentiable Outlier Detection Enable Robust Deep Multimodal Analysis\", \"topic\": \"Multimodal Language Models\", \"x\": 8.257, \"y\": 7.184}, {\"title\": \"Is ChatGPT better than Human Annotators? Potential and Limitations of  ChatGPT in Explaining Implicit Hate Speech\", \"topic\": \"Hate Speech Detection\", \"x\": 2.844, \"y\": 5.277}, {\"title\": \"ASDF: A Differential Testing Framework for Automatic Speech Recognition  Systems\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.235, \"y\": 5.509}, {\"title\": \"NapSS: Paragraph-level Medical Text Simplification via Narrative  Prompting and Sentence-matching Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.903, \"y\": 7.553}, {\"title\": \"FairPy: A Toolkit for Evaluation of Social Biases and their Mitigation  in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.308, \"y\": 4.321}, {\"title\": \"Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews  on Social Media\", \"topic\": \"Fake News Detection\", \"x\": 3.911, \"y\": 6.023}, {\"title\": \"Distillation of encoder-decoder transformers for sequence labelling\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.432, \"y\": 3.797}, {\"title\": \"Span-based Named Entity Recognition by Generating and Compressing  Information\", \"topic\": \"Named Entity Recognition\", \"x\": 7.362, \"y\": 6.808}, {\"title\": \"A Song of Ice and Fire: Analyzing Textual Autotelic Agents in  ScienceWorld\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.716, \"y\": 2.424}, {\"title\": \"The Wisdom of Hindsight Makes Language Models Better Instruction  Followers\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.166, \"y\": 1.58}, {\"title\": \"Realistic Conversational Question Answering with Answer Selection based  on Calibrated Confidence and Uncertainty Measurement\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.319, \"y\": 4.824}, {\"title\": \"Step by Step Loss Goes Very Far: Multi-Step Quantization for Adversarial  Text Attacks\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.121, \"y\": 3.018}, {\"title\": \"Cross-Corpora Spoken Language Identification with Domain Diversification  and Generalization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.361, \"y\": 5.306}, {\"title\": \"PATCorrect: Non-autoregressive Phoneme-augmented Transformer for ASR  Error Correction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.098, \"y\": 5.349}, {\"title\": \"AV-data2vec: Self-supervised Learning of Audio-Visual Speech  Representations with Contextualized Target Representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.755, \"y\": 5.461}, {\"title\": \"Is Multimodal Vision Supervision Beneficial to Language?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.504, \"y\": 7.303}, {\"title\": \"Language-Aware Multilingual Machine Translation with Self-Supervised  Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.786, \"y\": 4.714}, {\"title\": \"Leveraging supplementary text data to kick-start automatic speech  recognition system development with limited transcriptions\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.097, \"y\": 5.436}, {\"title\": \"In-Context Learning with Many Demonstration Examples\", \"topic\": \"In-Context Learning\", \"x\": 8.69, \"y\": 3.305}, {\"title\": \"Re-ViLM: Retrieval-Augmented Visual Language Model for Zero and Few-Shot  Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.721, \"y\": 7.415}, {\"title\": \"Explanation Selection Using Unlabeled Data for Chain-of-Thought  Prompting\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.854, \"y\": 3.642}, {\"title\": \"A Large-Scale Multilingual Study of Visual Constraints on Linguistic  Selection of Descriptions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.544, \"y\": 7.466}, {\"title\": \"Lightweight Transformers for Clinical Natural Language Processing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.94, \"y\": 7.884}, {\"title\": \"Robust Question Answering against Distribution Shifts with Test-Time  Adaptation: An Empirical Study\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.88, \"y\": 5.006}, {\"title\": \"Generating a Structured Summary of Numerous Academic Papers: Dataset and  Method\", \"topic\": \"Text Summarization\", \"x\": 5.629, \"y\": 6.348}, {\"title\": \"NLP-based Decision Support System for Examination of Eligibility  Criteria from Securities Prospectuses at the German Central Bank\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.11, \"y\": 6.562}, {\"title\": \"Data Augmentation for Robust Character Detection in Fantasy Novels\", \"topic\": \"Named Entity Recognition\", \"x\": 7.416, \"y\": 6.782}, {\"title\": \"Efficient Attention via Control Variates\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.902, \"y\": 3.155}, {\"title\": \"Enhancing E-Commerce Recommendation using Pre-Trained Language Model and  Fine-Tuning\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.958, \"y\": 2.94}, {\"title\": \"A Transformer-based Response Evaluator for Open-Domain Spoken  Conversation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.316, \"y\": 3.859}, {\"title\": \"Sentiment analysis and opinion mining on educational data: A survey\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.546, \"y\": 6.723}, {\"title\": \"Diagnosing and Rectifying Vision Models using Language\", \"topic\": \"Multimodal Language Models\", \"x\": 8.359, \"y\": 7.539}, {\"title\": \"Efficient Joint Learning for Clinical Named Entity Recognition and  Relation Extraction Using Fourier Networks: A Use Case in Adverse Drug Events\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.25, \"y\": 7.574}, {\"title\": \"Prompting for Multimodal Hateful Meme Classification\", \"topic\": \"Hate Speech Detection\", \"x\": 2.782, \"y\": 5.567}, {\"title\": \"ChatGPT versus Traditional Question Answering for Knowledge Graphs:  Current Status and Future Directions Towards Knowledge Graph Chatbots\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.705, \"y\": 5.489}, {\"title\": \"Leveraging Summary Guidance on Medical Report Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.888, \"y\": 8.235}, {\"title\": \"Improving (Dis)agreement Detection with Inductive Social Relation  Information From Comment-Reply Interactions\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.827, \"y\": 6.65}, {\"title\": \"COMBO: A Complete Benchmark for Open KG Canonicalization\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.126, \"y\": 6.151}, {\"title\": \"Clinical BioBERT Hyperparameter Optimization using Genetic Algorithm\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.483, \"y\": 7.876}, {\"title\": \"Long Text and Multi-Table Summarization: Dataset and Method\", \"topic\": \"Text Summarization\", \"x\": 5.518, \"y\": 6.427}, {\"title\": \"Reliable Natural Language Understanding with Large Language Models and  Answer Set Programming\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.736, \"y\": 3.032}, {\"title\": \"Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.581, \"y\": 4.735}, {\"title\": \"ZipLM: Inference-Aware Structured Pruning of Language Models\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.621, \"y\": 2.527}, {\"title\": \"Auditing Gender Presentation Differences in Text-to-Image Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.174, \"y\": 4.505}, {\"title\": \"Characterizing Financial Market Coverage using Artificial Intelligence\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.736, \"y\": 6.763}, {\"title\": \"Efficiently Upgrading Multilingual Machine Translation Models to Support  More Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.645, \"y\": 4.309}, {\"title\": \"A Survey on Arabic Named Entity Recognition: Past, Recent Advances, and  Future Trends\", \"topic\": \"Named Entity Recognition\", \"x\": 7.43, \"y\": 6.858}, {\"title\": \"Cluster-Level Contrastive Learning for Emotion Recognition in  Conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.263, \"y\": 7.792}, {\"title\": \"Learning Translation Quality Evaluation on Low Resource Languages from  Large Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.439, \"y\": 4.38}, {\"title\": \"Entity-Aware Dual Co-Attention Network for Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 3.955, \"y\": 5.878}, {\"title\": \"PLACES: Prompting Language Models for Social Conversation Synthesis\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.046, \"y\": 3.753}, {\"title\": \"Bringing the State-of-the-Art to Customers: A Neural Agent Assistant  Framework for Customer Service Support\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.114, \"y\": 3.618}, {\"title\": \"It's about Time: Rethinking Evaluation on Rumor Detection Benchmarks  using Chronological Splits\", \"topic\": \"Fake News Detection\", \"x\": 4.032, \"y\": 5.924}, {\"title\": \"Techniques to Improve Neural Math Word Problem Solvers\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.08, \"y\": 2.808}, {\"title\": \"Migration Reframed? A multilingual analysis on the stance shift in  Europe during the Ukrainian crisis\", \"topic\": \"Fake News Detection\", \"x\": 3.631, \"y\": 5.903}, {\"title\": \"Chain of Hindsight Aligns Language Models with Feedback\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.188, \"y\": 1.564}, {\"title\": \"Less is More: Understanding Word-level Textual Adversarial Attack via  n-gram Frequency Descend\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.14, \"y\": 3.03}, {\"title\": \"A Categorical Archive of ChatGPT Failures\", \"topic\": \"Bias in Language Models\", \"x\": 5.146, \"y\": 4.35}, {\"title\": \"Hatemongers ride on echo chambers to escalate hate speech diffusion\", \"topic\": \"Hate Speech Detection\", \"x\": 3.021, \"y\": 5.408}, {\"title\": \"Nationality Bias in Text Generation\", \"topic\": \"Bias in Language Models\", \"x\": 3.441, \"y\": 4.463}, {\"title\": \"FineDeb: A Debiasing Framework for Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.259, \"y\": 4.331}, {\"title\": \"deep learning of segment-level feature representation for speech emotion  recognition in conversations\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.253, \"y\": 7.812}, {\"title\": \"MAC: A unified framework boosting low resource automatic speech  recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.022, \"y\": 5.381}, {\"title\": \"Interaction Order Prediction for Temporal Graphs\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.827, \"y\": 6.122}, {\"title\": \"Greedy Ordering of Layer Weight Matrices in Transformers Improves  Translation\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.738, \"y\": 3.477}, {\"title\": \"A New cross-domain strategy based XAI models for fake news detection\", \"topic\": \"Fake News Detection\", \"x\": 3.988, \"y\": 5.867}, {\"title\": \"Knowledge Graph Completion Method Combined With Adaptive Enhanced  Semantic Information\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.131, \"y\": 5.933}, {\"title\": \"Sentiment Analysis on YouTube Smart Phone Unboxing Video Reviews in Sri  Lanka\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.713, \"y\": 6.499}, {\"title\": \"The Science of Detecting LLM-Generated Texts\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.172, \"y\": 4.734}, {\"title\": \"FGSI: Distant Supervision for Relation Extraction method based on  Fine-Grained Semantic Information\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.859, \"y\": 6.854}, {\"title\": \"TextShield: Beyond Successfully Detecting Adversarial Sentences in Text  Classification\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.138, \"y\": 3.105}, {\"title\": \"PSST! Prosodic Speech Segmentation with Transformers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.748, \"y\": 5.535}, {\"title\": \"Exploring the Cognitive Dynamics of Artificial Intelligence in the  Post-COVID-19 and Learning 3.0 Era: A Case Study of ChatGPT\", \"topic\": \"Bias in Language Models\", \"x\": 4.912, \"y\": 4.363}, {\"title\": \"GLADIS: A General and Large Acronym Disambiguation Benchmark\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.501, \"y\": 7.297}, {\"title\": \"Generalizing to Unseen Elements: A Survey on Knowledge Extrapolation for  Knowledge Graphs\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.038, \"y\": 5.991}, {\"title\": \"Entity-Agnostic Representation Learning for Parameter-Efficient  Knowledge Graph Embedding\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.235, \"y\": 6.282}, {\"title\": \"A Case Study for Compliance as Code with Graphs and Language Models:  Public release of the Regulatory Knowledge Graph\", \"topic\": \"Legal NLP\", \"x\": 5.253, \"y\": 5.635}, {\"title\": \"Investigating Stylistic Profiles for the Task of Empathy Classification  in Medical Narrative Essays\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.724, \"y\": 7.84}, {\"title\": \"CAB: Empathetic Dialogue Generation with Cognition, Affection and  Behavior\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.636, \"y\": 7.876}, {\"title\": \"LIQUID: A Framework for List Question Answering Dataset Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.298, \"y\": 5.214}, {\"title\": \"Show me your NFT and I tell you how it will perform: Multimodal  representation learning for NFT selling price prediction\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.831, \"y\": 6.854}, {\"title\": \"Modeling Sequential Sentence Relation to Improve Cross-lingual Dense  Retrieval\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.18, \"y\": 4.998}, {\"title\": \"Bioformer: an efficient transformer language model for biomedical text  mining\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.256, \"y\": 7.64}, {\"title\": \"Controlling for Stereotypes in Multimodal Language Model Evaluation\", \"topic\": \"Bias in Language Models\", \"x\": 3.25, \"y\": 4.447}, {\"title\": \"Detecting Reddit Users with Depression Using a Hybrid Neural Network  SBERT-CNN\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.139, \"y\": 7.39}, {\"title\": \"Using natural language processing and structured medical data to  phenotype patients hospitalized due to COVID-19\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.472, \"y\": 7.969}, {\"title\": \"Revisiting Intermediate Layer Distillation for Compressing Language  Models: An Overfitting Perspective\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.559, \"y\": 3.812}, {\"title\": \"Efficient Domain Adaptation for Speech Foundation Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.989, \"y\": 4.991}, {\"title\": \"Commonsense-Aware Prompting for Controllable Empathetic Dialogue  Generation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.685, \"y\": 7.868}, {\"title\": \"The unreasonable effectiveness of few-shot learning for machine  translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.587, \"y\": 4.492}, {\"title\": \"IC3: Image Captioning by Committee Consensus\", \"topic\": \"Multimodal Language Models\", \"x\": 9.007, \"y\": 7.433}, {\"title\": \"Double Equivariance for Inductive Link Prediction for Both New Nodes and  New Relation Types\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.102, \"y\": 6.06}, {\"title\": \"Curriculum-Guided Abstractive Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.575, \"y\": 6.359}, {\"title\": \"TransFool: An Adversarial Attack against Neural Machine Translation  Models\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.076, \"y\": 2.946}, {\"title\": \"Multimodal Chain-of-Thought Reasoning in Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.026, \"y\": 7.704}, {\"title\": \"History-Aware Hierarchical Transformer for Multi-session Open-domain  Dialogue System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.514, \"y\": 3.906}, {\"title\": \"Language Quantized AutoEncoders: Towards Unsupervised Text-Image  Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.763, \"y\": 7.085}, {\"title\": \"Improving Rare Words Recognition through Homophone Extension and Unified  Writing for Low-resource Cantonese Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.046, \"y\": 5.32}, {\"title\": \"Leveraging Task Dependency and Contrastive Learning for Case Outcome  Classification on European Court of Human Rights Cases\", \"topic\": \"Legal NLP\", \"x\": 5.09, \"y\": 5.885}, {\"title\": \"Visually Grounded Keyword Detection and Localisation for Low-Resource  Languages\", \"topic\": \"Multimodal Language Models\", \"x\": 8.945, \"y\": 6.95}, {\"title\": \"Collaborating with language models for embodied reasoning\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.806, \"y\": 2.494}, {\"title\": \"DANES: Deep Neural Network Ensemble Architecture for Social and Textual  Context-aware Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 3.948, \"y\": 5.894}, {\"title\": \"Synthetic Prompting: Generating Chain-of-Thought Demonstrations for  Large Language Models\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.797, \"y\": 2.591}, {\"title\": \"Zero-shot Transfer of Article-aware Legal Outcome Classification for  European Court of Human Rights Cases\", \"topic\": \"Legal NLP\", \"x\": 5.086, \"y\": 5.856}, {\"title\": \"Analyzing Feed-Forward Blocks in Transformers through the Lens of  Attention Maps\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.642, \"y\": 3.482}, {\"title\": \"HunSum-1: an Abstractive Summarization Dataset for Hungarian\", \"topic\": \"Text Summarization\", \"x\": 5.527, \"y\": 6.388}, {\"title\": \"Improved Knowledge Distillation for Pre-trained Language Models via  Knowledge Selection\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.503, \"y\": 3.811}, {\"title\": \"KNNs of Semantic Encodings for Rating Prediction\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.943, \"y\": 2.904}, {\"title\": \"mPLUG-2: A Modularized Multi-modal Foundation Model Across Text, Image  and Video\", \"topic\": \"Multimodal Language Models\", \"x\": 8.344, \"y\": 7.278}, {\"title\": \"Evaluating TCFD Reporting: A New Application of Zero-Shot Analysis to  Climate-Related Financial Disclosures\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.817, \"y\": 6.536}, {\"title\": \"An Evaluation of Persian-English Machine Translation Datasets with  Transformers\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.453, \"y\": 5.227}, {\"title\": \"Filtering Context Mitigates Scarcity and Selection Bias in Political  Ideology Prediction\", \"topic\": \"Fake News Detection\", \"x\": 3.63, \"y\": 5.589}, {\"title\": \"Grading Conversational Responses Of Chatbots\", \"topic\": \"Bias in Language Models\", \"x\": 5.05, \"y\": 4.382}, {\"title\": \"Program Generation from Diverse Video Demonstrations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.86, \"y\": 7.848}, {\"title\": \"Machine Translation Impact in E-commerce Multilingual Search\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.67, \"y\": 4.726}, {\"title\": \"Towards Detecting Harmful Agendas in News Articles\", \"topic\": \"Fake News Detection\", \"x\": 3.924, \"y\": 5.743}, {\"title\": \"Do Multi-Document Summarization Models Synthesize?\", \"topic\": \"Text Summarization\", \"x\": 5.451, \"y\": 6.297}, {\"title\": \"Grounding Language Models to Images for Multimodal Inputs and Outputs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.66, \"y\": 7.113}, {\"title\": \"Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image  Diffusion Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.934, \"y\": 6.837}, {\"title\": \"Execution-based Code Generation using Deep Reinforcement Learning\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.481, \"y\": 2.389}, {\"title\": \"Zero-shot cross-lingual transfer language selection using linguistic  similarity\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.41, \"y\": 4.883}, {\"title\": \"The Flan Collection: Designing Data and Methods for Effective  Instruction Tuning\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.226, \"y\": 2.263}, {\"title\": \"Automated Sentiment and Hate Speech Analysis of Facebook Data by  Employing Multilingual Transformer Models\", \"topic\": \"Hate Speech Detection\", \"x\": 2.828, \"y\": 5.424}, {\"title\": \"Faithful Chain-of-Thought Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.684, \"y\": 2.299}, {\"title\": \"Improving Open-Domain Dialogue Evaluation with a Causal Inference Model\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.258, \"y\": 3.863}, {\"title\": \"ViewCo: Discovering Text-Supervised Segmentation Masks via Multi-View  Semantic Consistency\", \"topic\": \"Multimodal Language Models\", \"x\": 8.82, \"y\": 7.127}, {\"title\": \"Alternating Updates for Efficient Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.834, \"y\": 3.242}, {\"title\": \"LongEval: Guidelines for Human Evaluation of Faithfulness in Long-form  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.486, \"y\": 6.033}, {\"title\": \"Advancing Radiograph Representation Learning with Masked Record Modeling\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.276, \"y\": 8.606}, {\"title\": \"LEXTREME: A Multi-Lingual and Multi-Task Benchmark for the Legal Domain\", \"topic\": \"Legal NLP\", \"x\": 5.442, \"y\": 5.35}, {\"title\": \"Quantifying Context Mixing in Transformers\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.795, \"y\": 3.474}, {\"title\": \"Active Learning for Multilingual Semantic Parser\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.224, \"y\": 4.908}, {\"title\": \"N-Gram Nearest Neighbor Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.016, \"y\": 4.326}, {\"title\": \"How Far Can It Go?: On Intrinsic Gender Bias Mitigation for Text  Classification\", \"topic\": \"Bias in Language Models\", \"x\": 3.194, \"y\": 4.304}, {\"title\": \"GE-Blender: Graph-Based Knowledge Enhancement for Blender\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.837, \"y\": 6.129}, {\"title\": \"Finding the Law: Enhancing Statutory Article Retrieval via Graph Neural  Networks\", \"topic\": \"Legal NLP\", \"x\": 5.361, \"y\": 5.815}, {\"title\": \"Specializing Smaller Language Models towards Multi-Step Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.162, \"y\": 2.906}, {\"title\": \"KG-BERTScore: Incorporating Knowledge Graph into BERTScore for  Reference-Free Machine Translation Evaluation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.806, \"y\": 4.855}, {\"title\": \"Knowledge Distillation $\\\\approx$ Label Smoothing: Fact or Fallacy?\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.596, \"y\": 3.795}, {\"title\": \"Learning to Speak from Text: Zero-Shot Multilingual Text-to-Speech with  Unsupervised Text Pretraining\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.446, \"y\": 5.317}, {\"title\": \"Schema-Guided Semantic Accuracy: Faithfulness in Task-Oriented Dialogue  Response Generation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.559, \"y\": 3.884}, {\"title\": \"Improving Cross-lingual Information Retrieval on Low-Resource Languages  via Optimal Transport Distillation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.498, \"y\": 4.867}, {\"title\": \"Vicarious Offense and Noise Audit of Offensive Speech Classifiers:  Unifying Human and Machine Disagreement on What is Offensive\", \"topic\": \"Hate Speech Detection\", \"x\": 2.988, \"y\": 5.199}, {\"title\": \"Large Language Models for Biomedical Knowledge Graph Construction:  Information extraction from EMR notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.914, \"y\": 7.753}, {\"title\": \"Syrupy Mouthfeel and Hints of Chocolate -- Predicting Coffee Review  Scores using Text Based Sentiment\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.546, \"y\": 6.58}, {\"title\": \"Achieving Timestamp Prediction While Recognizing with Non-Autoregressive  End-to-End ASR Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.333, \"y\": 5.106}, {\"title\": \"Time out of Mind: Generating Rate of Speech conditioned on emotion and  speaker\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.644, \"y\": 5.916}, {\"title\": \"MQAG: Multiple-choice Question Answering and Generation for Assessing  Information Consistency in Summarization\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.23, \"y\": 5.239}, {\"title\": \"Presence of informal language, such as emoticons, hashtags, and slang,  impact the performance of sentiment analysis models on social media text?\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.575, \"y\": 6.685}, {\"title\": \"Semantic Parsing for Conversational Question Answering over Knowledge  Graphs\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.865, \"y\": 5.364}, {\"title\": \"Multilingual Sentence Transformer as A Multilingual Word Aligner\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.291, \"y\": 5.021}, {\"title\": \"Bipol: Multi-axes Evaluation of Bias with Explainability in Benchmark  Datasets\", \"topic\": \"Bias in Language Models\", \"x\": 3.26, \"y\": 4.513}, {\"title\": \"AutoPEFT: Automatic Configuration Search for Parameter-Efficient  Fine-Tuning\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.024, \"y\": 2.31}, {\"title\": \"On Pre-trained Language Models for Antibody\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.59, \"y\": 7.674}, {\"title\": \"Comparing Intrinsic Gender Bias Evaluation Measures without using Human  Annotated Examples\", \"topic\": \"Bias in Language Models\", \"x\": 3.165, \"y\": 4.41}, {\"title\": \"Do Embodied Agents Dream of Pixelated Sheep: Embodied Decision Making  using Language Guided World Modelling\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.84, \"y\": 2.383}, {\"title\": \"Understanding INT4 Quantization for Transformer Models: Latency Speedup,  Composability, and Failure Cases\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.881, \"y\": 2.28}, {\"title\": \"Improved knowledge distillation by utilizing backward pass knowledge in  neural networks\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.604, \"y\": 3.849}, {\"title\": \"Large Language Models Are Latent Variable Models: Explaining and Finding  Good Demonstrations for In-Context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.384, \"y\": 3.377}, {\"title\": \"Predicting Sentence-Level Factuality of News and Bias of Media Outlets\", \"topic\": \"Fake News Detection\", \"x\": 4.111, \"y\": 5.84}, {\"title\": \"A Comparative Study of Pretrained Language Models for Long Clinical Text\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.877, \"y\": 8.014}, {\"title\": \"Learning the Effects of Physical Actions in a Multi-modal Environment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.325, \"y\": 7.336}, {\"title\": \"Graph Attention with Hierarchies for Multi-hop Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.783, \"y\": 5.499}, {\"title\": \"A Multi-task Multi-stage Transitional Training Framework for Neural Chat  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.04, \"y\": 4.628}, {\"title\": \"Pre-training for Speech Translation: CTC Meets Optimal Transport\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.525, \"y\": 5.146}, {\"title\": \"Can We Use Probing to Better Understand Fine-tuning and Knowledge  Distillation of the BERT NLU?\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.329, \"y\": 3.62}, {\"title\": \"A Multi-View Joint Learning Framework for Embedding Clinical Codes and  Text Using Graph Neural Networks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.999, \"y\": 8.353}, {\"title\": \"ThoughtSource: A central hub for large language model reasoning data\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.637, \"y\": 2.375}, {\"title\": \"Down the Rabbit Hole: Detecting Online Extremism, Radicalisation, and  Politicised Hate Speech\", \"topic\": \"Hate Speech Detection\", \"x\": 2.963, \"y\": 5.399}, {\"title\": \"Semi-Parametric Video-Grounded Text Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.963, \"y\": 7.839}, {\"title\": \"Candidate Soups: Fusing Candidate Results Improves Translation Quality  for Non-Autoregressive Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 10.171, \"y\": 4.468}, {\"title\": \"Exploring External Knowledge for Accurate modeling of Visual and  Language Problems\", \"topic\": \"Multimodal Language Models\", \"x\": 8.518, \"y\": 7.555}, {\"title\": \"Task formulation for Extracting Social Determinants of Health from  Clinical Narratives\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.402, \"y\": 7.827}, {\"title\": \"Style-Aware Contrastive Learning for Multi-Style Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.091, \"y\": 7.36}, {\"title\": \"Improving Cross-modal Alignment for Text-Guided Image Inpainting\", \"topic\": \"Multimodal Language Models\", \"x\": 8.742, \"y\": 7.045}, {\"title\": \"LoRaLay: A Multilingual and Multimodal Dataset for Long Range and  Layout-Aware Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.762, \"y\": 6.486}, {\"title\": \"DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability  Curvature\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.08, \"y\": 4.692}, {\"title\": \"Characterizing the Entities in Harmful Memes: Who is the Hero, the  Villain, the Victim?\", \"topic\": \"Hate Speech Detection\", \"x\": 2.933, \"y\": 5.717}, {\"title\": \"Semi-Supervised Image Captioning by Adversarially Propagating Labeled  Data\", \"topic\": \"Multimodal Language Models\", \"x\": 9.111, \"y\": 7.39}, {\"title\": \"A benchmark for toxic comment classification on Civil Comments dataset\", \"topic\": \"Hate Speech Detection\", \"x\": 2.899, \"y\": 5.201}, {\"title\": \"NLP as a Lens for Causal Analysis and Perception Mining to Infer Mental  Health on Social Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.283, \"y\": 7.512}, {\"title\": \"Cross Modal Global Local Representation Learning from Radiology Reports  and X-Ray Chest Images\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.25, \"y\": 8.566}, {\"title\": \"Affective Faces for Goal-Driven Dyadic Communication\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.537, \"y\": 7.768}, {\"title\": \"Parameter-Efficient Low-Resource Dialogue State Tracking by Prompt  Tuning\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.727, \"y\": 3.891}, {\"title\": \"Qualitative Analysis of a Graph Transformer Approach to Addressing Hate  Speech: Adapting to Dynamically Changing Content\", \"topic\": \"Hate Speech Detection\", \"x\": 2.822, \"y\": 5.443}, {\"title\": \"Partial Mobilization: Tracking Multilingual Information Flows Amongst  Russian Media Outlets and Telegram\", \"topic\": \"Fake News Detection\", \"x\": 3.741, \"y\": 5.859}, {\"title\": \"Towards a Unified Model for Generating Answers and Explanations in  Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.179, \"y\": 8.023}, {\"title\": \"A Holistic Cascade System, benchmark, and Human Evaluation Protocol for  Expressive Speech-to-Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.46, \"y\": 5.491}, {\"title\": \"A Study on FGSM Adversarial Training for Neural Retrieval\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.161, \"y\": 3.015}, {\"title\": \"Cross-lingual Argument Mining in the Medical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.879, \"y\": 7.6}, {\"title\": \"XLM-V: Overcoming the Vocabulary Bottleneck in Multilingual Masked  Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.357, \"y\": 4.391}, {\"title\": \"Improved Stock Price Movement Classification Using News Articles Based  on Embeddings and Label Smoothing\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.725, \"y\": 6.842}, {\"title\": \"Knowledge-augmented Graph Neural Networks with Concept-aware Attention  for Adverse Drug Event Detection\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.709, \"y\": 7.882}, {\"title\": \"Causal-Discovery Performance of ChatGPT in the context of Neuropathic  Pain Diagnosis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.372, \"y\": 7.744}, {\"title\": \"ViHOS: Hate Speech Spans Detection for Vietnamese\", \"topic\": \"Hate Speech Detection\", \"x\": 2.78, \"y\": 5.426}, {\"title\": \"Large Language Models as Fiduciaries: A Case Study Toward Robustly  Communicating With Artificial Intelligence Through Legal Standards\", \"topic\": \"Legal NLP\", \"x\": 5.033, \"y\": 5.293}, {\"title\": \"Gender Neutralization for an Inclusive Machine Translation: from  Theoretical Foundations to Open Challenges\", \"topic\": \"Bias in Language Models\", \"x\": 2.974, \"y\": 4.404}, {\"title\": \"Generating High-Precision Feedback for Programming Syntax Errors using  Large Language Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.271, \"y\": 2.465}, {\"title\": \"Applications and Challenges of Sentiment Analysis in Real-life Scenarios\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.686, \"y\": 6.565}, {\"title\": \"Cross-lingual German Biomedical Information Extraction: from Zero-shot  to Human-in-the-Loop\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.214, \"y\": 7.87}, {\"title\": \"A Stability Analysis of Fine-Tuning a Pre-Trained Model\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.946, \"y\": 2.406}, {\"title\": \"PrimeQA: The Prime Repository for State-of-the-Art Multilingual Question  Answering Research and Development\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.557, \"y\": 5.18}, {\"title\": \"Selective Explanations: Leveraging Human Input to Align Explainable AI\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.377, \"y\": 3.728}, {\"title\": \"Efficient Language Model Training through Cross-Lingual and Progressive  Transfer Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.38, \"y\": 4.616}, {\"title\": \"Lexi: Self-Supervised Learning of the UI Language\", \"topic\": \"Multimodal Language Models\", \"x\": 8.553, \"y\": 7.39}, {\"title\": \"Sensemaking About Contraceptive Methods Across Online Platforms\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.244, \"y\": 7.218}, {\"title\": \"StockEmotions: Discover Investor Emotions for Financial Sentiment  Analysis and Multivariate Time Series\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.586, \"y\": 6.856}, {\"title\": \"Efficient Encoders for Streaming Sequence Tagging\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.071, \"y\": 5.05}, {\"title\": \"An Empirical Study of Metrics to Measure Representational Harms in  Pre-Trained Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.301, \"y\": 4.272}, {\"title\": \"Summarize the Past to Predict the Future: Natural Language Descriptions  of Context Boost Multimodal Object Interaction Anticipation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.798, \"y\": 7.637}, {\"title\": \"Interpretability in Activation Space Analysis of Transformers: A Focused  Survey\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.562, \"y\": 3.559}, {\"title\": \"Unsupervised Data Selection for TTS: Using Arabic Broadcast News as a  Case Study\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.694, \"y\": 5.534}, {\"title\": \"Weakly-Supervised Questions for Zero-Shot Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.164, \"y\": 6.547}, {\"title\": \"Transfer Knowledge from Natural Language to Electrocardiography: Can We  Detect Cardiovascular Disease Through Language Models?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.928, \"y\": 8.494}, {\"title\": \"Poor Man's Quality Estimation: Predicting Reference-Based MT Metrics  Without the Reference\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.899, \"y\": 4.747}, {\"title\": \"REDAffectiveLM: Leveraging Affect Enriched Embedding and  Transformer-based Neural Language Model for Readers' Emotion Detection\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.35, \"y\": 7.541}, {\"title\": \"Exploring Methods for Building Dialects-Mandarin Code-Mixing Corpora: A  Case Study in Taiwanese Hokkien\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.54, \"y\": 4.932}, {\"title\": \"Investigating Strategies for Clause Recommendation\", \"topic\": \"Legal NLP\", \"x\": 5.17, \"y\": 5.788}, {\"title\": \"Rationalization for Explainable NLP: A Survey\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.88, \"y\": 3.85}, {\"title\": \"A Multi-Purpose Audio-Visual Corpus for Multi-Modal Persian Speech  Recognition: the Arman-AV Dataset\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.515, \"y\": 5.704}, {\"title\": \"Same Words, Different Meanings: Semantic Polarization in Broadcast Media  Language Forecasts Polarization on Social Media Discourse\", \"topic\": \"Fake News Detection\", \"x\": 3.611, \"y\": 5.629}, {\"title\": \"Document Summarization with Text Segmentation\", \"topic\": \"Text Summarization\", \"x\": 5.669, \"y\": 6.449}, {\"title\": \"Phoneme-Level BERT for Enhanced Prosody of Text-to-Speech with Grapheme  Predictions\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.714, \"y\": 5.742}, {\"title\": \"Visual Semantic Relatedness Dataset for Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.894, \"y\": 7.443}, {\"title\": \"Language Agnostic Data-Driven Inverse Text Normalization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.917, \"y\": 5.221}, {\"title\": \"Reversing The Twenty Questions Game\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.091, \"y\": 4.841}, {\"title\": \"Improving Machine Translation with Phrase Pair Injection and Corpus  Filtering\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.812, \"y\": 4.674}, {\"title\": \"Continuously Reliable Detection of New-Normal Misinformation: Semantic  Masking and Contrastive Smoothing in High-Density Latent Regions\", \"topic\": \"Fake News Detection\", \"x\": 4.214, \"y\": 6.057}, {\"title\": \"Batch Prompting: Efficient Inference with Large Language Model APIs\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.327, \"y\": 2.983}, {\"title\": \"Understanding and Detecting Hallucinations in Neural Machine Translation  via Model Introspection\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.125, \"y\": 1.008}, {\"title\": \"KILDST: Effective Knowledge-Integrated Learning for Dialogue State  Tracking using Gazetteer and Speaker Information\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.631, \"y\": 3.951}, {\"title\": \"Adapting Multilingual Speech Representation Model for a New,  Underresourced Language through Multilingual Fine-tuning and Continued  Pretraining\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.805, \"y\": 5.121}, {\"title\": \"Curriculum Script Distillation for Multilingual Visual Question  Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.219, \"y\": 8.024}, {\"title\": \"Leveraging Vision-Language Models for Granular Market Change Prediction\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.635, \"y\": 6.846}, {\"title\": \"On the State of German (Abstractive) Text Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.496, \"y\": 6.309}, {\"title\": \"Learning Customized Visual Models with Retrieval-Augmented Knowledge\", \"topic\": \"Multimodal Language Models\", \"x\": 8.746, \"y\": 7.233}, {\"title\": \"GLIGEN: Open-Set Grounded Text-to-Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.969, \"y\": 6.872}, {\"title\": \"Vision Learners Meet Web Image-Text Pairs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.508, \"y\": 7.155}, {\"title\": \"MooseNet: A Trainable Metric for Synthesized Speech with a PLDA Module\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.898, \"y\": 5.498}, {\"title\": \"Prompting Large Language Model for Machine Translation: A Case Study\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.454, \"y\": 3.285}, {\"title\": \"Transformer Based Implementation for Automatic Book Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.639, \"y\": 6.335}, {\"title\": \"The Newsbridge -Telecom SudParis VoxCeleb Speaker Recognition Challenge  2022 System Description\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.996, \"y\": 5.676}, {\"title\": \"HanoiT: Enhancing Context-aware Translation via Selective Context\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.8, \"y\": 4.248}, {\"title\": \"BERT-ERC: Fine-tuning BERT is Enough for Emotion Recognition in  Conversation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.291, \"y\": 7.802}, {\"title\": \"Two Stage Contextual Word Filtering for Context bias in Unified  Streaming and Non-streaming Transducer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.294, \"y\": 5.104}, {\"title\": \"PromptShots at the FinNLP-2022 ERAI Tasks: Pairwise Comparison and  Unsupervised Ranking\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.779, \"y\": 6.692}, {\"title\": \"Cross-institution text mining to uncover clinical associations: a case  study relating social factors and code status in intensive care medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.483, \"y\": 7.859}, {\"title\": \"XNLI 2.0: Improving XNLI dataset and performance on Cross Lingual  Understanding (XLU)\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.411, \"y\": 4.796}, {\"title\": \"BayesSpeech: A Bayesian Transformer Network for Automatic Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.195, \"y\": 5.011}, {\"title\": \"Using Kaldi for Automatic Speech Recognition of Conversational Austrian  German\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.137, \"y\": 5.424}, {\"title\": \"Towards an Automatic Consolidation of French Law\", \"topic\": \"Legal NLP\", \"x\": 5.172, \"y\": 5.719}, {\"title\": \"OLKAVS: An Open Large-Scale Korean Audio-Visual Speech Dataset\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.523, \"y\": 5.702}, {\"title\": \"Computational Assessment of Hyperpartisanship in News Titles\", \"topic\": \"Fake News Detection\", \"x\": 3.833, \"y\": 5.696}, {\"title\": \"EHRSQL: A Practical Text-to-SQL Benchmark for Electronic Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.946, \"y\": 7.832}, {\"title\": \"Summative Student Course Review Tool Based on Machine Learning Sentiment  Analysis to Enhance Life Science Feedback Efficacy\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.828, \"y\": 6.68}, {\"title\": \"Leveraging Large Language Models to Power Chatbots for Collecting User  Self-Reported Data\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.366, \"y\": 3.791}, {\"title\": \"The 2022 n2c2/UW Shared Task on Extracting Social Determinants of Health\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.344, \"y\": 7.76}, {\"title\": \"FUN with Fisher: Improving Generalization of Adapter-Based Cross-lingual  Transfer with Scheduled Unfreezing\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.343, \"y\": 4.352}, {\"title\": \"It's Just a Matter of Time: Detecting Depression with Time-Enriched  Multimodal Transformers\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.108, \"y\": 7.424}, {\"title\": \"Prompting Neural Machine Translation with Translation Memories\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.857, \"y\": 4.29}, {\"title\": \"Blind Judgement: Agent-Based Supreme Court Modelling With GPT\", \"topic\": \"Legal NLP\", \"x\": 4.992, \"y\": 5.63}, {\"title\": \"See, Think, Confirm: Interactive Prompting Between Vision and Language  Models for Knowledge-based Visual Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.324, \"y\": 7.836}, {\"title\": \"Adversarial Adaptation for French Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.455, \"y\": 6.758}, {\"title\": \"A Dataset of Kurdish (Sorani) Named Entities -- An Amendment to  Kurdish-BLARK Named Entities\", \"topic\": \"Named Entity Recognition\", \"x\": 7.412, \"y\": 6.747}, {\"title\": \"Think Twice: A Human-like Two-stage Conversational Agent for Emotional  Response Generation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.66, \"y\": 7.877}, {\"title\": \"SlideVQA: A Dataset for Document Visual Question Answering on Multiple  Images\", \"topic\": \"Multimodal Language Models\", \"x\": 7.965, \"y\": 7.956}, {\"title\": \"Learning to Memorize Entailment and Discourse Relations for  Persona-Consistent Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.322, \"y\": 3.713}, {\"title\": \"A Cohesive Distillation Architecture for Neural Language Models\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.304, \"y\": 3.816}, {\"title\": \"Multimodal Deep Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.164, \"y\": 7.236}, {\"title\": \"Semantic Web Enabled Geographic Question Answering Framework: GeoTR\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.707, \"y\": 5.494}, {\"title\": \"EXIF as Language: Learning Cross-Modal Associations Between Images and  Camera Metadata\", \"topic\": \"Multimodal Language Models\", \"x\": 8.288, \"y\": 7.213}, {\"title\": \"Modelling low-resource accents without accent-specific TTS frontend\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.837, \"y\": 5.495}, {\"title\": \"Analyzing And Improving Neural Speaker Embeddings for ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.229, \"y\": 5.179}, {\"title\": \"Learning to Exploit Temporal Structure for Biomedical Vision-Language  Processing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.426, \"y\": 8.361}, {\"title\": \"The Role of Interactive Visualization in Explaining (Large) NLP Models:  from Data to Inference\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.883, \"y\": 4.145}, {\"title\": \"Deteksi Depresi dan Kecemasan Pengguna Twitter Menggunakan Bidirectional  LSTM\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.155, \"y\": 7.362}, {\"title\": \"Diving Deep into Modes of Fact Hallucinations in Dialogue Systems\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.271, \"y\": 1.211}, {\"title\": \"Multilingual Entity and Relation Extraction from Unified to  Language-specific Training\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.094, \"y\": 6.834}, {\"title\": \"Perceive and predict: self-supervised speech representation based loss  functions for speech enhancement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.844, \"y\": 5.104}, {\"title\": \"Multimodal Inverse Cloze Task for Knowledge-based Visual Question  Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.136, \"y\": 7.792}, {\"title\": \"Counteracts: Testing Stereotypical Representation in Pre-trained  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.276, \"y\": 4.426}, {\"title\": \"Dual Learning for Large Vocabulary On-Device ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.145, \"y\": 5.096}, {\"title\": \"Predicting Hateful Discussions on Reddit using Graph Transformer  Networks and Communal Context\", \"topic\": \"Hate Speech Detection\", \"x\": 2.971, \"y\": 5.365}, {\"title\": \"AI Insights into Theoretical Physics and the Swampland Program: A  Journey Through the Cosmos with ChatGPT\", \"topic\": \"Bias in Language Models\", \"x\": 5.129, \"y\": 4.48}, {\"title\": \"There is No Big Brother or Small Brother: Knowledge Infusion in Language  Models for Link Prediction and Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.92, \"y\": 5.465}, {\"title\": \"Language Models sounds the Death Knell of Knowledge Graphs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.847, \"y\": 7.853}, {\"title\": \"AI based approach to Trailer Generation for Online Educational Courses\", \"topic\": \"Multimodal Language Models\", \"x\": 9.104, \"y\": 7.698}, {\"title\": \"Channel-aware Decoupling Network for Multi-turn Dialogue Comprehension\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.486, \"y\": 4.31}, {\"title\": \"The use of new technologies to support Public Administration. Sentiment  analysis and the case of the app IO\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.657, \"y\": 6.551}, {\"title\": \"Streaming Punctuation: A Novel Punctuation Technique Leveraging  Bidirectional Context for Continuous Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.064, \"y\": 5.187}, {\"title\": \"UnifySpeech: A Unified Framework for Zero-shot Text-to-Speech and Voice  Conversion\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.571, \"y\": 5.745}, {\"title\": \"ERNIE 3.0 Tiny: Frustratingly Simple Method to Improve Task-Agnostic  Distillation Generalization\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.582, \"y\": 3.788}, {\"title\": \"Universal Multimodal Representation for Language Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.417, \"y\": 7.192}, {\"title\": \"FullStop:Punctuation and Segmentation Prediction for Dutch with  Transformers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.778, \"y\": 5.378}, {\"title\": \"Universal Information Extraction as Unified Semantic Matching\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.935, \"y\": 6.709}, {\"title\": \"MAQA: A Multimodal QA Benchmark for Negation\", \"topic\": \"Multimodal Language Models\", \"x\": 7.996, \"y\": 7.845}, {\"title\": \"Machine Learning Algorithms for Depression Detection and Their  Comparison\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.032, \"y\": 7.372}, {\"title\": \"Removing Non-Stationary Knowledge From Pre-Trained Language Models for  Entity-Level Sentiment Classification in Finance\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.762, \"y\": 6.845}, {\"title\": \"SpeeChain: A Speech Toolkit for Large-Scale Machine Speech Chain\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.985, \"y\": 5.517}, {\"title\": \"Graph-based Keyword Planning for Legal Clause Generation from Topics\", \"topic\": \"Legal NLP\", \"x\": 5.322, \"y\": 5.583}, {\"title\": \"Linguistic-style-aware Neural Networks for Fake News Detection\", \"topic\": \"Fake News Detection\", \"x\": 3.985, \"y\": 5.783}, {\"title\": \"A Personalized Utterance Style (PUS) based Dialogue Strategy for  Efficient Service Requirement Elicitation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.225, \"y\": 3.714}, {\"title\": \"Building a Parallel Corpus and Training Translation Models Between  Luganda and English\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.665, \"y\": 4.72}, {\"title\": \"Causal Categorization of Mental Health Posts using Transformers\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.216, \"y\": 7.401}, {\"title\": \"SAIDS: A Novel Approach for Sentiment Analysis Informed of Dialect and  Sarcasm\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.552, \"y\": 6.669}, {\"title\": \"You Truly Understand What I Need: Intellectual and Friendly Dialogue  Agents grounding Knowledge and Persona\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.388, \"y\": 3.887}, {\"title\": \"Chatbots As Fluent Polyglots: Revisiting Breakthrough Code Snippets\", \"topic\": \"Bias in Language Models\", \"x\": 4.893, \"y\": 4.211}, {\"title\": \"Unsupervised Broadcast News Summarization; a comparative study on  Maximal Marginal Relevance (MMR) and Latent Semantic Analysis (LSA)\", \"topic\": \"Text Summarization\", \"x\": 5.61, \"y\": 6.331}, {\"title\": \"CiT: Curation in Training for Effective Vision-Language Data\", \"topic\": \"Multimodal Language Models\", \"x\": 9.1, \"y\": 7.394}, {\"title\": \"MedKLIP: Medical Knowledge Enhanced Language-Image Pre-Training in  Radiology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.439, \"y\": 8.465}, {\"title\": \"Towards Autoformalization of Mathematics and Code Correctness:  Experiments with Elementary Proofs\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.318, \"y\": 2.903}, {\"title\": \"Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.573, \"y\": 5.63}, {\"title\": \"HIT-SCIR at MMNLU-22: Consistency Regularization for Multilingual Spoken  Language Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.214, \"y\": 4.991}, {\"title\": \"Emotion-Cause Pair Extraction as Question Answering\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.461, \"y\": 7.698}, {\"title\": \"GIVL: Improving Geographical Inclusivity of Vision-Language Models with  Pre-Training Methods\", \"topic\": \"Multimodal Language Models\", \"x\": 8.505, \"y\": 7.504}, {\"title\": \"Parameter-Efficient Fine-Tuning Design Spaces\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.005, \"y\": 2.278}, {\"title\": \"A comprehensive review of automatic text summarization techniques:  method, data, evaluation and coding\", \"topic\": \"Text Summarization\", \"x\": 5.523, \"y\": 6.301}, {\"title\": \"Multi-Aspect Explainable Inductive Relation Prediction by Sentence  Transformer\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.081, \"y\": 5.913}, {\"title\": \"Rumor Classification through a Multimodal Fusion Framework and Ensemble  Learning\", \"topic\": \"Fake News Detection\", \"x\": 3.969, \"y\": 5.84}, {\"title\": \"Audio-Visual Efficient Conformer for Robust Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.157, \"y\": 5.214}, {\"title\": \"A Survey On Few-shot Knowledge Graph Completion with Structural and  Commonsense Knowledge\", \"topic\": \"Knowledge Graph Completion\", \"x\": 6.989, \"y\": 5.991}, {\"title\": \"PIE-QG: Paraphrased Information Extraction for Unsupervised Question  Generation from Small Corpora\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.483, \"y\": 5.234}, {\"title\": \"Supervised Acoustic Embeddings And Their Transferability Across  Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.805, \"y\": 5.03}, {\"title\": \"MAUD: An Expert-Annotated Legal NLP Dataset for Merger Agreement  Understanding\", \"topic\": \"Legal NLP\", \"x\": 5.16, \"y\": 5.791}, {\"title\": \"The Undesirable Dependence on Frequency of Gender Bias Metrics Based on  Word Embeddings\", \"topic\": \"Bias in Language Models\", \"x\": 3.34, \"y\": 4.503}, {\"title\": \"IRT2: Inductive Linking and Ranking in Knowledge Graphs of Varying Scale\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.083, \"y\": 6.189}, {\"title\": \"Design and analysis of tweet-based election models for the 2021 Mexican  legislative election\", \"topic\": \"Fake News Detection\", \"x\": 3.759, \"y\": 6.089}, {\"title\": \"Analysing Discrete Self Supervised Speech Representation for Spoken  Language Modeling\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.6, \"y\": 5.1}, {\"title\": \"Statistical Machine Translation for Indic Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.644, \"y\": 5.012}, {\"title\": \"Is word segmentation necessary for Vietnamese sentiment classification?\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.439, \"y\": 6.462}, {\"title\": \"Inflected Forms Are Redundant in Question Generation Models\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.449, \"y\": 5.139}, {\"title\": \"CORGI-PM: A Chinese Corpus For Gender Bias Probing and Mitigation\", \"topic\": \"Bias in Language Models\", \"x\": 3.116, \"y\": 4.398}, {\"title\": \"Second Thoughts are Best: Learning to Re-Align With Human Values from  Text Edits\", \"topic\": \"Preference Learning for Large Language Models\", \"x\": 6.422, \"y\": 1.394}, {\"title\": \"Floods Relevancy and Identification of Location from Twitter Posts using  NLP Techniques\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.146, \"y\": 6.6}, {\"title\": \"Relevance Classification of Flood-related Twitter Posts via Multiple  Transformers\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.204, \"y\": 6.666}, {\"title\": \"Sample-Efficient Unsupervised Domain Adaptation of Speech Recognition  Systems A case study for Modern Greek\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.001, \"y\": 5.133}, {\"title\": \"A Survey on In-context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.394, \"y\": 3.343}, {\"title\": \"Memory Augmented Lookup Dictionary based Language Modeling for Automatic  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.086, \"y\": 5.177}, {\"title\": \"ChatGPT Makes Medicine Easy to Swallow: An Exploratory Case Study on  Simplified Radiology Reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.979, \"y\": 8.464}, {\"title\": \"Active Learning for Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.799, \"y\": 4.436}, {\"title\": \"Distant Reading of the German Coalition Deal: Recognizing Policy  Positions with BERT-based Text Classification\", \"topic\": \"Fake News Detection\", \"x\": 3.668, \"y\": 5.455}, {\"title\": \"HiTeA: Hierarchical Temporal-Aware Video-Language Pre-training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.901, \"y\": 7.722}, {\"title\": \"ResGrad: Residual Denoising Diffusion Probabilistic Models for Text to  Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.446, \"y\": 6.037}, {\"title\": \"Multi-modal deep learning system for depression and anxiety detection\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.215, \"y\": 7.497}, {\"title\": \"Examining Political Rhetoric with Epistemic Stance Detection\", \"topic\": \"Fake News Detection\", \"x\": 3.557, \"y\": 5.624}, {\"title\": \"Learning Multimodal Data Augmentation in Feature Space\", \"topic\": \"Multimodal Language Models\", \"x\": 8.145, \"y\": 7.243}, {\"title\": \"Political representation bias in DBpedia and Wikidata as a challenge for  downstream processing\", \"topic\": \"Fake News Detection\", \"x\": 3.711, \"y\": 5.494}, {\"title\": \"Sequence Generation with Label Augmentation for Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.844, \"y\": 6.872}, {\"title\": \"Maximizing Use-Case Specificity through Precision Model Tuning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.246, \"y\": 7.658}, {\"title\": \"Multimodal Sequential Generative Models for Semi-Supervised Language  Instruction Following\", \"topic\": \"Multimodal Language Models\", \"x\": 8.775, \"y\": 7.285}, {\"title\": \"Macro-block dropout for improved regularization in training end-to-end  speech recognition models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.135, \"y\": 4.985}, {\"title\": \"Customizing Knowledge Graph Embedding to Improve Clinical Study  Recommendation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.106, \"y\": 7.69}, {\"title\": \"Leveraging World Knowledge in Implicit Hate Speech Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.702, \"y\": 5.366}, {\"title\": \"Demonstrate-Search-Predict: Composing retrieval and language models for  knowledge-intensive NLP\", \"topic\": \"In-Context Learning\", \"x\": 8.171, \"y\": 3.477}, {\"title\": \"Hungry Hungry Hippos: Towards Language Modeling with State Space Models\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.699, \"y\": 3.174}, {\"title\": \"TempCLR: Temporal Alignment Representation with Contrastive Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.937, \"y\": 7.855}, {\"title\": \"A Survey on Table-and-Text HybridQA: Concepts, Methods, Challenges and  Future Directions\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.498, \"y\": 5.421}, {\"title\": \"NEEDED: Introducing Hierarchical Transformer to Eye Diseases Diagnosis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.158, \"y\": 8.38}, {\"title\": \"Don't Be So Sure! Boosting ASR Decoding via Confidence Relaxation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.015, \"y\": 4.856}, {\"title\": \"Automatic Text Simplification of News Articles in the Context of Public  Broadcasting\", \"topic\": \"Text Summarization\", \"x\": 5.532, \"y\": 6.353}, {\"title\": \"Personalized Prediction of Offensive News Comments by Considering the  Characteristics of Commenters\", \"topic\": \"Hate Speech Detection\", \"x\": 3.013, \"y\": 5.442}, {\"title\": \"Large Language Models Encode Clinical Knowledge\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.842, \"y\": 7.91}, {\"title\": \"Improving Complex Knowledge Base Question Answering via  Question-to-Action and Question-to-Question Alignment\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.595, \"y\": 5.251}, {\"title\": \"Skit-S2I: An Indian Accented Speech to Intent dataset\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.707, \"y\": 5.167}, {\"title\": \"A Marker-based Neural Network System for Extracting Social Determinants  of Health\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.424, \"y\": 7.801}, {\"title\": \"A Comprehensive Study of Gender Bias in Chemical Named Entity  Recognition Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.188, \"y\": 4.396}, {\"title\": \"Real or Fake Text?: Investigating Human Ability to Detect Boundaries  Between Human-Written and Machine-Generated Text\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.259, \"y\": 4.879}, {\"title\": \"Optimizing Deep Transformers for Chinese-Thai Low-Resource Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.898, \"y\": 4.3}, {\"title\": \"Generalizable Natural Language Processing Framework for Migraine  Reporting from Social Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.319, \"y\": 7.355}, {\"title\": \"Discovering Customer-Service Dialog System with Semi-Supervised Learning  and Coarse-to-Fine Intent Detection\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.523, \"y\": 3.747}, {\"title\": \"From Judgement's Premises Towards Key Points\", \"topic\": \"Legal NLP\", \"x\": 4.96, \"y\": 5.847}, {\"title\": \"Dubbing in Practice: A Large Scale Study of Human Localization With  Insights for Automatic Dubbing\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.367, \"y\": 5.524}, {\"title\": \"Pushing the performances of ASR models on English and Spanish accents\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.116, \"y\": 5.321}, {\"title\": \"When are Lemons Purple? The Concept Association Bias of Vision-Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.46, \"y\": 7.763}, {\"title\": \"OPT-IML: Scaling Language Model Instruction Meta Learning through the  Lens of Generalization\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.382, \"y\": 2.39}, {\"title\": \"Alignment Entropy Regularization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.243, \"y\": 5.171}, {\"title\": \"Training Integer-Only Deep Recurrent Neural Networks\", \"topic\": \"Quantization and Compression of Large Language Models\", \"x\": 9.859, \"y\": 2.285}, {\"title\": \"CAMeMBERT: Cascading Assistant-Mediated Multilingual BERT\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.542, \"y\": 3.869}, {\"title\": \"Understanding Postpartum Parents' Experiences via Two Digital Platforms\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.185, \"y\": 7.442}, {\"title\": \"Automatic Emotion Modelling in Written Stories\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.43, \"y\": 7.581}, {\"title\": \"What do LLMs Know about Financial Markets? A Case Study on Reddit Market  Sentiment Analysis\", \"topic\": \"Financial Natural Language Processing\", \"x\": 4.684, \"y\": 6.891}, {\"title\": \"Generalized Decoding for Pixel, Image, and Language\", \"topic\": \"Multimodal Language Models\", \"x\": 8.728, \"y\": 7.215}, {\"title\": \"Contrastive Language-Vision AI Models Pretrained on Web-Scraped  Multimodal Data Exhibit Sexual Objectification Bias\", \"topic\": \"Bias in Language Models\", \"x\": 3.098, \"y\": 4.535}, {\"title\": \"Language models are better than humans at next-token prediction\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.386, \"y\": 3.63}, {\"title\": \"Multimodal Emotion Recognition among Couples from Lab Settings to Daily  Life using Smartwatches\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.423, \"y\": 7.649}, {\"title\": \"Computer says \\\"No\\\": The Case Against Empathetic Conversational AI\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.637, \"y\": 7.813}, {\"title\": \"SPT: Semi-Parametric Prompt Tuning for Multitask Prompted Learning\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.803, \"y\": 3.276}, {\"title\": \"Language Models as Inductive Reasoners\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.58, \"y\": 3.08}, {\"title\": \"Cross-Linguistic Syntactic Difference in Multilingual BERT: How Good is  It and How Does It Affect Transfer?\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.24, \"y\": 4.834}, {\"title\": \"Prompt-Augmented Linear Probing: Scaling beyond the Limit of Few-shot  In-Context Learners\", \"topic\": \"In-Context Learning\", \"x\": 8.341, \"y\": 3.418}, {\"title\": \"Generating Multiple-Length Summaries via Reinforcement Learning for  Unsupervised Sentence Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.454, \"y\": 6.191}, {\"title\": \"End-to-End Automatic Speech Recognition model for the Sudanese Dialect\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.797, \"y\": 5.481}, {\"title\": \"Attend to the Right Context: A Plug-and-Play Module for  Content-Controllable Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.614, \"y\": 6.207}, {\"title\": \"4D ASR: Joint modeling of CTC, Attention, Transducer, and Mask-Predict  decoders\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.208, \"y\": 5.096}, {\"title\": \"Multi-hop Evidence Retrieval for Cross-document Relation Extraction\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.888, \"y\": 6.862}, {\"title\": \"SERENGETI: Massively Multilingual Language Models for Africa\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.231, \"y\": 4.92}, {\"title\": \"MultiInstruct: Improving Multi-Modal Zero-Shot Learning via Instruction  Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.328, \"y\": 7.324}, {\"title\": \"Integrating Heterogeneous Domain Information into Relation Extraction: A  Case Study on Drug-Drug Interaction Extraction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.344, \"y\": 7.408}, {\"title\": \"Zero-shot Triplet Extraction by Template Infilling\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 7.065, \"y\": 6.523}, {\"title\": \"Extractive Text Summarization Using Generalized Additive Models with  Interactions for Sentence Selection\", \"topic\": \"Text Summarization\", \"x\": 5.579, \"y\": 6.317}, {\"title\": \"Generation-Augmented Query Expansion For Code Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.269, \"y\": 4.513}, {\"title\": \"METEOR Guided Divergence for Video Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.034, \"y\": 7.822}, {\"title\": \"Understanding Stereotypes in Language Models: Towards Robust Measurement  and Zero-Shot Debiasing\", \"topic\": \"Bias in Language Models\", \"x\": 3.361, \"y\": 4.37}, {\"title\": \"KronA: Parameter Efficient Tuning with Kronecker Adapter\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 9.124, \"y\": 2.382}, {\"title\": \"Ontologically Faithful Generation of Non-Player Character Dialogues\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.296, \"y\": 3.706}, {\"title\": \"Re-evaluating the Need for Multimodal Signals in Unsupervised Grammar  Induction\", \"topic\": \"Multimodal Language Models\", \"x\": 8.468, \"y\": 7.01}, {\"title\": \"BLIND: Bias Removal With No Demographics\", \"topic\": \"Bias in Language Models\", \"x\": 3.295, \"y\": 4.382}, {\"title\": \"Parsel: Algorithmic Reasoning with Language Models by Composing  Decompositions\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.663, \"y\": 2.712}, {\"title\": \"Character-Aware Models Improve Visual Text Rendering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.856, \"y\": 6.773}, {\"title\": \"Self-Instruct: Aligning Language Models with Self-Generated Instructions\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 7.92, \"y\": 2.209}, {\"title\": \"DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.319, \"y\": 3.703}, {\"title\": \"A Length-Extrapolatable Transformer\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.705, \"y\": 3.394}, {\"title\": \"Lego-MT: Learning Detachable Models for Massively Multilingual Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.784, \"y\": 4.418}, {\"title\": \"Cross-modal Attention Congruence Regularization for Vision-Language  Relation Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.701, \"y\": 7.163}, {\"title\": \"T-Projection: High Quality Annotation Projection for Sequence Labeling  Tasks\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.814, \"y\": 4.751}, {\"title\": \"Toward Human Readable Prompt Tuning: Kubrick's The Shining is a good  movie, and a good prompt too?\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.569, \"y\": 3.398}, {\"title\": \"Does CLIP Bind Concepts? Probing Compositionality in Large Image Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.943, \"y\": 7.095}, {\"title\": \"A Survey of Deep Learning for Mathematical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.04, \"y\": 3.069}, {\"title\": \"Trustworthy Social Bias Measurement\", \"topic\": \"Bias in Language Models\", \"x\": 3.309, \"y\": 4.468}, {\"title\": \"Open Domain Multi-document Summarization: A Comprehensive Study of Model  Brittleness under Retrieval\", \"topic\": \"Text Summarization\", \"x\": 5.675, \"y\": 6.419}, {\"title\": \"SLUE Phase-2: A Benchmark Suite of Diverse Spoken Language Understanding  Tasks\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.596, \"y\": 4.999}, {\"title\": \"Interleaving Retrieval with Chain-of-Thought Reasoning for  Knowledge-Intensive Multi-Step Questions\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.578, \"y\": 2.331}, {\"title\": \"DePlot: One-shot visual language reasoning by plot-to-table translation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.101, \"y\": 7.858}, {\"title\": \"Can Current Task-oriented Dialogue Models Automate Real-world Scenarios  in the Wild?\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.406, \"y\": 3.711}, {\"title\": \"Execution-Based Evaluation for Open-Domain Code Generation\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.489, \"y\": 2.452}, {\"title\": \"BMX: Boosting Natural Language Generation Metrics with Explainability\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.885, \"y\": 3.992}, {\"title\": \"SODA: Million-scale Dialogue Distillation with Social Commonsense  Contextualization\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.963, \"y\": 3.799}, {\"title\": \"Parameter-efficient Zero-shot Transfer for Cross-Language Dense  Retrieval with Adapters\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.39, \"y\": 4.75}, {\"title\": \"Perplexed by Quality: A Perplexity-based Method for Adult and Harmful  Content Detection in Multilingual Heterogeneous Web Data\", \"topic\": \"Hate Speech Detection\", \"x\": 2.93, \"y\": 5.154}, {\"title\": \"Localising In-Domain Adaptation of Transformer-Based Biomedical Language  Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.21, \"y\": 7.907}, {\"title\": \"AnnoBERT: Effectively Representing Multiple Annotators' Label Choices to  Improve Hate Speech Detection\", \"topic\": \"Hate Speech Detection\", \"x\": 2.752, \"y\": 5.392}, {\"title\": \"Towards Reasoning in Large Language Models: A Survey\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.522, \"y\": 3.196}, {\"title\": \"Debiasing Stance Detection Models with Counterfactual Reasoning and  Adversarial Bias Learning\", \"topic\": \"Fake News Detection\", \"x\": 3.515, \"y\": 5.83}, {\"title\": \"To Adapt or to Annotate: Challenges and Interventions for Domain  Adaptation in Open-Domain Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.634, \"y\": 5.078}, {\"title\": \"Data Curation Alone Can Stabilize In-context Learning\", \"topic\": \"In-Context Learning\", \"x\": 8.274, \"y\": 3.362}, {\"title\": \"Self-Adaptive In-Context Learning: An Information Compression  Perspective for In-Context Example Selection and Ordering\", \"topic\": \"In-Context Learning\", \"x\": 8.275, \"y\": 3.404}, {\"title\": \"Dissecting Transformer Length Extrapolation via the Lens of Receptive  Field Analysis\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.652, \"y\": 3.415}, {\"title\": \"CoCo: Coherence-Enhanced Machine-Generated Text Detection Under Data  Limitation With Contrastive Learning\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.171, \"y\": 5.011}, {\"title\": \"Extrinsic Evaluation of Machine Translation Metrics\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.806, \"y\": 4.733}, {\"title\": \"ReCode: Robustness Evaluation of Code Generation Models\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.388, \"y\": 2.404}, {\"title\": \"In and Out-of-Domain Text Adversarial Robustness via Label Smoothing\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.141, \"y\": 3.071}, {\"title\": \"Original or Translated? On the Use of Parallel Data for Translation  Quality Estimation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.831, \"y\": 4.792}, {\"title\": \"EIT: Enhanced Interactive Transformer\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.86, \"y\": 3.169}, {\"title\": \"Adam: Dense Retrieval Distillation with Adaptive Dark Examples\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.542, \"y\": 3.858}, {\"title\": \"Emotion Selectable End-to-End Text-based Speech Editing\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.354, \"y\": 7.768}, {\"title\": \"Pay Attention to Your Tone: Introducing a New Dataset for Polite  Language Rewrite\", \"topic\": \"Bias in Language Models\", \"x\": 3.518, \"y\": 4.282}, {\"title\": \"Do I have the Knowledge to Answer? Investigating Answerability of  Knowledge Base Questions\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.551, \"y\": 5.301}, {\"title\": \"Unsupervised Question Duplicate and Related Questions Detection in  e-learning platforms\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.365, \"y\": 5.185}, {\"title\": \"IndicMT Eval: A Dataset to Meta-Evaluate Machine Translation metrics for  Indian Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.699, \"y\": 4.847}, {\"title\": \"On the Role of Parallel Data in Cross-lingual Transfer Learning\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.508, \"y\": 4.825}, {\"title\": \"Document-level Relation Extraction with Relation Correlations\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.874, \"y\": 6.883}, {\"title\": \"Human-Guided Fair Classification for Natural Language Processing\", \"topic\": \"Bias in Language Models\", \"x\": 3.445, \"y\": 4.212}, {\"title\": \"Tackling Ambiguity with Images: Improved Multimodal Machine Translation  and Contrastive Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.601, \"y\": 6.881}, {\"title\": \"True Detective: A Deep Abductive Reasoning Benchmark Undoable for GPT-3  and Challenging for GPT-4\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.42, \"y\": 3.158}, {\"title\": \"Rumour detection using graph neural network and oversampling in  benchmark Twitter dataset\", \"topic\": \"Fake News Detection\", \"x\": 4.053, \"y\": 5.943}, {\"title\": \"A Survey on Pretrained Language Models for Neural Code Intelligence\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.817, \"y\": 2.646}, {\"title\": \"Large Language Models Are Reasoning Teachers\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.87, \"y\": 2.41}, {\"title\": \"A Framework of Customer Review Analysis Using the Aspect-Based Opinion  Mining Approach\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.271, \"y\": 6.735}, {\"title\": \"A Twitter BERT Approach for Offensive Language Detection in Marathi\", \"topic\": \"Hate Speech Detection\", \"x\": 2.812, \"y\": 5.439}, {\"title\": \"Benchmarking Spatial Relationships in Text-to-Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.587, \"y\": 7.153}, {\"title\": \"DocAsRef: An Empirical Study on Repurposing Reference-Based Summary  Quality Metrics Reference-Freely\", \"topic\": \"Text Summarization\", \"x\": 5.564, \"y\": 6.204}, {\"title\": \"Enhancing Task Bot Engagement with Synthesized Open-Domain Dialog\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.32, \"y\": 3.813}, {\"title\": \"CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file  Context\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.697, \"y\": 2.505}, {\"title\": \"(QA)$^2$: Question Answering with Questionable Assumptions\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.198, \"y\": 4.997}, {\"title\": \"Towards Understanding Chain-of-Thought Prompting: An Empirical Study of  What Matters\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.655, \"y\": 2.301}, {\"title\": \"Towards Robustness of Text-to-SQL Models Against Natural and Realistic  Adversarial Table Perturbation\", \"topic\": \"Adversarial Attacks on NLP Models\", \"x\": 3.155, \"y\": 3.036}, {\"title\": \"Joint Speech Transcription and Translation: Pseudo-Labeling with  Out-of-Distribution Data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.763, \"y\": 5.13}, {\"title\": \"BUMP: A Benchmark of Unfaithful Minimal Pairs for Meta-Evaluation of  Faithfulness Metrics\", \"topic\": \"Text Summarization\", \"x\": 5.669, \"y\": 6.09}, {\"title\": \"Dialog2API: Task-Oriented Dialogue with API Description and Example  Programs\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.491, \"y\": 3.779}, {\"title\": \"AnyTOD: A Programmable Task-Oriented Dialog System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.572, \"y\": 3.75}, {\"title\": \"Improving the Robustness of Summarization Models by Detecting and  Removing Input Noise\", \"topic\": \"Text Summarization\", \"x\": 5.574, \"y\": 6.195}, {\"title\": \"Inverse Reinforcement Learning for Text Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.337, \"y\": 6.105}, {\"title\": \"Improved Long-Form Spoken Language Translation with Large Language  Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.176, \"y\": 4.978}, {\"title\": \"Python Code Generation by Asking Clarification Questions\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.402, \"y\": 2.56}, {\"title\": \"Z-ICL: Zero-Shot In-Context Learning with Pseudo-Demonstrations\", \"topic\": \"In-Context Learning\", \"x\": 8.386, \"y\": 3.466}, {\"title\": \"Synthetic Pre-Training Tasks for Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.789, \"y\": 4.446}, {\"title\": \"Exploring Hybrid and Ensemble Models for Multiclass Prediction of Mental  Health Status on Social Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.203, \"y\": 7.444}, {\"title\": \"What to Read in a Contract? Party-Specific Summarization of Legal  Obligations, Entitlements, and Prohibitions\", \"topic\": \"Legal NLP\", \"x\": 5.109, \"y\": 5.767}, {\"title\": \"Do CoNLL-2003 Named Entity Taggers Still Work Well in 2023?\", \"topic\": \"Named Entity Recognition\", \"x\": 7.346, \"y\": 6.853}, {\"title\": \"Speaking Style Conversion in the Waveform Domain Using Discrete  Self-Supervised Units\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.641, \"y\": 5.746}, {\"title\": \"A Retrieve-and-Read Framework for Knowledge Graph Link Prediction\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.04, \"y\": 6.031}, {\"title\": \"MANER: Mask Augmented Named Entity Recognition for Extreme Low-Resource  Languages\", \"topic\": \"Named Entity Recognition\", \"x\": 7.414, \"y\": 6.817}, {\"title\": \"KNIFE: Distilling Reasoning Knowledge From Free-Text Rationales\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.916, \"y\": 2.509}, {\"title\": \"SegAugment: Maximizing the Utility of Speech Translation Data with  Segmentation-based Augmentations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.375, \"y\": 5.181}, {\"title\": \"Unnatural Instructions: Tuning Language Models with (Almost) No Human  Labor\", \"topic\": \"Instruction Tuning for Large Language Models\", \"x\": 8.102, \"y\": 2.297}, {\"title\": \"MatCha: Enhancing Visual Language Pretraining with Math Reasoning and  Chart Derendering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.031, \"y\": 7.67}, {\"title\": \"Cross-Lingual Retrieval Augmented Prompt for Low-Resource Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.266, \"y\": 4.516}, {\"title\": \"Optimal Transport for Unsupervised Hallucination Detection in Neural  Machine Translation\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.247, \"y\": 0.986}, {\"title\": \"Wukong-Reader: Multi-modal Pre-training for Fine-grained Visual Document  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.201, \"y\": 7.073}, {\"title\": \"Explanation Regeneration via Information Bottleneck\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.958, \"y\": 3.939}, {\"title\": \"Unsupervised Summarization Re-ranking\", \"topic\": \"Text Summarization\", \"x\": 5.564, \"y\": 6.272}, {\"title\": \"Large Language Models are Better Reasoners with Self-Verification\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.675, \"y\": 2.509}, {\"title\": \"Mu$^{2}$SLAM: Multitask, Multilingual Speech and Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.234, \"y\": 5.269}, {\"title\": \"BLOOM+1: Adding Language Support to BLOOM for Zero-Shot Prompting\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.452, \"y\": 4.482}, {\"title\": \"Rethinking Label Smoothing on Multi-hop Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.762, \"y\": 5.444}, {\"title\": \"Improving the Generalizability of Text-Based Emotion Detection by  Leveraging Transformers with Psycholinguistic Features\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.391, \"y\": 7.518}, {\"title\": \"Large Language Models Meet NL2Code: A Survey\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.552, \"y\": 2.675}, {\"title\": \"Medical Knowledge Graph QA for Drug-Drug Interaction Prediction based on  Multi-hop Machine Reading Comprehension\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.151, \"y\": 7.379}, {\"title\": \"Enriching Relation Extraction with OpenIE\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.895, \"y\": 6.73}, {\"title\": \"WACO: Word-Aligned Contrastive Learning for Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.346, \"y\": 5.304}, {\"title\": \"Bridging The Gap: Entailment Fused-T5 for Open-retrieval Conversational  Machine Reading Comprehension\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.448, \"y\": 5.062}, {\"title\": \"E-NER -- An Annotated Named Entity Recognition Corpus of Legal Text\", \"topic\": \"Named Entity Recognition\", \"x\": 7.298, \"y\": 6.828}, {\"title\": \"ChatGPT: The End of Online Exam Integrity?\", \"topic\": \"Bias in Language Models\", \"x\": 4.929, \"y\": 4.534}, {\"title\": \"An Investigation of Indian Native Language Phonemic Influences on L2  English Pronunciations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.907, \"y\": 5.591}, {\"title\": \"APOLLO: A Simple Approach for Adaptive Pretraining of Language Models  for Logical Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.81, \"y\": 2.882}, {\"title\": \"Mind the Knowledge Gap: A Survey of Knowledge-enhanced Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.517, \"y\": 3.92}, {\"title\": \"Discovering Language Model Behaviors with Model-Written Evaluations\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 6.283, \"y\": 3.806}, {\"title\": \"Natural Language to Code Generation in Interactive Data Science  Notebooks\", \"topic\": \"Large Language Models in Code Generation and Programming\", \"x\": 7.324, \"y\": 2.476}, {\"title\": \"I2D2: Inductive Knowledge Distillation with NeuroLogic and  Self-Imitation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.461, \"y\": 3.752}, {\"title\": \"OASum: Large-Scale Open Domain Aspect-based Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.516, \"y\": 6.45}, {\"title\": \"Don't Forget Your ABC's: Evaluating the State-of-the-Art in  Chat-Oriented Dialogue Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.144, \"y\": 3.822}, {\"title\": \"Chatbots in a Botnet World\", \"topic\": \"Bias in Language Models\", \"x\": 4.913, \"y\": 4.333}, {\"title\": \"CAPSTONE: Curriculum Sampling for Dense Retrieval with Document  Expansion\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.448, \"y\": 5.039}, {\"title\": \"Continual Knowledge Distillation for Neural Machine Translation\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.419, \"y\": 3.909}, {\"title\": \"Rethinking the Role of Scale for In-Context Learning: An  Interpretability-based Case Study at 66 Billion Scale\", \"topic\": \"In-Context Learning\", \"x\": 8.582, \"y\": 3.365}, {\"title\": \"PVGRU: Generating Diverse and Relevant Dialogue Responses via  Pseudo-Variational Mechanism\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.569, \"y\": 3.993}, {\"title\": \"BEATs: Audio Pre-Training with Acoustic Tokenizers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.858, \"y\": 5.14}, {\"title\": \"Beyond Digital \\\"Echo Chambers\\\": The Role of Viewpoint Diversity in  Political Discussion\", \"topic\": \"Fake News Detection\", \"x\": 3.693, \"y\": 5.54}, {\"title\": \"Task Preferences across Languages on Community Question Answering  Platforms\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.22, \"y\": 5.258}, {\"title\": \"PoE: a Panel of Experts for Generalized Automatic Dialogue Assessment\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.301, \"y\": 3.827}, {\"title\": \"Modeling Instance Interactions for Joint Information Extraction with  Neural High-Order Conditional Random Field\", \"topic\": \"Document-Level Relation Extraction\", \"x\": 6.904, \"y\": 6.891}, {\"title\": \"A Simple Baseline for Beam Search Reranking\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.248, \"y\": 4.608}, {\"title\": \"AdaTranS: Adapting with Boundary-based Shrinking for End-to-End Speech  Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.822, \"y\": 5.173}, {\"title\": \"PolQA: Polish Question Answering Dataset\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.451, \"y\": 5.291}, {\"title\": \"Exploiting Rich Textual User-Product Context for Improving Sentiment  Analysis\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.506, \"y\": 6.664}, {\"title\": \"HyPe: Better Pre-trained Language Model Fine-tuning with Hidden  Representation Perturbation\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.893, \"y\": 2.467}, {\"title\": \"Better Datastore, Better Translation: Generating Datastores from  Pre-Trained Models for Nearest Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.988, \"y\": 4.297}, {\"title\": \"RISE: Leveraging Retrieval Techniques for Summarization Evaluation\", \"topic\": \"Text Summarization\", \"x\": 5.472, \"y\": 6.237}, {\"title\": \"Fast Entropy-Based Methods of Word-Level Confidence Estimation for  End-To-End Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.267, \"y\": 5.029}, {\"title\": \"Evaluating Step-by-Step Reasoning through Symbolic Verification\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.638, \"y\": 2.71}, {\"title\": \"Enhancing Multi-modal and Multi-hop Question Answering via Structured  Knowledge and Unified Retrieval-Generation\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.656, \"y\": 5.361}, {\"title\": \"MURMUR: Modular Multi-Step Reasoning for Semi-Structured Data-to-Text  Generation\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.737, \"y\": 2.394}, {\"title\": \"Detecting and Mitigating Hallucinations in Machine Translation: Model  Internal Workings Alone Do Well, Sentence Similarity Even Better\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.182, \"y\": 1.017}, {\"title\": \"Fine-grained Czech News Article Dataset: An Interdisciplinary Approach  to Trustworthiness Analysis\", \"topic\": \"Fake News Detection\", \"x\": 4.138, \"y\": 5.745}, {\"title\": \"Context-aware Fine-tuning of Self-supervised Speech Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.869, \"y\": 4.905}, {\"title\": \"Effectiveness of Text, Acoustic, and Lattice-based representations in  Spoken Language Understanding tasks\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.624, \"y\": 5.075}, {\"title\": \"BLASER: A Text-Free Speech-to-Speech Translation Evaluation Metric\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.603, \"y\": 5.388}, {\"title\": \"Teaching Small Language Models to Reason\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.96, \"y\": 2.449}, {\"title\": \"Utilizing distilBert transformer model for sentiment classification of  COVID-19's Persian open-text responses\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 3.945, \"y\": 6.789}, {\"title\": \"Swing Distillation: A Privacy-Preserving Knowledge Distillation  Framework\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.578, \"y\": 3.798}, {\"title\": \"Law to Binary Tree -- An Formal Interpretation of Legal Natural Language\", \"topic\": \"Legal NLP\", \"x\": 5.099, \"y\": 5.723}, {\"title\": \"Text-to-speech synthesis based on latent variable conversion using  diffusion probabilistic model and variational autoencoder\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.492, \"y\": 5.956}, {\"title\": \"Convolution-enhanced Evolving Attention Networks\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.898, \"y\": 3.31}, {\"title\": \"Investigation of Japanese PnG BERT language model in text-to-speech  synthesis for pitch accent language\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.657, \"y\": 5.655}, {\"title\": \"SceneGATE: Scene-Graph based co-Attention networks for TExt visual  question answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.348, \"y\": 7.775}, {\"title\": \"EffMulti: Efficiently Modeling Complex Multimodal Interactions for  Emotion Analysis\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.279, \"y\": 7.73}, {\"title\": \"Meeting Summarization: A Survey of the State of the Art\", \"topic\": \"Text Summarization\", \"x\": 5.563, \"y\": 6.336}, {\"title\": \"LegalRelectra: Mixed-domain Language Modeling for Long-range Legal Text  Comprehension\", \"topic\": \"Legal NLP\", \"x\": 5.235, \"y\": 5.722}, {\"title\": \"MM-SHAP: A Performance-agnostic Metric for Measuring Multimodal  Contributions in Vision and Language Models & Tasks\", \"topic\": \"Multimodal Language Models\", \"x\": 8.065, \"y\": 7.501}, {\"title\": \"Efficient Long Sequence Modeling via State Space Augmented Transformer\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.77, \"y\": 3.286}, {\"title\": \"Injecting Domain Knowledge in Language Models for Task-Oriented Dialogue  Systems\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.926, \"y\": 3.829}, {\"title\": \"On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in  Zero-Shot Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.51, \"y\": 2.379}, {\"title\": \"UnitY: Two-pass Direct Speech-to-speech Translation with Discrete Units\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.556, \"y\": 5.29}, {\"title\": \"DAMP: Doubly Aligned Multilingual Parser for Task-Oriented Dialogue\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.423, \"y\": 5.085}, {\"title\": \"Revisiting the Gold Standard: Grounding Summarization Evaluation with  Robust Human Evaluation\", \"topic\": \"Text Summarization\", \"x\": 5.546, \"y\": 6.149}, {\"title\": \"Visually-augmented pretrained language models for NLP tasks without  images\", \"topic\": \"Multimodal Language Models\", \"x\": 8.707, \"y\": 7.253}, {\"title\": \"ROSCOE: A Suite of Metrics for Scoring Step-by-Step Reasoning\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 6.547, \"y\": 2.856}, {\"title\": \"The Effects of In-domain Corpus Size on pre-training BERT\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.31, \"y\": 7.734}, {\"title\": \"The effects of gender bias in word embeddings on depression prediction\", \"topic\": \"Bias in Language Models\", \"x\": 3.189, \"y\": 4.62}, {\"title\": \"Attention as a Guide for Simultaneous Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.363, \"y\": 5.071}, {\"title\": \"TeTIm-Eval: a novel curated evaluation data set for comparing  text-to-image models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.911, \"y\": 6.778}, {\"title\": \"COLA: Improving Conversational Recommender Systems by Collaborative  Augmentation\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.923, \"y\": 3.076}, {\"title\": \"Advancing Multilingual Pre-training: TRIP Triangular Document-level  Pre-training for Multilingual Language Models\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.494, \"y\": 4.815}, {\"title\": \"Best-Answer Prediction in Q&A Sites Using User Information\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.173, \"y\": 5.123}, {\"title\": \"Unsupervised Detection of Contextualized Embedding Bias with Application  to Ideology\", \"topic\": \"Fake News Detection\", \"x\": 3.606, \"y\": 5.527}, {\"title\": \"Leveraging Natural Language Processing to Augment Structured Social  Determinants of Health Data in the Electronic Health Record\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.398, \"y\": 7.839}, {\"title\": \"Causes and Cures for Interference in Multilingual Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.541, \"y\": 4.512}, {\"title\": \"Efficient Self-supervised Learning with Contextualized Target  Representations for Vision, Speech and Language\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.726, \"y\": 4.869}, {\"title\": \"APOLLO: An Optimized Training Approach for Long-form Numerical Reasoning\", \"topic\": \"Financial Natural Language Processing\", \"x\": 5.05, \"y\": 6.853}, {\"title\": \"Evaluating Byte and Wordpiece Level Models for Massively Multilingual  Semantic Parsing\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.318, \"y\": 4.82}, {\"title\": \"Mitigating Negative Style Transfer in Hybrid Dialogue System\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.426, \"y\": 4.036}, {\"title\": \"Speech and Natural Language Processing Technologies for Pseudo-Pilot  Simulator\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.019, \"y\": 5.555}, {\"title\": \"Explainability of Text Processing and Retrieval Methods: A Critical  Survey\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.125, \"y\": 4.021}, {\"title\": \"Cross-Modal Similarity-Based Curriculum Learning for Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 9.115, \"y\": 7.397}, {\"title\": \"Disentangling Prosody Representations with Unsupervised Speech  Reconstruction\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.312, \"y\": 7.959}, {\"title\": \"Find Someone Who: Visual Commonsense Understanding in Human-Centric  Grounding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.578, \"y\": 7.583}, {\"title\": \"Pre-trained Language Models Can be Fully Zero-Shot Learners\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.812, \"y\": 3.673}, {\"title\": \"CREPE: Can Vision-Language Foundation Models Reason Compositionally?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.443, \"y\": 7.542}, {\"title\": \"Foresight -- Generative Pretrained Transformer (GPT) for Modelling of  Patient Timelines using EHRs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.879, \"y\": 8.293}, {\"title\": \"Diverse Demonstrations Improve In-context Compositional Generalization\", \"topic\": \"In-Context Learning\", \"x\": 8.17, \"y\": 3.42}, {\"title\": \"ERNIE-Code: Beyond English-Centric Cross-lingual Pretraining for  Programming Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.227, \"y\": 4.589}, {\"title\": \"Structured Prompting: Scaling In-Context Learning to 1,000 Examples\", \"topic\": \"In-Context Learning\", \"x\": 8.221, \"y\": 3.341}, {\"title\": \"Exploring Fake News Detection with Heterogeneous Social Media Context  Graphs\", \"topic\": \"Fake News Detection\", \"x\": 3.92, \"y\": 5.871}, {\"title\": \"Style-Label-Free: Cross-Speaker Style Transfer by Quantized VAE and  Speaker-wise Normalization in Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.648, \"y\": 5.824}, {\"title\": \"TencentPretrain: A Scalable and Flexible Toolkit for Pre-training Models  of Different Modalities\", \"topic\": \"Multimodal Language Models\", \"x\": 8.47, \"y\": 7.116}, {\"title\": \"Towards a general purpose machine translation system for Sranantongo\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.614, \"y\": 5.187}, {\"title\": \"InferEM: Inferring the Speaker's Intention for Empathetic Dialogue  Generation\", \"topic\": \"Emotion Recognition and Analysis in Conversations\", \"x\": 3.586, \"y\": 7.906}, {\"title\": \"Technical Report -- Competition Solution for Prompt Tuning using  Pretrained Language Model\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.666, \"y\": 3.206}, {\"title\": \"Attentive Deep Neural Networks for Legal Document Retrieval\", \"topic\": \"Legal NLP\", \"x\": 5.254, \"y\": 5.874}, {\"title\": \"Mortality Prediction Models with Clinical Notes Using Sparse Attention  at the Word and Sentence Levels\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.817, \"y\": 8.312}, {\"title\": \"Prompting Is Programming: A Query Language for Large Language Models\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.114, \"y\": 3.005}, {\"title\": \"Continuation KD: Improved Knowledge Distillation through the Lens of  Continuation Optimization\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.594, \"y\": 3.834}, {\"title\": \"Parameter-Efficient Finetuning of Transformers for Source Code\", \"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\", \"x\": 8.878, \"y\": 2.483}, {\"title\": \"Earthquake Impact Analysis Based on Text Mining and Social Media  Analytics\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.085, \"y\": 6.626}, {\"title\": \"Automated ICD Coding using Extreme Multi-label Long Text  Transformer-based Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.902, \"y\": 8.397}, {\"title\": \"P-Transformer: Towards Better Document-to-Document Neural Machine  Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.964, \"y\": 4.248}, {\"title\": \"Direct Speech-to-speech Translation without Textual Annotation using  Bottleneck Features\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.474, \"y\": 5.289}, {\"title\": \"BigText-QA: Question Answering over a Large-Scale Hybrid Knowledge Graph\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.659, \"y\": 5.427}, {\"title\": \"Information-Theoretic Text Hallucination Reduction for Video-grounded  Dialogue\", \"topic\": \"Hallucination in Language Models\", \"x\": 5.439, \"y\": 1.304}, {\"title\": \"Domain Adaptation of Transformer-Based Models using Unlabeled Data for  Relevance and Polarity Classification of German Customer Feedback\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.693, \"y\": 6.771}, {\"title\": \"Momentum Contrastive Pre-training for Question Answering\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.538, \"y\": 5.295}, {\"title\": \"Searching for Effective Multilingual Fine-Tuning Methods: A Case Study  in Summarization\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.332, \"y\": 4.087}, {\"title\": \"TriNet: stabilizing self-supervised learning from complete or slow  collapse on ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 11.0, \"y\": 4.864}, {\"title\": \"Multimodal and Explainable Internet Meme Classification\", \"topic\": \"Hate Speech Detection\", \"x\": 2.928, \"y\": 5.734}, {\"title\": \"MAViC: Multimodal Active Learning for Video Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.837, \"y\": 7.787}, {\"title\": \"MnTTS2: An Open-Source Multi-Speaker Mongolian Text-to-Speech Synthesis  Dataset\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.555, \"y\": 5.677}, {\"title\": \"End-to-End Speech Translation of Arabic to English Broadcast News\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.351, \"y\": 5.252}, {\"title\": \"MORTY: Structured Summarization for Targeted Information Extraction from  Scholarly Articles\", \"topic\": \"Text Summarization\", \"x\": 5.798, \"y\": 6.506}, {\"title\": \"Towards Leaving No Indic Language Behind: Building Monolingual Corpora,  Benchmark and Models for Indic Languages\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.187, \"y\": 5.084}, {\"title\": \"BASPRO: a balanced script producer for speech corpus collection based on  the genetic algorithm\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.7, \"y\": 5.604}, {\"title\": \"Topic-Aware Response Generation in Task-Oriented Dialogue with  Unstructured Knowledge Access\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 5.669, \"y\": 4.012}, {\"title\": \"LEAD: Liberal Feature-based Distillation for Dense Retrieval\", \"topic\": \"Knowledge Distillation for Large Language Models\", \"x\": 10.596, \"y\": 3.907}, {\"title\": \"Artificial Text Detection with Multiple Training Strategies\", \"topic\": \"AI-Generated Text Detection\", \"x\": 4.014, \"y\": 5.042}, {\"title\": \"Multi-task Learning for Personal Health Mention Detection on Social  Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.123, \"y\": 7.368}, {\"title\": \"Incorporating Emotions into Health Mention Classification Task on Social  Media\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.03, \"y\": 7.385}, {\"title\": \"MOPRD: A multidisciplinary open peer review dataset\", \"topic\": \"Text Summarization\", \"x\": 5.488, \"y\": 6.164}, {\"title\": \"The Turing Deception\", \"topic\": \"Bias in Language Models\", \"x\": 4.901, \"y\": 4.522}, {\"title\": \"CKG: Dynamic Representation Based on Context and Knowledge Graph\", \"topic\": \"Knowledge Graph Completion\", \"x\": 7.117, \"y\": 6.023}, {\"title\": \"AUC Maximization for Low-Resource Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 7.436, \"y\": 6.783}, {\"title\": \"MED-SE: Medical Entity Definition-based Sentence Embedding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 6.142, \"y\": 7.928}, {\"title\": \"Comparative Study of Sentiment Analysis for Multi-Sourced Social Media  Platforms\", \"topic\": \"Aspect-Based Sentiment Analysis\", \"x\": 3.672, \"y\": 6.607}, {\"title\": \"Decomposing a Recurrent Neural Network into Modules for Enabling  Reusability and Replacement\", \"topic\": \"Efficient Transformer Models\", \"x\": 9.361, \"y\": 3.366}, {\"title\": \"VASR: Visual Analogies of Situation Recognition\", \"topic\": \"Multimodal Language Models\", \"x\": 8.678, \"y\": 7.598}, {\"title\": \"OFASys: A Multi-Modal Multi-Task Learning System for Building Generalist  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.342, \"y\": 7.109}, {\"title\": \"A Modality-level Explainable Framework for Misinformation Checking in  Social Networks\", \"topic\": \"Fake News Detection\", \"x\": 4.182, \"y\": 5.898}, {\"title\": \"ConsistTL: Modeling Consistency in Transfer Learning for Low-Resource  Neural Machine Translation\", \"topic\": \"Multilingual Language Models and Machine Translation\", \"x\": 9.918, \"y\": 4.412}, {\"title\": \"Harnessing the Power of Multi-Task Pretraining for Ground-Truth Level  Natural Language Explanations\", \"topic\": \"Reasoning Abilities of Large Language Models\", \"x\": 7.013, \"y\": 3.83}, {\"title\": \"LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large  Language Models\", \"topic\": \"Language Model-based Autonomous Agents and Planning\", \"x\": 5.837, \"y\": 2.611}, {\"title\": \"A Comprehensive Survey on Multi-hop Machine Reading Comprehension  Approaches\", \"topic\": \"Knowledge Graph Question Answering\", \"x\": 6.595, \"y\": 5.279}, {\"title\": \"Learning to Dub Movies via Hierarchical Prosody Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.554, \"y\": 5.985}, {\"title\": \"Demystifying Prompts in Language Models via Perplexity Estimation\", \"topic\": \"Prompt Optimization for Language Models\", \"x\": 7.238, \"y\": 3.331}, {\"title\": \"TweetDrought: A Deep-Learning Drought Impacts Recognizer based on  Twitter Data\", \"topic\": \"Mental Health Analysis using NLP\", \"x\": 4.204, \"y\": 6.576}, {\"title\": \"Pivotal Role of Language Modeling in Recommender Systems: Enriching  Task-specific and Task-agnostic Representation Learning\", \"topic\": \"Personalized Dialogue Systems\", \"x\": 4.894, \"y\": 2.854}, {\"title\": \"M3ST: Mix at Three Levels for Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.383, \"y\": 5.062}]}, {\"name\": \"source_0_x_domain_x\", \"values\": [{\"min\": 2.637, \"max\": 11.425}]}, {\"name\": \"source_0_y_domain_y\", \"values\": [{\"min\": 0.966, \"max\": 8.67}]}, {\"name\": \"source_0_color_domain_topic\", \"values\": [{\"topic\": \"Language Model-based Autonomous Agents and Planning\"}, {\"topic\": \"Multimodal Language Models\"}, {\"topic\": \"Hallucination in Language Models\"}, {\"topic\": \"Multilingual Language Models and Machine Translation\"}, {\"topic\": \"Fake News Detection\"}, {\"topic\": \"Jailbreak Attacks on LLMs\"}, {\"topic\": \"Quantization and Compression of Large Language Models\"}, {\"topic\": \"Reasoning Abilities of Large Language Models\"}, {\"topic\": \"Speech Recognition and Translation\"}, {\"topic\": \"Bias in Language Models\"}, {\"topic\": \"Preference Learning for Large Language Models\"}, {\"topic\": \"Instruction Tuning for Large Language Models\"}, {\"topic\": \"Natural Language Processing in Healthcare\"}, {\"topic\": \"Parameter-Efficient Fine-tuning of Large Language Models\"}, {\"topic\": \"AI-Generated Text Detection\"}, {\"topic\": \"Knowledge Graph Completion\"}, {\"topic\": \"Aspect-Based Sentiment Analysis\"}, {\"topic\": \"Personalized Dialogue Systems\"}, {\"topic\": \"Knowledge Distillation for Large Language Models\"}, {\"topic\": \"Emotion Recognition and Analysis in Conversations\"}, {\"topic\": \"Mental Health Analysis using NLP\"}, {\"topic\": \"Hate Speech Detection\"}, {\"topic\": \"Efficient Transformer Models\"}, {\"topic\": \"Financial Natural Language Processing\"}, {\"topic\": \"Prompt Optimization for Language Models\"}, {\"topic\": \"Named Entity Recognition\"}, {\"topic\": \"In-Context Learning\"}, {\"topic\": \"Legal NLP\"}, {\"topic\": \"Text Summarization\"}, {\"topic\": \"Retrieval-Augmented Generation\"}, {\"topic\": \"Document-Level Relation Extraction\"}, {\"topic\": \"Knowledge Graph Question Answering\"}, {\"topic\": \"Adversarial Attacks on NLP Models\"}, {\"topic\": \"Large Language Models in Code Generation and Programming\"}]}], \"signals\": [{\"name\": \"unit\", \"value\": {}, \"on\": [{\"events\": \"pointermove\", \"update\": \"isTuple(group()) ? group() : unit\"}]}, {\"name\": \"param_5\", \"update\": \"vlSelectionResolve(\\\"param_5_store\\\", \\\"union\\\")\"}, {\"name\": \"param_5_x\", \"on\": [{\"events\": [{\"source\": \"view\", \"type\": \"dblclick\"}], \"update\": \"null\"}, {\"events\": {\"signal\": \"param_5_translate_delta\"}, \"update\": \"panLinear(param_5_translate_anchor.extent_x, -param_5_translate_delta.x / width)\"}, {\"events\": {\"signal\": \"param_5_zoom_delta\"}, \"update\": \"zoomLinear(domain(\\\"x\\\"), param_5_zoom_anchor.x, param_5_zoom_delta)\"}]}, {\"name\": \"param_5_y\", \"on\": [{\"events\": [{\"source\": \"view\", \"type\": \"dblclick\"}], \"update\": \"null\"}, {\"events\": {\"signal\": \"param_5_translate_delta\"}, \"update\": \"panLinear(param_5_translate_anchor.extent_y, param_5_translate_delta.y / height)\"}, {\"events\": {\"signal\": \"param_5_zoom_delta\"}, \"update\": \"zoomLinear(domain(\\\"y\\\"), param_5_zoom_anchor.y, param_5_zoom_delta)\"}]}, {\"name\": \"param_5_tuple\", \"on\": [{\"events\": [{\"signal\": \"param_5_x || param_5_y\"}], \"update\": \"param_5_x && param_5_y ? {unit: \\\"\\\", fields: param_5_tuple_fields, values: [param_5_x,param_5_y]} : null\"}]}, {\"name\": \"param_5_tuple_fields\", \"value\": [{\"field\": \"x\", \"channel\": \"x\", \"type\": \"R\"}, {\"field\": \"y\", \"channel\": \"y\", \"type\": \"R\"}]}, {\"name\": \"param_5_translate_anchor\", \"value\": {}, \"on\": [{\"events\": [{\"source\": \"scope\", \"type\": \"pointerdown\"}], \"update\": \"{x: x(unit), y: y(unit), extent_x: domain(\\\"x\\\"), extent_y: domain(\\\"y\\\")}\"}]}, {\"name\": \"param_5_translate_delta\", \"value\": {}, \"on\": [{\"events\": [{\"source\": \"window\", \"between\": [{\"source\": \"scope\", \"type\": \"pointerdown\"}, {\"source\": \"window\", \"type\": \"pointerup\"}], \"type\": \"pointermove\", \"consume\": true}], \"update\": \"{x: param_5_translate_anchor.x - x(unit), y: param_5_translate_anchor.y - y(unit)}\"}]}, {\"name\": \"param_5_zoom_anchor\", \"on\": [{\"events\": [{\"source\": \"scope\", \"consume\": true, \"type\": \"wheel\"}], \"update\": \"{x: invert(\\\"x\\\", x(unit)), y: invert(\\\"y\\\", y(unit))}\"}]}, {\"name\": \"param_5_zoom_delta\", \"on\": [{\"events\": [{\"source\": \"scope\", \"consume\": true, \"type\": \"wheel\"}], \"update\": \"pow(1.001, event.deltaY * pow(16, event.deltaMode))\", \"force\": true}]}, {\"name\": \"param_5_modify\", \"on\": [{\"events\": {\"signal\": \"param_5_tuple\"}, \"update\": \"modify(\\\"param_5_store\\\", param_5_tuple, true)\"}]}], \"marks\": [{\"type\": \"symbol\", \"name\": \"marks\", \"from\": {\"data\": \"source_0\"}, \"encode\": {\"update\": {\"size\": {\"value\": 5}, \"tooltip\": {\"signal\": \"{\\\"title\\\": isValid(datum[\\\"title\\\"]) ? datum[\\\"title\\\"] : \\\"\\\"+datum[\\\"title\\\"], \\\"topic\\\": isValid(datum[\\\"topic\\\"]) ? datum[\\\"topic\\\"] : \\\"\\\"+datum[\\\"topic\\\"]}\"}, \"y\": {\"field\": \"y\", \"scale\": \"y\"}, \"opacity\": {\"value\": 0.7}, \"x\": {\"field\": \"x\", \"scale\": \"x\"}, \"shape\": {\"value\": \"circle\"}, \"fill\": {\"field\": \"topic\", \"scale\": \"color\"}}}, \"clip\": true, \"style\": [\"circle\"], \"interactive\": true}], \"scales\": [{\"name\": \"x\", \"type\": \"linear\", \"domain\": [{\"signal\": \"(data(\\\"source_0_x_domain_x\\\")[0] || {}).min\"}, {\"signal\": \"(data(\\\"source_0_x_domain_x\\\")[0] || {}).max\"}], \"range\": [0, {\"signal\": \"width\"}], \"zero\": true, \"domainRaw\": {\"signal\": \"param_5[\\\"x\\\"]\"}, \"nice\": true}, {\"name\": \"y\", \"type\": \"linear\", \"domain\": [{\"signal\": \"(data(\\\"source_0_y_domain_y\\\")[0] || {}).min\"}, {\"signal\": \"(data(\\\"source_0_y_domain_y\\\")[0] || {}).max\"}], \"range\": [{\"signal\": \"height\"}, 0], \"nice\": true, \"zero\": true, \"domainRaw\": {\"signal\": \"param_5[\\\"y\\\"]\"}}, {\"name\": \"color\", \"type\": \"ordinal\", \"domain\": {\"data\": \"source_0_color_domain_topic\", \"field\": \"topic\", \"sort\": true}, \"range\": [\"#1f77b4\", \"#aec7e8\", \"#ff7f0e\", \"#ffbb78\", \"#2ca02c\", \"#98df8a\", \"#d62728\", \"#ff9896\", \"#9467bd\", \"#c5b0d5\", \"#8c564b\", \"#c49c94\", \"#e377c2\", \"#f7b6d2\", \"#7f7f7f\", \"#c7c7c7\", \"#bcbd22\", \"#dbdb8d\", \"#17becf\", \"#9edae5\", \"#393b79\", \"#5254a3\", \"#6b6ecf\", \"#9c9ede\", \"#637939\", \"#8ca252\", \"#b5cf6b\", \"#cedb9c\", \"#8c6d31\", \"#bd9e39\", \"#e7ba52\", \"#e7cb94\", \"#843c39\", \"#ad494a\", \"#d6616b\"]}], \"axes\": [{\"scale\": \"x\", \"ticks\": false, \"aria\": false, \"zindex\": 0, \"grid\": true, \"maxExtent\": 0, \"gridScale\": \"y\", \"tickCount\": {\"signal\": \"ceil(width/40)\"}, \"labels\": false, \"domain\": false, \"orient\": \"bottom\", \"minExtent\": 0}, {\"scale\": \"y\", \"minExtent\": 0, \"labels\": false, \"domain\": false, \"maxExtent\": 0, \"grid\": true, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"orient\": \"left\", \"aria\": false, \"ticks\": false, \"gridScale\": \"x\", \"zindex\": 0}, {\"scale\": \"x\", \"title\": \"x\", \"labelFlush\": true, \"orient\": \"bottom\", \"tickCount\": {\"signal\": \"ceil(width/40)\"}, \"zindex\": 0, \"labelOverlap\": true, \"grid\": false}, {\"scale\": \"y\", \"grid\": false, \"orient\": \"left\", \"labelOverlap\": true, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"zindex\": 0, \"title\": \"y\"}], \"title\": {\"text\": \"25K arXiv Publications in cs.CL\", \"frame\": \"group\"}, \"legends\": [{\"fill\": \"color\", \"symbolType\": \"circle\", \"title\": \"topic\", \"encode\": {\"symbols\": {\"update\": {\"opacity\": {\"value\": 0.7}}}}}], \"width\": 600, \"padding\": 5, \"height\": 400, \"style\": \"cell\", \"background\": \"white\"}, {\"mode\": \"vega\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "h9DHAbaZbyL2"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "89e580233c514001b366cbc10388a6d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fb9154ef24f4ce09fd2e186d974b888",
              "IPY_MODEL_f962e923bda1493d93d7723c2ad1f4b2",
              "IPY_MODEL_02a7098d021546439019097aa61b4690"
            ],
            "layout": "IPY_MODEL_658984d8d29d4f73a8737d14f2ed7c14"
          }
        },
        "6fb9154ef24f4ce09fd2e186d974b888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00dcae144bb24b08864113536c8c0829",
            "placeholder": "",
            "style": "IPY_MODEL_a8c1137204e0431fb68fb16cddee9564",
            "value": "Batches:100%"
          }
        },
        "f962e923bda1493d93d7723c2ad1f4b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9112e783801453692ae8ef6ed60006d",
            "max": 393,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c73f8060e87472ab2eaff693d308131",
            "value": 393
          }
        },
        "02a7098d021546439019097aa61b4690": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1acdfcaa110c497d845e705ad8d41458",
            "placeholder": "",
            "style": "IPY_MODEL_4130501d45f74cc2abb375f9b1b8ae85",
            "value": "393/393[02:12&lt;00:00,6.97it/s]"
          }
        },
        "658984d8d29d4f73a8737d14f2ed7c14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00dcae144bb24b08864113536c8c0829": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8c1137204e0431fb68fb16cddee9564": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9112e783801453692ae8ef6ed60006d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c73f8060e87472ab2eaff693d308131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1acdfcaa110c497d845e705ad8d41458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4130501d45f74cc2abb375f9b1b8ae85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a714a64bbdb4b9b81a4f4ba36d85aa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23ecfe650a084c178a11d0d606d9bcf4",
              "IPY_MODEL_a7cd716c75454d93a7d5b82bfa3e636e",
              "IPY_MODEL_308c040d14614c18aca9bcb95557b119"
            ],
            "layout": "IPY_MODEL_dd0f2d787b8b4d058909144f6eee84eb"
          }
        },
        "23ecfe650a084c178a11d0d606d9bcf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_848a4e80474348219d5b716e16a3661e",
            "placeholder": "",
            "style": "IPY_MODEL_213ed3d74cfb4221ba5d5ddbe243efca",
            "value": "Batches:100%"
          }
        },
        "a7cd716c75454d93a7d5b82bfa3e636e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_318e41eeb18b4c9e9c7b62277acfd6c0",
            "max": 197,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc50ec877941494db18391fbade36a4f",
            "value": 197
          }
        },
        "308c040d14614c18aca9bcb95557b119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6c353f4f5ab41fc940094f817636cb1",
            "placeholder": "",
            "style": "IPY_MODEL_4505fdc24d124feeb287d795287a6b2b",
            "value": "197/197[02:16&lt;00:00,3.13it/s]"
          }
        },
        "dd0f2d787b8b4d058909144f6eee84eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "848a4e80474348219d5b716e16a3661e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "213ed3d74cfb4221ba5d5ddbe243efca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "318e41eeb18b4c9e9c7b62277acfd6c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc50ec877941494db18391fbade36a4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6c353f4f5ab41fc940094f817636cb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4505fdc24d124feeb287d795287a6b2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce9f01de318f49328141aa4082f7e443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b53306ed9ebe4a50aa996b673d700872",
              "IPY_MODEL_ac1ffcb274274f67acb51f39f70433c7",
              "IPY_MODEL_15f9f3b78b1140e6b4c484690a907de8"
            ],
            "layout": "IPY_MODEL_87f614bcd12445f8b3a858e3d792a082"
          }
        },
        "b53306ed9ebe4a50aa996b673d700872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b552e74a87f34bc2a734977c5d45bfb4",
            "placeholder": "",
            "style": "IPY_MODEL_b1f1e62d1f2641c489b12d3ce4716c7b",
            "value": "modules.json:100%"
          }
        },
        "ac1ffcb274274f67acb51f39f70433c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27c34349e7b44d549597f669596fd7bd",
            "max": 229,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b822b40d18624718a094ebca90f765cd",
            "value": 229
          }
        },
        "15f9f3b78b1140e6b4c484690a907de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_342c377108bc4a4d99dcf91545ecd410",
            "placeholder": "",
            "style": "IPY_MODEL_b4a4c259104944528cd94621cb2097c5",
            "value": "229/229[00:00&lt;00:00,17.7kB/s]"
          }
        },
        "87f614bcd12445f8b3a858e3d792a082": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b552e74a87f34bc2a734977c5d45bfb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1f1e62d1f2641c489b12d3ce4716c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27c34349e7b44d549597f669596fd7bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b822b40d18624718a094ebca90f765cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "342c377108bc4a4d99dcf91545ecd410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4a4c259104944528cd94621cb2097c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a02d6a68e8043cbb9564643c2aadc7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3503968046cc4ea4a7d818f39777f95d",
              "IPY_MODEL_07e797a02035492f859dd787ea0cb8fe",
              "IPY_MODEL_49e1da5e87b149b0aaecd80150d33482"
            ],
            "layout": "IPY_MODEL_4523f237d8f0410087a115b1024146c0"
          }
        },
        "3503968046cc4ea4a7d818f39777f95d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08688f23e0534a808c9007b8221af177",
            "placeholder": "",
            "style": "IPY_MODEL_b49430a127ce4fa296ced8967b90309d",
            "value": "config_sentence_transformers.json:100%"
          }
        },
        "07e797a02035492f859dd787ea0cb8fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64cd4470c25843ebb75df77b4b90f0dd",
            "max": 117,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cf578ad25d84e90a896b53551b68d1c",
            "value": 117
          }
        },
        "49e1da5e87b149b0aaecd80150d33482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef39f467b3dc4508a91d5de27fa6aa26",
            "placeholder": "",
            "style": "IPY_MODEL_1b0c2d029890450b8e5654fc85893322",
            "value": "117/117[00:00&lt;00:00,6.78kB/s]"
          }
        },
        "4523f237d8f0410087a115b1024146c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08688f23e0534a808c9007b8221af177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b49430a127ce4fa296ced8967b90309d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64cd4470c25843ebb75df77b4b90f0dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cf578ad25d84e90a896b53551b68d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef39f467b3dc4508a91d5de27fa6aa26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b0c2d029890450b8e5654fc85893322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bb0ea39b7df41c8ac06fe80734811b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ce399235f7e4284a806ba353eafe9fa",
              "IPY_MODEL_46b37e8d4c7842a29c08e45aa4586d32",
              "IPY_MODEL_e38bf6a22dd54475be7d2c607cb2e473"
            ],
            "layout": "IPY_MODEL_d201030a0c0445d1ae82463e361feb2e"
          }
        },
        "6ce399235f7e4284a806ba353eafe9fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8657cb405ed543acabded93c336127c8",
            "placeholder": "",
            "style": "IPY_MODEL_0e2bb0c3899947989ae504327023a4e7",
            "value": "README.md:100%"
          }
        },
        "46b37e8d4c7842a29c08e45aa4586d32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43fc509b6af840c699202bcd8eb87429",
            "max": 71486,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_619029d0630e467aaa597e8ea5a82d22",
            "value": 71486
          }
        },
        "e38bf6a22dd54475be7d2c607cb2e473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_309d1c5db5364f97a84034402bb404a4",
            "placeholder": "",
            "style": "IPY_MODEL_53dfb2b1fce049269ba546e03e066915",
            "value": "71.5k/71.5k[00:00&lt;00:00,5.11MB/s]"
          }
        },
        "d201030a0c0445d1ae82463e361feb2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8657cb405ed543acabded93c336127c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e2bb0c3899947989ae504327023a4e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43fc509b6af840c699202bcd8eb87429": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "619029d0630e467aaa597e8ea5a82d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "309d1c5db5364f97a84034402bb404a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53dfb2b1fce049269ba546e03e066915": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb7f2a9373184d37afe8be1bbc4d755e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8826ce2894124e6993569fb95434cb08",
              "IPY_MODEL_ffdd395a69fa48d897d10c17abd3d5a6",
              "IPY_MODEL_710b8554d3c44f9db8baa50eb5766182"
            ],
            "layout": "IPY_MODEL_151a94610046456197d8c854ac2fc309"
          }
        },
        "8826ce2894124e6993569fb95434cb08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_828df104ebf14490871bab42cbf7e59c",
            "placeholder": "",
            "style": "IPY_MODEL_e5a89cea437a479aa965348e7664854a",
            "value": "sentence_bert_config.json:100%"
          }
        },
        "ffdd395a69fa48d897d10c17abd3d5a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83f4161c855c4eab99b61d54378b9c85",
            "max": 99,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4a53ae3e38d64ac680e1348a60659825",
            "value": 99
          }
        },
        "710b8554d3c44f9db8baa50eb5766182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35ac412c0e874cf1b53b5142c21d7c50",
            "placeholder": "",
            "style": "IPY_MODEL_9b72d06da8e44dd89ffb87bb8f2f8719",
            "value": "99.0/99.0[00:00&lt;00:00,6.14kB/s]"
          }
        },
        "151a94610046456197d8c854ac2fc309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "828df104ebf14490871bab42cbf7e59c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a89cea437a479aa965348e7664854a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83f4161c855c4eab99b61d54378b9c85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a53ae3e38d64ac680e1348a60659825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35ac412c0e874cf1b53b5142c21d7c50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b72d06da8e44dd89ffb87bb8f2f8719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2a8d9c326b4483c9142cf89e21ab5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d0593c8eeba43f99564342870abef9c",
              "IPY_MODEL_69592a9157a54d8e948454da5aaa3cac",
              "IPY_MODEL_747a5acd712940a39b09d9e3d724d1cb"
            ],
            "layout": "IPY_MODEL_a61b20382b904af488583f48126c8311"
          }
        },
        "8d0593c8eeba43f99564342870abef9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89a994e968df485fb326bfcb755b723d",
            "placeholder": "",
            "style": "IPY_MODEL_c71af86b37bb47799c2ef74499817609",
            "value": "config.json:100%"
          }
        },
        "69592a9157a54d8e948454da5aaa3cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44825a6f8a604cb9bdddb84a39bdcb59",
            "max": 1176,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_577c1484b8e945ab8346d47ca5ba74a0",
            "value": 1176
          }
        },
        "747a5acd712940a39b09d9e3d724d1cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0312394ced074c47910b59ac25552823",
            "placeholder": "",
            "style": "IPY_MODEL_5aa22ca6c62c4880994626fbc790cd37",
            "value": "1.18k/1.18k[00:00&lt;00:00,91.2kB/s]"
          }
        },
        "a61b20382b904af488583f48126c8311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89a994e968df485fb326bfcb755b723d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c71af86b37bb47799c2ef74499817609": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44825a6f8a604cb9bdddb84a39bdcb59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "577c1484b8e945ab8346d47ca5ba74a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0312394ced074c47910b59ac25552823": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aa22ca6c62c4880994626fbc790cd37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3d0229290cf4f2da224d24f955267e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_267f1b05e2004202a8e1c5afbdc42da7",
              "IPY_MODEL_dc54bae145644df8b3ac5410651eb537",
              "IPY_MODEL_7579dc18ccc74cb5ab1ad8292f763e01"
            ],
            "layout": "IPY_MODEL_570302592ee2444997cd1dec91639809"
          }
        },
        "267f1b05e2004202a8e1c5afbdc42da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_835e76794b764ce9b4f19c21722110a7",
            "placeholder": "",
            "style": "IPY_MODEL_ea9959aad60a4fa3abaf84da6b1e7255",
            "value": "configuration_bert.py:100%"
          }
        },
        "dc54bae145644df8b3ac5410651eb537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6d0d3decff941219a6f6ecbec7d1373",
            "max": 8241,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1879ed3ae3944070bbcf254c2321df71",
            "value": 8241
          }
        },
        "7579dc18ccc74cb5ab1ad8292f763e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49f02842a2b94dafb2470122c56e9d31",
            "placeholder": "",
            "style": "IPY_MODEL_87108e58563442ed9e820c909e0eae50",
            "value": "8.24k/8.24k[00:00&lt;00:00,620kB/s]"
          }
        },
        "570302592ee2444997cd1dec91639809": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "835e76794b764ce9b4f19c21722110a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea9959aad60a4fa3abaf84da6b1e7255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6d0d3decff941219a6f6ecbec7d1373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1879ed3ae3944070bbcf254c2321df71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "49f02842a2b94dafb2470122c56e9d31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87108e58563442ed9e820c909e0eae50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f9312e2fa67405698ff887e3dce5519": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_281cd288d5ca4eaabde32028fd556736",
              "IPY_MODEL_d42d9c45737b4d71a4cd917b8ce0361b",
              "IPY_MODEL_909a63ad4ee54557b9ac6704884bf4b0"
            ],
            "layout": "IPY_MODEL_ebaa0daab5294ce194143a107ea6d40a"
          }
        },
        "281cd288d5ca4eaabde32028fd556736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ec8ca73b2444c6e86a61d4722aa442c",
            "placeholder": "",
            "style": "IPY_MODEL_4a256da087a147ee96b4d5cc86c4c37c",
            "value": "modeling_bert.py:100%"
          }
        },
        "d42d9c45737b4d71a4cd917b8ce0361b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea2d85e01d3f4ba7aded1fbe5546795e",
            "max": 97656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f304c67bbf894e4f87822a9be904a79c",
            "value": 97656
          }
        },
        "909a63ad4ee54557b9ac6704884bf4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8911c5ece5bc48429b1c0da04cdfeba1",
            "placeholder": "",
            "style": "IPY_MODEL_7b41ad5fb42f4966bf7f41db80b346d0",
            "value": "97.7k/97.7k[00:00&lt;00:00,7.59MB/s]"
          }
        },
        "ebaa0daab5294ce194143a107ea6d40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ec8ca73b2444c6e86a61d4722aa442c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a256da087a147ee96b4d5cc86c4c37c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea2d85e01d3f4ba7aded1fbe5546795e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f304c67bbf894e4f87822a9be904a79c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8911c5ece5bc48429b1c0da04cdfeba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b41ad5fb42f4966bf7f41db80b346d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96f9e75862e94e028246e4012446e751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed5da8a8c8f744a59f0468bd94e1fb3d",
              "IPY_MODEL_b6f3727cc1fd40bda6b0a65ad5cfa656",
              "IPY_MODEL_0aa4b1500dcf47898930dd5c661126bc"
            ],
            "layout": "IPY_MODEL_49f72371702e42f79fa4ca65baa5156d"
          }
        },
        "ed5da8a8c8f744a59f0468bd94e1fb3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90c0165b94884f05b16dcfd93d4a540b",
            "placeholder": "",
            "style": "IPY_MODEL_5f55ba99af5841bdb48b12d77f491717",
            "value": "model.safetensors:100%"
          }
        },
        "b6f3727cc1fd40bda6b0a65ad5cfa656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7202abba15c64751929156e7a4e18085",
            "max": 274757256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e38e357e9494e90bcb002b13ee4ec77",
            "value": 274757256
          }
        },
        "0aa4b1500dcf47898930dd5c661126bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71d12919d4c140f6ac254ce9a5142fc1",
            "placeholder": "",
            "style": "IPY_MODEL_989859c42f4940bea1a2086d25a94b77",
            "value": "275M/275M[00:00&lt;00:00,408MB/s]"
          }
        },
        "49f72371702e42f79fa4ca65baa5156d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c0165b94884f05b16dcfd93d4a540b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f55ba99af5841bdb48b12d77f491717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7202abba15c64751929156e7a4e18085": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e38e357e9494e90bcb002b13ee4ec77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71d12919d4c140f6ac254ce9a5142fc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "989859c42f4940bea1a2086d25a94b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "412ce4e5687e4cf0970e6c49716fbf97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a434e54e561e4f79a4eb17ac21b97fca",
              "IPY_MODEL_50be2b2706ab4c2d9fc08aab0a9fa340",
              "IPY_MODEL_5415f9ec74854d1989157a82fe3662c0"
            ],
            "layout": "IPY_MODEL_22b459f08d7747ab95e7dfcf638aedd5"
          }
        },
        "a434e54e561e4f79a4eb17ac21b97fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6d362dc26a54c73b02dbc309d57c346",
            "placeholder": "",
            "style": "IPY_MODEL_2774916cfb4d4264985a5c5aec73053d",
            "value": "tokenizer_config.json:100%"
          }
        },
        "50be2b2706ab4c2d9fc08aab0a9fa340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8543cd975cd8425db3e4f8083321f88b",
            "max": 373,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_382f31752c714cf390b8f8cbed889667",
            "value": 373
          }
        },
        "5415f9ec74854d1989157a82fe3662c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97cbed154d144037be9f799f9160ca61",
            "placeholder": "",
            "style": "IPY_MODEL_9477a8f1eb244c7684e298f6dcb99571",
            "value": "373/373[00:00&lt;00:00,28.5kB/s]"
          }
        },
        "22b459f08d7747ab95e7dfcf638aedd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6d362dc26a54c73b02dbc309d57c346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2774916cfb4d4264985a5c5aec73053d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8543cd975cd8425db3e4f8083321f88b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "382f31752c714cf390b8f8cbed889667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97cbed154d144037be9f799f9160ca61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9477a8f1eb244c7684e298f6dcb99571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d493ec267f09428bb8d0672b0c57c7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ff8d130605f4e0cb5f4ab9672308907",
              "IPY_MODEL_cab88500a4284a5bae59d188bc1e54e2",
              "IPY_MODEL_91b5d621ecdb4d40ad6640de1d4715a2"
            ],
            "layout": "IPY_MODEL_67453b5851aa4673a3fa6e5ef4c1bb40"
          }
        },
        "6ff8d130605f4e0cb5f4ab9672308907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7d92714a0184413b1dc7be0f204cd5f",
            "placeholder": "",
            "style": "IPY_MODEL_23c2fc3bc2cf419aacc24f5e0329362c",
            "value": "vocab.txt:100%"
          }
        },
        "cab88500a4284a5bae59d188bc1e54e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d3b7ca98ae2487e96e2fb9d27dde328",
            "max": 231589,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5f0ba938b3a4d97a1e1e5e77e5a3dc0",
            "value": 231589
          }
        },
        "91b5d621ecdb4d40ad6640de1d4715a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04430ca6826c40e29385200a6f476fd5",
            "placeholder": "",
            "style": "IPY_MODEL_ba880061c3524364bdd7ca22166e206e",
            "value": "232k/232k[00:00&lt;00:00,15.4MB/s]"
          }
        },
        "67453b5851aa4673a3fa6e5ef4c1bb40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7d92714a0184413b1dc7be0f204cd5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23c2fc3bc2cf419aacc24f5e0329362c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d3b7ca98ae2487e96e2fb9d27dde328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5f0ba938b3a4d97a1e1e5e77e5a3dc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04430ca6826c40e29385200a6f476fd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba880061c3524364bdd7ca22166e206e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f176028bcd54c11babfeb13f0bdec4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aac079b9522d472696f3a6f82ac8f704",
              "IPY_MODEL_38b311911d5944b59df69919317a7791",
              "IPY_MODEL_ed514f905cd64eee994f1eb36eb23f20"
            ],
            "layout": "IPY_MODEL_361f1e6f832342bdadf164f55f3fa638"
          }
        },
        "aac079b9522d472696f3a6f82ac8f704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_156e40178525453db7ed4a4c988a8f67",
            "placeholder": "",
            "style": "IPY_MODEL_cdd9827b42a648e48a0cdefc9c09630c",
            "value": "tokenizer.json:100%"
          }
        },
        "38b311911d5944b59df69919317a7791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c79ceec5dd64d72b382d4b61080ac2d",
            "max": 711577,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ebc3c6697974d31938c3c137a0d49b8",
            "value": 711577
          }
        },
        "ed514f905cd64eee994f1eb36eb23f20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6606ba7527ef40e892511deed04a5e7d",
            "placeholder": "",
            "style": "IPY_MODEL_ecfc74a4c5bc4f8dac29baeb4b0ac0c8",
            "value": "712k/712k[00:00&lt;00:00,3.27MB/s]"
          }
        },
        "361f1e6f832342bdadf164f55f3fa638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "156e40178525453db7ed4a4c988a8f67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdd9827b42a648e48a0cdefc9c09630c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c79ceec5dd64d72b382d4b61080ac2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ebc3c6697974d31938c3c137a0d49b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6606ba7527ef40e892511deed04a5e7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecfc74a4c5bc4f8dac29baeb4b0ac0c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11069fa5997244b188f15c2fdc32ccb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b69b3e52aee74c56954d8ff9d0ddb5b6",
              "IPY_MODEL_2727a0af9e294c9d8f477f497e0d56e3",
              "IPY_MODEL_e3d9016b2e4f418e82e1226b5fe143e9"
            ],
            "layout": "IPY_MODEL_9d530d6cfc604dc88fc1cdfa1aa33c29"
          }
        },
        "b69b3e52aee74c56954d8ff9d0ddb5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b43c2f21de449c9abbace483d8768d8",
            "placeholder": "",
            "style": "IPY_MODEL_76f058c799f14ddc9e5a5458e0111f55",
            "value": "special_tokens_map.json:100%"
          }
        },
        "2727a0af9e294c9d8f477f497e0d56e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fe583a6e67844b08f80935ed39cf7d5",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_061c73c6d54d47c299c0428f896c6ddb",
            "value": 125
          }
        },
        "e3d9016b2e4f418e82e1226b5fe143e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12240f85d1c248d5ad3486cfdc20bf12",
            "placeholder": "",
            "style": "IPY_MODEL_e37f42e752fe42b99591b0af4353101f",
            "value": "125/125[00:00&lt;00:00,10.2kB/s]"
          }
        },
        "9d530d6cfc604dc88fc1cdfa1aa33c29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b43c2f21de449c9abbace483d8768d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f058c799f14ddc9e5a5458e0111f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fe583a6e67844b08f80935ed39cf7d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "061c73c6d54d47c299c0428f896c6ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12240f85d1c248d5ad3486cfdc20bf12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e37f42e752fe42b99591b0af4353101f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4498e612202433e8b89680d0e14924f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9b70cfdab104c2d92e0a45ffc64a6a6",
              "IPY_MODEL_4be375bb1256483384018e38cc6b4f26",
              "IPY_MODEL_bfb2b61d505248c496d4c1e77bb6c17a"
            ],
            "layout": "IPY_MODEL_3541b7ddf7bd477088f5d976493a362e"
          }
        },
        "d9b70cfdab104c2d92e0a45ffc64a6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1308f9801f8f4d6191be48d222439a20",
            "placeholder": "",
            "style": "IPY_MODEL_2ccde0fea33f4ee7837fe5e8ce7f21b2",
            "value": "1_Pooling/config.json:100%"
          }
        },
        "4be375bb1256483384018e38cc6b4f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb52d1c37def402289f1f577dea32cfa",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cb920b40d75435e9133ecada674a84a",
            "value": 190
          }
        },
        "bfb2b61d505248c496d4c1e77bb6c17a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0e626b0979f45b0acf28cbeedbdc567",
            "placeholder": "",
            "style": "IPY_MODEL_3b06d2a810ff46a9aed80695287019d6",
            "value": "190/190[00:00&lt;00:00,16.6kB/s]"
          }
        },
        "3541b7ddf7bd477088f5d976493a362e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1308f9801f8f4d6191be48d222439a20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ccde0fea33f4ee7837fe5e8ce7f21b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb52d1c37def402289f1f577dea32cfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cb920b40d75435e9133ecada674a84a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0e626b0979f45b0acf28cbeedbdc567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b06d2a810ff46a9aed80695287019d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}