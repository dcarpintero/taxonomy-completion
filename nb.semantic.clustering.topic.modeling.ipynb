{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# An LLM-Approach to Semantic Clustering and Topic Modeling of Academic Literature"
      ],
      "metadata": {
        "id": "ohasq_p_8DMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Clustering](https://en.wikipedia.org/wiki/Cluster_analysis) stands as a fundamental task in unsupervised learning, where the goal is to group unlabeled data into related categories; whereas [Topic Modeling](https://en.wikipedia.org/wiki/Topic_model) focuses on identifying thematic structures within a collection of documents. These techniques find applications across various domains, enabling tasks such as information retrieval, anomaly detection, trend analysis, and biomedical research.\n",
        "\n",
        "This notebook provides an end-to-end guide to building an LLM-based pipeline for automatic categorization of research articles into latent topics using open source. Our playground is a  [dataset of 25,000 research arXiv publications](https://huggingface.co/datasets/dcarpintero/arxiv.cs.CL.embedv3.clustering.medium) from Computational Linguistics (Natural Language Processing) published before May 2024.\n",
        "\n",
        "At its core, the clustering problem relies on finding similar examples. This is a natural task for embeddings, as they capture the semantic relationships in a corpus, and can be provided as input features to a clustering algorithm to establish similarity links among the examples. We begin by transforming the `title:abstract` pairs of our dataset into an embeddings representation using  [Jina-Embeddings-v2](https://arxiv.org/abs/2310.19923), a BERT-ALiBi based attention model supporting 8192 sequence length, and subsequently applying HDBSCAN [2] in a reduced dimensional space. Topic modeling is then performed at cluster level using a random subset of `titles` within each cluster. This latter process combines [LangChain](https://www.langchain.com/) and [Pydantic](https://docs.pydantic.dev/) with [Mistral-7B-Instruct](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2) to define a topic pipeline that generates structured `JSON` output.\n",
        "\n",
        "To measure the clustering and topic modeling effectiveness, we visualize the outcomes after further applying [UMAP](https://en.wikipedia.org/wiki/Uniform_Manifold_Approximation_and_Projection) [1] dimensionality reduction.\n",
        "\n",
        "<figure>\n",
        "  <img style=\"margin: 0 auto; display: block;\" src=\"https://cdn-uploads.huggingface.co/production/uploads/64a13b68b14ab77f9e3eb061/iE3e4VJSY84JyyTR9krmf.png\">\n",
        "  <figcaption style=\"text-align: center;\">LLM-based Pipeline for Semantic Clustering and Topic Modeling of Academic Literature </figcaption>\n",
        "</figure>"
      ],
      "metadata": {
        "id": "7Dc0nbdRAaRy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uKSN9LlQ7caJ",
        "outputId": "29151cbd-e818-4a97-e5c4-4ee4f28c297c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade altair datasets hdbscan scikit-learn umap-learn --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Embeddings Transformation"
      ],
      "metadata": {
        "id": "H7Dbk-Pw8HJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[intro]"
      ],
      "metadata": {
        "id": "I2mWlEpLNJTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import tqdm as notebook_tqdm\n",
        "\n",
        "ds = load_dataset(\"dcarpintero/arxiv.cs.CL.10k.embeddings.mpnet\", split=\"train\")"
      ],
      "metadata": {
        "id": "_9-6JBvV7e28",
        "outputId": "957a75a1-9e82-44eb-c198-16c6ca58ef1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "4157078bb2374809a9d20f0b8f9ba57b",
            "970a60f1222a49639ee9a3b97a1b5f7b",
            "d0871b4078e440de9b6a541e4f1e27d4",
            "5babd32d8c7e48189dc8d5b52403a646",
            "cfd9250f97b649ae9d9e8be2cfe9f75a",
            "553a5736cc6f452cbf4694251fb85f3a",
            "34129117bfed48d2a1af829275dd3607",
            "39267c41913c4bd1a3ac88968f56ec85",
            "b3892b6560634c6bacb567d6fba2e046",
            "7a08abc106744991b0448d2ed042d073",
            "16d4f529ff9441b997eb7ec6a665458c",
            "076fc8f757934ae1b493d41834251357",
            "88806abd3bd548a1a05410476e9d5fd3",
            "e6e5bd5d71b94217bdf2e000ce6dd7a2",
            "8c62455b42594e9e98226ecc4b4e2396",
            "e2369b043dcb493a8c55813cc3df4898",
            "c0974924023044149e220a2b47850dab",
            "d604bc6dc08c4aa5aec6f86a05ce3d56",
            "a2abe2c137cf4c689a3753233eedbff3",
            "5a3e0300e9bf48dbbad076e6c64def4a",
            "b5d3b78cae5842c99c27ad00565578d1",
            "12002e9f2b6445b09a0588a9352b970f"
          ]
        }
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/178M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4157078bb2374809a9d20f0b8f9ba57b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "076fc8f757934ae1b493d41834251357"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ylvNR-j8sPy",
        "outputId": "74da36e3-b025-486a-8366-09ff71b2028d"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'doc_url', 'title', 'publication_date', 'update_date', 'authors', 'category_primary', 'category_all', 'abstract', 'embeddings'],\n",
              "    num_rows: 10000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Projecting Embeddings for Dimensionality Reduction"
      ],
      "metadata": {
        "id": "1xzN9ohN8xVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then project our (`title:abstract`) embeddings pairs from a high-dimensional space (768) to a lower-dimensional one (5) using\n",
        "[dimensionality reduction](https://en.wikipedia.org/wiki/Dimensionality_reduction). This process will reduce the computational complexity and memory usage during clustering.\n",
        "\n",
        "To implement this step, we use [UMAP](https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction#Uniform_manifold_approximation_and_projection) [1], a popular technique known for its effectiveness in preserving both the local and global data structures. In practice, this makes it a preferred choice for handling complex datasets with high-dimensional embeddings."
      ],
      "metadata": {
        "id": "rvIphImiArUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import umap\n",
        "\n",
        "umap_reducer = umap.UMAP(n_neighbors=100,\n",
        "                         n_components=5,\n",
        "                         min_dist=0.1,\n",
        "                         metric='cosine')\n",
        "umap_embedding = umap_reducer.fit_transform(ds['embeddings'])"
      ],
      "metadata": {
        "id": "uD51VhMG8yrI"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our implementation, we configure UMAP with:\n",
        "- `n_neighbors=100` to consider 100 nearest neighbors for each point (arXiv publication);\n",
        "- `n_components=5` to reduce the embeddings from 768 to 5 dimensions;\n",
        "- `min_dist=0.1` to maintain a balance between the local and global structure; and,\n",
        "- `metric='cosine'` to measure the distance between points using the cosine similarity metric.\n",
        "\n",
        "Note that when we apply HDBSCAN clustering in the next step, the clusters found will be influenced by how UMAP preserved the local structures. A smaller `n_neighbors` value means UMAP will focus more on local structures, whereas a larger value allows to capture more global representations, which might be beneficial for understanding overall patterns in the data."
      ],
      "metadata": {
        "id": "WSYIVW33A7dq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Semantic Clustering"
      ],
      "metadata": {
        "id": "1hH0Ra-x80I4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section shows how to use the reduced (`title:abstract`) embeddings pairs as input features of a clustering algorithm. This allows for the identification of related categories based on the distance between the provided embeddings.\n",
        "\n",
        "We have opted for [HDBSCAN](https://en.wikipedia.org/wiki/HDBSCAN) (Hierarchical Density-Based Spatial Clustering of Applications with Noise) [2], an advanced clustering algorithm that extends DBSCAN by adapting to varying density clusters. Unlike K-Means which requires pre-specifying the number of clusters, HDBSCAN has only one important hyperparameter, `n`, which establishes the minimum number of examples to include in a cluster. As a density-based method, it can also detect outliers in the data.\n",
        "\n",
        "HDBSCAN works by first transforming the data space according to the density of the data points, making denser regions (areas where data points are close together in high numbers) more attractive for cluster formation. The algorithm then builds a hierarchy of clusters based on the minimum cluster size established by the hyperparameter `n`. This allows it to distinguish between noise (sparse areas) and dense regions (potential clusters). Finally, HDBSCAN condenses this hierarchy to derive the most persistent clusters, efficiently identifying clusters of different densities and shapes."
      ],
      "metadata": {
        "id": "Qj0zQPWHCLoE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that while we define a minimum cluster size similar to the number of neighbors in UMAP, in practice they do not need to be equal."
      ],
      "metadata": {
        "id": "H5S6DW47Cd_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import hdbscan\n",
        "\n",
        "hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=100,\n",
        "                                metric='euclidean',\n",
        "                                cluster_selection_method='eom')\n",
        "clusters = hdbscan_model.fit_predict(umap_embedding)"
      ],
      "metadata": {
        "id": "wND3TL1O83OX"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We prepare the dataset for visualization by further reducing the number of dimensions, in this case from '5' to '2'."
      ],
      "metadata": {
        "id": "sDmhg0Yzel3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "reduced_embeddings = umap.UMAP(n_neighbors=100, n_components=2, min_dist=0.1, metric='cosine').fit_transform(ds['embeddings'])\n",
        "df = pd.DataFrame(reduced_embeddings, columns=['x', 'y'])\n",
        "df['cluster'] = clusters\n",
        "df['title'] = ds['title']\n",
        "\n",
        "df = df[df['cluster'] != -1] # remove outliers"
      ],
      "metadata": {
        "id": "ZF381fmRegYq"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "Aa1LLthXqcMA",
        "outputId": "c292bc51-9555-4d31-e40f-0c6135440b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           x         y  cluster  \\\n",
              "0   6.390210  1.447678        8   \n",
              "1   8.269410  7.373854        4   \n",
              "2   8.124364  7.802285        4   \n",
              "3   6.167572  1.872279        8   \n",
              "5   9.568141  4.940374       16   \n",
              "6   3.335279  3.650203       11   \n",
              "9   3.523068  0.792918        1   \n",
              "10  3.603736  0.815879        1   \n",
              "12  6.899806  2.962453       15   \n",
              "13  5.016772  5.896140        3   \n",
              "\n",
              "                                                title  \n",
              "0   Planetarium: A Rigorous Benchmark for Translat...  \n",
              "1   InternLM-XComposer-2.5: A Versatile Large Visi...  \n",
              "2   BACON: Supercharge Your VLM with Bag-of-Concep...  \n",
              "3   A Review of the Applications of Deep Learning-...  \n",
              "5   Evaluating Automatic Metrics with Incremental ...  \n",
              "6   How Similar Are Elected Politicians and Their ...  \n",
              "9   Self-Evaluation as a Defense Against Adversari...  \n",
              "10  Single Character Perturbations Break LLM Align...  \n",
              "12    How Does Quantization Affect Multilingual LLMs?  \n",
              "13  CiteAssist: A System for Automated Preprint Ci...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a99bb51c-6acd-4100-81f2-4c6337bf6717\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>cluster</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.390210</td>\n",
              "      <td>1.447678</td>\n",
              "      <td>8</td>\n",
              "      <td>Planetarium: A Rigorous Benchmark for Translat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.269410</td>\n",
              "      <td>7.373854</td>\n",
              "      <td>4</td>\n",
              "      <td>InternLM-XComposer-2.5: A Versatile Large Visi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.124364</td>\n",
              "      <td>7.802285</td>\n",
              "      <td>4</td>\n",
              "      <td>BACON: Supercharge Your VLM with Bag-of-Concep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.167572</td>\n",
              "      <td>1.872279</td>\n",
              "      <td>8</td>\n",
              "      <td>A Review of the Applications of Deep Learning-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>9.568141</td>\n",
              "      <td>4.940374</td>\n",
              "      <td>16</td>\n",
              "      <td>Evaluating Automatic Metrics with Incremental ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.335279</td>\n",
              "      <td>3.650203</td>\n",
              "      <td>11</td>\n",
              "      <td>How Similar Are Elected Politicians and Their ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3.523068</td>\n",
              "      <td>0.792918</td>\n",
              "      <td>1</td>\n",
              "      <td>Self-Evaluation as a Defense Against Adversari...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3.603736</td>\n",
              "      <td>0.815879</td>\n",
              "      <td>1</td>\n",
              "      <td>Single Character Perturbations Break LLM Align...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>6.899806</td>\n",
              "      <td>2.962453</td>\n",
              "      <td>15</td>\n",
              "      <td>How Does Quantization Affect Multilingual LLMs?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>5.016772</td>\n",
              "      <td>5.896140</td>\n",
              "      <td>3</td>\n",
              "      <td>CiteAssist: A System for Automated Preprint Ci...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a99bb51c-6acd-4100-81f2-4c6337bf6717')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a99bb51c-6acd-4100-81f2-4c6337bf6717 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a99bb51c-6acd-4100-81f2-4c6337bf6717');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a9fc1d29-e8dd-4b3a-bc61-f6748d2e58c0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a9fc1d29-e8dd-4b3a-bc61-f6748d2e58c0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a9fc1d29-e8dd-4b3a-bc61-f6748d2e58c0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6011,\n  \"fields\": [\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6008,\n        \"samples\": [\n          9.89002799987793,\n          8.879278182983398,\n          8.240867614746094\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 6009,\n        \"samples\": [\n          6.019493579864502,\n          0.38496971130371094,\n          2.930267095565796\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          8,\n          4,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6011,\n        \"samples\": [\n          \"Robust Zero-Shot Text-to-Speech Synthesis with Reverse Inference  Optimization\",\n          \"VISLA Benchmark: Evaluating Embedding Sensitivity to Semantic and  Lexical Alterations\",\n          \"HyperTTS: Parameter Efficient Adaptation in Text to Speech using  Hypernetworks\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['cluster'].unique()\n"
      ],
      "metadata": {
        "id": "rkdscDt7y_wI",
        "outputId": "f948b6d1-2b50-4865-9439-d1faecae243a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8,  4, 16, 11,  1, 15,  3, 14,  5,  9,  2,  7, 10, 17,  6, 13, 12,\n",
              "        0])"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Topic Modeling with LLMs"
      ],
      "metadata": {
        "id": "CXMs-a3X9ADN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Having performed the clustering step, we now illustrate how to identify the topic of each cluster by combining an LLM such as [Mistral-7B-Instruct](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3) with [Pydantic](https://docs.pydantic.dev/) and [LangChain](https://www.langchain.com/) to create a topic modeling pipeline."
      ],
      "metadata": {
        "id": "HX-AO-1FZKKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install huggingface_hub langchain langchain_huggingface --upgrade --quiet"
      ],
      "metadata": {
        "id": "AwR9byUaHzJ2"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Pydantic Model"
      ],
      "metadata": {
        "id": "N7WIZ3YE-Fut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Pydantic Models](https://docs.pydantic.dev/latest/concepts/models/) are classes that derive from `pydantic.BaseModel`, defining fields as type-annotated attributes. They bear a strong resemblance to `Python` dataclasses. However, they have been designed with subtle but significant differences that optimize various operations such as validation, serialization, and `JSON` schema generation. Our `Topic` class defines a field named `category`. This will generate output in a structured format, rather than a free-form text block, facilitating easier processing and analysis of the topic modeling results."
      ],
      "metadata": {
        "id": "A8sTrB9LZP_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Topic(BaseModel):\n",
        "    \"\"\"\n",
        "    Pydantic Model to generate an structured Topic Model\n",
        "    \"\"\"\n",
        "    label: str = Field(..., description=\"Identified topic\")"
      ],
      "metadata": {
        "id": "O9KmSyHU-B8m"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 LangChain Prompt Template"
      ],
      "metadata": {
        "id": "vH8Dtg_B-Hl1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[LangChain Prompt Templates](https://python.langchain.com/v0.2/docs/concepts/#prompt-templates) are pre-defined recipes for generating prompts for language models."
      ],
      "metadata": {
        "id": "DNrIOOovZVYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "topic_prompt = \"\"\"\n",
        "    You are a helpful Research Engineer. Your task is to analyze a set of research paper titles related to Natural Language Processing and\n",
        "    determine the overarching topic of the cluster. Based on the titles provided, you should identify and label the most relevant topic.\n",
        "    The response should be concise, clearly stating the single  identified topic. Format your response in JSON as indicated in the 'EXPECTED OUTPUT' section below.\n",
        "    No additional information or follow-up questions are needed.\n",
        "\n",
        "    EXPECTED OUTPUT:\n",
        "    {{\"label\": \"Topic Name\"}}\n",
        "\n",
        "    TITLES:\n",
        "    {titles}\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "DMRmlB-5-KiN"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Inference of Topic Identification"
      ],
      "metadata": {
        "id": "eC8YuK3E-X5s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section illustrates how to compose a topic pipeline using the [LangChain Expression Language (LCEL)](https://python.langchain.com/v0.2/docs/concepts/#langchain-expression-language-lcel)."
      ],
      "metadata": {
        "id": "ji3ur9psaHjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = userdata.get('HUGGINGFACEHUB_API_TOKEN')"
      ],
      "metadata": {
        "id": "8ZEXsbpLW_xg"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "from langchain.chains import LLMChain\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain_core.output_parsers import PydanticOutputParser\n",
        "\n",
        "from typing import List\n",
        "\n",
        "def TopicModeling(titles: List[str]) -> str:\n",
        "    \"\"\"\n",
        "    Infer the common topic of the given titles w/ LangChain, Pydantic, OpenAI\n",
        "    \"\"\"\n",
        "    repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "    llm = HuggingFaceEndpoint(\n",
        "        repo_id=repo_id,\n",
        "        temperature=0.2,\n",
        "        huggingfacehub_api_token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
        "    )\n",
        "    prompt = PromptTemplate.from_template(topic_prompt)\n",
        "    parser = PydanticOutputParser(pydantic_object=Topic)\n",
        "\n",
        "    topic_chain = prompt | llm | parser\n",
        "    return topic_chain.invoke({\"titles\": titles})"
      ],
      "metadata": {
        "id": "4xozoy2KIY0d"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To enable the model to infer the topic of each cluster, we provide a random subset of 25 paper titles from each cluster as input."
      ],
      "metadata": {
        "id": "aIAOMIV3axWc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "topics = []\n",
        "for i, cluster in df.groupby('cluster'):\n",
        "    titles = cluster['title'].sample(25).tolist()\n",
        "    topic = TopicModeling(titles)\n",
        "    topics.append(topic.label)"
      ],
      "metadata": {
        "id": "-Dv4uORJVP6B"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets assign each arXiv publication to each cluster, and see what are the top 15 topics."
      ],
      "metadata": {
        "id": "fmOoIUEca0u0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters = len(df['cluster'].unique())\n",
        "\n",
        "topic_map = dict(zip(range(n_clusters), topics))\n",
        "df['topic'] = df['cluster'].map(topic_map)"
      ],
      "metadata": {
        "id": "y543zJ6d-9u1"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['topic'].value_counts().head(15)"
      ],
      "metadata": {
        "id": "bvzbQXRYYTLP",
        "outputId": "8c5ce26d-db7e-454a-d719-15ac3bfc3361",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "topic\n",
              "Large Language Models Efficiency and Compression       691\n",
              "Multimodal Language Models                             600\n",
              "Bias in Language Models                                591\n",
              "Jailbreak Attacks and Defense                          566\n",
              "Natural Language Processing in Healthcare              552\n",
              "Multilingual Machine Translation                       370\n",
              "Speech Recognition and Translation                     354\n",
              "Chain-of-Thought Reasoning in Large Language Models    339\n",
              "Retrieval-Augmented Generation                         314\n",
              "Autonomous Agents and Planning with Language Models    238\n",
              "Named Entity Recognition                               217\n",
              "Large Language Models in Education                     203\n",
              "Large Language Model Alignment                         197\n",
              "Text Summarization                                     194\n",
              "Natural Language Processing for Dialogue Systems       166\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Visualization"
      ],
      "metadata": {
        "id": "8zhDty-P9Lz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install vegafusion[embed]>=1.5.0 --quiet\n",
        "\n",
        "import altair as alt\n",
        "alt.data_transformers.enable(\"vegafusion\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO0Vieeu9NY-",
        "outputId": "10395a5a-58bd-4728-a7e5-ee63d2fb1e9c"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataTransformerRegistry.enable('vegafusion')"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chart = alt.Chart(df).mark_circle(size=5).encode(\n",
        "    x='x',\n",
        "    y='y',\n",
        "    color='topic:N',\n",
        "    tooltip=['title', 'topic']\n",
        ").interactive().properties(\n",
        "    title='10K arXiv Abstracts in NLP | Embeddings | UMAP | HDBSCAN | Mistral-7B',\n",
        "    width=600,\n",
        "    height=400,\n",
        ")\n",
        "chart.display()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "xfUIaJ1g_A8d",
        "outputId": "b6d4093b-d46e-4b1e-bf17-4e1907bf8660"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "  #altair-viz-153cff042db84b42a41a8e6357c5f726.vega-embed {\n",
              "    width: 100%;\n",
              "    display: flex;\n",
              "  }\n",
              "\n",
              "  #altair-viz-153cff042db84b42a41a8e6357c5f726.vega-embed details,\n",
              "  #altair-viz-153cff042db84b42a41a8e6357c5f726.vega-embed details summary {\n",
              "    position: relative;\n",
              "  }\n",
              "</style>\n",
              "<div id=\"altair-viz-153cff042db84b42a41a8e6357c5f726\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-153cff042db84b42a41a8e6357c5f726\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-153cff042db84b42a41a8e6357c5f726\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.17.0?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function maybeLoadScript(lib, version) {\n",
              "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
              "      return (VEGA_DEBUG[key] == version) ?\n",
              "        Promise.resolve(paths[lib]) :\n",
              "        new Promise(function(resolve, reject) {\n",
              "          var s = document.createElement('script');\n",
              "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "          s.async = true;\n",
              "          s.onload = () => {\n",
              "            VEGA_DEBUG[key] = version;\n",
              "            return resolve(paths[lib]);\n",
              "          };\n",
              "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "          s.src = paths[lib];\n",
              "        });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else {\n",
              "      maybeLoadScript(\"vega\", \"5\")\n",
              "        .then(() => maybeLoadScript(\"vega-lite\", \"5.17.0\"))\n",
              "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"$schema\": \"https://vega.github.io/schema/vega/v5.json\", \"data\": [{\"name\": \"param_4_store\"}, {\"name\": \"source_0\", \"values\": [{\"title\": \"Planetarium: A Rigorous Benchmark for Translating Text to Structured  Planning Languages\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.39, \"y\": 1.448}, {\"title\": \"InternLM-XComposer-2.5: A Versatile Large Vision Language Model  Supporting Long-Contextual Input and Output\", \"topic\": \"Multimodal Language Models\", \"x\": 8.269, \"y\": 7.374}, {\"title\": \"BACON: Supercharge Your VLM with Bag-of-Concept Graph to Mitigate  Hallucinations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.124, \"y\": 7.802}, {\"title\": \"A Review of the Applications of Deep Learning-Based Emergent  Communication\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.168, \"y\": 1.872}, {\"title\": \"Evaluating Automatic Metrics with Incremental Machine Translation  Systems\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.568, \"y\": 4.94}, {\"title\": \"How Similar Are Elected Politicians and Their Constituents? Quantitative  Evidence From Online Social Network\", \"topic\": \"Bias in Language Models\", \"x\": 3.335, \"y\": 3.65}, {\"title\": \"Self-Evaluation as a Defense Against Adversarial Attacks on LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.523, \"y\": 0.793}, {\"title\": \"Single Character Perturbations Break LLM Alignment\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.604, \"y\": 0.816}, {\"title\": \"How Does Quantization Affect Multilingual LLMs?\", \"topic\": \"Large Language Models in Education\", \"x\": 6.9, \"y\": 2.962}, {\"title\": \"CiteAssist: A System for Automated Preprint Citation and BibTeX  Generation\", \"topic\": \"Text Summarization\", \"x\": 5.017, \"y\": 5.896}, {\"title\": \"Fine-Tuning with Divergent Chains of Thought Boosts Reasoning Through  Self-Correction in Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.481, \"y\": 2.042}, {\"title\": \"Investigating Decoder-only Large Language Models for Speech-to-text  Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.079, \"y\": 5.346}, {\"title\": \"SOS! Soft Prompt Attack Against Open-Source Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.341, \"y\": 0.638}, {\"title\": \"Let the Code LLM Edit Itself When You Edit the Code\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.151, \"y\": 0.061}, {\"title\": \"Enhancing Translation Accuracy of Large Language Models through  Continual Pre-Training on Parallel Data\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.619, \"y\": 4.601}, {\"title\": \"Speaker- and Text-Independent Estimation of Articulatory Movements and  Phoneme Alignments from Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.178, \"y\": 5.999}, {\"title\": \"Social Bias Evaluation for Large Language Models Requires Prompt  Variations\", \"topic\": \"Bias in Language Models\", \"x\": 3.696, \"y\": 2.668}, {\"title\": \"KeyVideoLLM: Towards Large-scale Video Keyframe Selection\", \"topic\": \"Multimodal Language Models\", \"x\": 8.776, \"y\": 7.393}, {\"title\": \"Cactus: Towards Psychological Counseling Conversations using Cognitive  Behavioral Theory\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 2.977, \"y\": 6.38}, {\"title\": \"A Case Study on Context-Aware Neural Machine Translation with Multi-Task  Learning\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.703, \"y\": 4.57}, {\"title\": \"Improving Conversational Abilities of Quantized Large Language Models  via Direct Preference Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.737, \"y\": 0.667}, {\"title\": \"JailbreakHunter: A Visual Analytics Approach for Jailbreak Prompts  Discovery from Large-Scale Human-LLM Conversational Datasets\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.023, \"y\": 0.497}, {\"title\": \"On the Client Preference of LLM Fine-tuning in Federated Learning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.214, \"y\": 0.035}, {\"title\": \"Human-like Linguistic Biases in Neural Speech Models: Phonetic  Categorization and Phonotactic Constraints in Wav2Vec2.0\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.186, \"y\": 5.634}, {\"title\": \"SemioLLM: Assessing Large Language Models for Semiological Analysis in  Epilepsy Research\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.999, \"y\": 7.197}, {\"title\": \"VIVA: A Benchmark for Vision-Grounded Decision-Making with Human Values\", \"topic\": \"Multimodal Language Models\", \"x\": 7.909, \"y\": 7.56}, {\"title\": \"Are Large Language Models Consistent over Value-laden Questions?\", \"topic\": \"Bias in Language Models\", \"x\": 4.323, \"y\": 2.722}, {\"title\": \"LoRA-Guard: Parameter-Efficient Guardrail Adaptation for Content  Moderation of Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.932, \"y\": 1.213}, {\"title\": \"Large Language Models as Evaluators for Scientific Synthesis\", \"topic\": \"Text Summarization\", \"x\": 5.014, \"y\": 5.776}, {\"title\": \"ObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary  LLMs on Private Datasets\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.813, \"y\": 0.201}, {\"title\": \"IncogniText: Privacy-enhancing Conditional Text Anonymization via  LLM-based Private Attribute Randomization\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.558, \"y\": 0.375}, {\"title\": \"PII-Compass: Guiding LLM training data extraction prompts towards the  target PII via grounding\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.72, \"y\": 0.49}, {\"title\": \"Probing the Feasibility of Multilingual Speaker Anonymization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.411, \"y\": 6.122}, {\"title\": \"Towards Negotiative Dialogue for the Talkamatic Dialogue Manager\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.139, \"y\": 2.878}, {\"title\": \"Translatotron-V(ison): An End-to-End Model for In-Image Machine  Translation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.901, \"y\": 6.431}, {\"title\": \"GPTQT: Quantize Large Language Models Twice to Push the Efficiency\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.568, \"y\": 2.284}, {\"title\": \"CoIR: A Comprehensive Benchmark for Code Information Retrieval Models\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.037, \"y\": 0.149}, {\"title\": \"Safe Unlearning: A Surprisingly Effective and Generalizable Solution to  Defend Against Jailbreak Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.108, \"y\": 0.56}, {\"title\": \"MindBench: A Comprehensive Benchmark for Mind Map Structure Recognition  and Analysis\", \"topic\": \"Multimodal Language Models\", \"x\": 7.551, \"y\": 7.118}, {\"title\": \"Comparing Feature-based and Context-aware Approaches to PII  Generalization Level Prediction\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.627, \"y\": 0.421}, {\"title\": \"Images Speak Louder than Words: Understanding and Mitigating Bias in  Vision-Language Model from a Causal Mediation Perspective\", \"topic\": \"Bias in Language Models\", \"x\": 3.155, \"y\": 2.683}, {\"title\": \"52B to 1T: Lessons Learned via Tele-FLM Series\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.584, \"y\": 2.011}, {\"title\": \"A Framework for Quantum Finite-State Languages with Density Mapping\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.474, \"y\": 2.65}, {\"title\": \"Automatic gradient descent with generalized Newton's method\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.941, \"y\": 2.368}, {\"title\": \"Emotion and Intent Joint Understanding in Multimodal Conversation: A  Benchmarking Dataset\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.582, \"y\": 5.252}, {\"title\": \"A Comparative Study of DSL Code Generation: Fine-Tuning vs. Optimized  Retrieval Augmentation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.039, \"y\": 0.145}, {\"title\": \"MentalAgora: A Gateway to Advanced Personalized Care in Mental Health  through Multi-Agent Debating and Attribute Control\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.045, \"y\": 6.419}, {\"title\": \"e-Health CSIRO at \\\"Discharge Me!\\\" 2024: Generating Discharge Summary  Sections with Fine-tuned Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.158, \"y\": 7.433}, {\"title\": \"Boosting Biomedical Concept Extraction by Rule-Based Data Augmentation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.786, \"y\": 7.054}, {\"title\": \"LLM-Select: Feature Selection with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.07, \"y\": 7.328}, {\"title\": \"Reasoning in Large Language Models: A Geometric Perspective\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.48, \"y\": 2.28}, {\"title\": \"Ensuring Responsible Sourcing of Large Language Model Training Data  Through Knowledge Graph Comparison\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.306, \"y\": 1.469}, {\"title\": \"A Practical Review of Mechanistic Interpretability for Transformer-Based  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.91, \"y\": 2.713}, {\"title\": \"Nollywood: Let's Go to the Movies!\", \"topic\": \"Bias in Language Models\", \"x\": 2.523, \"y\": 3.223}, {\"title\": \"Uplifting Lower-Income Data: Strategies for Socioeconomic Perspective  Shifts in Vision-Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.514, \"y\": 2.792}, {\"title\": \"D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data  and eXpert model predictions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.2, \"y\": 7.956}, {\"title\": \"Towards More Realistic Extraction Attacks: An Adversarial Perspective\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.405, \"y\": 0.726}, {\"title\": \"MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via  Dynamic Sparse Attention\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.119, \"y\": 2.886}, {\"title\": \"RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in  LLMs\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.288, \"y\": 4.501}, {\"title\": \"MMedAgent: Learning to Use Medical Tools with Multi-modal Agent\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.077, \"y\": 7.576}, {\"title\": \"Understanding Alignment in Multimodal LLMs: A Comprehensive Study\", \"topic\": \"Multimodal Language Models\", \"x\": 8.194, \"y\": 7.58}, {\"title\": \"ValueScope: Unveiling Implicit Norms and Values via Return Potential  Model of Social Interactions\", \"topic\": \"Bias in Language Models\", \"x\": 3.315, \"y\": 3.365}, {\"title\": \"RLHF Can Speak Many Languages: Unlocking Multilingual Preference  Optimization for LLMs\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.618, \"y\": 0.568}, {\"title\": \"Ensemble of pre-trained language models and data augmentation for hate  speech detection from Arabic tweets\", \"topic\": \"Bias in Language Models\", \"x\": 2.487, \"y\": 3.443}, {\"title\": \"CEB: Compositional Evaluation Benchmark for Fairness in Large Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.238, \"y\": 2.774}, {\"title\": \"Learning to Refine with Fine-Grained Natural Language Feedback\", \"topic\": \"Text Summarization\", \"x\": 5.252, \"y\": 4.905}, {\"title\": \"Is Your AI-Generated Code Really Secure? Evaluating Large Language  Models on Secure Code Generation with CodeSecEval\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.784, \"y\": 0.107}, {\"title\": \"SafaRi:Adaptive Sequence Transformer for Weakly Supervised Referring  Expression Segmentation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.262, \"y\": 7.273}, {\"title\": \"Talking to Machines: do you read me?\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.268, \"y\": 2.995}, {\"title\": \"Pelican: Correcting Hallucination in Vision-LLMs via Claim Decomposition  and Program of Thought Verification\", \"topic\": \"Multimodal Language Models\", \"x\": 8.186, \"y\": 7.965}, {\"title\": \"Generative Large Language Models in Automated Fact-Checking: A Survey\", \"topic\": \"Bias in Language Models\", \"x\": 3.85, \"y\": 3.835}, {\"title\": \"MORPHEUS: Modeling Role from Personalized Dialogue History by Exploring  and Utilizing Latent Space\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.122, \"y\": 3.339}, {\"title\": \"RVISA: Reasoning and Verification for Implicit Sentiment Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.994, \"y\": 4.834}, {\"title\": \"Open foundation models for Azerbaijani language\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.008, \"y\": 4.316}, {\"title\": \"Why do LLaVA Vision-Language Models Reply to Images in English?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.211, \"y\": 7.704}, {\"title\": \"Efficient Sparse Attention needs Adaptive Token Release\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.142, \"y\": 3.073}, {\"title\": \"Exploring the Role of Transliteration in In-Context Learning for  Low-resource Languages Written in Non-Latin Scripts\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.46, \"y\": 4.477}, {\"title\": \"Soft Language Prompts for Language Transfer\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.097, \"y\": 4.123}, {\"title\": \"Multilingual Trolley Problems for Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.034, \"y\": 2.248}, {\"title\": \"Robust Zero-Shot Text-to-Speech Synthesis with Reverse Inference  Optimization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.89, \"y\": 6.019}, {\"title\": \"Towards a Holistic Framework for Multimodal Large Language Models in  Three-dimensional Brain CT Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.332, \"y\": 8.108}, {\"title\": \"Synthetic Multimodal Question Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.603, \"y\": 7.074}, {\"title\": \"How to Learn in a Noisy World? Self-Correcting the Real-World Data Noise  on Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.634, \"y\": 4.613}, {\"title\": \"Fake News Detection: It's All in the Data!\", \"topic\": \"Bias in Language Models\", \"x\": 3.438, \"y\": 3.696}, {\"title\": \"Cost-Effective Proxy Reward Model Construction with On-Policy and Active  Learning\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.497, \"y\": 0.613}, {\"title\": \"Crossroads of Continents: Automated Artifact Extraction for Cultural  Adaptation with Large Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.197, \"y\": 7.68}, {\"title\": \"BiasDora: Exploring Hidden Biased Associations in Vision-Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.203, \"y\": 2.717}, {\"title\": \"Are Data Augmentation Methods in Named Entity Recognition Applicable for  Uncertainty Estimation?\", \"topic\": \"Named Entity Recognition\", \"x\": 6.186, \"y\": 6.784}, {\"title\": \"Accompanied Singing Voice Synthesis with Fully Text-controlled Melody\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.701, \"y\": 5.962}, {\"title\": \"Concise and Precise Context Compression for Tool-Using Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.293, \"y\": 2.61}, {\"title\": \"Fake News Detection and Manipulation Reasoning via Large Vision-Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.47, \"y\": 3.745}, {\"title\": \"Breaking Bias, Building Bridges: Evaluation and Mitigation of Social  Biases in LLMs via Contact Hypothesis\", \"topic\": \"Bias in Language Models\", \"x\": 3.343, \"y\": 2.703}, {\"title\": \"Why does in-context learning fail sometimes? Evaluating in-context  learning on open and closed questions\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.385, \"y\": 4.321}, {\"title\": \"An End-to-End Speech Summarization Using Large Language Model\", \"topic\": \"Text Summarization\", \"x\": 5.308, \"y\": 4.953}, {\"title\": \"Towards the Next Frontier in Speech Representation Learning Using  Disentanglement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.193, \"y\": 5.918}, {\"title\": \"Simple Augmentations of Logical Rules for Neuro-Symbolic Knowledge Graph  Completion\", \"topic\": \"Named Entity Recognition\", \"x\": 6.662, \"y\": 5.709}, {\"title\": \"Is Your Large Language Model Knowledgeable or a Choices-Only Cheater?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 6.887, \"y\": 2.919}, {\"title\": \"AdaCQR: Enhancing Query Reformulation for Conversational Search via  Sparse and Dense Retrieval Alignment\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.98, \"y\": 4.412}, {\"title\": \"Enabling Discriminative Reasoning in LLMs for Legal Judgment Prediction\", \"topic\": \"Legal NLP\", \"x\": 4.4, \"y\": 4.541}, {\"title\": \"S2D: Sorted Speculative Decoding For More Efficient Deployment of Nested  Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.494, \"y\": 3.247}, {\"title\": \"Extracting and Encoding: Leveraging Large Language Models and Medical  Knowledge to Enhance Radiological Text Representation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.233, \"y\": 7.941}, {\"title\": \"Certainly Uncertain: A Benchmark and Metric for Multimodal Epistemic and  Aleatoric Awareness\", \"topic\": \"Multimodal Language Models\", \"x\": 7.88, \"y\": 7.737}, {\"title\": \"Efficient-Empathy: Towards Efficient and Effective Selection of Empathy  Data\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.679, \"y\": 5.717}, {\"title\": \"To Forget or Not? Towards Practical Knowledge Unlearning for Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.946, \"y\": 0.52}, {\"title\": \"Investigating the Effects of Large-Scale Pseudo-Stereo Data and  Different Speech Foundation Model on Dialogue Generative Spoken Language  Model\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.247, \"y\": 3.413}, {\"title\": \"Pinyin Regularization in Error Correction for Chinese Speech Recognition  with Large Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.537, \"y\": 5.685}, {\"title\": \"Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for  Sparse Architectural Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.771, \"y\": 2.093}, {\"title\": \"SoP: Unlock the Power of Social Facilitation for Automatic Jailbreak  Attack\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.032, \"y\": 0.438}, {\"title\": \"Proposal Report for the 2nd SciCAP Competition 2024\", \"topic\": \"Text Summarization\", \"x\": 5.15, \"y\": 5.254}, {\"title\": \"Beyond Numeric Awards: In-Context Dueling Bandits with LLM Agents\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.543, \"y\": 1.005}, {\"title\": \"VSP: Assessing the dual challenges of perception and reasoning in  spatial planning tasks for VLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.782, \"y\": 7.019}, {\"title\": \"Purple-teaming LLMs with Adversarial Defender Training\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.329, \"y\": 0.796}, {\"title\": \"A Study of Nationality Bias in Names and Perplexity using Off-the-Shelf  Affect-related Tweet Classifiers\", \"topic\": \"Bias in Language Models\", \"x\": 2.827, \"y\": 3.673}, {\"title\": \"Race and Privacy in Broadcast Police Communications\", \"topic\": \"Bias in Language Models\", \"x\": 3.199, \"y\": 2.861}, {\"title\": \"NLPGuard: A Framework for Mitigating the Use of Protected Attributes by  NLP Classifiers\", \"topic\": \"Bias in Language Models\", \"x\": 2.873, \"y\": 2.751}, {\"title\": \"Deciphering the Factors Influencing the Efficacy of Chain-of-Thought:  Probability, Memorization, and Noisy Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.339, \"y\": 1.883}, {\"title\": \"KV Cache Compression, But What Must We Give in Return? A Comprehensive  Benchmark of Long Context Capable Approaches\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.198, \"y\": 2.962}, {\"title\": \"Empowering 3D Visual Grounding with Reasoning Capabilities\", \"topic\": \"Multimodal Language Models\", \"x\": 7.886, \"y\": 7.408}, {\"title\": \"MIA-Bench: Towards Better Instruction Following Evaluation of Multimodal  LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.186, \"y\": 7.432}, {\"title\": \"Expressive and Generalizable Low-rank Adaptation for Large Models via  Slow Cascaded Learning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.902, \"y\": 1.711}, {\"title\": \"Agentless: Demystifying LLM-based Software Engineering Agents\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.913, \"y\": 0.385}, {\"title\": \"Tree Search for Language Model Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.169, \"y\": 1.597}, {\"title\": \"DogeRM: Equipping Reward Models with Domain Knowledge through Model  Merging\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.575, \"y\": 0.65}, {\"title\": \"Retrieval-augmented generation in multilingual settings\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.177, \"y\": 4.389}, {\"title\": \"Enhancing the Capability and Robustness of Large Language Models through  Reinforcement Learning-Driven Query Refinement\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.603, \"y\": 1.004}, {\"title\": \"A Global-Local Attention Mechanism for Relation Classification\", \"topic\": \"Named Entity Recognition\", \"x\": 6.381, \"y\": 6.561}, {\"title\": \"HyperLoader: Integrating Hypernetwork-Based LoRA and Adapter Layers into  Multi-Task Transformers for Sequence Labelling\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.437, \"y\": 2.16}, {\"title\": \"Optimization of Retrieval-Augmented Generation Context with Outlier  Detection\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.293, \"y\": 4.416}, {\"title\": \"POLygraph: Polish Fake News Dataset\", \"topic\": \"Bias in Language Models\", \"x\": 3.43, \"y\": 3.709}, {\"title\": \"Badllama 3: removing safety finetuning from Llama 3 in minutes\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.13, \"y\": 0.548}, {\"title\": \"Bridging the Gap: Transfer Learning from English PLMs to Malaysian  English\", \"topic\": \"Named Entity Recognition\", \"x\": 6.184, \"y\": 6.8}, {\"title\": \"Summary of a Haystack: A Challenge to Long-Context LLMs and RAG Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.929, \"y\": 4.608}, {\"title\": \"Nullpointer at ArAIEval Shared Task: Arabic Propagandist Technique  Detection with Token-to-Word Mapping in Sequence Tagging\", \"topic\": \"Bias in Language Models\", \"x\": 3.144, \"y\": 3.561}, {\"title\": \"Evaluating Knowledge-based Cross-lingual Inconsistency in Large Language  Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.655, \"y\": 4.166}, {\"title\": \"Protecting Privacy in Classifiers by Token Manipulation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.647, \"y\": 0.367}, {\"title\": \"Increasing Model Capacity for Free: A Simple Strategy for Parameter  Efficient Fine-tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.789, \"y\": 1.779}, {\"title\": \"Language Portability Strategies for Open-domain Dialogue with  Pre-trained Language Models from High to Low Resource Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.49, \"y\": 4.351}, {\"title\": \"Lightweight Zero-shot Text-to-Speech with Mixture of Adapters\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.035, \"y\": 5.978}, {\"title\": \"We-Math: Does Your Large Multimodal Model Achieve Human-like  Mathematical Reasoning?\", \"topic\": \"Multimodal Language Models\", \"x\": 7.598, \"y\": 7.613}, {\"title\": \"Leveraging Large Language Models for Actionable Course Evaluation  Student Feedback to Lecturers\", \"topic\": \"Large Language Models in Education\", \"x\": 6.296, \"y\": 2.32}, {\"title\": \"Show Less, Instruct More: Enriching Prompts with Definitions and  Guidelines for Zero-Shot NER\", \"topic\": \"Named Entity Recognition\", \"x\": 6.2, \"y\": 6.815}, {\"title\": \"First Place Solution of 2023 Global Artificial Intelligence Technology  Innovation Competition Track 1\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.248, \"y\": 7.982}, {\"title\": \"The African Woman is Rhythmic and Soulful: Evaluation of Open-ended  Generation for Implicit Biases\", \"topic\": \"Bias in Language Models\", \"x\": 3.358, \"y\": 2.744}, {\"title\": \"Searching for Best Practices in Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.143, \"y\": 4.359}, {\"title\": \"Learning to Explore and Select for Coverage-Conditioned  Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.123, \"y\": 4.427}, {\"title\": \"Unaligning Everything: Or Aligning Any Text to Any Image in Multimodal  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.033, \"y\": 1.157}, {\"title\": \"Sociocultural Considerations in Monitoring Anti-LGBTQ+ Content on Social  Media\", \"topic\": \"Bias in Language Models\", \"x\": 2.526, \"y\": 3.428}, {\"title\": \"Calibrated Large Language Models for Binary Question Answering\", \"topic\": \"Large Language Models in Education\", \"x\": 6.605, \"y\": 3.127}, {\"title\": \"BERGEN: A Benchmarking Library for Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.274, \"y\": 4.421}, {\"title\": \"Eliminating Position Bias of Language Models: A Mechanistic Approach\", \"topic\": \"Multimodal Language Models\", \"x\": 7.805, \"y\": 7.404}, {\"title\": \"CVLUE: A New Benchmark Dataset for Chinese Vision-Language Understanding  Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.131, \"y\": 7.813}, {\"title\": \"FRoG: Evaluating Fuzzy Reasoning of Generalized Quantifiers in Large  Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.595, \"y\": 1.316}, {\"title\": \"PocketLLM: Enabling On-Device Fine-Tuning for Personalized LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 4.206, \"y\": 0.041}, {\"title\": \"Augmenting Document-level Relation Extraction with Efficient  Multi-Supervision\", \"topic\": \"Named Entity Recognition\", \"x\": 6.32, \"y\": 6.485}, {\"title\": \"DynaThink: Fast or Slow? A Dynamic Decision-Making Framework for Large  Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.182, \"y\": 1.918}, {\"title\": \"Can Small Language Models Learn, Unlearn, and Retain Noise Patterns?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.145, \"y\": 2.545}, {\"title\": \"LLM Uncertainty Quantification through Directional Entailment Graph and  Claim Level Response Augmentation\", \"topic\": \"Large Language Models in Education\", \"x\": 6.599, \"y\": 3.115}, {\"title\": \"Mobile-Bench: An Evaluation Benchmark for LLM-based Mobile Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.162, \"y\": 1.599}, {\"title\": \"Universal Approximation Theory: The basic theory for large language  models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.29, \"y\": 2.758}, {\"title\": \"SplitLoRA: A Split Parameter-Efficient Fine-Tuning Framework for Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.113, \"y\": 0.032}, {\"title\": \"MalAlgoQA: A Pedagogical Approach for Evaluating Counterfactual  Reasoning Abilities\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.362, \"y\": 1.735}, {\"title\": \"FoldGPT: Simple and Effective Large Language Model Compression Scheme\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.305, \"y\": 2.455}, {\"title\": \"Deep Image-to-Recipe Translation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.077, \"y\": 7.146}, {\"title\": \"FineSurE: Fine-grained Summarization Evaluation using LLMs\", \"topic\": \"Text Summarization\", \"x\": 5.183, \"y\": 5.093}, {\"title\": \"From Introspection to Best Practices: Principled Analysis of  Demonstrations in Multimodal In-Context Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.224, \"y\": 7.437}, {\"title\": \"MathCAMPS: Fine-grained Synthesis of Mathematical Problems From Human  Curricula\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.683, \"y\": 1.223}, {\"title\": \"Papez: Resource-Efficient Speech Separation with Auditory Working Memory\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.438, \"y\": 5.616}, {\"title\": \"Mechanistic Interpretation through Contextual Decomposition in  Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.049, \"y\": 2.684}, {\"title\": \"Large Language Models Are Involuntary Truth-Tellers: Exploiting Fallacy  Failure for Jailbreak Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.121, \"y\": 0.529}, {\"title\": \"Towards Robust Speech Representation Learning for Thousands of Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.379, \"y\": 5.838}, {\"title\": \"NAIST Simultaneous Speech Translation System for IWSLT 2024\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.075, \"y\": 5.625}, {\"title\": \"Step-Controlled DPO: Leveraging Stepwise Error for Enhanced Mathematical  Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.445, \"y\": 1.6}, {\"title\": \"Characterizing Stereotypical Bias from Privacy-preserving Pre-Training\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.739, \"y\": 0.308}, {\"title\": \"A Comparative Study of Quality Evaluation Methods for Text Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.12, \"y\": 5.137}, {\"title\": \"Large Language Models Struggle in Token-Level Clinical Named Entity  Recognition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.345, \"y\": 7.292}, {\"title\": \"BAPO: Base-Anchored Preference Optimization for Personalized Alignment  in Large Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.528, \"y\": 0.575}, {\"title\": \"Actionable Cyber Threat Intelligence using Knowledge Graphs and Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.477, \"y\": 1.417}, {\"title\": \"HRDE: Retrieval-Augmented Large Language Models for Chinese Health Rumor  Detection and Explainability\", \"topic\": \"Bias in Language Models\", \"x\": 3.641, \"y\": 3.916}, {\"title\": \"A Collocation-based Method for Addressing Challenges in Word-level  Metric Differential Privacy\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.782, \"y\": 0.228}, {\"title\": \"DP-MLM: Differentially Private Text Rewriting Using Masked Language  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.623, \"y\": 0.339}, {\"title\": \"CAMON: Cooperative Agents for Multi-Object Navigation with LLM-based  Conversations\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.042, \"y\": 1.494}, {\"title\": \"Iterative Nash Policy Optimization: Aligning LLMs with General  Preferences via No-Regret Learning\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.557, \"y\": 0.527}, {\"title\": \"Efficient Personalized Text-to-image Generation by Leveraging Textual  Subspace\", \"topic\": \"Multimodal Language Models\", \"x\": 8.433, \"y\": 6.908}, {\"title\": \"MasonTigers at SemEval-2024 Task 10: Emotion Discovery and Flip  Reasoning in Conversation with Ensemble of Transformers and Prompting\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.572, \"y\": 5.43}, {\"title\": \"Investigating and Mitigating the Multimodal Hallucination Snowballing in  Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.306, \"y\": 8.015}, {\"title\": \"Answering real-world clinical questions using large language model based  systems\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.853, \"y\": 7.146}, {\"title\": \"It's Morphing Time: Unleashing the Potential of Multiple LLMs via  Multi-objective Optimization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.236, \"y\": 1.987}, {\"title\": \"Towards Massive Multilingual Holistic Bias\", \"topic\": \"Bias in Language Models\", \"x\": 3.221, \"y\": 2.652}, {\"title\": \"Large Language Models for Power Scheduling: A User-Centric Approach\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.446, \"y\": 1.609}, {\"title\": \"MMEvalPro: Calibrating Multimodal Benchmarks Towards Trustworthy and  Efficient Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 7.84, \"y\": 7.565}, {\"title\": \"Open-Source Conversational AI with SpeechBrain 1.0\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.889, \"y\": 5.921}, {\"title\": \"Polarization and Morality: Lexical Analysis of Abortion Discourse on  Reddit\", \"topic\": \"Bias in Language Models\", \"x\": 3.221, \"y\": 3.526}, {\"title\": \"Self-Translate-Train: A Simple but Strong Baseline for Cross-lingual  Transfer of Large Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.426, \"y\": 4.312}, {\"title\": \"PerSEval: Assessing Personalization in Text Summarizers\", \"topic\": \"Text Summarization\", \"x\": 5.136, \"y\": 5.184}, {\"title\": \"A Recipe of Parallel Corpora Exploitation for Multilingual Large  Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.23, \"y\": 4.407}, {\"title\": \"Brevity is the soul of wit: Pruning long files for code generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.207, \"y\": 0.027}, {\"title\": \"Too Late to Train, Too Early To Use? A Study on Necessity and Viability  of Low-Resource Bengali LLMs\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.82, \"y\": 4.235}, {\"title\": \"Advancing Process Verification for Large Language Models via Tree-Based  Preference Learning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.315, \"y\": 1.678}, {\"title\": \"GraphArena: Benchmarking Large Language Models on Graph Computational  Problems\", \"topic\": \"Named Entity Recognition\", \"x\": 6.662, \"y\": 5.723}, {\"title\": \"The Factuality Tax of Diversity-Intervened Text-to-Image Generation:  Benchmark and Fact-Augmented Intervention\", \"topic\": \"Bias in Language Models\", \"x\": 3.225, \"y\": 2.626}, {\"title\": \"How to Train Your Fact Verifier: Knowledge Transfer with Multimodal Open  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.667, \"y\": 3.833}, {\"title\": \"From RAG to RICHES: Retrieval Interlaced with Sequence Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.194, \"y\": 4.306}, {\"title\": \"LiteSearch: Efficacious Tree Search for LLM\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.341, \"y\": 1.57}, {\"title\": \"From Local Concepts to Universals: Evaluating the Multicultural  Understanding of Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.131, \"y\": 7.792}, {\"title\": \"DiffuseDef: Improved Robustness to Adversarial Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.04, \"y\": 1.163}, {\"title\": \"EHRmonize: A Framework for Medical Concept Abstraction from Electronic  Health Records using Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.221, \"y\": 7.29}, {\"title\": \"Web2Code: A Large-scale Webpage-to-Code Dataset and Evaluation Framework  for Multimodal LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.19, \"y\": 7.0}, {\"title\": \"Token Erasure as a Footprint of Implicit Vocabulary Items in LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.508, \"y\": 3.003}, {\"title\": \"Applying RLAIF for Code Generation with API-usage in Lightweight LLMs\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.997, \"y\": 0.38}, {\"title\": \"Covert Malicious Finetuning: Challenges in Safeguarding LLM Adaptation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.284, \"y\": 0.607}, {\"title\": \"Single Parent Family: A Spectrum of Family Members from a Single  Pre-Trained Foundation Model\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.182, \"y\": 2.316}, {\"title\": \"BESTOW: Efficient and Streamable Speech Language Model with the Best of  Two Worlds in GPT and T5\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.359, \"y\": 5.493}, {\"title\": \"From the Least to the Most: Building a Plug-and-Play Visual Reasoner via  Data Synthesis\", \"topic\": \"Multimodal Language Models\", \"x\": 7.766, \"y\": 7.641}, {\"title\": \"A Simple Attention-Based Mechanism for Bimodal Emotion Classification\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.54, \"y\": 5.311}, {\"title\": \"NLPerturbator: Studying the Robustness of Code LLMs to Natural Language  Variations\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.054, \"y\": 0.225}, {\"title\": \"Belief Revision: The Adaptability of Large Language Models Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.072, \"y\": 2.698}, {\"title\": \"Learning Interpretable Legal Case Retrieval via Knowledge-Guided Case  Reformulation\", \"topic\": \"Legal NLP\", \"x\": 4.417, \"y\": 4.576}, {\"title\": \"Breaking the Script Barrier in Multilingual Pre-Trained Language Models  with Transliteration-Based Post-Training Alignment\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.37, \"y\": 4.322}, {\"title\": \"MM-Instruct: Generated Visual Instructions for Large Multimodal Model  Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.116, \"y\": 7.497}, {\"title\": \"Uncertainty Quantification in Large Language Models Through Convex Hull  Analysis\", \"topic\": \"Large Language Models in Education\", \"x\": 6.614, \"y\": 3.1}, {\"title\": \"Less is More: Accurate Speech Recognition & Translation without  Web-Scale Data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.491, \"y\": 5.655}, {\"title\": \"IDT: Dual-Task Adversarial Attacks for Privacy Protection\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.453, \"y\": 0.539}, {\"title\": \"SK-VQA: Synthetic Knowledge Generation at Scale for Training  Context-Augmented Multimodal LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.911, \"y\": 7.257}, {\"title\": \"PathAlign: A vision-language model for whole slide images in  histopathology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.372, \"y\": 8.139}, {\"title\": \"Demarked: A Strategy for Enhanced Abusive Speech Moderation through  Counterspeech, Detoxification, and Message Management\", \"topic\": \"Bias in Language Models\", \"x\": 2.512, \"y\": 3.333}, {\"title\": \"TocBERT: Medical Document Structure Extraction Using Bidirectional  Transformers\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.413, \"y\": 7.345}, {\"title\": \"Captioning Visualizations with Large Language Models (CVLLM): A Tutorial\", \"topic\": \"Multimodal Language Models\", \"x\": 8.544, \"y\": 7.136}, {\"title\": \"Are Generative Language Models Multicultural? A Study on Hausa Culture  and Emotions using ChatGPT\", \"topic\": \"Bias in Language Models\", \"x\": 4.028, \"y\": 2.776}, {\"title\": \"Investigating How Large Language Models Leverage Internal Knowledge to  Perform Complex Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.582, \"y\": 2.436}, {\"title\": \"Knowledge acquisition for dialogue agents using reinforcement learning  on graph representations\", \"topic\": \"Named Entity Recognition\", \"x\": 6.678, \"y\": 5.393}, {\"title\": \"Inclusivity in Large Language Models: Personality Traits and Gender Bias  in Scientific Abstracts\", \"topic\": \"Bias in Language Models\", \"x\": 3.647, \"y\": 2.918}, {\"title\": \"xTower: A Multilingual LLM for Explaining and Correcting Translation  Errors\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.493, \"y\": 4.926}, {\"title\": \"Sparse Regression for Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.593, \"y\": 4.585}, {\"title\": \"Changing Answer Order Can Decrease MMLU Accuracy\", \"topic\": \"Large Language Models in Education\", \"x\": 6.829, \"y\": 2.986}, {\"title\": \"Can Large Language Models Generate High-quality Patent Claims?\", \"topic\": \"Legal NLP\", \"x\": 4.712, \"y\": 4.716}, {\"title\": \"Taming Data and Transformers for Audio Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.71, \"y\": 6.181}, {\"title\": \"The Remarkable Robustness of LLMs: Stages of Inference?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.519, \"y\": 2.91}, {\"title\": \"The Model Arena for Cross-lingual Sentiment Analysis: A Comparative  Study in the Era of Large Language Models\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.027, \"y\": 4.78}, {\"title\": \"IndoToxic2024: A Demographically-Enriched Dataset of Hate Speech and  Toxicity Types for Indonesian Language\", \"topic\": \"Bias in Language Models\", \"x\": 2.495, \"y\": 3.42}, {\"title\": \"Jump Starting Bandits with LLM-Generated Prior Knowledge\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.498, \"y\": 0.998}, {\"title\": \"LiveBench: A Challenging, Contamination-Free LLM Benchmark\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.566, \"y\": 1.326}, {\"title\": \"Efficient Long-distance Latent Relation-aware Graph Neural Network for  Multi-modal Emotion Recognition in Conversations\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.515, \"y\": 5.328}, {\"title\": \"HuatuoGPT-Vision, Towards Injecting Medical Visual Knowledge into  Multimodal LLMs at Scale\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.424, \"y\": 8.011}, {\"title\": \"ColPali: Efficient Document Retrieval with Vision Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.048, \"y\": 7.169}, {\"title\": \"Enhancing Video-Language Representations with Structural Spatio-Temporal  Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.708, \"y\": 7.401}, {\"title\": \"AutoRAG-HP: Automatic Online Hyper-Parameter Tuning for  Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.25, \"y\": 4.425}, {\"title\": \"FlowVQA: Mapping Multimodal Logic in Visual Question Answering with  Flowcharts\", \"topic\": \"Multimodal Language Models\", \"x\": 7.692, \"y\": 7.641}, {\"title\": \"Spiking Convolutional Neural Networks for Text Classification\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.016, \"y\": 2.883}, {\"title\": \"Tools Fail: Detecting Silent Errors in Faulty Tools\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.341, \"y\": 1.315}, {\"title\": \"SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented  Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.246, \"y\": 4.322}, {\"title\": \"Annotation Errors and NER: A Study with OntoNotes 5.0\", \"topic\": \"Named Entity Recognition\", \"x\": 6.083, \"y\": 6.845}, {\"title\": \"Fairness and Bias in Multimodal AI: A Survey\", \"topic\": \"Bias in Language Models\", \"x\": 3.287, \"y\": 2.709}, {\"title\": \"A Case Study on Contextual Machine Translation in a Professional  Scenario of Subtitling\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.594, \"y\": 5.058}, {\"title\": \"EmPO: Theory-Driven Dataset Construction for Empathetic Response  Generation through Preference Optimization\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.655, \"y\": 5.662}, {\"title\": \"UnUnlearning: Unlearning is not sufficient for content regulation in  advanced generative AI\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.911, \"y\": 0.577}, {\"title\": \"Applying LLMs for Rescoring N-best ASR Hypotheses of Casual  Conversations: Effects of Domain Adaptation and Context Carry-over\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.403, \"y\": 5.677}, {\"title\": \"Curriculum Learning with Quality-Driven Data Selection\", \"topic\": \"Multimodal Language Models\", \"x\": 8.188, \"y\": 7.233}, {\"title\": \"The single-use restriction for register automata and transducers over  infinite alphabets\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.74, \"y\": 3.189}, {\"title\": \"Enhanced ASR Robustness to Packet Loss with a Front-End Adaptation  Network\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.582, \"y\": 5.725}, {\"title\": \"Selective Vision is the Challenge for Visual Reasoning: A Benchmark for  Visual Argument Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 7.66, \"y\": 7.655}, {\"title\": \"Can we teach language models to gloss endangered languages?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.076, \"y\": 4.38}, {\"title\": \"SSP: Self-Supervised Prompting for Cross-Lingual Transfer to  Low-Resource Languages using Large Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.124, \"y\": 4.185}, {\"title\": \"Two-Pronged Human Evaluation of ChatGPT Self-Correction in Radiology  Report Simplification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.186, \"y\": 7.621}, {\"title\": \"On Discrete Prompt Optimization for Diffusion Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.521, \"y\": 6.754}, {\"title\": \"Learning Retrieval Augmentation for Personalized Dialogue Generation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.175, \"y\": 3.412}, {\"title\": \"OutlierTune: Efficient Channel-Wise Quantization for Large Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.577, \"y\": 2.252}, {\"title\": \"Psychological Profiling in Cybersecurity: A Look at LLMs and  Psycholinguistic Features\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.281, \"y\": 1.33}, {\"title\": \"Categorical Syllogisms Revisited: A Review of the Logical Reasoning  Abilities of LLMs for Analyzing Categorical Syllogism\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.492, \"y\": 2.203}, {\"title\": \"Re-Ranking Step by Step: Investigating Pre-Filtering for Re-Ranking with  Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.952, \"y\": 4.582}, {\"title\": \"WavRx: a Disease-Agnostic, Generalizable, and Privacy-Preserving Speech  Health Diagnostic Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.462, \"y\": 6.161}, {\"title\": \"Jailbreaking LLMs with Arabic Transliteration and Arabizi\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.055, \"y\": 0.508}, {\"title\": \"Learning to Correct for QA Reasoning with Black-box LLMs\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.374, \"y\": 1.963}, {\"title\": \"Speakers Unembedded: Embedding-free Approach to Long-form Neural  Diarization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.518, \"y\": 5.962}, {\"title\": \"Understand What LLM Needs: Dual Preference Alignment for  Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.192, \"y\": 4.37}, {\"title\": \"Evaluating Copyright Takedown Methods for Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.497, \"y\": 1.128}, {\"title\": \"Symbolic Learning Enables Self-Evolving Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.483, \"y\": 1.535}, {\"title\": \"ChronoMagic-Bench: A Benchmark for Metamorphic Evaluation of  Text-to-Time-lapse Video Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.624, \"y\": 6.91}, {\"title\": \"CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal  LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.527, \"y\": 7.404}, {\"title\": \"Step-DPO: Step-wise Preference Optimization for Long-chain Reasoning of  LLMs\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.512, \"y\": 1.497}, {\"title\": \"WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially)  Safer Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.259, \"y\": 0.727}, {\"title\": \"Mental Modeling of Reinforcement Learning Agents by Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.965, \"y\": 1.544}, {\"title\": \"Is In-Context Learning a Type of Gradient-Based Learning? Evidence from  the Inverse Frequency Effect in Structural Priming\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.388, \"y\": 2.937}, {\"title\": \"WildGuard: Open One-Stop Moderation Tools for Safety Risks, Jailbreaks,  and Refusals of LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.624, \"y\": 1.066}, {\"title\": \"Clustering in pure-attention hardmax transformers and its role in  sentiment analysis\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.42, \"y\": 2.818}, {\"title\": \"Role-Play Zero-Shot Prompting with Large Language Models for Open-Domain  Human-Machine Conversation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.292, \"y\": 3.115}, {\"title\": \"Do LLMs dream of elephants (when told not to)? Latent concept  association and associative memory in transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.778, \"y\": 2.73}, {\"title\": \"An LLM-based Knowledge Synthesis and Scientific Reasoning Framework for  Biomedical Discovery\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.899, \"y\": 6.813}, {\"title\": \"Dynamic Data Pruning for Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.534, \"y\": 5.574}, {\"title\": \"Themis: Towards Flexible and Interpretable NLG Evaluation\", \"topic\": \"Large Language Models in Education\", \"x\": 6.438, \"y\": 3.631}, {\"title\": \"Research on Information Extraction of LCSTS Dataset Based on an Improved  BERTSum-LSTM Model\", \"topic\": \"Text Summarization\", \"x\": 5.221, \"y\": 5.122}, {\"title\": \"MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large  Language Models Using Odyssey Math Data\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.673, \"y\": 1.262}, {\"title\": \"Advancing Airport Tower Command Recognition: Integrating  Squeeze-and-Excitation and Broadcasted Residual Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.392, \"y\": 5.586}, {\"title\": \"S3: A Simple Strong Sample-effective Multimodal Dialog System\", \"topic\": \"Multimodal Language Models\", \"x\": 8.12, \"y\": 7.146}, {\"title\": \"MSR-86K: An Evolving, Multilingual Corpus with 86,300 Hours of  Transcribed Audio for Speech Recognition Research\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.356, \"y\": 5.75}, {\"title\": \"FactFinders at CheckThat! 2024: Refining Check-worthy Statement  Detection with LLMs through Data Pruning\", \"topic\": \"Bias in Language Models\", \"x\": 3.833, \"y\": 3.86}, {\"title\": \"Hierarchical Context Pruning: Optimizing Real-World Code Completion with  Repository-Level Pretrained Code LLMs\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.081, \"y\": 0.09}, {\"title\": \"\\\"Vorbe\\u015fti Rom\\u00e2ne\\u015fte?\\\" A Recipe to Train Powerful Romanian LLMs  with English Instructions\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.94, \"y\": 4.034}, {\"title\": \"GUIDE: A Guideline-Guided Dataset for Instructional Video Comprehension\", \"topic\": \"Multimodal Language Models\", \"x\": 8.665, \"y\": 7.248}, {\"title\": \"Enhancing Data Privacy in Large Language Models through Private  Association Editing\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.737, \"y\": 0.319}, {\"title\": \"A Closer Look into Mixture-of-Experts in Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.844, \"y\": 2.218}, {\"title\": \"SEED: Accelerating Reasoning Tree Construction via Scheduled Speculative  Decoding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.462, \"y\": 3.176}, {\"title\": \"Selective Prompting Tuning for Personalized Conversations with LLMs\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.249, \"y\": 3.376}, {\"title\": \"UIO-LLMs: Unbiased Incremental Optimization for Long-Context LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.717, \"y\": 3.14}, {\"title\": \"NeBuLa: A discourse aware Minecraft Builder\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.871, \"y\": 1.756}, {\"title\": \"LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal  Long-Context Inference\", \"topic\": \"Multimodal Language Models\", \"x\": 8.25, \"y\": 7.384}, {\"title\": \"Automatic Speech Recognition for Hindi\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.242, \"y\": 5.86}, {\"title\": \"Assessing \\\"Implicit\\\" Retrieval Robustness of Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.295, \"y\": 4.205}, {\"title\": \"ConvoCache: Smart Re-Use of Chatbot Responses\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.312, \"y\": 3.09}, {\"title\": \"Poisoned LangChain: Jailbreak LLMs by LangChain\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.106, \"y\": 0.572}, {\"title\": \"ArzEn-LLM: Code-Switched Egyptian Arabic-English Translation and Speech  Recognition Using LLMs\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.959, \"y\": 5.438}, {\"title\": \"SafeAligner: Safety Alignment against Jailbreak Attacks via Response  Disparity Guidance\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.051, \"y\": 0.477}, {\"title\": \"Token-Weighted RNN-T for Learning from Flawed Data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.547, \"y\": 5.453}, {\"title\": \"Shimo Lab at \\\"Discharge Me!\\\": Discharge Summarization by Prompt-Driven  Concatenation of Electronic Health Record Sections\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.143, \"y\": 7.461}, {\"title\": \"LLM-Driven Multimodal Opinion Expression Identification\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.615, \"y\": 5.184}, {\"title\": \"EHR-Based Mobile and Web Platform for Chronic Disease Risk Prediction  Using Large Language Multimodal Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.95, \"y\": 7.348}, {\"title\": \"Multilingual Knowledge Graph Completion from Pretrained Language Models  with Knowledge Constraints\", \"topic\": \"Named Entity Recognition\", \"x\": 6.875, \"y\": 5.624}, {\"title\": \"Octo-planner: On-device Language Model for Planner-Action Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.303, \"y\": 1.465}, {\"title\": \"Large Language Models for Cuffless Blood Pressure Measurement From  Wearable Biosignals\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.025, \"y\": 7.332}, {\"title\": \"Evaluating Quality of Answers for Retrieval-Augmented Generation: A  Strong LLM Is All You Need\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.094, \"y\": 4.063}, {\"title\": \"AdaZeta: Adaptive Zeroth-Order Tensor-Train Adaption for  Memory-Efficient Large Language Models Fine-Tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.857, \"y\": 1.994}, {\"title\": \"Towards Large Language Model Aided Program Refinement\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.055, \"y\": 0.298}, {\"title\": \"Improving Entity Recognition Using Ensembles of Deep Learning and  Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction  from Multiple Sources\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.744, \"y\": 7.166}, {\"title\": \"PharmaGPT: Domain-Specific Large Language Models for Bio-Pharmaceutical  and Chemistry\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.976, \"y\": 6.889}, {\"title\": \"LLMs for Doctors: Leveraging Medical LLMs to Assist Doctors, Not Replace  Them\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.84, \"y\": 7.451}, {\"title\": \"Automated Clinical Data Extraction with Knowledge Conditioned LLMs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.26, \"y\": 7.559}, {\"title\": \"JailbreakZoo: Survey, Landscapes, and Horizons in Jailbreaking Large  Language and Vision-Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.035, \"y\": 0.49}, {\"title\": \"Catching Chameleons: Detecting Evolving Disinformation Generated using  Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.639, \"y\": 3.749}, {\"title\": \"Explicit Diversity Conditions for Effective Question Answer Generation  with Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.421, \"y\": 4.414}, {\"title\": \"Inherent Challenges of Post-Hoc Membership Inference for Large Language  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.869, \"y\": 0.817}, {\"title\": \"Evaluating Fairness in Large Vision-Language Models Across Diverse  Demographic Attributes and Prompts\", \"topic\": \"Bias in Language Models\", \"x\": 3.168, \"y\": 2.679}, {\"title\": \"Unmasking the Imposters: In-Domain Detection of Human vs.  Machine-Generated Tweets\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.922, \"y\": 1.727}, {\"title\": \"Do they mean 'us'? Interpreting Referring Expressions in Intergroup Bias\", \"topic\": \"Bias in Language Models\", \"x\": 3.264, \"y\": 2.873}, {\"title\": \"FASA: a Flexible and Automatic Speech Aligner for Extracting  High-quality Aligned Children Speech Data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.545, \"y\": 5.804}, {\"title\": \"X-ray Made Simple: Radiology Report Generation and Evaluation with  Layman's Terms\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.24, \"y\": 8.009}, {\"title\": \"Script-Agnostic Language Identification\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.034, \"y\": 4.364}, {\"title\": \"CTBench: A Comprehensive Benchmark for Evaluating Language Model  Capabilities in Clinical Trial Design\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.219, \"y\": 7.097}, {\"title\": \"ET tu, CLIP? Addressing Common Object Errors for Unseen Environments\", \"topic\": \"Multimodal Language Models\", \"x\": 8.418, \"y\": 7.48}, {\"title\": \"Cloaked Classifiers: Pseudonymization Strategies on Sensitive  Classification Tasks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.605, \"y\": 0.428}, {\"title\": \"Improving Arithmetic Reasoning Ability of Large Language Models through  Relation Tuples, Verification and Dynamic Feedback\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.684, \"y\": 1.285}, {\"title\": \"Accelerating Clinical Evidence Synthesis with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.467, \"y\": 6.852}, {\"title\": \"LLM Targeted Underperformance Disproportionately Impacts Vulnerable  Users\", \"topic\": \"Bias in Language Models\", \"x\": 4.07, \"y\": 2.275}, {\"title\": \"FedBiOT: LLM Local Fine-tuning in Federated Learning without Full Model\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.15, \"y\": 0.003}, {\"title\": \"From Distributional to Overton Pluralism: Investigating Large Language  Model Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.774, \"y\": 0.955}, {\"title\": \"This Paper Had the Smartest Reviewers -- Flattery Detection Utilising an  Audio-Textual Transformer-Based Approach\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.6, \"y\": 5.232}, {\"title\": \"LLM-ARC: Enhancing LLMs with an Automated Reasoning Critic\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.275, \"y\": 1.898}, {\"title\": \"Variationist: Exploring Multifaceted Variation and Bias in Written  Language Data\", \"topic\": \"Bias in Language Models\", \"x\": 3.58, \"y\": 2.819}, {\"title\": \"Mitigate the Gap: Investigating Approaches for Improving Cross-Modal  Alignment in CLIP\", \"topic\": \"Multimodal Language Models\", \"x\": 8.327, \"y\": 7.327}, {\"title\": \"CoSafe: Evaluating Large Language Model Safety in Multi-Turn Dialogue  Coreference\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.445, \"y\": 0.857}, {\"title\": \"Towards Building an End-to-End Multilingual Automatic Lyrics  Transcription Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.818, \"y\": 5.734}, {\"title\": \"FrenchToxicityPrompts: a Large Benchmark for Evaluating and Mitigating  Toxicity in French Texts\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.674, \"y\": 1.571}, {\"title\": \"Retrieval-Augmented Code Generation for Situated Action Generation: A  Case Study on Minecraft\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.026, \"y\": 1.686}, {\"title\": \"CDQuant: Accurate Post-training Weight Quantization of Large Pre-trained  Models using Greedy Coordinate Descent\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.493, \"y\": 2.266}, {\"title\": \"Disce aut Deficere: Evaluating LLMs Proficiency on the INVALSI Italian  Benchmark\", \"topic\": \"Large Language Models in Education\", \"x\": 7.037, \"y\": 2.915}, {\"title\": \"LumberChunker: Long-Form Narrative Document Segmentation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.429, \"y\": 4.78}, {\"title\": \"Entropy-Based Decoding for Retrieval-Augmented Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.497, \"y\": 4.301}, {\"title\": \"Automatic speech recognition for the Nepali language using CNN,  bidirectional LSTM and ResNet\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.335, \"y\": 5.775}, {\"title\": \"MedCare: Advancing Medical LLMs through Decoupling Clinical Alignment  and Knowledge Aggregation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.148, \"y\": 7.394}, {\"title\": \"Transformer-based Named Entity Recognition with Combined Data  Representation\", \"topic\": \"Named Entity Recognition\", \"x\": 6.209, \"y\": 6.806}, {\"title\": \"MoE-CT: A Novel Approach For Large Language Models Training With  Resistance To Catastrophic Forgetting\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.209, \"y\": 3.976}, {\"title\": \"Layer-Wise Quantization: A Pragmatic and Effective Method for Quantizing  LLMs Beyond Integer Bit-Levels\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.585, \"y\": 2.26}, {\"title\": \"Native Design Bias: Studying the Impact of English Nativeness on  Language Model Performance\", \"topic\": \"Bias in Language Models\", \"x\": 4.073, \"y\": 2.474}, {\"title\": \"A Three-Pronged Approach to Cross-Lingual Adaptation with Multilingual  LLMs\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.09, \"y\": 4.078}, {\"title\": \"An Empirical Study on the Characteristics of Bias upon Context Length  Variation for Bangla\", \"topic\": \"Bias in Language Models\", \"x\": 3.296, \"y\": 2.764}, {\"title\": \"Leveraging Synthetic Audio Data for End-to-End Low-Resource Speech  Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.13, \"y\": 5.667}, {\"title\": \"ARES: Alternating Reinforcement Learning and Supervised Fine-Tuning for  Enhanced Multi-Modal Chain-of-Thought Reasoning Through Diverse AI Feedback\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.41, \"y\": 1.886}, {\"title\": \"Delving into the Utilisation of ChatGPT in Scientific Publications in  Astronomy\", \"topic\": \"Text Summarization\", \"x\": 4.967, \"y\": 5.968}, {\"title\": \"Not All Preference Pairs Are Created Equal: A Recipe for  Annotation-Efficient Iterative Preference Learning\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.439, \"y\": 0.573}, {\"title\": \"Retrieval Augmented Instruction Tuning for Open NER with Large Language  Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.253, \"y\": 6.721}, {\"title\": \"Leveraging LLMs for Dialogue Quality Measurement\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.252, \"y\": 3.272}, {\"title\": \"CausalScore: An Automatic Reference-Free Metric for Assessing Response  Relevance in Open-Domain Dialogue Systems\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.307, \"y\": 3.366}, {\"title\": \"Math-LLaVA: Bootstrapping Mathematical Reasoning for Multimodal Large  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.673, \"y\": 7.636}, {\"title\": \"AG-LSEC: Audio Grounded Lexical Speaker Error Correction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.544, \"y\": 5.862}, {\"title\": \"D2LLM: Decomposed and Distilled Large Language Models for Semantic  Search\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.836, \"y\": 4.565}, {\"title\": \"TRAWL: Tensor Reduced and Approximated Weights for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.074, \"y\": 2.206}, {\"title\": \"Mitigating Hallucination in Fictional Character Role-Play\", \"topic\": \"Bias in Language Models\", \"x\": 5.16, \"y\": 2.708}, {\"title\": \"Leveraging Parameter-Efficient Transfer Learning for Multi-Lingual  Text-to-Speech Adaptation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.14, \"y\": 5.785}, {\"title\": \"MPCODER: Multi-user Personalized Code Generator with Explicit and  Implicit Style Representation Learning\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.2, \"y\": -0.006}, {\"title\": \"Self-Constructed Context Decompilation with Fined-grained Alignment  Enhancement\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.219, \"y\": 0.104}, {\"title\": \"Beyond Demographics: Aligning Role-playing LLM-based Agents Using Human  Belief Networks\", \"topic\": \"Bias in Language Models\", \"x\": 4.308, \"y\": 2.548}, {\"title\": \"Detecting Frames in News Headlines and Lead Images in U.S. Gun Violence  Coverage\", \"topic\": \"Bias in Language Models\", \"x\": 3.39, \"y\": 4.029}, {\"title\": \"CLERC: A Dataset for Legal Case Retrieval and Retrieval-Augmented  Analysis Generation\", \"topic\": \"Legal NLP\", \"x\": 4.462, \"y\": 4.646}, {\"title\": \"Multi-LogiEval: Towards Evaluating Multi-Step Logical Reasoning Ability  of Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.339, \"y\": 2.118}, {\"title\": \"DEXTER: A Benchmark for open-domain Complex Question Answering using  LLMs\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.715, \"y\": 4.555}, {\"title\": \"Testing network clustering algorithms with Natural Language Processing\", \"topic\": \"Bias in Language Models\", \"x\": 3.372, \"y\": 3.67}, {\"title\": \"Automated Adversarial Discovery for Safety Classifiers\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.274, \"y\": 1.225}, {\"title\": \"modeLing: A Novel Dataset for Testing Linguistic Reasoning in Language  Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.37, \"y\": 1.999}, {\"title\": \"Losing Visual Needles in Image Haystacks: Vision Language Models are  Easily Distracted in Short and Long Contexts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.066, \"y\": 7.629}, {\"title\": \"RaTEScore: A Metric for Radiology Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.198, \"y\": 7.927}, {\"title\": \"From Decoding to Meta-Generation: Inference-time Algorithms for Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.325, \"y\": 3.305}, {\"title\": \"USDC: A Dataset of $\\\\underline{U}$ser $\\\\underline{S}$tance and  $\\\\underline{D}$ogmatism in Long $\\\\underline{C}$onversations\", \"topic\": \"Bias in Language Models\", \"x\": 3.275, \"y\": 4.313}, {\"title\": \"Ragnar\\u00f6k: A Reusable RAG Framework and Baselines for TREC 2024  Retrieval-Augmented Generation Track\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.168, \"y\": 4.512}, {\"title\": \"PISTOL: Dataset Compilation Pipeline for Structural Unlearning of LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.142, \"y\": 0.575}, {\"title\": \"Beyond Thumbs Up/Down: Untangling Challenges of Fine-Grained Feedback  for Text-to-Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.473, \"y\": 6.821}, {\"title\": \"RES-Q: Evaluating Code-Editing Large Language Model Systems at the  Repository Scale\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.037, \"y\": 0.112}, {\"title\": \"Lottery Ticket Adaptation: Mitigating Destructive Interference in LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.247, \"y\": 2.037}, {\"title\": \"Finding Transformer Circuits with Edge Pruning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.188, \"y\": 2.639}, {\"title\": \"Blending LLMs into Cascaded Speech Translation: KIT's Offline Speech  Translation System for IWSLT 2024\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.148, \"y\": 5.468}, {\"title\": \"Towards Fast Multilingual LLM Inference: Speculative Decoding and  Specialized Drafters\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.491, \"y\": 3.262}, {\"title\": \"Towards Zero-Shot Text-To-Speech for Arabic Dialects\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.025, \"y\": 5.767}, {\"title\": \"OCALM: Object-Centric Assessment with Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.957, \"y\": 1.245}, {\"title\": \"Sparser is Faster and Less is More: Efficient Sparse Attention for  Long-Range Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.828, \"y\": 3.019}, {\"title\": \"Adversarial Contrastive Decoding: Boosting Safety Alignment of Large  Language Models via Opposite Prompt Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 4.885, \"y\": 1.003}, {\"title\": \"Venturing into Uncharted Waters: The Navigation Compass from Transformer  to Mamba\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.725, \"y\": 2.958}, {\"title\": \"Scaling Laws for Linear Complexity Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.783, \"y\": 2.761}, {\"title\": \"Large Language Models Are Cross-Lingual Knowledge-Free Reasoners\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.634, \"y\": 2.439}, {\"title\": \"ShadowLLM: Predictor-based Contextual Sparsity for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.01, \"y\": 2.576}, {\"title\": \"OmAgent: A Multi-modal Agent Framework for Complex Video Understanding  with Task Divide-and-Conquer\", \"topic\": \"Multimodal Language Models\", \"x\": 8.676, \"y\": 7.439}, {\"title\": \"Evaluation of Language Models in the Medical Context Under  Resource-Constrained Settings\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.259, \"y\": 7.376}, {\"title\": \"Data Augmentation of Multi-turn Psychological Dialogue via  Knowledge-driven Progressive Thought Prompting\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.243, \"y\": 3.365}, {\"title\": \"Are there identifiable structural parts in the sentence embedding whole?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.753, \"y\": 3.102}, {\"title\": \"EVALALIGN: Supervised Fine-Tuning Multimodal LLMs with Human-Aligned  Data for Evaluating Text-to-Image Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.459, \"y\": 6.977}, {\"title\": \"LLaMA-MoE: Building Mixture-of-Experts from LLaMA with Continual  Pre-training\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.84, \"y\": 2.369}, {\"title\": \"Evaluating the Ability of Large Language Models to Reason about Cardinal  Directions\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.395, \"y\": 2.372}, {\"title\": \"OTCE: Hybrid SSM and Attention with Cross Domain Mixture of Experts to  construct Observer-Thinker-Conceiver-Expresser\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.604, \"y\": 3.082}, {\"title\": \"eagerlearners at SemEval2024 Task 5: The Legal Argument Reasoning Task  in Civil Procedure\", \"topic\": \"Legal NLP\", \"x\": 4.449, \"y\": 4.575}, {\"title\": \"Deepfake tweets automatic detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.284, \"y\": 3.61}, {\"title\": \"DaLPSR: Leverage Degradation-Aligned Language Prompt for Real-World  Image Super-Resolution\", \"topic\": \"Multimodal Language Models\", \"x\": 8.458, \"y\": 7.318}, {\"title\": \"Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark  with Human-VLM Collaboration\", \"topic\": \"Multimodal Language Models\", \"x\": 8.057, \"y\": 7.841}, {\"title\": \"InterCLIP-MEP: Interactive CLIP and Memory-Enhanced Predictor for  Multi-modal Sarcasm Detection\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.534, \"y\": 4.907}, {\"title\": \"Building on Efficient Foundations: Effectively Training LLMs with  Structured Feedforward Layers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.95, \"y\": 2.725}, {\"title\": \"UniCoder: Scaling Code Large Language Model via Universal Code\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.079, \"y\": 0.28}, {\"title\": \"UNO Arena for Evaluating Sequential Decision-Making Capability of Large  Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.877, \"y\": 1.388}, {\"title\": \"KEHRL: Learning Knowledge-Enhanced Language Representations with  Hierarchical Reinforcement Learning\", \"topic\": \"Named Entity Recognition\", \"x\": 6.744, \"y\": 5.64}, {\"title\": \"ADVSCORE: A Metric for the Evaluation and Creation of Adversarial  Benchmarks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.121, \"y\": 1.06}, {\"title\": \"EHRCon: Dataset for Checking Consistency between Unstructured Notes and  Structured Tables in Electronic Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.207, \"y\": 7.419}, {\"title\": \"Pruning via Merging: Compressing LLMs via Manifold Alignment Based Layer  Merging\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.136, \"y\": 2.384}, {\"title\": \"What Do VLMs NOTICE? A Mechanistic Interpretability Pipeline for  Noise-free Text-Image Corruption and Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.102, \"y\": 7.786}, {\"title\": \"Modelled Multivariate Overlap: A method for measuring vowel merger\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.065, \"y\": 5.705}, {\"title\": \"Does Cross-Cultural Alignment Change the Commonsense Morality of  Language Models?\", \"topic\": \"Bias in Language Models\", \"x\": 4.147, \"y\": 2.29}, {\"title\": \"Song Data Cleansing for End-to-End Neural Singer Diarization Using  Neural Analysis and Synthesis Framework\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.804, \"y\": 5.855}, {\"title\": \"Training-Free Exponential Extension of Sliding Window Context with  Cascading KV Cache\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.315, \"y\": 2.936}, {\"title\": \"Compensate Quantization Errors: Make Weights Hierarchical to Compensate  Each Other\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.584, \"y\": 2.212}, {\"title\": \"LangSuitE: Planning, Controlling and Interacting with Large Language  Models in Embodied Text Environments\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.028, \"y\": 1.565}, {\"title\": \"Combining Supervised Learning and Reinforcement Learning for Multi-Label  Classification Tasks with Partial Labels\", \"topic\": \"Named Entity Recognition\", \"x\": 6.314, \"y\": 6.502}, {\"title\": \"PlagBench: Exploring the Duality of Large Language Models in Plagiarism  Generation and Detection\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.048, \"y\": 1.526}, {\"title\": \"Investigating the Influence of Prompt-Specific Shortcuts in AI Generated  Text Detection\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.044, \"y\": 1.182}, {\"title\": \"Confidence Regulation Neurons in Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.938, \"y\": 3.101}, {\"title\": \"Preference Tuning For Toxicity Mitigation Generalizes Across Languages\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.898, \"y\": 1.455}, {\"title\": \"Blind Baselines Beat Membership Inference Attacks for Foundation Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.67, \"y\": 0.716}, {\"title\": \"GraphEval2000: Benchmarking and Improving Large Language Models on Graph  Datasets\", \"topic\": \"Named Entity Recognition\", \"x\": 6.622, \"y\": 5.783}, {\"title\": \"FS-RAG: A Frame Semantics Based Approach for Improved Factual Accuracy  in Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.198, \"y\": 4.531}, {\"title\": \"Towards Region-aware Bias Evaluation Metrics\", \"topic\": \"Bias in Language Models\", \"x\": 3.253, \"y\": 2.781}, {\"title\": \"INDICT: Code Generation with Internal Dialogues of Critiques for Both  Security and Helpfulness\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.908, \"y\": 0.227}, {\"title\": \"Chain-of-Probe: Examing the Necessity and Accuracy of CoT Step-by-Step\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.065, \"y\": 2.293}, {\"title\": \"Crosslingual Capabilities and Knowledge Barriers in Multilingual Large  Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.197, \"y\": 4.273}, {\"title\": \"Contextualized End-to-end Automatic Speech Recognition with Intermediate  Biasing Loss\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.541, \"y\": 5.639}, {\"title\": \"Decoder-only Architecture for Streaming End-to-end Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.54, \"y\": 5.647}, {\"title\": \"Enhancing Commentary Strategies for Imperfect Information Card Games: A  Study of Large Language Models in Guandan Commentary\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.819, \"y\": 1.569}, {\"title\": \"First Heuristic Then Rational: Dynamic Use of Heuristics in Language  Model Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.227, \"y\": 1.983}, {\"title\": \"Dancing in the syntax forest: fast, accurate and explainable sentiment  analysis with SALSA\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.111, \"y\": 4.909}, {\"title\": \"FastMem: Fast Memorization of Prompt Improves Context Awareness of Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.78, \"y\": 3.346}, {\"title\": \"PORT: Preference Optimization on Reasoning Traces\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.108, \"y\": 2.114}, {\"title\": \"Unlocking the Future: Exploring Look-Ahead Planning Mechanistic  Interpretability in Large Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.36, \"y\": 1.565}, {\"title\": \"AudioBench: A Universal Benchmark for Audio Large Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.933, \"y\": 6.087}, {\"title\": \"Database-Augmented Query Representation for Information Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.119, \"y\": 4.669}, {\"title\": \"Can LLM Graph Reasoning Generalize beyond Pattern Memorization?\", \"topic\": \"Named Entity Recognition\", \"x\": 6.652, \"y\": 5.782}, {\"title\": \"Evaluating the Effectiveness of the Foundational Models for Q&A  Classification in Mental Health care\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.336, \"y\": 6.566}, {\"title\": \"Effectiveness of ChatGPT in explaining complex medical reports to  patients\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.815, \"y\": 7.347}, {\"title\": \"MOSSBench: Is Your Multimodal Language Model Oversensitive to Safe  Queries?\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.928, \"y\": 1.424}, {\"title\": \"Modular Pluralism: Pluralistic Alignment via Multi-LLM Collaboration\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.568, \"y\": 0.961}, {\"title\": \"Language Alignment via Nash-learning and Adaptive feedback\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.524, \"y\": 0.569}, {\"title\": \"Real-time Speech Summarization for Medical Conversations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.159, \"y\": 7.1}, {\"title\": \"SimSMoE: Solving Representational Collapse via Similarity Measure\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.866, \"y\": 2.43}, {\"title\": \"BigCodeBench: Benchmarking Code Generation with Diverse Function Calls  and Complex Instructions\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.087, \"y\": 0.139}, {\"title\": \"Uncovering Hidden Intentions: Exploring Prompt Recovery for Deeper  Insights into Generated Texts\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.828, \"y\": 1.622}, {\"title\": \"A multitask learning framework for leveraging subjectivity of annotators  to identify misogyny\", \"topic\": \"Bias in Language Models\", \"x\": 2.573, \"y\": 3.347}, {\"title\": \"Revisiting Interpolation Augmentation for Speech-to-Text Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.921, \"y\": 5.959}, {\"title\": \"LOGIC-LM++: Multi-Step Refinement for Symbolic Formulations\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.245, \"y\": 1.871}, {\"title\": \"CaT-BENCH: Benchmarking Language Model Understanding of Causal and  Temporal Dependencies in Plans\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.137, \"y\": 1.853}, {\"title\": \"A multi-speaker multi-lingual voice cloning system based on vits2 for  limmits 2024 challenge\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.11, \"y\": 5.877}, {\"title\": \"Intrinsic Dimension Correlation: uncovering nonlinear connections in  multimodal representations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.137, \"y\": 7.339}, {\"title\": \"LaMSUM: A Novel Framework for Extractive Summarization of User Generated  Content using LLMs\", \"topic\": \"Text Summarization\", \"x\": 5.042, \"y\": 5.024}, {\"title\": \"Rethinking Entity-level Unlearning for Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.953, \"y\": 0.532}, {\"title\": \"What Matters in Transformers? Not All Attention is Needed\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.934, \"y\": 2.684}, {\"title\": \"Unveiling and Harnessing Hidden Attention Sinks: Enhancing Large  Language Models without Training through Attention Calibration\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.639, \"y\": 2.928}, {\"title\": \"Multimodal Segmentation for Vocal Tract Modeling\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.07, \"y\": 6.229}, {\"title\": \"TacoLM: GaTed Attention Equipped Codec Language Model are Efficient  Zero-Shot Text to Speech Synthesizers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.983, \"y\": 5.941}, {\"title\": \"Ladder: A Model-Agnostic Framework Boosting LLM-based Machine  Translation to the Next Level\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.71, \"y\": 4.632}, {\"title\": \"Evaluating Large Vision-and-Language Models on Children's Mathematical  Olympiads\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.674, \"y\": 1.409}, {\"title\": \"RankAdaptor: Hierarchical Dynamic Low-Rank Adaptation for Structural  Pruned LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.998, \"y\": 1.954}, {\"title\": \"Acoustic Feature Mixup for Balanced Multi-aspect Pronunciation  Assessment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.472, \"y\": 5.97}, {\"title\": \"Beyond the Turn-Based Game: Enabling Real-Time Conversations with Duplex  Models\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.188, \"y\": 3.105}, {\"title\": \"MetaGreen: Meta-Learning Inspired Transformer Selection for Green  Semantic Communication\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.8, \"y\": 2.871}, {\"title\": \"PI-Whisper: An Adaptive and Incremental ASR Framework for Diverse and  Evolving Speaker Characteristics\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.529, \"y\": 5.845}, {\"title\": \"Shortcomings of LLMs for Low-Resource Translation: Retrieval and  Understanding are Both the Problem\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.399, \"y\": 4.471}, {\"title\": \"Logicbreaks: A Framework for Understanding Subversion of Rule-based  Inference\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.063, \"y\": 0.492}, {\"title\": \"Detecting AI-Generated Text: Factors Influencing Detectability with  Current Methods\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.762, \"y\": 1.665}, {\"title\": \"SAIL: Self-Improving Efficient Online Alignment of Large Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.584, \"y\": 0.598}, {\"title\": \"A SMART Mnemonic Sounds like \\\"Glue Tonic\\\": Mixing LLMs with Student  Feedback to Make Mnemonic Learning Stick\", \"topic\": \"Large Language Models in Education\", \"x\": 6.483, \"y\": 2.127}, {\"title\": \"Multimodal Task Vectors Enable Many-Shot Multimodal In-Context Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.248, \"y\": 7.415}, {\"title\": \"Gradient-Mask Tuning Elevates the Upper Limits of LLM Performance\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.553, \"y\": 2.284}, {\"title\": \"LongRAG: Enhancing Retrieval-Augmented Generation with Long-context LLMs\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.333, \"y\": 4.58}, {\"title\": \"STARD: A Chinese Statute Retrieval Dataset with Real Queries Issued by  Non-professionals\", \"topic\": \"Legal NLP\", \"x\": 4.438, \"y\": 4.61}, {\"title\": \"NLP-KG: A System for Exploratory Search of Scientific Literature in  Natural Language Processing\", \"topic\": \"Text Summarization\", \"x\": 5.092, \"y\": 5.975}, {\"title\": \"The Greek podcast corpus: Competitive speech models for low-resourced  languages with weakly supervised data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.394, \"y\": 5.731}, {\"title\": \"Cross-Modality Safety Alignment\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.196, \"y\": 1.582}, {\"title\": \"Cognitive Map for Language Models: Optimal Planning via Verbally  Representing the World Model\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.299, \"y\": 1.42}, {\"title\": \"Perception of Phonological Assimilation by Neural Speech Recognition  Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.268, \"y\": 5.645}, {\"title\": \"A LLM-Based Ranking Method for the Evaluation of Automatic  Counter-Narrative Generation\", \"topic\": \"Bias in Language Models\", \"x\": 3.767, \"y\": 3.725}, {\"title\": \"Unsupervised Extraction of Dialogue Policies from Conversations\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.174, \"y\": 3.177}, {\"title\": \"Reward Steering with Evolutionary Heuristics for Decoding-time Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.629, \"y\": 0.599}, {\"title\": \"Hybrid Alignment Training for Large Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.68, \"y\": 0.691}, {\"title\": \"Geneverse: A collection of Open-source Multimodal Large Language Models  for Genomic and Proteomic Research\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.997, \"y\": 6.914}, {\"title\": \"A Syntax-Injected Approach for Faster and More Accurate Sentiment  Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.068, \"y\": 4.894}, {\"title\": \"Investigating the impact of 2D gesture representation on co-speech  gesture generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.965, \"y\": 7.013}, {\"title\": \"Tri-VQA: Triangular Reasoning Medical Visual Question Answering for  Multi-Attribute Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.238, \"y\": 7.935}, {\"title\": \"Harnessing Knowledge Retrieval with Large Language Models for Clinical  Report Error Correction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.086, \"y\": 7.729}, {\"title\": \"GiusBERTo: A Legal Language Model for Personal Data De-identification in  Italian Court of Auditors Decisions\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.695, \"y\": 0.361}, {\"title\": \"MedOdyssey: A Medical Domain Benchmark for Long Context Evaluation Up to  200K Tokens\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.242, \"y\": 7.262}, {\"title\": \"GraLMatch: Matching Groups of Entities with Graphs and Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.433, \"y\": 6.224}, {\"title\": \"Disability Representations: Finding Biases in Automatic Image Generation\", \"topic\": \"Bias in Language Models\", \"x\": 3.214, \"y\": 2.591}, {\"title\": \"Pistis-RAG: A Scalable Cascading Framework Towards Content-Centric  Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.136, \"y\": 4.519}, {\"title\": \"Retrieve-Plan-Generation: An Iterative Planning and Answering Framework  for Knowledge-Intensive LLM Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.187, \"y\": 4.284}, {\"title\": \"A Tale of Trust and Accuracy: Base vs. Instruct LLMs in RAG Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.268, \"y\": 4.302}, {\"title\": \"Unlocking the Global Synergies in Low-Rank Adapters\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.821, \"y\": 1.835}, {\"title\": \"Towards Retrieval Augmented Generation over Large Video Libraries\", \"topic\": \"Multimodal Language Models\", \"x\": 8.632, \"y\": 7.374}, {\"title\": \"Data Efficient Evaluation of Large Language Models and Text-to-Image  Models via Adaptive Sampling\", \"topic\": \"Multimodal Language Models\", \"x\": 8.412, \"y\": 7.222}, {\"title\": \"Autonomous Agents for Collaborative Task under Information Asymmetry\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.05, \"y\": 1.621}, {\"title\": \"MoA: Mixture of Sparse Attention for Automatic Large Language Model  Compression\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.949, \"y\": 2.983}, {\"title\": \"Safely Learning with Private Data: A Federated Learning Framework for  Large Language Model\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.93, \"y\": 0.147}, {\"title\": \"Generate-then-Ground in Retrieval-Augmented Generation for Multi-hop  Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.507, \"y\": 4.413}, {\"title\": \"InterBiasing: Boost Unseen Word Recognition through Biasing Intermediate  Predictions\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.629, \"y\": 5.666}, {\"title\": \"InternLM-Law: An Open Source Chinese Legal Large Language Model\", \"topic\": \"Legal NLP\", \"x\": 4.427, \"y\": 4.53}, {\"title\": \"FlowBench: Revisiting and Benchmarking Workflow-Guided Planning for  LLM-based Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.185, \"y\": 1.488}, {\"title\": \"OATH-Frames: Characterizing Online Attitudes Towards Homelessness with  LLM Assistants\", \"topic\": \"Bias in Language Models\", \"x\": 3.29, \"y\": 4.321}, {\"title\": \"70B-parameter large language models in Japanese medical  question-answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.054, \"y\": 7.377}, {\"title\": \"Sports Intelligence: Assessing the Sports Understanding Capabilities of  Language Models through Question Answering from Text to Video\", \"topic\": \"Multimodal Language Models\", \"x\": 7.999, \"y\": 7.072}, {\"title\": \"Rethinking Pruning Large Language Models: Benefits and Pitfalls of  Reconstruction Error Minimization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.065, \"y\": 2.337}, {\"title\": \"Direct Multi-Turn Preference Optimization for Language Agents\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.625, \"y\": 0.688}, {\"title\": \"DistiLRR: Transferring Code Repair for Low-Resource Programming  Languages\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.11, \"y\": 0.167}, {\"title\": \"From LLMs to MLLMs: Exploring the Landscape of Multimodal Jailbreaking\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.076, \"y\": 0.667}, {\"title\": \"Efficient Continual Pre-training by Mitigating the Stability Gap\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 4.364, \"y\": 7.394}, {\"title\": \"Word Matters: What Influences Domain Adaptation in Summarization?\", \"topic\": \"Text Summarization\", \"x\": 5.276, \"y\": 5.124}, {\"title\": \"Steering Without Side Effects: Improving Post-Deployment Control of  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.173, \"y\": 0.697}, {\"title\": \"How Well Do LLMs Represent Values Across Cultures? Empirical Analysis of  LLM Responses Based on Hofstede Cultural Dimensions\", \"topic\": \"Bias in Language Models\", \"x\": 4.084, \"y\": 2.539}, {\"title\": \"Evaluating RAG-Fusion with RAGElo: an Automated Elo-based Framework\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.225, \"y\": 4.487}, {\"title\": \"Evaluating Numerical Reasoning in Text-to-Image Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.269, \"y\": 7.065}, {\"title\": \"RE-AdaptIR: Improving Information Retrieval through Reverse Engineered  Adaptation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.151, \"y\": 4.508}, {\"title\": \"An LLM Feature-based Framework for Dialogue Constructiveness Assessment\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.116, \"y\": 3.335}, {\"title\": \"System Description for the Displace Speaker Diarization Challenge 2023\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.421, \"y\": 5.906}, {\"title\": \"An Adapter-Based Unified Model for Multiple Spoken Language Processing  Tasks\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.454, \"y\": 5.664}, {\"title\": \"MultiAgent Collaboration Attack: Investigating Adversarial Attacks in  Large Language Model Collaborations via Debate\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.33, \"y\": 0.969}, {\"title\": \"Factual Dialogue Summarization via Learning from Large Language Models\", \"topic\": \"Text Summarization\", \"x\": 5.15, \"y\": 5.031}, {\"title\": \"Speech Prefix-Tuning with RNNT Loss for Improving LLM Predictions\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.56, \"y\": 5.658}, {\"title\": \"A Contrastive Learning Approach to Mitigate Bias in Speech Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.477, \"y\": 5.706}, {\"title\": \"Insights into LLM Long-Context Failures: When Transformers Know but  Don't Tell\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.908, \"y\": 2.868}, {\"title\": \"Exploring Design Choices for Building Language-Specific LLMs\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.123, \"y\": 3.848}, {\"title\": \"PKU-SafeRLHF: A Safety Alignment Preference Dataset for Llama Family  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.037, \"y\": 1.408}, {\"title\": \"Major Entity Identification: A Generalizable Alternative to Coreference  Resolution\", \"topic\": \"Named Entity Recognition\", \"x\": 6.072, \"y\": 6.26}, {\"title\": \"Holistic Evaluation for Interleaved Text-and-Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.538, \"y\": 6.799}, {\"title\": \"Can LLMs Learn by Teaching? A Preliminary Study\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.25, \"y\": 2.007}, {\"title\": \"Whiteboard-of-Thought: Thinking Step-by-Step Across Modalities\", \"topic\": \"Multimodal Language Models\", \"x\": 7.659, \"y\": 7.638}, {\"title\": \"xCOMET-lite: Bridging the Gap Between Efficiency and Quality in Learned  MT Evaluation Metrics\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.71, \"y\": 4.739}, {\"title\": \"Unmasking Database Vulnerabilities: Zero-Knowledge Schema Inference  Attacks in Text-to-SQL Systems\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.542, \"y\": 0.498}, {\"title\": \"Prism: A Framework for Decoupling and Assessing the Capabilities of VLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.949, \"y\": 7.623}, {\"title\": \"RL on Incorrect Synthetic Data Scales the Efficiency of LLM Math  Reasoning by Eight-Fold\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.512, \"y\": 1.418}, {\"title\": \"Investigating Mysteries of CoT-Augmented Distillation\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.479, \"y\": 1.911}, {\"title\": \"Translating Across Cultures: LLMs for Intralingual Cultural Adaptation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.473, \"y\": 4.744}, {\"title\": \"Improving Expert Radiology Report Summarization by Prompting Large  Language Models with a Layperson Summary\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.109, \"y\": 7.727}, {\"title\": \"CodeRAG-Bench: Can Retrieval Augment Code Generation?\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.09, \"y\": 0.097}, {\"title\": \"African or European Swallow? Benchmarking Large Vision-Language Models  for Fine-Grained Object Classification\", \"topic\": \"Multimodal Language Models\", \"x\": 8.131, \"y\": 7.722}, {\"title\": \"Does Object Grounding Really Reduce Hallucination of Large  Vision-Language Models?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.344, \"y\": 8.008}, {\"title\": \"On Layer-wise Representation Similarity: Application for Multi-Exit  Models with a Single Classifier\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.594, \"y\": 2.779}, {\"title\": \"A Review of Common Online Speaker Diarization Methods\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.479, \"y\": 5.972}, {\"title\": \"Explicit and Implicit Large Language Model Personas Generate Opinions  but Fail to Replicate Deeper Perceptions and Biases\", \"topic\": \"Bias in Language Models\", \"x\": 3.88, \"y\": 2.773}, {\"title\": \"Towards Truthful Multilingual Large Language Models: Benchmarking and  Alignment Strategies\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.627, \"y\": 4.152}, {\"title\": \"FVEL: Interactive Formal Verification Environment with Large Language  Models via Theorem Proving\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.437, \"y\": 1.04}, {\"title\": \"Jailbreaking as a Reward Misspecification Problem\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.155, \"y\": 0.617}, {\"title\": \"Validation of a new, minimally-invasive, software smartphone device to  predict sleep apnea and its severity: transversal study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.962, \"y\": 7.277}, {\"title\": \"medIKAL: Integrating Knowledge Graphs as Assistants of LLMs for Enhanced  Clinical Diagnosis on EMRs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.004, \"y\": 7.34}, {\"title\": \"Mind the Privacy Unit! User-Level Differential Privacy for Language  Model Fine-Tuning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.827, \"y\": 0.244}, {\"title\": \"The Fire Thief Is Also the Keeper: Balancing Usability and Privacy in  Prompts\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.628, \"y\": 0.391}, {\"title\": \"Identifying User Goals from UI Trajectories\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.079, \"y\": 1.779}, {\"title\": \"Infusing clinical knowledge into tokenisers for language models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.412, \"y\": 7.322}, {\"title\": \"QuST-LLM: Integrating Large Language Models for Comprehensive Spatial  Transcriptomics Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.781, \"y\": 6.996}, {\"title\": \"Learning to Plan for Retrieval-Augmented Large Language Models from  Knowledge Graphs\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.616, \"y\": 4.731}, {\"title\": \"Augmenting Query and Passage for Retrieval-Augmented Generation using  LLMs for Open-Domain Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.463, \"y\": 4.453}, {\"title\": \"On the Evaluation Practices in Multilingual NLP: Can Machine Translation  Offer an Alternative to Human Translations?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.437, \"y\": 4.722}, {\"title\": \"Complexity of Symbolic Representation in Working Memory of Transformer  Correlates with the Complexity of a Task\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.177, \"y\": 2.893}, {\"title\": \"On the Representational Capacity of Neural Language Models with  Chain-of-Thought Reasoning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.968, \"y\": 2.819}, {\"title\": \"Temporal Knowledge Graph Question Answering: A Survey\", \"topic\": \"Named Entity Recognition\", \"x\": 6.586, \"y\": 5.388}, {\"title\": \"SimulSeamless: FBK at IWSLT 2024 Simultaneous Speech Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.942, \"y\": 4.993}, {\"title\": \"A Data-Driven Guided Decoding Mechanism for Diagnostic Captioning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.235, \"y\": 8.008}, {\"title\": \"DIRAS: Efficient LLM-Assisted Annotation of Document Relevance in  Retrieval Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.108, \"y\": 4.528}, {\"title\": \"Watching the Watchers: A Comparative Fairness Audit of Cloud-based  Content Moderation Services\", \"topic\": \"Bias in Language Models\", \"x\": 2.677, \"y\": 3.121}, {\"title\": \"Finding Safety Neurons in Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.041, \"y\": 1.024}, {\"title\": \"Towards Event-oriented Long Video Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.798, \"y\": 7.381}, {\"title\": \"Take the essence and discard the dross: A Rethinking on Data Selection  for Fine-Tuning Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.293, \"y\": 2.234}, {\"title\": \"Seamless Language Expansion: Enhancing Multilingual Mastery in  Self-Supervised Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.38, \"y\": 5.659}, {\"title\": \"Protecting Privacy Through Approximating Optimal Parameters for Sequence  Unlearning in Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.793, \"y\": 0.356}, {\"title\": \"ReaLHF: Optimized RLHF Training for Large Language Models through  Parameter Reallocation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.673, \"y\": 2.222}, {\"title\": \"How Many Parameters Does it Take to Change a Light Bulb? Evaluating  Performance in Self-Play of Conversational Games as a Function of Model  Characteristics\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.782, \"y\": 1.737}, {\"title\": \"Prompt Injection Attacks in Defended Systems\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.227, \"y\": 0.59}, {\"title\": \"Toward Infinite-Long Prefix in Transformer\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.423, \"y\": 2.791}, {\"title\": \"Two Giraffes in a Dirt Field: Using Game Play to Investigate Situation  Modelling in Large Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.084, \"y\": 7.208}, {\"title\": \"Demystifying Forgetting in Language Model Fine-Tuning with Statistical  Analysis of Example Associations\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.957, \"y\": 2.086}, {\"title\": \"LLM Critics Help Catch Bugs in Mathematics: Towards a Better  Mathematical Verifier with Natural Language Feedback\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.612, \"y\": 1.251}, {\"title\": \"Evaluating Implicit Bias in Large Language Models by Attacking From a  Psychometric Perspective\", \"topic\": \"Bias in Language Models\", \"x\": 3.526, \"y\": 2.744}, {\"title\": \"Information Guided Regularization for Fine-tuning Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.339, \"y\": 2.272}, {\"title\": \"\\\"Global is Good, Local is Bad?\\\": Understanding Brand Bias in LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.699, \"y\": 2.734}, {\"title\": \"Exploring Changes in Nation Perception with Nationality-Assigned  Personas in LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.943, \"y\": 2.647}, {\"title\": \"MR-BEN: A Comprehensive Meta-Reasoning Benchmark for Large Language  Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.333, \"y\": 1.965}, {\"title\": \"AspirinSum: an Aspect-based utility-preserved de-identification  Summarization framework\", \"topic\": \"Text Summarization\", \"x\": 4.99, \"y\": 5.161}, {\"title\": \"AutoCAP: Towards Automatic Cross-lingual Alignment Planning for  Zero-shot Chain-of-Thought\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.416, \"y\": 2.311}, {\"title\": \"Reasoning Like a Doctor: Improving Medical Dialogue Systems via  Diagnostic Reasoning Process Alignment\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.773, \"y\": 7.395}, {\"title\": \"Large Language Models are Skeptics: False Negative Problem of  Input-conflicting Hallucination\", \"topic\": \"Large Language Models in Education\", \"x\": 6.053, \"y\": 3.114}, {\"title\": \"GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.254, \"y\": 2.739}, {\"title\": \"PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal  Documents\", \"topic\": \"Multimodal Language Models\", \"x\": 7.82, \"y\": 7.275}, {\"title\": \"LLM-A*: Large Language Model Enhanced Incremental Heuristic Search on  Path Planning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.33, \"y\": 1.359}, {\"title\": \"Generative AI for Enhancing Active Learning in Education: A Comparative  Study of GPT-3.5 and GPT-4 in Crafting Customized Test Questions\", \"topic\": \"Large Language Models in Education\", \"x\": 6.326, \"y\": 2.254}, {\"title\": \"The Use of Multimodal Large Language Models to Detect Objects from  Thermal Images: Transportation Applications\", \"topic\": \"Multimodal Language Models\", \"x\": 8.158, \"y\": 7.49}, {\"title\": \"Open Generative Large Language Models for Galician\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.141, \"y\": 4.06}, {\"title\": \"ClinicalLab: Aligning Agents for Multi-Departmental Clinical Diagnostics  in the Real World\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.864, \"y\": 7.358}, {\"title\": \"Knowledge Graph-Enhanced Large Language Models via Path Selection\", \"topic\": \"Named Entity Recognition\", \"x\": 6.673, \"y\": 5.668}, {\"title\": \"Distributional reasoning in LLMs: Parallel reasoning processes in  multi-hop reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.569, \"y\": 2.383}, {\"title\": \"Joint vs Sequential Speaker-Role Detection and Automatic Speech  Recognition for Air-traffic Control\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.559, \"y\": 5.833}, {\"title\": \"StackRAG Agent: Improving Developer Answers with Retrieval-Augmented  Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.093, \"y\": 4.326}, {\"title\": \"Fine-Tuning BERTs for Definition Extraction from Mathematical Text\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.71, \"y\": 1.234}, {\"title\": \"Framing Social Movements on Social Media: Unpacking Diagnostic,  Prognostic, and Motivational Strategies\", \"topic\": \"Bias in Language Models\", \"x\": 3.338, \"y\": 3.973}, {\"title\": \"AlanaVLM: A Multimodal Embodied AI Foundation Model for Egocentric Video  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.448, \"y\": 7.294}, {\"title\": \"IoT-Based Preventive Mental Health Using Knowledge Graphs and Standards  for Better Well-Being\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.165, \"y\": 6.528}, {\"title\": \"A Primal-Dual Framework for Transformers and Neural Networks\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.628, \"y\": 2.83}, {\"title\": \"FoRAG: Factuality-optimized Retrieval Augmented Generation for  Web-enhanced Long-form Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.108, \"y\": 4.294}, {\"title\": \"Elliptical Attention\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.684, \"y\": 2.894}, {\"title\": \"Can LLMs Reason in the Wild with Programs?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.345, \"y\": 1.742}, {\"title\": \"Unveiling the Hidden Structure of Self-Attention via Kernel Principal  Component Analysis\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.625, \"y\": 2.829}, {\"title\": \"Every Language Counts: Learn and Unlearn in Multilingual LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.872, \"y\": 0.937}, {\"title\": \"GenAI-Bench: Evaluating and Improving Compositional Text-to-Visual  Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.412, \"y\": 6.918}, {\"title\": \"On the Utility of Domain-Adjacent Fine-Tuned Model Ensembles for  Few-shot Problems\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.317, \"y\": 2.171}, {\"title\": \"Evaluating Large Language Models along Dimensions of Language Variation:  A Systematik Invesdigatiom uv Cross-lingual Generalization\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.136, \"y\": 4.11}, {\"title\": \"Benchmarking Open-Source Language Models for Efficient Question  Answering in Industrial Applications\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.706, \"y\": 4.199}, {\"title\": \"Combinatorial Reasoning: Selecting Reasons in Generative AI Pipelines  via Combinatorial Optimization\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.25, \"y\": 1.896}, {\"title\": \"Dr.E Bridges Graphs with Large Language Models through Words\", \"topic\": \"Named Entity Recognition\", \"x\": 6.6, \"y\": 5.867}, {\"title\": \"Synchronous Faithfulness Monitoring for Trustworthy Retrieval-Augmented  Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.111, \"y\": 4.025}, {\"title\": \"Leveraging Large Language Models to Measure Gender Bias in Gendered  Languages\", \"topic\": \"Bias in Language Models\", \"x\": 3.193, \"y\": 2.709}, {\"title\": \"ObscurePrompt: Jailbreaking Large Language Models via Obscure Input\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.31, \"y\": 0.66}, {\"title\": \"InstructRAG: Instructing Retrieval-Augmented Generation with Explicit  Denoising\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.26, \"y\": 4.274}, {\"title\": \"Improving Visual Commonsense in Language Models via Multiple Image  Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.016, \"y\": 7.57}, {\"title\": \"In-Context Former: Lightning-fast Compressing Context for Large Language  Model\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.657, \"y\": 3.134}, {\"title\": \"Optimizing Psychological Counseling with Instruction-Tuned Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.004, \"y\": 6.401}, {\"title\": \"Evaluating Short-Term Temporal Fluctuations of Social Biases in Social  Media Data and Masked Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.161, \"y\": 2.866}, {\"title\": \"Mining United Nations General Assembly Debates\", \"topic\": \"Bias in Language Models\", \"x\": 3.614, \"y\": 4.242}, {\"title\": \"Mitigating Social Biases in Language Models through Unlearning\", \"topic\": \"Bias in Language Models\", \"x\": 3.351, \"y\": 2.481}, {\"title\": \"ManWav: The First Manchu ASR Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.53, \"y\": 5.705}, {\"title\": \"LLMs Are Zero-Shot Context-Aware Simultaneous Translators\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.729, \"y\": 4.62}, {\"title\": \"Encoder vs Decoder: Comparative Analysis of Encoder and Decoder Language  Models on Multilingual NLU Tasks\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.115, \"y\": 4.241}, {\"title\": \"VDebugger: Harnessing Execution Feedback for Debugging Visual Programs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.729, \"y\": 7.671}, {\"title\": \"Children's Speech Recognition through Discrete Token Enhancement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.533, \"y\": 5.793}, {\"title\": \"Factual Confidence of LLMs: on Reliability and Robustness of Current  Estimators\", \"topic\": \"Large Language Models in Education\", \"x\": 6.37, \"y\": 3.107}, {\"title\": \"CoAct: A Global-Local Hierarchy for Autonomous Agent Collaboration\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.209, \"y\": 1.498}, {\"title\": \"Evaluating Structural Generalization in Neural Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.445, \"y\": 4.142}, {\"title\": \"VisualRWKV: Exploring Recurrent Neural Networks for Visual Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.271, \"y\": 7.461}, {\"title\": \"Improving Zero-Shot Cross-Lingual Transfer via Progressive  Code-Switching\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.291, \"y\": 4.416}, {\"title\": \"Textual Unlearning Gives a False Sense of Unlearning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.787, \"y\": 0.49}, {\"title\": \"SD-Eval: A Benchmark Dataset for Spoken Dialogue Understanding Beyond  Words\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.303, \"y\": 3.345}, {\"title\": \"How effective is Multi-source pivoting for Translation of Low Resource  Indian Languages?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.52, \"y\": 4.733}, {\"title\": \"Improving Zero-shot LLM Re-Ranker with Risk Minimization\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.087, \"y\": 4.536}, {\"title\": \"In-Context Learning on a Budget: A Case Study in Named Entity  Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 6.303, \"y\": 6.745}, {\"title\": \"Enhancing Automated Audio Captioning via Large Language Models with  Optimized Audio Encoding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.789, \"y\": 6.13}, {\"title\": \"Investigating Low-Cost LLM Annotation for~Spoken Dialogue Understanding  Datasets\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.248, \"y\": 3.22}, {\"title\": \"R^2AG: Incorporating Retrieval Information into Retrieval Augmented  Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.257, \"y\": 4.365}, {\"title\": \"GSR-BENCH: A Benchmark for Grounded Spatial Reasoning Evaluation via  Multimodal LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.866, \"y\": 7.443}, {\"title\": \"Towards Robust Evaluation: A Comprehensive Taxonomy of Datasets and  Metrics for Open Domain Question Answering in the Era of Large Language  Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.657, \"y\": 4.464}, {\"title\": \"Enhancing Language Model Factuality via Activation-Based Confidence  Calibration and Guided Decoding\", \"topic\": \"Large Language Models in Education\", \"x\": 6.319, \"y\": 3.166}, {\"title\": \"Probing the Emergence of Cross-lingual Alignment during LLM Training\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.269, \"y\": 4.035}, {\"title\": \"MC-MKE: A Fine-Grained Multimodal Knowledge Editing Benchmark  Emphasizing Modality Consistency\", \"topic\": \"Multimodal Language Models\", \"x\": 7.948, \"y\": 7.24}, {\"title\": \"Bridging Law and Data: Augmenting Reasoning via a Semi-Structured  Dataset with IRAC methodology\", \"topic\": \"Legal NLP\", \"x\": 4.379, \"y\": 4.506}, {\"title\": \"Multi-Meta-RAG: Improving RAG for Multi-Hop Queries using Database  Filtering with LLM-Extracted Metadata\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.273, \"y\": 4.558}, {\"title\": \"Learning Translations via Matrix Completion\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.345, \"y\": 4.469}, {\"title\": \"Synthetic Context Generation for Question Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.363, \"y\": 4.064}, {\"title\": \"Learnable In-Context Vector for Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 7.925, \"y\": 7.574}, {\"title\": \"Biomedical Visual Instruction Tuning with Clinician Preference Alignment\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.264, \"y\": 8.034}, {\"title\": \"Amphista: Accelerate LLM Inference with Bi-directional Multiple Drafting  Heads in a Non-autoregressive Style\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.457, \"y\": 3.142}, {\"title\": \"QRMeM: Unleash the Length Limitation through Question then Reflection  Memory Mechanism\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.657, \"y\": 4.631}, {\"title\": \"Analyzing Diversity in Healthcare LLM Research: A Scientometric  Perspective\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.881, \"y\": 6.984}, {\"title\": \"DialSim: A Real-Time Simulator for Evaluating Long-Term Dialogue  Understanding of Conversational Agents\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.14, \"y\": 3.016}, {\"title\": \"PathoLM: Identifying pathogenicity from the DNA sequence through the  Genome Foundation Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.925, \"y\": 7.0}, {\"title\": \"Accelerating Complex Disease Treatment through Network Medicine and  GenAI: A Case Study on Drug Repurposing for Breast Cancer\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.642, \"y\": 7.0}, {\"title\": \"Exploring and Benchmarking the Planning Capabilities of Large Language  Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.368, \"y\": 1.417}, {\"title\": \"Multilingual Synopses of Movie Narratives: A Dataset for Story  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.77, \"y\": 7.301}, {\"title\": \"Think-then-Act: A Dual-Angle Evaluated Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.323, \"y\": 4.282}, {\"title\": \"D2O: Dynamic Discriminative Operations for Efficient Generative  Inference of Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.201, \"y\": 2.97}, {\"title\": \"Detecting Errors through Ensembling Prompts (DEEP): An End-to-End LLM  Framework for Detecting Factual Errors\", \"topic\": \"Text Summarization\", \"x\": 5.225, \"y\": 4.925}, {\"title\": \"Articulatory Encodec: Vocal Tract Kinematics as a Codec for Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.1, \"y\": 6.062}, {\"title\": \"SHIELD: Evaluation and Defense Strategies for Copyright Compliance in  LLM Text Generation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.001, \"y\": 1.05}, {\"title\": \"Interpretable Preferences via Multi-Objective Reward Modeling and  Mixture-of-Experts\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.472, \"y\": 0.772}, {\"title\": \"LaMDA: Large Model Fine-Tuning via Spectrally Decomposed Low-Dimensional  Adaptation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.871, \"y\": 1.882}, {\"title\": \"What Are the Odds? Language Models Are Capable of Probabilistic  Reasoning\", \"topic\": \"Large Language Models in Education\", \"x\": 6.771, \"y\": 2.788}, {\"title\": \"From RAGs to rich parameters: Probing how language models utilize  external knowledge over parametric information for factual queries\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.342, \"y\": 4.271}, {\"title\": \"Is It Good Data for Multilingual Instruction Tuning or Just Bad  Multilingual Evaluation for Large Language Models?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.078, \"y\": 3.959}, {\"title\": \"Adversarial Attacks on Multimodal Agents\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.105, \"y\": 1.053}, {\"title\": \"Generating Educational Materials with Different Levels of Readability  using LLMs\", \"topic\": \"Large Language Models in Education\", \"x\": 6.489, \"y\": 3.549}, {\"title\": \"UBENCH: Benchmarking Uncertainty in Large Language Models with Multiple  Choice Questions\", \"topic\": \"Large Language Models in Education\", \"x\": 6.84, \"y\": 2.853}, {\"title\": \"Composited-Nested-Learning with Data Augmentation for Nested Named  Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 6.24, \"y\": 6.738}, {\"title\": \"OlympicArena: Benchmarking Multi-discipline Cognitive Reasoning for  Superintelligent AI\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.069, \"y\": 2.02}, {\"title\": \"Rationale-based Ensemble of Multiple QA Strategies for Zero-shot  Knowledge-based VQA\", \"topic\": \"Multimodal Language Models\", \"x\": 7.7, \"y\": 7.656}, {\"title\": \"Benchmarking Multi-Image Understanding in Vision and Language Models:  Perception, Knowledge, Reasoning, and Multi-Hop Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.829, \"y\": 7.594}, {\"title\": \"Self-Distillation for Model Stacking Unlocks Cross-Lingual NLU in 200+  Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.499, \"y\": 4.363}, {\"title\": \"Large Language Model as a Universal Clinical Multi-task Decoder\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.168, \"y\": 7.435}, {\"title\": \"AGLA: Mitigating Object Hallucinations in Large Vision-Language Models  with Assembly of Global and Local Attention\", \"topic\": \"Multimodal Language Models\", \"x\": 8.351, \"y\": 8.029}, {\"title\": \"[WIP] Jailbreak Paradox: The Achilles' Heel of LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.01, \"y\": 0.42}, {\"title\": \"Using LLMs to Aid Annotation and Collection of Clinically-Enriched Data  in Bipolar Disorder and Schizophrenia\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.441, \"y\": 6.637}, {\"title\": \"Vernacular? I Barely Know Her: Challenges with Style Control and  Stereotyping\", \"topic\": \"Bias in Language Models\", \"x\": 3.578, \"y\": 2.693}, {\"title\": \"Transforming Surgical Interventions with Embodied Intelligence for  Ultrasound Robotics\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.896, \"y\": 7.506}, {\"title\": \"DetectBench: Can Large Language Model Detect and Piece Together Implicit  Evidence?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.276, \"y\": 2.132}, {\"title\": \"Ask-before-Plan: Proactive Language Agents for Real-World Planning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.174, \"y\": 1.548}, {\"title\": \"Saliency Attention and Semantic Similarity-Driven Adversarial  Perturbation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.014, \"y\": 1.181}, {\"title\": \"SeTAR: Out-of-Distribution Detection with Selective Low-Rank  Approximation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.923, \"y\": 2.185}, {\"title\": \"Judging the Judges: Evaluating Alignment and Vulnerabilities in  LLMs-as-Judges\", \"topic\": \"Large Language Models in Education\", \"x\": 6.539, \"y\": 2.926}, {\"title\": \"What Makes Two Language Models Think Alike?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.618, \"y\": 3.052}, {\"title\": \"EUvsDisinfo: a Dataset for Multilingual Detection of Pro-Kremlin  Disinformation in News Articles\", \"topic\": \"Bias in Language Models\", \"x\": 3.46, \"y\": 3.798}, {\"title\": \"Rapid Language Adaptation for Multilingual E2E Speech Recognition Using  Encoder Prompting\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.485, \"y\": 5.62}, {\"title\": \"Low-Redundant Optimization for Large Language Model Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.701, \"y\": 0.63}, {\"title\": \"PromptDSI: Prompt-based Rehearsal-free Instance-wise Incremental  Learning for Document Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.423, \"y\": 4.725}, {\"title\": \"Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large  Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.653, \"y\": 1.262}, {\"title\": \"Causal Discovery Inspired Unsupervised Domain Adaptation for  Emotion-Cause Pair Extraction\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.515, \"y\": 5.304}, {\"title\": \"Applying Ensemble Methods to Model-Agnostic Machine-Generated Text  Detection\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.713, \"y\": 1.719}, {\"title\": \"RichRAG: Crafting Rich Responses for Multi-faceted Queries in  Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.166, \"y\": 4.498}, {\"title\": \"Low-Resource Machine Translation through the Lens of Personalized  Federated Learning\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.456, \"y\": 4.413}, {\"title\": \"Liar, Liar, Logical Mire: A Benchmark for Suppositional Reasoning in  Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.324, \"y\": 1.996}, {\"title\": \"Unified Active Retrieval for Retrieval Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.147, \"y\": 4.306}, {\"title\": \"Code-Optimise: Self-Generated Preference Data for Correctness and  Efficiency\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.107, \"y\": 0.108}, {\"title\": \"LightPAL: Lightweight Passage Retrieval for Open Domain Multi-Document  Summarization\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.353, \"y\": 4.681}, {\"title\": \"Fighting Randomness with Randomness: Mitigating Optimisation Instability  of Fine-Tuning using Delayed Ensemble and Noisy Interpolation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.252, \"y\": 2.299}, {\"title\": \"Abstraction-of-Thought Makes Language Models Better Reasoners\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.399, \"y\": 1.896}, {\"title\": \"PlanRAG: A Plan-then-Retrieval Augmented Generation for Generative Large  Language Models as Decision Makers\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.195, \"y\": 1.671}, {\"title\": \"PSLM: Parallel Generation of Text and Speech with LLMs for Low-Latency  Spoken Dialogue Systems\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.085, \"y\": 3.348}, {\"title\": \"AI-Assisted Human Evaluation of Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.508, \"y\": 4.954}, {\"title\": \"Beyond Under-Alignment: Atomic Preference Enhanced Factuality Tuning for  Large Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.557, \"y\": 0.645}, {\"title\": \"PDSS: A Privacy-Preserving Framework for Step-by-Step Distillation of  Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.848, \"y\": 0.238}, {\"title\": \"Flee the Flaw: Annotating the Underlying Logic of Fallacious Arguments  Through Templates and Slot-filling\", \"topic\": \"Bias in Language Models\", \"x\": 4.036, \"y\": 3.826}, {\"title\": \"QueerBench: Quantifying Discrimination in Language Models Toward Queer  Identities\", \"topic\": \"Bias in Language Models\", \"x\": 2.991, \"y\": 3.013}, {\"title\": \"Instruction Data Generation and Unsupervised Adaptation for Speech  Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.652, \"y\": 6.088}, {\"title\": \"EMO-KNOW: A Large Scale Dataset on Emotion and Emotion-cause\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.805, \"y\": 5.487}, {\"title\": \"Performant ASR Models for Medical Entities in Accented Speech\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.638, \"y\": 7.495}, {\"title\": \"IPEval: A Bilingual Intellectual Property Agency Consultation Evaluation  Benchmark for Large Language Models\", \"topic\": \"Legal NLP\", \"x\": 4.63, \"y\": 4.681}, {\"title\": \"WebCanvas: Benchmarking Web Agents in Online Environments\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.999, \"y\": 1.71}, {\"title\": \"Does Context Help Mitigate Gender Bias in Neural Machine Translation?\", \"topic\": \"Bias in Language Models\", \"x\": 3.19, \"y\": 2.691}, {\"title\": \"Cross-Lingual Unlearning of Selective Knowledge in Multilingual Language  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.878, \"y\": 0.532}, {\"title\": \"Interpreting Bias in Large Language Models: A Feature-Based Approach\", \"topic\": \"Bias in Language Models\", \"x\": 3.397, \"y\": 2.785}, {\"title\": \"Attention Score is not All You Need for Token Importance Indicator in KV  Cache Reduction: Value Also Matters\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.315, \"y\": 2.884}, {\"title\": \"SNAP: Unlearning Selective Knowledge in Large Language Models with  Negative Instructions\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.046, \"y\": 0.677}, {\"title\": \"Automatic benchmarking of large multimodal models via iterative  experiment programming\", \"topic\": \"Multimodal Language Models\", \"x\": 7.911, \"y\": 7.31}, {\"title\": \"PRePair: Pointwise Reasoning Enhance Pairwise Evaluating for Robust  Instruction-Following Assessments\", \"topic\": \"Large Language Models in Education\", \"x\": 6.354, \"y\": 3.152}, {\"title\": \"Finding Task-specific Subnetworks in Multi-task Spoken Language  Understanding Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.343, \"y\": 5.33}, {\"title\": \"COT: A Generative Approach for Hate Speech Counter-Narratives via  Contrastive Optimal Transport\", \"topic\": \"Bias in Language Models\", \"x\": 2.49, \"y\": 3.431}, {\"title\": \"Fast and Slow Generating: An Empirical Study on Large and Small Language  Models Collaborative Decoding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.391, \"y\": 3.288}, {\"title\": \"CodeNav: Beyond tool-use to using real-world codebases with LLM agents\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.817, \"y\": 0.5}, {\"title\": \"SafeInfer: Context Adaptive Decoding Time Safety Alignment for Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.913, \"y\": 1.239}, {\"title\": \"Defending Against Social Engineering Attacks in the Age of LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.283, \"y\": 1.347}, {\"title\": \"A Hopfieldian View-based Interpretation for Chain-of-Thought Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.455, \"y\": 2.066}, {\"title\": \"TroL: Traversal of Layers for Large Language and Vision Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.257, \"y\": 7.61}, {\"title\": \"PFID: Privacy First Inference Delegation Framework for LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.727, \"y\": 0.25}, {\"title\": \"\\\"You Gotta be a Doctor, Lin\\\": An Investigation of Name-Based Bias of  Large Language Models in Employment Recommendations\", \"topic\": \"Bias in Language Models\", \"x\": 3.261, \"y\": 2.783}, {\"title\": \"MCSD: An Efficient Language Model with Diverse Fusion\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.879, \"y\": 2.97}, {\"title\": \"ToxiCloakCN: Evaluating Robustness of Offensive Language Detection in  Chinese with Cloaking Perturbations\", \"topic\": \"Bias in Language Models\", \"x\": 2.475, \"y\": 3.31}, {\"title\": \"On-Policy Fine-grained Knowledge Feedback for Hallucination Mitigation\", \"topic\": \"Large Language Models in Education\", \"x\": 6.108, \"y\": 3.361}, {\"title\": \"Interface Design for Self-Supervised Speech Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.53, \"y\": 5.887}, {\"title\": \"Knowledge Fusion By Evolving Weights of Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.203, \"y\": 2.046}, {\"title\": \"Aqulia-Med LLM: Pioneering Full-Process Open-Source Medical Language  Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.975, \"y\": 7.441}, {\"title\": \"BPO: Supercharging Online Preference Learning by Adhering to the  Proximity of Behavior LLM\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.508, \"y\": 0.58}, {\"title\": \"Statistical Uncertainty in Word Embeddings: GloVe-V\", \"topic\": \"Bias in Language Models\", \"x\": 3.367, \"y\": 2.827}, {\"title\": \"Exploring the Impact of a Transformer's Latent Space Geometry on  Downstream Task Performance\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.101, \"y\": 2.889}, {\"title\": \"Improving Text-To-Audio Models with Synthetic Captions\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.717, \"y\": 6.209}, {\"title\": \"Bias in Text Embedding Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.255, \"y\": 2.795}, {\"title\": \"Decoding the Narratives: Analyzing Personal Drug Experiences Shared on  Reddit\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.47, \"y\": 6.466}, {\"title\": \"Who's asking? User personas and the mechanics of latent misalignment\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.831, \"y\": 1.222}, {\"title\": \"Is poisoning a real threat to LLM alignment? Maybe more so than you  think\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.583, \"y\": 0.762}, {\"title\": \"COMMUNITY-CROSS-INSTRUCT: Unsupervised Instruction Generation for  Aligning Large Language Models to Online Communities\", \"topic\": \"Bias in Language Models\", \"x\": 3.659, \"y\": 3.538}, {\"title\": \"Language Models are Surprisingly Fragile to Drug Names in Biomedical  Benchmarks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.277, \"y\": 7.088}, {\"title\": \"Not Eliminate but Aggregate: Post-Hoc Control over Mixture-of-Experts to  Address Shortcut Shifts in Natural Language Understanding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.266, \"y\": 2.232}, {\"title\": \"WellDunn: On the Robustness and Explainability of Language Models and  Large Language Models in Identifying Wellness Dimensions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.218, \"y\": 6.475}, {\"title\": \"UniGLM: Training One Unified Language Model for Text-Attributed Graphs\", \"topic\": \"Named Entity Recognition\", \"x\": 6.545, \"y\": 5.882}, {\"title\": \"Learn Beyond The Answer: Training Language Models with Reflection for  Mathematical Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.459, \"y\": 1.762}, {\"title\": \"$\\u03c4$-bench: A Benchmark for Tool-Agent-User Interaction in Real-World  Domains\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.993, \"y\": 1.706}, {\"title\": \"Soft Prompting for Unlearning in Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.09, \"y\": 0.547}, {\"title\": \"MedCalc-Bench: Evaluating Large Language Models for Medical Calculations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.902, \"y\": 7.298}, {\"title\": \"Self-MoE: Towards Compositional Large Language Models with  Self-Specialized Experts\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.241, \"y\": 1.999}, {\"title\": \"Unveiling and Mitigating Bias in Mental Health Analysis with Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.337, \"y\": 6.548}, {\"title\": \"SPA-VL: A Comprehensive Safety Preference Alignment Dataset for Vision  Language Model\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.927, \"y\": 1.473}, {\"title\": \"LiLiuM: eBay's Large Language Models for e-commerce\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.727, \"y\": 3.977}, {\"title\": \"CItruS: Chunked Instruction-aware State Eviction for Long Sequence  Modeling\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.891, \"y\": 3.064}, {\"title\": \"Dialogue Action Tokens: Steering Language Models in Goal-Directed  Dialogue with a Multi-Turn Planner\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.766, \"y\": 1.646}, {\"title\": \"mDPO: Conditional Preference Optimization for Multimodal Large Language  Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.615, \"y\": 0.568}, {\"title\": \"Language Modeling with Editable External Knowledge\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.528, \"y\": 3.932}, {\"title\": \"WPO: Enhancing RLHF with Weighted Preference Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.564, \"y\": 0.578}, {\"title\": \"On Efficient Language and Vision Assistants for Visually-Situated  Natural Language Understanding: What Matters in Reading and Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.933, \"y\": 7.541}, {\"title\": \"Iterative Length-Regularized Direct Preference Optimization: A Case  Study on Improving 7B Language Models to GPT-4 Level\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.534, \"y\": 0.509}, {\"title\": \"RepLiQA: A Question-Answering Dataset for Benchmarking LLMs on Unseen  Reference Content\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.624, \"y\": 4.388}, {\"title\": \"Transcoders Find Interpretable LLM Feature Circuits\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.129, \"y\": 2.646}, {\"title\": \"Safety Arithmetic: A Framework for Test-time Safety Alignment of  Language Models by Steering Parameters and Activations\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.031, \"y\": 1.221}, {\"title\": \"Split, Unlearn, Merge: Leveraging Data Attributes for More Effective  Unlearning in LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.08, \"y\": 0.649}, {\"title\": \"STAR: SocioTechnical Approach to Red Teaming Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.896, \"y\": 1.339}, {\"title\": \"A Semantic-based Layer Freezing Approach to Efficient Fine-Tuning of  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.476, \"y\": 2.15}, {\"title\": \"1000 African Voices: Advancing inclusive multi-speaker multi-accent  speech synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.022, \"y\": 5.977}, {\"title\": \"Refusal in Language Models Is Mediated by a Single Direction\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.393, \"y\": 0.876}, {\"title\": \"Measuring memorization in RLHF for code completion\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.916, \"y\": 0.536}, {\"title\": \"Prompts as Auto-Optimized Training Hyperparameters: Training  Best-in-Class IR Models from Scratch with 10 Gold Labels\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.066, \"y\": 4.668}, {\"title\": \"Meta Reasoning for Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.166, \"y\": 1.968}, {\"title\": \"Knowledge-to-Jailbreak: One Knowledge Point Worth One Attack\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.119, \"y\": 0.521}, {\"title\": \"R-Eval: A Unified Toolkit for Evaluating Domain Knowledge of Retrieval  Augmented Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.144, \"y\": 4.441}, {\"title\": \"TourRank: Utilizing Large Language Models for Documents Ranking with a  Tournament-Inspired Strategy\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.836, \"y\": 4.549}, {\"title\": \"BLoB: Bayesian Low-Rank Adaptation by Backpropagation for Large Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.747, \"y\": 1.853}, {\"title\": \"Endor: Hardware-Friendly Sparse Format for Offloaded LLM Inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.511, \"y\": 2.69}, {\"title\": \"\\\"Not Aligned\\\" is Not \\\"Malicious\\\": Being Careful about Hallucinations of  Large Language Models' Jailbreak\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.138, \"y\": 0.568}, {\"title\": \"See It from My Perspective: Diagnosing the Western Cultural Bias of  Large Vision-Language Models in Image Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.124, \"y\": 7.811}, {\"title\": \"Cultural Conditioning or Placebo? On the Effectiveness of  Socio-Demographic Prompting\", \"topic\": \"Bias in Language Models\", \"x\": 3.801, \"y\": 2.626}, {\"title\": \"Ruby Teaming: Improving Quality Diversity Search with Memory for  Automated Red Teaming\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.366, \"y\": 0.69}, {\"title\": \"A Two-dimensional Zero-shot Dialogue State Tracking Evaluation Method  using GPT-4\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.22, \"y\": 3.383}, {\"title\": \"Compress then Serve: Serving Thousands of LoRA Adapters with Little  Overhead\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.25, \"y\": 2.274}, {\"title\": \"The Base-Rate Effect on LLM Benchmark Performance: Disambiguating  Test-Taking Strategies from Benchmark Performance\", \"topic\": \"Large Language Models in Education\", \"x\": 6.978, \"y\": 2.957}, {\"title\": \"Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding  for Neural Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.752, \"y\": 4.704}, {\"title\": \"Can Many-Shot In-Context Learning Help Long-Context LLM Judges? See  More, Judge Better!\", \"topic\": \"Large Language Models in Education\", \"x\": 6.66, \"y\": 2.802}, {\"title\": \"Words in Motion: Representation Engineering for Motion Forecasting\", \"topic\": \"Multimodal Language Models\", \"x\": 8.01, \"y\": 6.616}, {\"title\": \"Building Knowledge-Guided Lexica to Model Cultural Variation\", \"topic\": \"Bias in Language Models\", \"x\": 4.016, \"y\": 2.768}, {\"title\": \"DELLA-Merging: Reducing Interference in Model Merging through  Magnitude-Based Sampling\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.375, \"y\": 2.108}, {\"title\": \"Intrinsic Evaluation of Unlearning Using Parametric Knowledge Traces\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.923, \"y\": 0.658}, {\"title\": \"Understanding \\\"Democratization\\\" in NLP and ML Research\", \"topic\": \"Bias in Language Models\", \"x\": 3.846, \"y\": 2.878}, {\"title\": \"Error Span Annotation: A Balanced Approach for Human Evaluation of  Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.588, \"y\": 4.92}, {\"title\": \"Mathematical Entities: Corpora and Benchmarks\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.716, \"y\": 1.2}, {\"title\": \"Extrinsic Evaluation of Cultural Competence in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.07, \"y\": 2.695}, {\"title\": \"Input Conditioned Graph Generation for Language Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.434, \"y\": 1.649}, {\"title\": \"GigaSpeech 2: An Evolving, Large-Scale and Multi-domain ASR Corpus for  Low-Resource Languages with Automated Crawling, Transcription and Refinement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.549, \"y\": 5.739}, {\"title\": \"A Critical Study of What Code-LLMs (Do Not) Learn\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.174, \"y\": 0.01}, {\"title\": \"GeoGPT4V: Towards Geometric Multi-modal Large Language Models with  Geometric Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 7.617, \"y\": 7.573}, {\"title\": \"Analysing zero-shot temporal relation extraction on clinical notes using  temporal consistency\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.337, \"y\": 7.252}, {\"title\": \"Vocabulary Expansion for Low-resource Cross-lingual Transfer\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.186, \"y\": 4.004}, {\"title\": \"How Far Can In-Context Alignment Go? Exploring the State of In-Context  Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.861, \"y\": 0.793}, {\"title\": \"TRACE the Evidence: Constructing Knowledge-Grounded Reasoning Chains for  Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.505, \"y\": 4.677}, {\"title\": \"Adaptive Reinforcement Learning Planning: Harnessing Large Language  Models for Complex Information Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.283, \"y\": 6.401}, {\"title\": \"Super(ficial)-alignment: Strong Models May Deceive Weak Models in  Weak-to-Strong Generalization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.026, \"y\": 1.031}, {\"title\": \"A Simple and Effective $L_2$ Norm-Based Strategy for KV Cache  Compression\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.235, \"y\": 2.875}, {\"title\": \"Fusion Makes Perfection: An Efficient Multi-Grained Matching Approach  for Zero-Shot Relation Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.426, \"y\": 6.494}, {\"title\": \"DiTTo-TTS: Efficient and Scalable Zero-Shot Text-to-Speech with  Diffusion Transformer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.025, \"y\": 5.972}, {\"title\": \"Evaluating the Efficacy of Open-Source LLMs in Enterprise-Specific RAG  Systems: A Comparative Study of Performance and Scalability\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.177, \"y\": 4.418}, {\"title\": \"Dredge Word, Social Media, and Webgraph Networks for Unreliable Website  Classification and Identification\", \"topic\": \"Bias in Language Models\", \"x\": 3.427, \"y\": 3.701}, {\"title\": \"SampleAttention: Near-Lossless Acceleration of Long Context LLM  Inference with Adaptive Structured Sparse Attention\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.086, \"y\": 3.031}, {\"title\": \"HARE: HumAn pRiors, a key to small language model Efficiency\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.995, \"y\": 3.15}, {\"title\": \"CodeGemma: Open Code Models Based on Gemma\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.143, \"y\": 0.058}, {\"title\": \"Multimodal Structured Generation: CVPR's 2nd MMFM Challenge Technical  Report\", \"topic\": \"Multimodal Language Models\", \"x\": 7.636, \"y\": 7.098}, {\"title\": \"MetaGPT: Merging Large Language Models Using Model Exclusive Task  Arithmetic\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.256, \"y\": 2.032}, {\"title\": \"Boosting Scientific Concepts Understanding: Can Analogy from Teacher  Models Empower Student Models?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.429, \"y\": 2.54}, {\"title\": \"Fairer Preferences Elicit Improved Human-Aligned Large Language Model  Judgments\", \"topic\": \"Large Language Models in Education\", \"x\": 6.258, \"y\": 3.105}, {\"title\": \"A Complete Survey on LLM-based AI Chatbots\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.334, \"y\": 2.761}, {\"title\": \"Refiner: Restructure Retrieval Content Efficiently to Advance  Question-Answering Capabilities\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.386, \"y\": 4.537}, {\"title\": \"Self-Train Before You Transcribe\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.609, \"y\": 5.747}, {\"title\": \"Preserving Knowledge in Large Language Model with Model-Agnostic  Self-Decompression\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.098, \"y\": 2.067}, {\"title\": \"$\\\\texttt{MoE-RBench}$: Towards Building Reliable Language Models with  Sparse Mixture-of-Experts\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.824, \"y\": 2.22}, {\"title\": \"JobFair: A Framework for Benchmarking Gender Hiring Bias in Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.192, \"y\": 2.884}, {\"title\": \"A Systematic Analysis of Large Language Models as Soft Reasoners: The  Case of Syllogistic Inferences\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.461, \"y\": 2.163}, {\"title\": \"Are Large Language Models True Healthcare Jacks-of-All-Trades?  Benchmarking Across Health Professions Beyond Physician Exams\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.91, \"y\": 7.383}, {\"title\": \"DocCGen: Document-based Controlled Code Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.137, \"y\": 0.091}, {\"title\": \"An Empirical Investigation of Matrix Factorization Methods for  Pre-trained Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.094, \"y\": 2.424}, {\"title\": \"VideoVista: A Versatile Benchmark for Video Understanding and Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.635, \"y\": 7.489}, {\"title\": \"Iterative Utility Judgment Framework via LLMs Inspired by Relevance in  Philosophy\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.276, \"y\": 4.471}, {\"title\": \"A Systematic Survey of Text Summarization: From Statistical Methods to  Large Language Models\", \"topic\": \"Text Summarization\", \"x\": 5.166, \"y\": 5.167}, {\"title\": \"MFC-Bench: Benchmarking Multimodal Fact-Checking with Large  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.797, \"y\": 7.621}, {\"title\": \"Self and Cross-Model Distillation for LLMs: Effective Methods for  Refusal Pattern Alignment\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.797, \"y\": 1.055}, {\"title\": \"Do Not Design, Learn: A Trainable Scoring Function for Uncertainty  Estimation in Generative LLMs\", \"topic\": \"Large Language Models in Education\", \"x\": 6.601, \"y\": 3.081}, {\"title\": \"Skip-Layer Attention: Bridging Abstract and Detailed Dependencies in  Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.67, \"y\": 2.896}, {\"title\": \"Mitigating Large Language Model Hallucination with Faithful Finetuning\", \"topic\": \"Large Language Models in Education\", \"x\": 6.161, \"y\": 3.317}, {\"title\": \"Enhancing Biomedical Knowledge Retrieval-Augmented Generation with  Self-Rewarding Tree Search and Proximal Policy Optimization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.225, \"y\": 6.98}, {\"title\": \"Duplicate Detection with GenAI\", \"topic\": \"Named Entity Recognition\", \"x\": 6.352, \"y\": 6.25}, {\"title\": \"Can Machines Resonate with Humans? Evaluating the Emotional and Empathic  Comprehension of LMs\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.695, \"y\": 5.727}, {\"title\": \"CSRT: Evaluation and Analysis of LLMs using Code-Switching Red-Teaming  Dataset\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.397, \"y\": 0.813}, {\"title\": \"Evading AI-Generated Content Detectors using Homoglyphs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.576, \"y\": 1.278}, {\"title\": \"Enabling robots to follow abstract instructions and complete complex  dynamic tasks\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.192, \"y\": 1.311}, {\"title\": \"Multimodal Needle in a Haystack: Benchmarking Long-Context Capability of  Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.184, \"y\": 7.388}, {\"title\": \"ComperDial: Commonsense Persona-grounded Dialogue Dataset and Benchmark\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.224, \"y\": 3.427}, {\"title\": \"WeatherQA: Can Multimodal Language Models Reason about Severe Weather?\", \"topic\": \"Multimodal Language Models\", \"x\": 7.838, \"y\": 7.548}, {\"title\": \"Fine-Tuning or Fine-Failing? Debunking Performance Myths in Large  Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.411, \"y\": 4.343}, {\"title\": \"MMNeuron: Discovering Neuron-Level Domain-Specific Interpretation in  Multimodal Large Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.107, \"y\": 7.538}, {\"title\": \"Beyond Boundaries: Learning a Universal Entity Taxonomy across Datasets  and Languages for Open Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 6.188, \"y\": 6.815}, {\"title\": \"A Survey on Human Preference Learning for Large Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.365, \"y\": 0.795}, {\"title\": \"Aligning Large Language Models from Self-Reference AI Feedback with one  General Principle\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.37, \"y\": 1.103}, {\"title\": \"TIFG: Text-Informed Feature Generation with Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.223, \"y\": 4.407}, {\"title\": \"Watch Every Step! LLM Agent Learning via Iterative Step-Level Process  Refinement\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.085, \"y\": 1.322}, {\"title\": \"BSRBF-KAN: A combination of B-splines and Radial Basic Functions in  Kolmogorov-Arnold Networks\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.797, \"y\": 2.407}, {\"title\": \"Enhancing Criminal Case Matching through Diverse Legal Factors\", \"topic\": \"Legal NLP\", \"x\": 4.401, \"y\": 4.555}, {\"title\": \"SUGARCREPE++ Dataset: Vision-Language Model Sensitivity to Semantic and  Lexical Alterations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.37, \"y\": 7.556}, {\"title\": \"On Giant's Shoulders: Effortless Weak to Strong by Dynamic Logits Fusion\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.401, \"y\": 2.052}, {\"title\": \"How Good are LLMs at Relation Extraction under Low-Resource Scenario?  Comprehensive Evaluation\", \"topic\": \"Named Entity Recognition\", \"x\": 6.286, \"y\": 6.544}, {\"title\": \"Twin-Merging: Dynamic Integration of Modular Expertise in Model Merging\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.361, \"y\": 2.04}, {\"title\": \"GoldCoin: Grounding Large Language Models in Privacy Laws via Contextual  Integrity Theory\", \"topic\": \"Legal NLP\", \"x\": 3.894, \"y\": 2.093}, {\"title\": \"RePrompt: Planning by Automatic Prompt Engineering for Large Language  Models Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.248, \"y\": 1.683}, {\"title\": \"Investigating Annotator Bias in Large Language Models for Hate Speech  Detection\", \"topic\": \"Bias in Language Models\", \"x\": 2.543, \"y\": 3.338}, {\"title\": \"Exploring Safety-Utility Trade-Offs in Personalized Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.008, \"y\": 1.386}, {\"title\": \"Grading Massive Open Online Courses Using Large Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.387, \"y\": 2.505}, {\"title\": \"InstructCMP: Length Control in Sentence Compression through  Instruction-based Large Language Models\", \"topic\": \"Text Summarization\", \"x\": 5.35, \"y\": 5.051}, {\"title\": \"The Potential and Challenges of Evaluating Attitudes, Opinions, and  Values in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.23, \"y\": 2.492}, {\"title\": \"RAEmoLLM: Retrieval Augmented LLMs for Cross-Domain Misinformation  Detection Using In-Context Learning based on Emotional Information\", \"topic\": \"Bias in Language Models\", \"x\": 3.438, \"y\": 3.782}, {\"title\": \"MemDPT: Differential Privacy for Memory Efficient Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.865, \"y\": 0.145}, {\"title\": \"Multiple Sources are Better Than One: Incorporating External Knowledge  in Low-Resource Glossing\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.174, \"y\": 4.421}, {\"title\": \"WildVision: Evaluating Vision-Language Models in the Wild with Human  Preferences\", \"topic\": \"Multimodal Language Models\", \"x\": 8.228, \"y\": 7.894}, {\"title\": \"Can LLMs Understand the Implication of Emphasized Sentences in Dialogue?\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.448, \"y\": 3.425}, {\"title\": \"A Peek into Token Bias: Large Language Models Are Not Yet Genuine  Reasoners\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.339, \"y\": 2.24}, {\"title\": \"Evaluating the Performance of Large Language Models via Debates\", \"topic\": \"Large Language Models in Education\", \"x\": 6.498, \"y\": 2.887}, {\"title\": \"garak: A Framework for Security Probing Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.38, \"y\": 0.777}, {\"title\": \"Scaling Synthetic Logical Reasoning Datasets with Context-Sensitive  Declarative Grammars\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.405, \"y\": 1.789}, {\"title\": \"FoodieQA: A Multimodal Dataset for Fine-Grained Understanding of Chinese  Food Culture\", \"topic\": \"Multimodal Language Models\", \"x\": 7.962, \"y\": 7.68}, {\"title\": \"Universal Cross-Lingual Text Classification\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.962, \"y\": 4.35}, {\"title\": \"Large Language Models for Dysfluency Detection in Stuttered Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.442, \"y\": 5.941}, {\"title\": \"RUPBench: Benchmarking Reasoning Under Perturbations for Robustness  Evaluation in Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.322, \"y\": 2.435}, {\"title\": \"Optimized Speculative Sampling for GPU Hardware Accelerators\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.514, \"y\": 2.855}, {\"title\": \"Connecting the Dots: Evaluating Abstract Reasoning Capabilities of LLMs  Using the New York Times Connections Word Game\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.177, \"y\": 2.066}, {\"title\": \"Data Shapley in One Training Run\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.889, \"y\": 0.678}, {\"title\": \"CoSTA: Code-Switched Speech Translation using Aligned Speech-Text  Interleaving\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.229, \"y\": 5.526}, {\"title\": \"Adaptive Query Rewriting: Aligning Rewriters through Marginal  Probability of Conversational Answers\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.055, \"y\": 4.381}, {\"title\": \"WundtGPT: Shaping Large Language Models To Be An Empathetic, Proactive  Psychologist\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.002, \"y\": 6.425}, {\"title\": \"Taking a Deep Breath: Enhancing Language Modeling of Large Language  Models with Sentinel Tokens\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.467, \"y\": 3.224}, {\"title\": \"Toward Optimal LLM Alignments Using Two-Player Games\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.244, \"y\": 0.832}, {\"title\": \"Promoting Data and Model Privacy in Federated Learning through Quantized  LoRA\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.932, \"y\": 0.12}, {\"title\": \"Towards Supporting Legal Argumentation with NLP: Is More Data Really All  You Need?\", \"topic\": \"Legal NLP\", \"x\": 4.367, \"y\": 4.455}, {\"title\": \"DocNet: Semantic Structure in Inductive Bias Detection Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.284, \"y\": 3.726}, {\"title\": \"ESCoT: Towards Interpretable Emotional Support Dialogue Systems\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.656, \"y\": 5.726}, {\"title\": \"City-LEO: Toward Transparent City Management Using LLM with End-to-End  Optimization\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.311, \"y\": 1.63}, {\"title\": \"Eliminating Biased Length Reliance of Direct Preference Optimization via  Down-Sampled KL Divergence\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.414, \"y\": 0.56}, {\"title\": \"Avoiding Copyright Infringement via Machine Unlearning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.849, \"y\": 0.724}, {\"title\": \"Understanding Understanding: A Pragmatic Framework Motivated by Large  Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.058, \"y\": 2.405}, {\"title\": \"Investigating Video Reasoning Capability of Large Language Models with  Tropes in Movies\", \"topic\": \"Multimodal Language Models\", \"x\": 8.592, \"y\": 7.535}, {\"title\": \"Embodied Question Answering via Multi-LLM Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.613, \"y\": 4.572}, {\"title\": \"Breaking the Attention Bottleneck\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.717, \"y\": 2.931}, {\"title\": \"New Solutions on LLM Acceleration, Optimization, and Application\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.446, \"y\": 2.697}, {\"title\": \"Light Up the Shadows: Enhance Long-Tailed Entity Grounding with  Concept-Guided Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.566, \"y\": 7.1}, {\"title\": \"AUTOHALLUSION: Automatic Generation of Hallucination Benchmarks for  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.333, \"y\": 8.067}, {\"title\": \"Automatic Speech Recognition for Biomedical Data in Bengali Language\", \"topic\": \"Speech Recognition and Translation\", \"x\": 4.635, \"y\": 7.436}, {\"title\": \"RWKU: Benchmarking Real-World Knowledge Unlearning for Large Language  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.922, \"y\": 0.557}, {\"title\": \"Distilling Opinions at Scale: Incremental Opinion Summarization using  XL-OPSUMM\", \"topic\": \"Text Summarization\", \"x\": 5.013, \"y\": 5.034}, {\"title\": \"On the Role of Entity and Event Level Conceptualization in Generalizable  Reasoning: A Survey of Tasks, Methods, Applications, and Future Directions\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.355, \"y\": 2.29}, {\"title\": \"Teaching Large Language Models to Express Knowledge Boundary from Their  Own Signals\", \"topic\": \"Large Language Models in Education\", \"x\": 6.332, \"y\": 3.242}, {\"title\": \"Exploring the Potential of Multimodal LLM with Knowledge-Intensive  Multimodal ASR\", \"topic\": \"Multimodal Language Models\", \"x\": 9.079, \"y\": 6.88}, {\"title\": \"Optimizing Automatic Speech Assessment: W-RankSim Regularization and  Hybrid Feature Fusion Strategies\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.575, \"y\": 5.982}, {\"title\": \"COOL: Comprehensive Knowledge Enhanced Prompt Learning for Domain  Adaptive Few-shot Fake News Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.45, \"y\": 3.76}, {\"title\": \"Step-level Value Preference Optimization for Mathematical Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.352, \"y\": 1.559}, {\"title\": \"TorchOpera: A Compound AI System for LLM Safety\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.054, \"y\": 1.292}, {\"title\": \"Large Language Models for Automatic Milestone Detection in Group  Discussions\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.188, \"y\": 3.235}, {\"title\": \"Reminding Multimodal Large Language Models of Object-aware Knowledge  with Retrieved Tags\", \"topic\": \"Multimodal Language Models\", \"x\": 8.128, \"y\": 7.453}, {\"title\": \"Exposing the Achilles' Heel: Evaluating LLMs Ability to Handle Mistakes  in Mathematical Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.664, \"y\": 1.263}, {\"title\": \"Citation-Based Summarization of Landmark Judgments\", \"topic\": \"Legal NLP\", \"x\": 4.479, \"y\": 4.701}, {\"title\": \"Self-Evolution Fine-Tuning for Policy Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.714, \"y\": 0.652}, {\"title\": \"Post-hoc Utterance Refining Method by Entity Mining for Faithful  Knowledge Grounded Conversations\", \"topic\": \"Large Language Models in Education\", \"x\": 5.924, \"y\": 3.511}, {\"title\": \"ptt5-v2: A Closer Look at Continued Pretraining of T5 Models for the  Portuguese Language\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.299, \"y\": 3.974}, {\"title\": \"KGPA: Robustness Evaluation for Large Language Models via Cross-Domain  Knowledge Graphs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.264, \"y\": 0.984}, {\"title\": \"Towards Understanding Jailbreak Attacks in LLMs: A Representation Space  Analysis\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.055, \"y\": 0.501}, {\"title\": \"ShareLoRA: Parameter Efficient and Robust Large Language Model  Fine-tuning via Shared Low-Rank Adaptation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.824, \"y\": 1.812}, {\"title\": \"RoseLoRA: Row and Column-wise Sparse Low-rank Adaptation of Pre-trained  Language Model for Knowledge Editing and Fine-tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.731, \"y\": 1.807}, {\"title\": \"Quest: Query-Aware Sparsity for Efficient Long-Context LLM Inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.201, \"y\": 2.918}, {\"title\": \"Quantifying Generative Media Bias with a Corpus of Real-world and  Generated News Articles\", \"topic\": \"Bias in Language Models\", \"x\": 3.379, \"y\": 3.482}, {\"title\": \"GNOME: Generating Negotiations through Open-Domain Mapping of Exchanges\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.155, \"y\": 2.814}, {\"title\": \"How Should We Extract Discrete Audio Tokens from Self-Supervised Models?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.358, \"y\": 5.946}, {\"title\": \"SyntheT2C: Generating Synthetic Data for Fine-Tuning Large Language  Models on the Text2Cypher Task\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.673, \"y\": 6.947}, {\"title\": \"MIND: Multimodal Shopping Intention Distillation from Large  Vision-language Models for E-commerce Purchase Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 7.51, \"y\": 7.064}, {\"title\": \"Emerging Safety Attack and Defense in Federated Instruction Tuning of  Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.437, \"y\": 0.649}, {\"title\": \"On the Hardness of Faithful Chain-of-Thought Reasoning in Large Language  Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.424, \"y\": 2.227}, {\"title\": \"Evaluating the Generalization Ability of Quantized LLMs: Benchmark,  Analysis, and Toolbox\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.591, \"y\": 2.232}, {\"title\": \"Multilingual Large Language Models and Curse of Multilinguality\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.013, \"y\": 4.27}, {\"title\": \"BlockPruner: Fine-grained Pruning for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.035, \"y\": 2.484}, {\"title\": \"Mental Disorder Classification via Temporal Representation of Text\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.398, \"y\": 6.446}, {\"title\": \"Optimization-based Structural Pruning for Large Language Models without  Back-Propagation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.018, \"y\": 2.358}, {\"title\": \"We Care: Multimodal Depression Detection and Knowledge Infused Mental  Health Therapeutic Response Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.118, \"y\": 6.328}, {\"title\": \"Lightweight Audio Segmentation for Long-form Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.332, \"y\": 5.713}, {\"title\": \"Reactor Mk.1 performances: MMLU, HumanEval and BBH test results\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.59, \"y\": 1.686}, {\"title\": \"GTR-Voice: Articulatory Phonetics Informed Controllable Expressive  Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.951, \"y\": 6.094}, {\"title\": \"Benchmarking Children's ASR with Supervised and Self-supervised Speech  Foundation Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.57, \"y\": 5.814}, {\"title\": \"Large Language Models as Event Forecasters\", \"topic\": \"Named Entity Recognition\", \"x\": 6.424, \"y\": 5.278}, {\"title\": \"Do Large Language Models Discriminate in Hiring Decisions on the Basis  of Race, Ethnicity, and Gender?\", \"topic\": \"Bias in Language Models\", \"x\": 3.267, \"y\": 2.835}, {\"title\": \"Cutting through the noise to motivate people: A comprehensive analysis  of COVID-19 social media posts de/motivating vaccination\", \"topic\": \"Bias in Language Models\", \"x\": 3.311, \"y\": 4.342}, {\"title\": \"CancerLLM: A Large Language Model in Cancer Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.168, \"y\": 7.294}, {\"title\": \"Enhancing In-Context Learning with Semantic Representations for Relation  Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.33, \"y\": 6.479}, {\"title\": \"SciEx: Benchmarking Large Language Models on Scientific Exams with Human  Expert Grading and Automatic Grading\", \"topic\": \"Large Language Models in Education\", \"x\": 6.553, \"y\": 2.501}, {\"title\": \"Self-Reflection Outcome is Sensitive to Prompt Construction\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 6.974, \"y\": 2.191}, {\"title\": \"EWEK-QA: Enhanced Web and Efficient Knowledge Graph Retrieval for  Citation-based Question Answering Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.309, \"y\": 4.728}, {\"title\": \"From Pixels to Prose: A Large Dataset of Dense Image Captions\", \"topic\": \"Multimodal Language Models\", \"x\": 2.75, \"y\": 3.071}, {\"title\": \"VEGA: Learning Interleaved Image-Text Comprehension in Vision-Language  Large Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.858, \"y\": 7.593}, {\"title\": \"Short Film Dataset (SFD): A Benchmark for Story-Level Video  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.738, \"y\": 7.418}, {\"title\": \"Regularizing Hidden States Enables Learning Generalizable Reward Model  for LLMs\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.539, \"y\": 0.645}, {\"title\": \"DevBench: A multimodal developmental benchmark for language learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.148, \"y\": 7.443}, {\"title\": \"Be like a Goldfish, Don't Memorize! Mitigating Memorization in  Generative LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.938, \"y\": 0.55}, {\"title\": \"A Fundamental Trade-off in Aligned Language Models and its Relation to  Sampling Adaptors\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.585, \"y\": 0.75}, {\"title\": \"Inclusive ASR for Disfluent Speech: Cascaded Large-Scale Self-Supervised  Learning with Targeted Fine-Tuning and Data Augmentation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.555, \"y\": 5.89}, {\"title\": \"Evaluation of Large Language Models: STEM education and Gender  Stereotypes\", \"topic\": \"Bias in Language Models\", \"x\": 3.258, \"y\": 2.739}, {\"title\": \"The Devil is in the Neurons: Interpreting and Mitigating Social Biases  in Pre-trained Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.248, \"y\": 2.697}, {\"title\": \"SEACrowd: A Multilingual Multimodal Data Hub and Benchmark Suite for  Southeast Asian Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.22, \"y\": 4.619}, {\"title\": \"Know the Unknown: An Uncertainty-Sensitive Method for LLM Instruction  Tuning\", \"topic\": \"Large Language Models in Education\", \"x\": 6.772, \"y\": 2.797}, {\"title\": \"Exploring the Correlation between Human and Machine Evaluation of  Simultaneous Speech Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.619, \"y\": 4.941}, {\"title\": \"Enhancing Question Answering on Charts Through Effective Pre-training  Tasks\", \"topic\": \"Multimodal Language Models\", \"x\": 7.416, \"y\": 7.271}, {\"title\": \"On the Evaluation of Speech Foundation Models for Spoken Language  Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.161, \"y\": 5.709}, {\"title\": \"Simul-Whisper: Attention-Guided Streaming Whisper with Truncation  Detection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.492, \"y\": 5.704}, {\"title\": \"GLiNER multi-task: Generalist Lightweight Model for Various Information  Extraction Tasks\", \"topic\": \"Named Entity Recognition\", \"x\": 6.312, \"y\": 6.726}, {\"title\": \"FZI-WIM at SemEval-2024 Task 2: Self-Consistent CoT for Complex NLI in  Biomedical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.182, \"y\": 7.012}, {\"title\": \"Deep Bayesian Active Learning for Preference Modeling in Large Language  Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.432, \"y\": 0.666}, {\"title\": \"Group and Shuffle: Efficient Structured Orthogonal Parametrization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.808, \"y\": 1.84}, {\"title\": \"Precision Empowers, Excess Distracts: Visual Question Answering With  Dynamically Infused Knowledge In Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.776, \"y\": 7.681}, {\"title\": \"CNVSRC 2023: The First Chinese Continuous Visual Speech Recognition  Challenge\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.057, \"y\": 6.259}, {\"title\": \"HIRO: Hierarchical Information Retrieval Optimization\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.23, \"y\": 4.54}, {\"title\": \"Disentangling Dialect from Social Bias via Multitask Learning to Improve  Fairness\", \"topic\": \"Bias in Language Models\", \"x\": 3.115, \"y\": 2.766}, {\"title\": \"In-depth analysis of recall initiators of medical devices with a Machine  Learning-Natural language Processing workflow\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.255, \"y\": 6.997}, {\"title\": \"A Better LLM Evaluator for Text Generation: The Impact of Prompt Output  Sequencing and Optimization\", \"topic\": \"Large Language Models in Education\", \"x\": 6.307, \"y\": 3.219}, {\"title\": \"Bag of Lies: Robustness in Continuous Pre-training BERT\", \"topic\": \"Bias in Language Models\", \"x\": 3.545, \"y\": 3.732}, {\"title\": \"ChartMimic: Evaluating LMM's Cross-Modal Reasoning Capability via  Chart-to-Code Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 7.519, \"y\": 7.389}, {\"title\": \"BiVLC: Extending Vision-Language Compositionality Evaluation with  Text-to-Image Retrieval\", \"topic\": \"Multimodal Language Models\", \"x\": 8.381, \"y\": 7.391}, {\"title\": \"An efficient text augmentation approach for contextualized Mandarin  speech recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.571, \"y\": 5.576}, {\"title\": \"BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures  and Languages\", \"topic\": \"Bias in Language Models\", \"x\": 4.181, \"y\": 2.784}, {\"title\": \"Experiments in News Bias Detection with Pre-Trained Neural Transformers\", \"topic\": \"Bias in Language Models\", \"x\": 3.328, \"y\": 3.656}, {\"title\": \"CliBench: Multifaceted Evaluation of Large Language Models in Clinical  Decisions on Diagnoses, Procedures, Lab Tests Orders and Prescriptions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.962, \"y\": 7.312}, {\"title\": \"GEB-1.3B: Open Lightweight Large Language Model\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.162, \"y\": 2.87}, {\"title\": \"3D-RPE: Enhancing Long-Context Modeling Through 3D Rotary Position  Encoding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.442, \"y\": 3.232}, {\"title\": \"Enhancing Fake News Detection in Social Media via Label Propagation on  Cross-modal Tweet Graph\", \"topic\": \"Bias in Language Models\", \"x\": 3.387, \"y\": 3.81}, {\"title\": \"A Unified Data Augmentation Framework for Low-Resource Multi-Domain  Dialogue Generation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.175, \"y\": 3.422}, {\"title\": \"LUMA: A Benchmark Dataset for Learning from Uncertain and Multimodal  Data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.247, \"y\": 7.226}, {\"title\": \"On the Encoding of Gender in Transformer-based ASR Representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.342, \"y\": 5.811}, {\"title\": \"Federated Learning driven Large Language Models for Swarm Intelligence:  A Survey\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.945, \"y\": 0.147}, {\"title\": \"HiP Attention: Sparse Sub-Quadratic Attention with Hierarchical  Attention Pruning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.011, \"y\": 3.093}, {\"title\": \"RadEx: A Framework for Structured Information Extraction from Radiology  Reports based on Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.203, \"y\": 7.988}, {\"title\": \"Retrieval Augmented Fact Verification by Synthesizing Contrastive  Arguments\", \"topic\": \"Bias in Language Models\", \"x\": 3.887, \"y\": 3.887}, {\"title\": \"OSPC: Detecting Harmful Memes with Large Language Model as a Catalyst\", \"topic\": \"Bias in Language Models\", \"x\": 2.628, \"y\": 3.42}, {\"title\": \"Bootstrapping Language Models with DPO Implicit Rewards\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.532, \"y\": 0.564}, {\"title\": \"CHiSafetyBench: A Chinese Hierarchical Safety Benchmark for Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.916, \"y\": 1.32}, {\"title\": \"UniBridge: A Unified Approach to Cross-Lingual Transfer Learning for  Low-Resource Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.109, \"y\": 4.377}, {\"title\": \"What is the best model? Application-driven Evaluation for Large Language  Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.71, \"y\": 3.134}, {\"title\": \"Enhancing Voice Wake-Up for Dysarthria: Mandarin Dysarthria Speech  Corpus Release and Customized System Design\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.494, \"y\": 5.981}, {\"title\": \"Optimizing Byte-level Representation for End-to-end ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.559, \"y\": 5.652}, {\"title\": \"Evaluating ChatGPT-4 Vision on Brazil's National Undergraduate Computer  Science Exam\", \"topic\": \"Large Language Models in Education\", \"x\": 6.406, \"y\": 2.397}, {\"title\": \"A Survey on Large Language Models from General Purpose to Medical  Applications: Datasets, Methodologies, and Evaluations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.044, \"y\": 7.293}, {\"title\": \"Speech ReaLLM -- Real-time Streaming Speech Recognition with Multimodal  LLMs by Teaching the Flow of Time\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.497, \"y\": 5.678}, {\"title\": \"Decoding the Diversity: A Review of the Indic AI Research Landscape\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.924, \"y\": 4.305}, {\"title\": \"A Systematic Review of Generative AI for Teaching and Learning Practice\", \"topic\": \"Large Language Models in Education\", \"x\": 6.136, \"y\": 2.391}, {\"title\": \"Talking Heads: Understanding Inter-layer Communication in Transformer  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.134, \"y\": 2.841}, {\"title\": \"MuirBench: A Comprehensive Benchmark for Robust Multi-image  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 7.794, \"y\": 7.564}, {\"title\": \"Visual Sketchpad: Sketching as a Visual Chain of Thought for Multimodal  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.658, \"y\": 7.62}, {\"title\": \"Improving Autoregressive Training with Dynamic Oracles\", \"topic\": \"Named Entity Recognition\", \"x\": 6.251, \"y\": 6.748}, {\"title\": \"DiscreteSLU: A Large Language Model with Self-Supervised Discrete Speech  Units for Spoken Language Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.938, \"y\": 5.602}, {\"title\": \"ProxyLM: Predicting Language Model Performance on Multilingual Tasks via  Proxy Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.13, \"y\": 3.819}, {\"title\": \"REVS: Unlearning Sensitive Information in Language Models via Rank  Editing in the Vocabulary Space\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.789, \"y\": 0.507}, {\"title\": \"Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.08, \"y\": 0.527}, {\"title\": \"JailbreakEval: An Integrated Toolkit for Evaluating Jailbreak Attempts  Against Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.98, \"y\": 0.427}, {\"title\": \"AlignMMBench: Evaluating Chinese Multimodal Alignment in Large  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.157, \"y\": 7.484}, {\"title\": \"Exploring Spoken Language Identification Strategies for Automatic  Transcription of Multilingual Broadcast and Institutional Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.436, \"y\": 5.758}, {\"title\": \"Understanding Jailbreak Success: A Study of Latent Space Dynamics in  Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.316, \"y\": 0.818}, {\"title\": \"On the Effects of Heterogeneous Data Sources on Speech-to-Text  Foundation Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.407, \"y\": 5.731}, {\"title\": \"Unpacking DPO and PPO: Disentangling Best Practices for Learning from  Preference Feedback\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.547, \"y\": 0.691}, {\"title\": \"End-to-end Streaming model for Low-Latency Speech Anonymization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.368, \"y\": 6.081}, {\"title\": \"Sharing Matters: Analysing Neurons Across Languages and Tasks in LLMs\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.311, \"y\": 3.895}, {\"title\": \"Orthogonality and isotropy of speaker and phonetic information in  self-supervised speech representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.523, \"y\": 5.881}, {\"title\": \"ReMI: A Dataset for Reasoning with Multiple Images\", \"topic\": \"Multimodal Language Models\", \"x\": 7.812, \"y\": 7.607}, {\"title\": \"DefAn: Definitive Answer Dataset for LLMs Hallucination Evaluation\", \"topic\": \"Large Language Models in Education\", \"x\": 6.174, \"y\": 3.223}, {\"title\": \"Diffusion Gaussian Mixture Audio Denoise\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.007, \"y\": 6.047}, {\"title\": \"LASER: Learning by Aligning Self-supervised Representations of Speech  for Improving Content-related Tasks\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.665, \"y\": 5.837}, {\"title\": \"Investigating the translation capabilities of Large Language Models  trained on parallel data only\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.669, \"y\": 4.545}, {\"title\": \"Leveraging Explicit Reasoning for Inference Integration in  Commonsense-Augmented Dialogue Models\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.425, \"y\": 3.53}, {\"title\": \"Chain of Preference Optimization: Improving Chain-of-Thought Reasoning  in LLMs\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.309, \"y\": 1.84}, {\"title\": \"INS-MMBench: A Comprehensive Benchmark for Evaluating LVLMs' Performance  in Insurance\", \"topic\": \"Multimodal Language Models\", \"x\": 7.915, \"y\": 7.586}, {\"title\": \"Chain-of-Though (CoT) prompting strategies for medical error detection  and correction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.078, \"y\": 7.383}, {\"title\": \"How structured are the representations in transformer-based vision  encoders? An analysis of multi-object representations in vision-language  models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.127, \"y\": 7.67}, {\"title\": \"CUDRT: Benchmarking the Detection of Human vs. Large Language Models  Generated Texts\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.732, \"y\": 1.792}, {\"title\": \"MiLoRA: Harnessing Minor Singular Components for Parameter-Efficient LLM  Finetuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.693, \"y\": 1.866}, {\"title\": \"ME-Switch: A Memory-Efficient Expert Switching Framework for Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.179, \"y\": 2.24}, {\"title\": \"CLST: Cold-Start Mitigation in Knowledge Tracing by Aligning a  Generative Language Model as a Students' Knowledge Tracer\", \"topic\": \"Large Language Models in Education\", \"x\": 6.661, \"y\": 2.314}, {\"title\": \"Word Order in English-Japanese Simultaneous Interpretation: Analyses and  Evaluation using Chunk-wise Monotonic Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.82, \"y\": 4.926}, {\"title\": \"Exploring Multilingual Unseen Speaker Emotion Recognition: Leveraging  Co-Attention Cues in Multitask Learning\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.405, \"y\": 5.379}, {\"title\": \"Navigating the Shadows: Unveiling Effective Disturbances for Modern AI  Content Detectors\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.762, \"y\": 1.668}, {\"title\": \"Advanced Multimodal Deep Learning Architecture for Image-Text Matching\", \"topic\": \"Multimodal Language Models\", \"x\": 8.08, \"y\": 7.218}, {\"title\": \"An Initial Investigation of Language Adaptation for TTS Systems under  Low-resource Scenarios\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.386, \"y\": 5.757}, {\"title\": \"Delta-CoMe: Training-Free Delta-Compression with Mixed-Precision for  Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.388, \"y\": 2.214}, {\"title\": \"No perspective, no perception!! Perspective-aware Healthcare Answer  Summarization\", \"topic\": \"Text Summarization\", \"x\": 4.958, \"y\": 5.348}, {\"title\": \"Plan, Generate and Complicate: Improving Low-resource Dialogue State  Tracking via Easy-to-Difficult Zero-shot Data Augmentation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.206, \"y\": 3.275}, {\"title\": \"RelevAI-Reviewer: A Benchmark on AI Reviewers for Survey Paper Relevance\", \"topic\": \"Text Summarization\", \"x\": 4.984, \"y\": 5.863}, {\"title\": \"An Approach to Build Zero-Shot Slot-Filling System for Industry-Grade  Conversational Assistants\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.196, \"y\": 3.238}, {\"title\": \"ContraSolver: Self-Alignment of Language Models by Resolving Internal  Preference Contradictions\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.529, \"y\": 0.712}, {\"title\": \"Research on Optimization of Natural Language Processing Model Based on  Multimodal Deep Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.072, \"y\": 7.317}, {\"title\": \"LLM-Driven Robots Risk Enacting Discrimination, Violence, and Unlawful  Actions\", \"topic\": \"Bias in Language Models\", \"x\": 3.584, \"y\": 2.293}, {\"title\": \"DisfluencySpeech -- Single-Speaker Conversational Speech Dataset with  Paralanguage\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.842, \"y\": 6.151}, {\"title\": \"Linguistic Bias in ChatGPT: Language Models Reinforce Dialect  Discrimination\", \"topic\": \"Bias in Language Models\", \"x\": 3.572, \"y\": 2.751}, {\"title\": \"Automatically Labeling $200B Life-Saving Datasets: A Large Clinical  Trial Outcome Benchmark\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.365, \"y\": 7.027}, {\"title\": \"ResearchArena: Benchmarking LLMs' Ability to Collect and Organize  Information as Research Agents\", \"topic\": \"Text Summarization\", \"x\": 5.179, \"y\": 5.957}, {\"title\": \"MMFakeBench: A Mixed-Source Multimodal Misinformation Detection  Benchmark for LVLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.518, \"y\": 3.758}, {\"title\": \"StructuralSleight: Automated Jailbreak Attacks on Large Language Models  Utilizing Uncommon Text-Encoded Structure\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.098, \"y\": 0.622}, {\"title\": \"Standard Language Ideology in AI-Generated Language\", \"topic\": \"Bias in Language Models\", \"x\": 4.064, \"y\": 2.611}, {\"title\": \"ECBD: Evidence-Centered Benchmark Design for NLP\", \"topic\": \"Large Language Models in Education\", \"x\": 6.878, \"y\": 3.045}, {\"title\": \"Enhancing Psychotherapy Counseling: A Data Augmentation Pipeline  Leveraging Large Language Models for Counseling Conversations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.008, \"y\": 6.4}, {\"title\": \"mOSCAR: A Large-scale Multilingual and Multimodal Document-level Corpus\", \"topic\": \"Multimodal Language Models\", \"x\": 8.289, \"y\": 7.401}, {\"title\": \"VLind-Bench: Measuring Language Priors in Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.232, \"y\": 7.825}, {\"title\": \"MobileAIBench: Benchmarking LLMs and LMMs for On-Device Use Cases\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.308, \"y\": 2.486}, {\"title\": \"Analyzing Large Language Models for Classroom Discussion Assessment\", \"topic\": \"Large Language Models in Education\", \"x\": 6.474, \"y\": 2.786}, {\"title\": \"HelpSteer2: Open-source dataset for training top-performing reward  models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.488, \"y\": 0.678}, {\"title\": \"Mistral-C2F: Coarse to Fine Actor for Analytical and Reasoning  Enhancement in RLHF and Effective-Merged LLMs\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.507, \"y\": 2.873}, {\"title\": \"TC-Bench: Benchmarking Temporal Compositionality in Text-to-Video and  Image-to-Video Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.596, \"y\": 6.99}, {\"title\": \"VeraCT Scan: Retrieval-Augmented Fake News Detection with Justifiable  Reasoning\", \"topic\": \"Bias in Language Models\", \"x\": 3.563, \"y\": 3.73}, {\"title\": \"ML-SUPERB 2.0: Benchmarking Multilingual Speech Models Across Modeling  Constraints, Languages, and Datasets\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.584, \"y\": 5.826}, {\"title\": \"Unraveling Code-Mixing Patterns in Migration Discourse: Automated  Detection and Analysis of Online Conversations on Reddit\", \"topic\": \"Bias in Language Models\", \"x\": 2.734, \"y\": 3.516}, {\"title\": \"Updating CLIP to Prefer Descriptions Over Captions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.519, \"y\": 7.375}, {\"title\": \"Self-Supervised Speech Representations are More Phonetic than Semantic\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.442, \"y\": 5.877}, {\"title\": \"Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning  Framework from Logit Difference\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.101, \"y\": 0.516}, {\"title\": \"CS-Bench: A Comprehensive Benchmark for Large Language Models towards  Computer Science Mastery\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.561, \"y\": 1.283}, {\"title\": \"Mimicking User Data: On Mitigating Fine-Tuning Risks in Closed Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.645, \"y\": 0.945}, {\"title\": \"Advancing High Resolution Vision-Language Models in Biomedicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.426, \"y\": 8.044}, {\"title\": \"Words Worth a Thousand Pictures: Measuring and Understanding Perceptual  Variability in Text-to-Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.566, \"y\": 6.782}, {\"title\": \"What If We Recaption Billions of Web Images with LLaMA-3?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.385, \"y\": 7.314}, {\"title\": \"The Impact of Initialization on LoRA Finetuning Dynamics\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.876, \"y\": 1.752}, {\"title\": \"OLMES: A Standard for Language Model Evaluations\", \"topic\": \"Large Language Models in Education\", \"x\": 6.681, \"y\": 2.954}, {\"title\": \"TasTe: Teaching Large Language Models to Translate through  Self-Reflection\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.711, \"y\": 4.618}, {\"title\": \"MMWorld: Towards Multi-discipline Multi-faceted World Model Evaluation  in Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.592, \"y\": 7.5}, {\"title\": \"cPAPERS: A Dataset of Situated and Multimodal Interactive Conversations  in Scientific Papers\", \"topic\": \"Text Summarization\", \"x\": 5.096, \"y\": 5.867}, {\"title\": \"Large Language Models Must Be Taught to Know What They Don't Know\", \"topic\": \"Large Language Models in Education\", \"x\": 6.651, \"y\": 2.931}, {\"title\": \"Towards Unsupervised Speech Recognition Without Pronunciation Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.636, \"y\": 5.651}, {\"title\": \"Is Programming by Example solved by LLMs?\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.108, \"y\": 0.355}, {\"title\": \"Research Trends for the Interplay between Large Language Models and  Knowledge Graphs\", \"topic\": \"Named Entity Recognition\", \"x\": 6.635, \"y\": 5.25}, {\"title\": \"SumHiS: Extractive Summarization Exploiting Hidden Structure\", \"topic\": \"Text Summarization\", \"x\": 5.089, \"y\": 5.164}, {\"title\": \"Transformer-based Model for ASR N-Best Rescoring and Rewriting\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.539, \"y\": 5.696}, {\"title\": \"A Dialogue Game for Eliciting Balanced Collaboration\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.532, \"y\": 1.726}, {\"title\": \"Underneath the Numbers: Quantitative and Qualitative Gender Fairness in  LLMs for Depression Prediction\", \"topic\": \"Bias in Language Models\", \"x\": 3.094, \"y\": 2.93}, {\"title\": \"Examining Post-Training Quantization for Mixture-of-Experts: A Benchmark\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.536, \"y\": 2.288}, {\"title\": \"Supportiveness-based Knowledge Rewriting for Retrieval-augmented  Language Modeling\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.266, \"y\": 4.527}, {\"title\": \"Languages Transferred Within the Encoder: On Representation Transfer in  Zero-Shot Multilingual Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.486, \"y\": 4.376}, {\"title\": \"AustroTox: A Dataset for Target-Based Austrian German Offensive Language  Detection\", \"topic\": \"Bias in Language Models\", \"x\": 2.471, \"y\": 3.396}, {\"title\": \"A Concept-Based Explainability Framework for Large Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.88, \"y\": 7.577}, {\"title\": \"Large Language Models Meet Text-Centric Multimodal Sentiment Analysis: A  Survey\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.604, \"y\": 5.159}, {\"title\": \"Adversarial Evasion Attack Efficiency against Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.051, \"y\": 1.143}, {\"title\": \"Improving child speech recognition with augmented child-like speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.515, \"y\": 5.784}, {\"title\": \"Attentive Merging of Hidden Embeddings from Pre-trained Speech Model for  Anti-spoofing Detection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.53, \"y\": 5.907}, {\"title\": \"Blowfish: Topological and statistical signatures for quantifying  ambiguity in semantic search\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.252, \"y\": 4.552}, {\"title\": \"It Takes Two: On the Seamlessness between Reward and Policy Model in  RLHF\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.602, \"y\": 0.681}, {\"title\": \"Guiding In-Context Learning of LLMs through Quality Estimation for  Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.599, \"y\": 4.708}, {\"title\": \"LibriTTS-P: A Corpus with Speaking Style and Speaker Identity Prompts  for Text-to-Speech and Style Captioning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.692, \"y\": 6.112}, {\"title\": \"Better than Random: Reliable NLG Human Evaluation with Constrained  Active Sampling\", \"topic\": \"Large Language Models in Education\", \"x\": 6.306, \"y\": 3.28}, {\"title\": \"Political Leaning Inference through Plurinational Scenarios\", \"topic\": \"Bias in Language Models\", \"x\": 3.267, \"y\": 3.837}, {\"title\": \"Defining and Detecting Vulnerability in Human Evaluation Guidelines: A  Preliminary Study Towards Reliable NLG Evaluation\", \"topic\": \"Large Language Models in Education\", \"x\": 6.259, \"y\": 3.441}, {\"title\": \"Large Language Model Unlearning via Embedding-Corrupted Prompts\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.088, \"y\": 0.575}, {\"title\": \"Automated Information Extraction from Thyroid Operation Narrative: A  Comparative Study of GPT-4 and Fine-tuned KoELECTRA\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.303, \"y\": 7.341}, {\"title\": \"Analyzing Multi-Head Attention on Trojan BERT Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.045, \"y\": 1.135}, {\"title\": \"Guiding Frame-Level CTC Alignments Using Self-knowledge Distillation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.485, \"y\": 5.786}, {\"title\": \"Exploring Self-Supervised Multi-view Contrastive Learning for Speech  Emotion Recognition with Limited Annotations\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.453, \"y\": 5.373}, {\"title\": \"Exploring Speech Foundation Models for Speaker Diarization in  Child-Adult Dyadic Interactions\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.593, \"y\": 5.901}, {\"title\": \"An Empirical Study of Mamba-based Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.84, \"y\": 2.972}, {\"title\": \"Label-aware Hard Negative Sampling Strategies with Momentum Contrastive  Learning for Implicit Hate Speech Detection\", \"topic\": \"Bias in Language Models\", \"x\": 2.462, \"y\": 3.343}, {\"title\": \"Transferable Embedding Inversion Attack: Uncovering Privacy Risks in  Text Embeddings without Model Queries\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.617, \"y\": 0.303}, {\"title\": \"VALL-E R: Robust and Efficient Zero-Shot Text-to-Speech Synthesis via  Monotonic Alignment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.031, \"y\": 5.952}, {\"title\": \"Dynamic Stochastic Decoding Strategy for Open-Domain Dialogue Generation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.225, \"y\": 3.47}, {\"title\": \"Dual-Pipeline with Low-Rank Adaptation for New Language Integration in  Multilingual ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.462, \"y\": 5.68}, {\"title\": \"Labeling Comic Mischief Content in Online Videos with a Multimodal  Hierarchical-Cross-Attention Model\", \"topic\": \"Bias in Language Models\", \"x\": 2.652, \"y\": 3.349}, {\"title\": \"PRoDeliberation: Parallel Robust Deliberation for End-to-End Spoken  Language Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.305, \"y\": 5.449}, {\"title\": \"Spoof Diarization: \\\"What Spoofed When\\\" in Partially Spoofed Audio\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.462, \"y\": 5.985}, {\"title\": \"Are Large Language Models Good Statisticians?\", \"topic\": \"Large Language Models in Education\", \"x\": 7.166, \"y\": 2.885}, {\"title\": \"Collective Constitutional AI: Aligning a Language Model with Public  Input\", \"topic\": \"Bias in Language Models\", \"x\": 4.278, \"y\": 2.579}, {\"title\": \"PolySpeech: Exploring Unified Multitask Speech Models for  Competitiveness with Single-task Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.209, \"y\": 5.869}, {\"title\": \"GenDistiller: Distilling Pre-trained Language Models based on an  Autoregressive Generative Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.462, \"y\": 5.609}, {\"title\": \"Making Task-Oriented Dialogue Datasets More Natural by Synthetically  Generating Indirect User Requests\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.242, \"y\": 3.144}, {\"title\": \"Judging the Judges: A Systematic Investigation of Position Bias in  Pairwise Comparative Assessments by LLMs\", \"topic\": \"Large Language Models in Education\", \"x\": 6.549, \"y\": 2.788}, {\"title\": \"On Trojans in Refined Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.24, \"y\": 0.774}, {\"title\": \"Soft Language Identification for Language-Agnostic Many-to-One  End-to-End Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.163, \"y\": 5.657}, {\"title\": \"The MuSe 2024 Multimodal Sentiment Analysis Challenge: Social Perception  and Humor Recognition\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.583, \"y\": 5.079}, {\"title\": \"UICoder: Finetuning Large Language Models to Generate User Interface  Code through Automated Feedback\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.091, \"y\": 0.202}, {\"title\": \"ExHuBERT: Enhancing HuBERT Through Block Extension and Fine-Tuning on 37  Emotion Datasets\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.436, \"y\": 5.421}, {\"title\": \"Question-Answering (QA) Model for a Personalized Learning Assistant for  Arabic Language\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.526, \"y\": 3.96}, {\"title\": \"Sustainable self-supervised learning for speech representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.618, \"y\": 5.719}, {\"title\": \"Using General Large Language Models to Classify Mathematical Documents\", \"topic\": \"Text Summarization\", \"x\": 4.955, \"y\": 5.979}, {\"title\": \"A Labelled Dataset for Sentiment Analysis of Videos on YouTube, TikTok,  and Other Sources about the 2024 Outbreak of Measles\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.195, \"y\": 4.886}, {\"title\": \"Transformer Models in Education: Summarizing Science Textbooks with  AraBART, MT5, AraT5, and mBART\", \"topic\": \"Text Summarization\", \"x\": 5.178, \"y\": 5.21}, {\"title\": \"Out-Of-Context Prompting Boosts Fairness and Robustness in Large  Language Model Predictions\", \"topic\": \"Bias in Language Models\", \"x\": 3.679, \"y\": 2.398}, {\"title\": \"Beyond Words: On Large Language Models Actionability in Mission-Critical  Risk Analysis\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.956, \"y\": 1.509}, {\"title\": \"Connected Speech-Based Cognitive Assessment in Chinese and English\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.653, \"y\": 6.971}, {\"title\": \"OPTune: Efficient Online Preference Tuning\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.558, \"y\": 0.561}, {\"title\": \"Commonsense-T2I Challenge: Can Text-to-Image Generation Models  Understand Commonsense?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.374, \"y\": 6.945}, {\"title\": \"Open-LLM-Leaderboard: From Multi-choice to Open-style Questions for LLMs  Evaluation, Benchmark, and Arena\", \"topic\": \"Large Language Models in Education\", \"x\": 6.697, \"y\": 2.937}, {\"title\": \"Situational Awareness Matters in 3D Vision Language Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.952, \"y\": 7.384}, {\"title\": \"Samba: Simple Hybrid State Space Models for Efficient Unlimited Context  Language Modeling\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.78, \"y\": 3.166}, {\"title\": \"Just Because We Camp, Doesn't Mean We Should: The Ethics of Modelling  Queer Voices\", \"topic\": \"Bias in Language Models\", \"x\": 3.041, \"y\": 3.036}, {\"title\": \"Image Textualization: An Automatic Framework for Creating Accurate and  Detailed Image Descriptions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.406, \"y\": 7.252}, {\"title\": \"CADS: A Systematic Literature Review on the Challenges of Abstractive  Dialogue Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.177, \"y\": 4.996}, {\"title\": \"Advancing Annotation of Stance in Social Media Posts: A Comparative  Analysis of Large Language Models and Crowd Sourcing\", \"topic\": \"Bias in Language Models\", \"x\": 3.172, \"y\": 4.213}, {\"title\": \"VideoLLaMA 2: Advancing Spatial-Temporal Modeling and Audio  Understanding in Video-LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.816, \"y\": 7.424}, {\"title\": \"On the Robustness of Document-Level Relation Extraction Models to Entity  Name Variations\", \"topic\": \"Named Entity Recognition\", \"x\": 6.303, \"y\": 6.521}, {\"title\": \"Textual Similarity as a Key Metric in Machine Translation Quality  Estimation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.546, \"y\": 4.965}, {\"title\": \"Learning Domain-Invariant Features for Out-of-Context News Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.403, \"y\": 3.769}, {\"title\": \"VersiCode: Towards Version-controllable Code Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.044, \"y\": 0.031}, {\"title\": \"Limited Out-of-Context Knowledge Reasoning in Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.514, \"y\": 2.328}, {\"title\": \"When Linear Attention Meets Autoregressive Decoding: Towards More  Effective and Efficient Linearized Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.129, \"y\": 3.168}, {\"title\": \"Autograding Mathematical Induction Proofs with Natural Language  Processing\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.471, \"y\": 1.334}, {\"title\": \"GLIMPSE: Pragmatically Informative Multi-Document Summarization for  Scholarly Reviews\", \"topic\": \"Text Summarization\", \"x\": 5.021, \"y\": 5.387}, {\"title\": \"AI Sandbagging: Language Models can Strategically Underperform on  Evaluations\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.686, \"y\": 0.968}, {\"title\": \"Toxic Memes: A Survey of Computational Perspectives on the Detection and  Explanation of Meme Toxicities\", \"topic\": \"Bias in Language Models\", \"x\": 2.731, \"y\": 3.34}, {\"title\": \"DR-RAG: Applying Dynamic Document Relevance to Retrieval-Augmented  Generation for Question-Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.319, \"y\": 4.522}, {\"title\": \"CTC-based Non-autoregressive Textless Speech-to-Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.209, \"y\": 5.609}, {\"title\": \"3D-Properties: Identifying Challenges in DPO and Charting a Path Forward\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.528, \"y\": 0.59}, {\"title\": \"MM-KWS: Multi-modal Prompts for Multilingual User-defined Keyword  Spotting\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.387, \"y\": 5.53}, {\"title\": \"Joint Learning of Context and Feedback Embeddings in Spoken Dialogue\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.216, \"y\": 3.314}, {\"title\": \"Can We Achieve High-quality Direct Speech-to-Speech Translation without  Parallel Speech Data?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.113, \"y\": 5.75}, {\"title\": \"Bilingual Sexism Classification: Fine-Tuned XLM-RoBERTa and GPT-3.5  Few-Shot Learning\", \"topic\": \"Bias in Language Models\", \"x\": 2.634, \"y\": 3.249}, {\"title\": \"Advancing Grounded Multimodal Named Entity Recognition via LLM-Based  Reformulation and Box-Based Segmentation\", \"topic\": \"Multimodal Language Models\", \"x\": 7.368, \"y\": 7.072}, {\"title\": \"MLLMGuard: A Multi-dimensional Safety Evaluation Suite for Multimodal  Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.75, \"y\": 1.296}, {\"title\": \"Scholarly Question Answering using Large Language Models in the  NFDI4DataScience Gateway\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.798, \"y\": 4.924}, {\"title\": \"MBBQ: A Dataset for Cross-Lingual Comparison of Stereotypes in  Generative LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.636, \"y\": 2.597}, {\"title\": \"On the Hallucination in Simultaneous Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.679, \"y\": 4.731}, {\"title\": \"DUAL-REFLECT: Enhancing Large Language Models for Reflective Translation  through Dual Learning Feedback Mechanisms\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.726, \"y\": 4.715}, {\"title\": \"Decipherment-Aware Multilingual Learning in Jointly Trained Language  Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.151, \"y\": 4.265}, {\"title\": \"Improving Commonsense Bias Classification by Mitigating the Influence of  Demographic Terms\", \"topic\": \"Bias in Language Models\", \"x\": 3.305, \"y\": 2.796}, {\"title\": \"Improving Autoformalization using Type Checking\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.455, \"y\": 1.061}, {\"title\": \"A Synthetic Dataset for Personal Attribute Inference\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.69, \"y\": 0.398}, {\"title\": \"Towards Human-AI Collaboration in Healthcare: Guided Deferral Systems  with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.71, \"y\": 7.27}, {\"title\": \"Merging Improves Self-Critique Against Jailbreak Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.112, \"y\": 0.627}, {\"title\": \"EmoBox: Multilingual Multi-corpus Speech Emotion Recognition Toolkit and  Benchmark\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.479, \"y\": 5.385}, {\"title\": \"Scaling Large-Language-Model-based Multi-Agent Collaboration\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.022, \"y\": 1.722}, {\"title\": \"Never Miss A Beat: An Efficient Recipe for Context Window Extension of  Large Language Models with Consistent \\\"Middle\\\" Enhancement\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.469, \"y\": 3.164}, {\"title\": \"Tag and correct: high precision post-editing approach to correction of  speech recognition errors\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.594, \"y\": 5.7}, {\"title\": \"Fast Context-Biasing for CTC and Transducer ASR models with CTC-based  Word Spotter\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.648, \"y\": 5.634}, {\"title\": \"Unused information in token probability distribution of generative LLM:  improving LLM reading comprehension through calculation of expected values\", \"topic\": \"Large Language Models in Education\", \"x\": 6.589, \"y\": 3.174}, {\"title\": \"Efficiently Exploring Large Language Models for Document-Level Machine  Translation with In-context Learning\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.697, \"y\": 4.503}, {\"title\": \"Reading Miscue Detection in Primary School through Automatic Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.524, \"y\": 5.838}, {\"title\": \"Benchmarking Trustworthiness of Multimodal Large Language Models: A  Comprehensive Study\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.75, \"y\": 1.412}, {\"title\": \"Effectively Compress KV Heads for LLM\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.159, \"y\": 2.889}, {\"title\": \"AIM: Let Any Multi-modal Large Language Models Embrace Efficient  In-Context Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.373, \"y\": 7.389}, {\"title\": \"Paying More Attention to Source Context: Mitigating Unfaithful  Translations from Large Language Model\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.64, \"y\": 4.506}, {\"title\": \"Improving Multi-hop Logical Reasoning in Knowledge Graphs with  Context-Aware Query Representation Learning\", \"topic\": \"Named Entity Recognition\", \"x\": 6.691, \"y\": 5.425}, {\"title\": \"Improving Language Models for Emotion Analysis: Insights from Cognitive  Science\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.643, \"y\": 5.471}, {\"title\": \"MoreauPruner: Robust Pruning of Large Language Models against Weight  Perturbations\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.018, \"y\": 2.39}, {\"title\": \"Delving into ChatGPT usage in academic writing through excess vocabulary\", \"topic\": \"Text Summarization\", \"x\": 4.902, \"y\": 5.923}, {\"title\": \"Bridging Language Gaps in Audio-Text Retrieval\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.822, \"y\": 6.017}, {\"title\": \"Evolving Subnetwork Training for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.772, \"y\": 2.382}, {\"title\": \"Post-Hoc Answer Attribution for Grounded and Trustworthy Long Document  Comprehension: Task, Insights, and Challenges\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.395, \"y\": 4.32}, {\"title\": \"A Non-autoregressive Generation Framework for End-to-End Simultaneous  Speech-to-Any Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.106, \"y\": 5.674}, {\"title\": \"Agent-SiMT: Agent-assisted Simultaneous Machine Translation with Large  Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.825, \"y\": 4.653}, {\"title\": \"PLUM: Preference Learning Plus Test Cases Yields Better Code Language  Models\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.059, \"y\": 0.117}, {\"title\": \"Flextron: Many-in-One Flexible Large Language Model\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.005, \"y\": 2.626}, {\"title\": \"What's in an embedding? Would a rose by any embedding smell as sweet?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.515, \"y\": 2.449}, {\"title\": \"A Survey of Backdoor Attacks and Defenses on Large Language Models:  Implications for Security Measures\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.351, \"y\": 0.829}, {\"title\": \"Silent Signals, Loud Impact: LLMs for Word-Sense Disambiguation of Coded  Dog Whistles\", \"topic\": \"Bias in Language Models\", \"x\": 2.492, \"y\": 3.362}, {\"title\": \"AGB-DE: A Corpus for the Automated Legal Assessment of Clauses in German  Consumer Contracts\", \"topic\": \"Legal NLP\", \"x\": 4.432, \"y\": 4.525}, {\"title\": \"SciRIFF: A Resource to Enhance Language Model Instruction-Following over  Scientific Literature\", \"topic\": \"Text Summarization\", \"x\": 5.036, \"y\": 6.041}, {\"title\": \"LLM-dCache: Improving Tool-Augmented LLMs with GPT-Driven Localized Data  Caching\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.423, \"y\": 2.747}, {\"title\": \"Evaluating Zero-Shot Long-Context LLM Compression\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.182, \"y\": 2.442}, {\"title\": \"Scaling the Vocabulary of Non-autoregressive Models for Efficient  Generative Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.092, \"y\": 4.624}, {\"title\": \"Raccoon: Prompt Extraction Benchmark of LLM-Integrated Applications\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.201, \"y\": 0.537}, {\"title\": \"Synthetic Query Generation using Large Language Models for Virtual  Assistants\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.059, \"y\": 4.304}, {\"title\": \"Leveraging Large Language Models for Knowledge-free Weak Supervision in  Clinical Natural Language Processing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.222, \"y\": 7.357}, {\"title\": \"Direct Preference Optimization for Suppressing Hallucinated Prior Exams  in Radiology Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.231, \"y\": 8.036}, {\"title\": \"Can Language Models Serve as Text-Based World Simulators?\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.018, \"y\": 1.654}, {\"title\": \"Parallelizing Linear Transformers with the Delta Rule over Sequence  Length\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.858, \"y\": 2.929}, {\"title\": \"Towards a Personal Health Large Language Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.892, \"y\": 7.312}, {\"title\": \"Husky: A Unified, Open-Source Language Agent for Multi-Step Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.244, \"y\": 1.872}, {\"title\": \"AID: Adapting Image2Video Diffusion Models for Instruction-guided Video  Prediction\", \"topic\": \"Multimodal Language Models\", \"x\": 8.654, \"y\": 7.222}, {\"title\": \"Transforming Wearable Data into Health Insights using Large Language  Model Agents\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.745, \"y\": 7.182}, {\"title\": \"Evaluating the Retrieval Component in LLM-Based Question Answering  Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.235, \"y\": 4.028}, {\"title\": \"A Large Language Model Pipeline for Breast Cancer Oncology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.151, \"y\": 7.303}, {\"title\": \"LLM Dataset Inference: Did you train on my dataset?\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.64, \"y\": 0.924}, {\"title\": \"Interpretability of Language Models via Task Spaces\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.232, \"y\": 2.764}, {\"title\": \"Multimodal Contextualized Semantic Parsing from Speech\", \"topic\": \"Multimodal Language Models\", \"x\": 8.537, \"y\": 7.312}, {\"title\": \"Language Models are Alignable Decision-Makers: Dataset and Application  to the Medical Triage Domain\", \"topic\": \"Bias in Language Models\", \"x\": 4.075, \"y\": 2.176}, {\"title\": \"Enrolment-based personalisation for improving individual-level fairness  in speech emotion recognition\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.494, \"y\": 5.353}, {\"title\": \"Meta Learning Text-to-Speech Synthesis in over 7000 Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.061, \"y\": 5.88}, {\"title\": \"INTERSPEECH 2009 Emotion Challenge Revisited: Benchmarking 15 Years of  Progress in Speech Emotion Recognition\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.45, \"y\": 5.457}, {\"title\": \"Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt  LLMs for Dialogue\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.317, \"y\": 3.405}, {\"title\": \"STimage-1K4M: A histopathology image-gene expression dataset for spatial  transcriptomics\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.407, \"y\": 8.077}, {\"title\": \"Low-Rank Quantization-Aware Training for LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.435, \"y\": 2.093}, {\"title\": \"Diffusion-RPO: Aligning Diffusion Models through Relative Preference  Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 8.509, \"y\": 6.701}, {\"title\": \"mHuBERT-147: A Compact Multilingual HuBERT Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.354, \"y\": 5.789}, {\"title\": \"Annotation alignment: Comparing LLM and human annotations of  conversational safety\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.006, \"y\": 1.534}, {\"title\": \"Symmetric Dot-Product Attention for Efficient Training of BERT Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.789, \"y\": 2.867}, {\"title\": \"Explicit Word Density Estimation for Language Modelling\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.793, \"y\": 2.673}, {\"title\": \"MASSW: A New Dataset and Benchmark Tasks for AI-Assisted Scientific  Workflows\", \"topic\": \"Text Summarization\", \"x\": 5.032, \"y\": 5.902}, {\"title\": \"Sustained Vowels for Pre- vs Post-Treatment COPD Classification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.517, \"y\": 6.149}, {\"title\": \"MedExQA: Medical Question Answering Benchmark with Multiple Explanations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.794, \"y\": 7.274}, {\"title\": \"A Parameter-efficient Language Extension Framework for Multilingual ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.555, \"y\": 5.62}, {\"title\": \"Towards Signal Processing In Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.68, \"y\": 2.922}, {\"title\": \"Learning Fine-Grained Controllability on Speech Generation via Efficient  Fine-Tuning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.959, \"y\": 6.002}, {\"title\": \"SecureNet: A Comparative Study of DeBERTa and Large Language Models for  Phishing Detection\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.111, \"y\": 1.546}, {\"title\": \"AutoSurvey: Large Language Models Can Automatically Write Surveys\", \"topic\": \"Text Summarization\", \"x\": 5.096, \"y\": 5.846}, {\"title\": \"Label-Looping: Highly Efficient Decoding for Transducers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.52, \"y\": 3.111}, {\"title\": \"LINGOLY: A Benchmark of Olympiad-Level Linguistic Reasoning Puzzles in  Low-Resource and Extinct Languages\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.502, \"y\": 2.127}, {\"title\": \"Harnessing AI for efficient analysis of complex policy documents: a case  study of Executive Order 14110\", \"topic\": \"Legal NLP\", \"x\": 4.399, \"y\": 4.535}, {\"title\": \"Thunder : Unified Regression-Diffusion Speech Enhancement with a Single  Reverse Step using Brownian Bridge\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.965, \"y\": 6.026}, {\"title\": \"Building Bridges: A Dataset for Evaluating Gender-Fair Machine  Translation into German\", \"topic\": \"Bias in Language Models\", \"x\": 3.117, \"y\": 2.689}, {\"title\": \"Comparing Data Augmentation Methods for End-to-End Task-Oriented Dialog  Systems\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.211, \"y\": 3.22}, {\"title\": \"Recurrent Context Compression: Efficiently Expanding the Context Window  of LLM\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.695, \"y\": 3.097}, {\"title\": \"StreamAtt: Direct Streaming Speech-to-Text Translation with  Attention-based Audio History Selection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.156, \"y\": 5.598}, {\"title\": \"The Impact of Quantization on Retrieval-Augmented Generation: An  Analysis of Small LLMs\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.39, \"y\": 4.294}, {\"title\": \"Efficient k-Nearest-Neighbor Machine Translation with Dynamic Retrieval\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.822, \"y\": 4.607}, {\"title\": \"Synth-SBDH: A Synthetic Dataset of Social and Behavioral Determinants of  Health for Clinical Text\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.847, \"y\": 6.907}, {\"title\": \"MATES: Model-Aware Data Selection for Efficient Pretraining with Data  Influence Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.909, \"y\": 2.559}, {\"title\": \"The Curse of Popularity: Popular Entities have Catastrophic Side Effects  when Deleting Knowledge from Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.947, \"y\": 0.636}, {\"title\": \"RepoQA: Evaluating Long Context Code Understanding\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.074, \"y\": 0.137}, {\"title\": \"CARES: A Comprehensive Benchmark of Trustworthiness in Medical Vision  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.802, \"y\": 7.244}, {\"title\": \"FLEUR: An Explainable Reference-Free Evaluation Metric for Image  Captioning Using a Large Multimodal Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.488, \"y\": 7.303}, {\"title\": \"A Dual-View Approach to Classifying Radiology Reports by Co-Training\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.231, \"y\": 8.054}, {\"title\": \"ShiftAddLLM: Accelerating Pretrained LLMs via Post-Training  Multiplication-Less Reparameterization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.402, \"y\": 2.363}, {\"title\": \"Prompting Large Language Models with Audio for General-Purpose Speech  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.337, \"y\": 5.064}, {\"title\": \"CVQA: Culturally-diverse Multilingual Visual Question Answering  Benchmark\", \"topic\": \"Multimodal Language Models\", \"x\": 7.952, \"y\": 7.783}, {\"title\": \"Turbo Sparse: Achieving LLM SOTA Performance with Minimal Activated  Parameters\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.145, \"y\": 2.354}, {\"title\": \"Hello Again! LLM-powered Personalized Agent for Long-term Dialogue\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.291, \"y\": 3.2}, {\"title\": \"Why Don't Prompt-Based Fairness Metrics Correlate?\", \"topic\": \"Bias in Language Models\", \"x\": 3.318, \"y\": 2.732}, {\"title\": \"TTM-RE: Memory-Augmented Document-Level Relation Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.139, \"y\": 6.527}, {\"title\": \"Whose Preferences? Differences in Fairness Preferences and Their Impact  on the Fairness of AI Utilizing Human Feedback\", \"topic\": \"Bias in Language Models\", \"x\": 3.109, \"y\": 2.899}, {\"title\": \"Feriji: A French-Zarma Parallel Corpus, Glossary & Translator\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.374, \"y\": 4.779}, {\"title\": \"LGR2: Language Guided Reward Relabeling for Accelerating Hierarchical  Reinforcement Learning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.051, \"y\": 1.239}, {\"title\": \"Zero-Shot End-To-End Spoken Question Answering In Medical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.001, \"y\": 7.376}, {\"title\": \"STARLING: Self-supervised Training of Text-based Reinforcement Learning  Agent with Large Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.876, \"y\": 1.487}, {\"title\": \"Machine Against the RAG: Jamming Retrieval-Augmented Generation with  Blocker Documents\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.29, \"y\": 0.614}, {\"title\": \"II-Bench: An Image Implication Understanding Benchmark for Multimodal  Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.903, \"y\": 7.645}, {\"title\": \"MedREQAL: Examining Medical Knowledge Recall of Large Language Models  via Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.896, \"y\": 7.203}, {\"title\": \"Unified Text-to-Image Generation and Retrieval\", \"topic\": \"Multimodal Language Models\", \"x\": 8.317, \"y\": 7.046}, {\"title\": \"A Survey on LLM-Based Agents: Common Workflows and Reusable LLM-Profiled  Components\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.434, \"y\": 1.471}, {\"title\": \"Hidden Holes: topological aspects of language models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.986, \"y\": 2.942}, {\"title\": \"RE-RAG: Improving Open-Domain QA Performance and Interpretability with  Relevance Estimator in Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.401, \"y\": 4.432}, {\"title\": \"Gentle-CLIP: Exploring Aligned Semantic In Low-Quality Multimodal Data  With Soft Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.215, \"y\": 7.352}, {\"title\": \"EmbSpatial-Bench: Benchmarking Spatial Understanding for Embodied Tasks  with Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.026, \"y\": 7.272}, {\"title\": \"MrRank: Improving Question Answering Retrieval System through  Multi-Result Ranking Model\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.325, \"y\": 4.575}, {\"title\": \"LLM Questionnaire Completion for Automatic Psychiatric Assessment\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.234, \"y\": 6.559}, {\"title\": \"SinkLoRA: Enhanced Efficiency and Chat Capabilities for Long-Context  Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.933, \"y\": 3.01}, {\"title\": \"Flow of Reasoning: Efficient Training of LLM Policy with Divergent  Thinking\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.345, \"y\": 1.711}, {\"title\": \"MS-HuBERT: Mitigating Pre-training and Inference Mismatch in Masked  Language Modelling methods for learning Speech Representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.476, \"y\": 5.814}, {\"title\": \"DomainRAG: A Chinese Benchmark for Evaluating Domain-specific  Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.211, \"y\": 4.425}, {\"title\": \"A Superalignment Framework in Autonomous Driving with Large Language  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.602, \"y\": 0.567}, {\"title\": \"How Alignment and Jailbreak Work: Explain LLM Safety through  Intermediate Hidden States\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.666, \"y\": 0.952}, {\"title\": \"ATLAS: Improving Lay Summarisation with Attribute-based Control\", \"topic\": \"Text Summarization\", \"x\": 5.104, \"y\": 5.325}, {\"title\": \"Video-Language Understanding: A Survey from Model Architecture, Model  Training, and Data Perspectives\", \"topic\": \"Multimodal Language Models\", \"x\": 8.783, \"y\": 7.489}, {\"title\": \"GrowOVER: How Can LLMs Adapt to Growing Real-World Knowledge?\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.509, \"y\": 4.343}, {\"title\": \"Can Prompt Modifiers Control Bias? A Comparative Analysis of  Text-to-Image Generative Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.408, \"y\": 2.501}, {\"title\": \"CERET: Cost-Effective Extrinsic Refinement for Text Generation\", \"topic\": \"Large Language Models in Education\", \"x\": 6.52, \"y\": 3.664}, {\"title\": \"Automata Extraction from Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.217, \"y\": 2.78}, {\"title\": \"ThatiAR: Subjectivity Detection in Arabic News Sentences\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.154, \"y\": 4.455}, {\"title\": \"Autoregressive Diffusion Transformer for Text-to-Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.987, \"y\": 6.008}, {\"title\": \"Exploring the Benefits of Tokenization of Discrete Acoustic Units\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.061, \"y\": 5.746}, {\"title\": \"Online DPO: Online Direct Preference Optimization with Fast-Slow Chasing\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.535, \"y\": 0.557}, {\"title\": \"Verbalized Probabilistic Graphical Modeling with Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 6.976, \"y\": 2.466}, {\"title\": \"Mmm whatcha say? Uncovering distal and proximal context effects in first  and second-language word perception using psychophysical reverse correlation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.255, \"y\": 5.774}, {\"title\": \"Representation Learning with Conditional Information Flow Maximization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.357, \"y\": 2.61}, {\"title\": \"Generalist Multimodal AI: A Review of Architectures, Challenges and  Opportunities\", \"topic\": \"Multimodal Language Models\", \"x\": 8.217, \"y\": 7.279}, {\"title\": \"Investigating and Addressing Hallucinations of LLMs in Tasks Involving  Negation\", \"topic\": \"Large Language Models in Education\", \"x\": 6.048, \"y\": 3.379}, {\"title\": \"Fighting Against the Repetitive Training and Sample Dependency Problem  in Few-shot Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 6.215, \"y\": 6.803}, {\"title\": \"Design of reliable technology valuation model with calibrated machine  learning of patent indicators\", \"topic\": \"Legal NLP\", \"x\": 4.61, \"y\": 4.938}, {\"title\": \"QCQA: Quality and Capacity-aware grouped Query Attention\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.318, \"y\": 2.927}, {\"title\": \"Planning Like Human: A Dual-process Framework for Dialogue Planning\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.329, \"y\": 2.689}, {\"title\": \"VALL-E 2: Neural Codec Language Models are Human Parity Zero-Shot Text  to Speech Synthesizers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.012, \"y\": 6.052}, {\"title\": \"Write Summary Step-by-Step: A Pilot Study of Stepwise Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.192, \"y\": 5.146}, {\"title\": \"Flexible and Adaptable Summarization via Expertise Separation\", \"topic\": \"Text Summarization\", \"x\": 5.149, \"y\": 5.163}, {\"title\": \"MemeGuard: An LLM and VLM-based Framework for Advancing Content  Moderation via Meme Intervention\", \"topic\": \"Bias in Language Models\", \"x\": 2.667, \"y\": 3.372}, {\"title\": \"LoCoCo: Dropping In Convolutions for Long Context Compression\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.791, \"y\": 3.157}, {\"title\": \"Behavior Structformer: Learning Players Representations with Structured  Tokenization\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.694, \"y\": 1.938}, {\"title\": \"A model of early word acquisition based on realistic-scale audiovisual  naming events\", \"topic\": \"Multimodal Language Models\", \"x\": 8.31, \"y\": 7.54}, {\"title\": \"Improving Logits-based Detector without Logits from Black-box LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.723, \"y\": 1.728}, {\"title\": \"CPLIP: Zero-Shot Learning for Histopathology with Comprehensive  Vision-Language Alignment\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.319, \"y\": 8.056}, {\"title\": \"LLMs Are Not Intelligent Thinkers: Introducing Mathematical Topic Tree  Benchmark for Comprehensive Evaluation of LLMs\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.559, \"y\": 1.286}, {\"title\": \"Evaluating the Effectiveness of Data Augmentation for Emotion  Classification in Low-Resource Settings\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.529, \"y\": 5.342}, {\"title\": \"3D-GRAND: A Million-Scale Dataset for 3D-LLMs with Better Grounding and  Less Hallucination\", \"topic\": \"Multimodal Language Models\", \"x\": 8.054, \"y\": 7.267}, {\"title\": \"An Empirical Study on Parameter-Efficient Fine-Tuning for MultiModal  Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.473, \"y\": 7.251}, {\"title\": \"Multi-Head RAG: Solving Multi-Aspect Problems with LLMs\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.356, \"y\": 4.475}, {\"title\": \"On Ambiguity and the Expressive Function of Law: The Role of Pragmatics  in Smart Legal Ecosystems\", \"topic\": \"Legal NLP\", \"x\": 4.434, \"y\": 4.354}, {\"title\": \"I2EDL: Interactive Instruction Error Detection and Localization\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.094, \"y\": 1.667}, {\"title\": \"SUMIE: A Synthetic Benchmark for Incremental Entity Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.271, \"y\": 5.265}, {\"title\": \"Bootstrapping Referring Multi-Object Tracking\", \"topic\": \"Multimodal Language Models\", \"x\": 8.102, \"y\": 7.227}, {\"title\": \"Adversarial Tuning: Defending Against Jailbreak Attacks for LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.184, \"y\": 0.709}, {\"title\": \"CHIQ: Contextual History Enhancement for Improving Query Rewriting in  Conversational Search\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.938, \"y\": 4.357}, {\"title\": \"MEFT: Memory-Efficient Fine-Tuning through Sparse Adapter\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.993, \"y\": 2.098}, {\"title\": \"BAMO at SemEval-2024 Task 9: BRAINTEASER: A Novel Task Defying Common  Sense\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.246, \"y\": 1.931}, {\"title\": \"TCMD: A Traditional Chinese Medicine QA Dataset for Evaluating Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.859, \"y\": 7.387}, {\"title\": \"LLM-based speaker diarization correction: A generalizable approach\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.487, \"y\": 5.91}, {\"title\": \"XTTS: a Massively Multilingual Zero-Shot Text-to-Speech Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.01, \"y\": 5.849}, {\"title\": \"Sexism Detection on a Data Diet\", \"topic\": \"Bias in Language Models\", \"x\": 2.67, \"y\": 3.255}, {\"title\": \"Seeing the Unseen: Visual Metaphor Captioning for Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.491, \"y\": 7.354}, {\"title\": \"A Deep Dive into the Trade-Offs of Parameter-Efficient Preference  Alignment Techniques\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.633, \"y\": 0.57}, {\"title\": \"HateDebias: On the Diversity and Variability of Hate Speech Debiasing\", \"topic\": \"Bias in Language Models\", \"x\": 2.483, \"y\": 3.369}, {\"title\": \"The Russian Legislative Corpus\", \"topic\": \"Legal NLP\", \"x\": 4.466, \"y\": 4.571}, {\"title\": \"Digital assistant in a point of sales\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.19, \"y\": 2.625}, {\"title\": \"FedLLM-Bench: Realistic Benchmarks for Federated Learning of Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.311, \"y\": 0.073}, {\"title\": \"Revisiting Catastrophic Forgetting in Large Language Model Tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.271, \"y\": 2.095}, {\"title\": \"BERTs are Generative In-Context Learners\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.598, \"y\": 3.107}, {\"title\": \"SelfGoal: Your Language Agents Already Know How to Achieve High-level  Goals\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.985, \"y\": 1.476}, {\"title\": \"Think out Loud: Emotion Deducing Explanation in Dialogues\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.508, \"y\": 5.39}, {\"title\": \"CRiskEval: A Chinese Multi-Level Risk Evaluation Benchmark Dataset for  Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.904, \"y\": 1.298}, {\"title\": \"PQPP: A Joint Benchmark for Text-to-Image Prompt and Query Performance  Prediction\", \"topic\": \"Multimodal Language Models\", \"x\": 8.515, \"y\": 6.839}, {\"title\": \"CRAG -- Comprehensive RAG Benchmark\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.428, \"y\": 4.583}, {\"title\": \"Generative AI Models: Opportunities and Risks for Industry and  Authorities\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.6, \"y\": 1.175}, {\"title\": \"LoRA-Whisper: Parameter-Efficient and Extensible Multilingual ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.453, \"y\": 5.701}, {\"title\": \"AICoderEval: Improving AI Domain Code Generation of Large Language  Models\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.113, \"y\": 0.437}, {\"title\": \"Transforming Dental Diagnostics with Artificial Intelligence: Advanced  Integration of ChatGPT and Large Language Models for Patient Care\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.97, \"y\": 7.546}, {\"title\": \"Low-Resource Cross-Lingual Summarization through Few-Shot Learning with  Large Language Models\", \"topic\": \"Text Summarization\", \"x\": 5.502, \"y\": 5.089}, {\"title\": \"Language Guided Skill Discovery\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.22, \"y\": 1.264}, {\"title\": \"Key-Element-Informed sLLM Tuning for Document Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.239, \"y\": 5.142}, {\"title\": \"What do MLLMs hear? Examining reasoning with text and sound components  in Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.62, \"y\": 7.135}, {\"title\": \"LawGPT: A Chinese Legal Knowledge-Enhanced Large Language Model\", \"topic\": \"Legal NLP\", \"x\": 4.42, \"y\": 4.558}, {\"title\": \"Pitch-Aware RNN-T for Mandarin Chinese Mispronunciation Detection and  Diagnosis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.599, \"y\": 5.723}, {\"title\": \"GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.149, \"y\": 1.682}, {\"title\": \"Label-Synchronous Neural Transducer for E2E Simultaneous Speech  Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.127, \"y\": 5.609}, {\"title\": \"llmNER: (Zero|Few)-Shot Named Entity Recognition, Exploiting the Power  of Large Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.227, \"y\": 6.796}, {\"title\": \"NATURAL PLAN: Benchmarking LLMs on Natural Language Planning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.364, \"y\": 1.471}, {\"title\": \"To Distill or Not to Distill? On the Robustness of Robust Knowledge  Distillation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.186, \"y\": 5.463}, {\"title\": \"PromptFix: Few-shot Backdoor Removal via Adversarial Prompt Tuning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.192, \"y\": 0.922}, {\"title\": \"Small-E: Small Language Model with Linear Attention for Efficient Speech  Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.014, \"y\": 5.908}, {\"title\": \"MAIRA-2: Grounded Radiology Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.22, \"y\": 8.032}, {\"title\": \"TexIm FAST: Text-to-Image Representation for Semantic Similarity  Evaluation using Transformers\", \"topic\": \"Multimodal Language Models\", \"x\": 8.287, \"y\": 7.274}, {\"title\": \"LipGER: Visually-Conditioned Generative Error Correction for Robust  Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.182, \"y\": 6.185}, {\"title\": \"Aligning Large Language Models with Self-generated Preference Data\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.507, \"y\": 0.609}, {\"title\": \"Improving Alignment and Robustness with Circuit Breakers\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.145, \"y\": 0.999}, {\"title\": \"Why Has Predicting Downstream Capabilities of Frontier AI Models with  Scale Remained Elusive?\", \"topic\": \"Large Language Models in Education\", \"x\": 6.995, \"y\": 2.745}, {\"title\": \"Measuring and Addressing Indexical Bias in Information Retrieval\", \"topic\": \"Bias in Language Models\", \"x\": 3.381, \"y\": 3.013}, {\"title\": \"VISTA: Visualized Text Embedding For Universal Multi-Modal Retrieval\", \"topic\": \"Multimodal Language Models\", \"x\": 8.171, \"y\": 7.31}, {\"title\": \"What Languages are Easy to Language-Model? A Perspective from Learning  Probabilistic Regular Languages\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.119, \"y\": 2.934}, {\"title\": \"Self-Play with Adversarial Critic: Provable and Scalable Offline  Alignment for Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.49, \"y\": 0.523}, {\"title\": \"Buffer of Thoughts: Thought-Augmented Reasoning with Large Language  Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.181, \"y\": 1.779}, {\"title\": \"Transformers need glasses! Information over-squashing in language tasks\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.402, \"y\": 2.765}, {\"title\": \"MLVU: A Comprehensive Benchmark for Multi-Task Long Video Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.823, \"y\": 7.469}, {\"title\": \"Hypernetworks for Personalizing ASR to Atypical Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.53, \"y\": 5.716}, {\"title\": \"FairytaleQA Translated: Enabling Educational Question and Answer  Generation in Less-Resourced Languages\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.625, \"y\": 3.85}, {\"title\": \"The CLRS-Text Algorithmic Reasoning Language Benchmark\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.47, \"y\": 1.883}, {\"title\": \"BEADs: Bias Evaluation Across Domains\", \"topic\": \"Bias in Language Models\", \"x\": 3.244, \"y\": 2.7}, {\"title\": \"Linguistic Steganalysis via LLMs: Two Modes for Efficient Detection of  Strongly Concealed Stego\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.571, \"y\": 1.107}, {\"title\": \"ValueBench: Towards Comprehensively Evaluating Value Orientations and  Understanding of Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.271, \"y\": 2.311}, {\"title\": \"Legal Documents Drafting with Fine-Tuned Pre-Trained Large Language  Model\", \"topic\": \"Legal NLP\", \"x\": 4.466, \"y\": 4.586}, {\"title\": \"DICE: Detecting In-distribution Contamination in LLM's Fine-tuning Phase  for Math Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.655, \"y\": 1.231}, {\"title\": \"Prototypical Reward Network for Data-Efficient RLHF\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.53, \"y\": 0.774}, {\"title\": \"AgentGym: Evolving Large Language Model-based Agents across Diverse  Environments\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.306, \"y\": 1.463}, {\"title\": \"Towards Understanding Task-agnostic Debiasing Through the Lenses of  Intrinsic Bias and Forgetfulness\", \"topic\": \"Bias in Language Models\", \"x\": 3.314, \"y\": 2.593}, {\"title\": \"Do Language Models Understand Morality? Towards a Robust Detection of  Moral Content\", \"topic\": \"Bias in Language Models\", \"x\": 3.886, \"y\": 2.34}, {\"title\": \"Legal Judgment Reimagined: PredEx and the Rise of Intelligent AI  Interpretation in Indian Courts\", \"topic\": \"Legal NLP\", \"x\": 4.378, \"y\": 4.529}, {\"title\": \"Promoting Fairness and Diversity in Speech Datasets for Mental Health  and Neurological Disorders Research\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.423, \"y\": 6.699}, {\"title\": \"Explainability and Hate Speech: Structured Explanations Make Social  Media Moderators Faster\", \"topic\": \"Bias in Language Models\", \"x\": 2.55, \"y\": 3.339}, {\"title\": \"A Human-in-the-Loop Approach to Improving Cross-Text Prosody Transfer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.972, \"y\": 5.967}, {\"title\": \"HORAE: A Domain-Agnostic Modeling Language for Automating Multimodal  Service Regulation\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.882, \"y\": 1.668}, {\"title\": \"Ask LLMs Directly, \\\"What shapes your bias?\\\": Measuring Social Bias in  Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.312, \"y\": 2.795}, {\"title\": \"Assessing LLMs for Zero-shot Abstractive Summarization Through the Lens  of Relevance Paraphrasing\", \"topic\": \"Text Summarization\", \"x\": 5.209, \"y\": 5.086}, {\"title\": \"On The Persona-based Summarization of Domain-Specific Documents\", \"topic\": \"Text Summarization\", \"x\": 5.037, \"y\": 5.333}, {\"title\": \"A + B: A General Generator-Reader Framework for Optimizing LLMs to  Unleash Synergy Potential\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.256, \"y\": 4.243}, {\"title\": \"Tox-BART: Leveraging Toxicity Attributes for Explanation Generation of  Implicit Hate Speech\", \"topic\": \"Bias in Language Models\", \"x\": 2.549, \"y\": 3.345}, {\"title\": \"UltraMedical: Building Specialized Generalists in Biomedicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.161, \"y\": 7.286}, {\"title\": \"Anna Karenina Strikes Again: Pre-Trained LLM Embeddings May Favor  High-Performing Learners\", \"topic\": \"Large Language Models in Education\", \"x\": 6.622, \"y\": 2.277}, {\"title\": \"Culturally Aware and Adapted NLP: A Taxonomy and a Survey of the State  of the Art\", \"topic\": \"Bias in Language Models\", \"x\": 4.051, \"y\": 2.716}, {\"title\": \"ArMeme: Propagandistic Content in Arabic Memes\", \"topic\": \"Bias in Language Models\", \"x\": 2.909, \"y\": 3.633}, {\"title\": \"HeSum: a Novel Dataset for Abstractive Text Summarization in Hebrew\", \"topic\": \"Text Summarization\", \"x\": 5.237, \"y\": 5.045}, {\"title\": \"How Good is Zero-Shot MT Evaluation for Low Resource Indian Languages?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.419, \"y\": 4.807}, {\"title\": \"Spontaneous Speech-Based Suicide Risk Detection Using Whisper and Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.282, \"y\": 6.337}, {\"title\": \"Evaluating the IWSLT2023 Speech Translation Tasks: Human Annotations,  Automatic Metrics, and Segmentation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.655, \"y\": 4.976}, {\"title\": \"Decoder-only Streaming Transformer for Simultaneous Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.914, \"y\": 4.672}, {\"title\": \"BLSP-Emo: Towards Empathetic Large Speech-Language Models\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.549, \"y\": 5.598}, {\"title\": \"Recovering document annotations for sentence-level bitext\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.486, \"y\": 4.643}, {\"title\": \"Performance of large language models in numerical vs. semantic medical  knowledge: Benchmarking on evidence-based Q&As\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.852, \"y\": 7.224}, {\"title\": \"Speculative Decoding via Early-exiting for Faster LLM Inference with  Thompson Sampling Control Mechanism\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.521, \"y\": 3.229}, {\"title\": \"Lean Workbook: A large-scale Lean problem set formalized from natural  language math problems\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.684, \"y\": 1.159}, {\"title\": \"ReST-MCTS*: LLM Self-Training via Process Reward Guided Tree Search\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.204, \"y\": 1.58}, {\"title\": \"Improving Zero-Shot Chinese-English Code-Switching ASR with kNN-CTC and  Gated Monolingual Datastores\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.47, \"y\": 5.668}, {\"title\": \"Tool-Planner: Dynamic Solution Tree Planning for Large Language Model  with Tool Clustering\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.665, \"y\": 1.41}, {\"title\": \"Light-PEFT: Lightening Parameter-Efficient Fine-Tuning via Early Pruning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.652, \"y\": 2.009}, {\"title\": \"End-to-End Trainable Soft Retriever for Low-resource Relation Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.331, \"y\": 6.48}, {\"title\": \"XL-HeadTags: Leveraging Multimodal Retrieval Augmentation for the  Multilingual Generation of News Headlines and Tags\", \"topic\": \"Text Summarization\", \"x\": 5.544, \"y\": 5.353}, {\"title\": \"Effective Context Selection in LLM-based Leaderboard Generation: An  Empirical Study\", \"topic\": \"Text Summarization\", \"x\": 5.081, \"y\": 5.81}, {\"title\": \"Exploring the Latest LLMs for Leaderboard Extraction\", \"topic\": \"Text Summarization\", \"x\": 5.144, \"y\": 5.907}, {\"title\": \"NAP^2: A Benchmark for Naturalness and Privacy-Preserving Text Rewriting  by Learning from Human\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.631, \"y\": 0.44}, {\"title\": \"Efficient Knowledge Infusion via KG-LLM Alignment\", \"topic\": \"Named Entity Recognition\", \"x\": 6.647, \"y\": 5.668}, {\"title\": \"Generalization-Enhanced Code Vulnerability Detection via Multi-Task  Instruction Fine-Tuning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 6.705, \"y\": 0.069}, {\"title\": \"A Survey on Medical Large Language Models: Technology, Application,  Trustworthiness, and Future Directions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.886, \"y\": 7.175}, {\"title\": \"What Should Embeddings Embed? Autoregressive Models Represent Latent  Generating Distributions\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.909, \"y\": 3.158}, {\"title\": \"Improving Audio Codec-based Zero-Shot Text-to-Speech Synthesis with  Multi-Modal Context and Large Language Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.981, \"y\": 6.001}, {\"title\": \"Synthesizing Conversations from Unlabeled Documents using Automatic  Response Segmentation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.391, \"y\": 3.709}, {\"title\": \"M-QALM: A Benchmark to Assess Clinical Reading Comprehension and  Knowledge Recall in Large Language Models via Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.862, \"y\": 7.332}, {\"title\": \"What Makes Language Models Good-enough?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.693, \"y\": 2.909}, {\"title\": \"VHDL-Eval: A Framework for Evaluating Large Language Models in VHDL Code  Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.172, \"y\": 0.196}, {\"title\": \"Is Free Self-Alignment Possible?\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.64, \"y\": 0.549}, {\"title\": \"Style Mixture of Experts for Expressive Text-To-Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.918, \"y\": 6.062}, {\"title\": \"One Queue Is All You Need: Resolving Head-of-Line Blocking in Large  Language Model Serving\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.447, \"y\": 2.741}, {\"title\": \"Knowledge-Infused Legal Wisdom: Navigating LLM Consultation through the  Lens of Diagnostics and Positive-Unlabeled Reinforcement Learning\", \"topic\": \"Legal NLP\", \"x\": 4.445, \"y\": 4.545}, {\"title\": \"Measuring Retrieval Complexity in Question Answering Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.522, \"y\": 4.405}, {\"title\": \"Improve Mathematical Reasoning in Language Models by Automated Process  Supervision\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.319, \"y\": 1.545}, {\"title\": \"Ranking Manipulation for Conversational Search Engines\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.192, \"y\": 0.806}, {\"title\": \"Wings: Learning Multimodal LLMs without Text-only Forgetting\", \"topic\": \"Multimodal Language Models\", \"x\": 8.07, \"y\": 7.441}, {\"title\": \"Analyzing LLM Behavior in Dialogue Summarization: Unveiling  Circumstantial Hallucination Trends\", \"topic\": \"Text Summarization\", \"x\": 5.224, \"y\": 4.9}, {\"title\": \"QJL: 1-Bit Quantized JL Transform for KV Cache Quantization with Zero  Overhead\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.642, \"y\": 2.386}, {\"title\": \"MODABS: Multi-Objective Learning for Dynamic Aspect-Based Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.099, \"y\": 5.194}, {\"title\": \"What is the Best Way for ChatGPT to Translate Poetry?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.391, \"y\": 5.132}, {\"title\": \"Exploring Multilingual Large Language Models for Enhanced TNM  classification of Radiology Report in lung cancer staging\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.2, \"y\": 7.99}, {\"title\": \"Automating Turkish Educational Quiz Generation Using Large Language  Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.454, \"y\": 2.466}, {\"title\": \"Are LLMs classical or nonmonotonic reasoners? Lessons from generics\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.404, \"y\": 2.226}, {\"title\": \"IrokoBench: A New Benchmark for African Languages in the Age of Large  Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.123, \"y\": 4.308}, {\"title\": \"LLM-based Rewriting of Inappropriate Argumentation using Reinforcement  Learning from Machine Feedback\", \"topic\": \"Bias in Language Models\", \"x\": 3.689, \"y\": 3.538}, {\"title\": \"SpikeLM: Towards General Spike-Driven Language Modeling via Elastic  Bi-Spiking Mechanisms\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.957, \"y\": 2.918}, {\"title\": \"PatentEval: Understanding Errors in Patent Generation\", \"topic\": \"Legal NLP\", \"x\": 4.737, \"y\": 4.662}, {\"title\": \"FusionBench: A Comprehensive Benchmark of Deep Model Fusion\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.481, \"y\": 2.075}, {\"title\": \"Document-level Claim Extraction and Decontextualisation for  Fact-Checking\", \"topic\": \"Bias in Language Models\", \"x\": 3.85, \"y\": 3.979}, {\"title\": \"Error-preserving Automatic Speech Recognition of Young English Learners'  Language\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.582, \"y\": 5.785}, {\"title\": \"Assessing the Emergent Symbolic Reasoning Abilities of Llama Large  Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.658, \"y\": 1.298}, {\"title\": \"Missci: Reconstructing Fallacies in Misrepresented Science\", \"topic\": \"Bias in Language Models\", \"x\": 3.794, \"y\": 3.873}, {\"title\": \"Towards Real-world Scenario: Imbalanced New Intent Discovery\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.499, \"y\": 3.612}, {\"title\": \"How Truncating Weights Improves Reasoning in Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.836, \"y\": 2.627}, {\"title\": \"RadBARTsum: Domain Specific Adaption of Denoising Sequence-to-Sequence  Models for Abstractive Radiology Report Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.194, \"y\": 7.88}, {\"title\": \"StreamSpeech: Simultaneous Speech-to-Speech Translation with Multi-task  Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.053, \"y\": 5.569}, {\"title\": \"Bi-Chainer: Automated Large Language Models Reasoning with Bidirectional  Chaining\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.355, \"y\": 1.894}, {\"title\": \"BadAgent: Inserting and Activating Backdoor Attacks in LLM Agents\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.338, \"y\": 0.668}, {\"title\": \"Evaluation of data inconsistency for multi-modal sentiment analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.734, \"y\": 5.089}, {\"title\": \"Filtered not Mixed: Stochastic Filtering-Based Online Gating for Mixture  of Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.895, \"y\": 2.206}, {\"title\": \"PrE-Text: Training Language Models on Private Federated Data in the Age  of LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.802, \"y\": 0.183}, {\"title\": \"4D ASR: Joint Beam Search Integrating CTC, Attention, Transducer, and  Mask Predict Decoders\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.688, \"y\": 5.501}, {\"title\": \"The Task-oriented Queries Benchmark (ToQB)\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.291, \"y\": 3.291}, {\"title\": \"Task Arithmetic can Mitigate Synthetic-to-Real Gap in Automatic Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.514, \"y\": 5.815}, {\"title\": \"Pruner-Zero: Evolving Symbolic Pruning Metric from scratch for Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.966, \"y\": 2.28}, {\"title\": \"Text Injection for Neural Contextual Biasing\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.555, \"y\": 5.64}, {\"title\": \"MultifacetEval: Multifaceted Evaluation to Probe LLMs in Mastering  Medical Knowledge\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.963, \"y\": 7.361}, {\"title\": \"Improving In-Context Learning with Prediction Feedback for Sentiment  Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.112, \"y\": 4.854}, {\"title\": \"Open Grounded Planning: Challenges and Benchmark Construction\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.304, \"y\": 1.386}, {\"title\": \"Scaling Laws for Reward Model Overoptimization in Direct Alignment  Algorithms\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.605, \"y\": 0.57}, {\"title\": \"Language Model Can Do Knowledge Tracing: Simple but Effective Method to  Integrate Language Model and Knowledge Tracing Task\", \"topic\": \"Large Language Models in Education\", \"x\": 6.639, \"y\": 2.319}, {\"title\": \"Evaluating the Efficacy of Large Language Models in Detecting Fake News:  A Comparative Analysis\", \"topic\": \"Bias in Language Models\", \"x\": 3.46, \"y\": 3.637}, {\"title\": \"LCS: A Language Converter Strategy for Zero-Shot Neural Machine  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.699, \"y\": 4.618}, {\"title\": \"NUMCoT: Numerals and Units of Measurement in Chain-of-Thought Reasoning  using Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.77, \"y\": 1.317}, {\"title\": \"Xmodel-LM Technical Report\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.106, \"y\": 3.765}, {\"title\": \"Efficient Minimum Bayes Risk Decoding using Low-Rank Matrix Completion  Algorithms\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.733, \"y\": 4.859}, {\"title\": \"Exploring Robustness in Doctor-Patient Conversation Summarization: An  Analysis of Out-of-Domain SOAP Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.166, \"y\": 7.274}, {\"title\": \"$\\\\texttt{ACCORD}$: Closing the Commonsense Measurability Gap\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.274, \"y\": 2.544}, {\"title\": \"Language Models can Infer Action Semantics for Classical Planners from  Environment Feedback\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.301, \"y\": 1.396}, {\"title\": \"Disentangling Logic: The Role of Context in Large Language Model  Reasoning Capabilities\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.337, \"y\": 2.163}, {\"title\": \"Aligning Large Language Models via Fine-grained Supervision\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.53, \"y\": 0.773}, {\"title\": \"RATT: A Thought Structure for Coherent and Correct LLM Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.177, \"y\": 1.837}, {\"title\": \"Textless Acoustic Model with Self-Supervised Distillation for  Noise-Robust Expressive Speech-to-Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.136, \"y\": 5.811}, {\"title\": \"To Believe or Not to Believe Your LLM\", \"topic\": \"Large Language Models in Education\", \"x\": 6.539, \"y\": 3.027}, {\"title\": \"Parrot: Multilingual Visual Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.038, \"y\": 7.568}, {\"title\": \"TopViewRS: Vision-Language Models as Top-View Spatial Reasoners\", \"topic\": \"Multimodal Language Models\", \"x\": 7.806, \"y\": 7.148}, {\"title\": \"SpecExec: Massively Parallel Speculative Decoding for Interactive LLM  Inference on Consumer Devices\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.579, \"y\": 2.978}, {\"title\": \"Scalable MatMul-free Language Modeling\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.202, \"y\": 2.419}, {\"title\": \"Block Transformer: Global-to-Local Language Modeling for Fast Inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.268, \"y\": 2.864}, {\"title\": \"Deterministic Reversible Data Augmentation for Neural Machine  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.771, \"y\": 4.551}, {\"title\": \"Language-Universal Speech Attributes Modeling for Zero-Shot Multilingual  Spoken Keyword Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.507, \"y\": 5.683}, {\"title\": \"Landscape-Aware Growing: The Power of a Little LAG\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.752, \"y\": 2.541}, {\"title\": \"Multiple Choice Questions and Large Languages Models: A Case Study with  Fictional Medical Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.904, \"y\": 7.241}, {\"title\": \"Language Models Do Hard Arithmetic Tasks Easily and Hardly Do Easy  Arithmetic Tasks\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.984, \"y\": 1.397}, {\"title\": \"LlamaCare: A Large Medical Language Model for Enhancing Healthcare  Knowledge Sharing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.057, \"y\": 7.4}, {\"title\": \"Linguistic Fingerprint in Transformer Models: How Language Variation  Influences Parameter Selection in Irony Detection\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.561, \"y\": 4.935}, {\"title\": \"Break the Chain: Large Language Models Can be Shortcut Reasoners\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.306, \"y\": 2.108}, {\"title\": \"Translation Deserves Better: Analyzing Translation Artifacts in  Cross-lingual Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.004, \"y\": 7.656}, {\"title\": \"From Redundancy to Relevance: Enhancing Explainability in Multimodal  Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.947, \"y\": 7.658}, {\"title\": \"SMS Spam Detection and Classification to Combat Abuse in Telephone  Networks Using Natural Language Processing\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.114, \"y\": 1.772}, {\"title\": \"mCoT: Multilingual Instruction Tuning for Reasoning Consistency in  Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.638, \"y\": 1.352}, {\"title\": \"Prompting Large Language Models with Human Error Markings for  Self-Correcting Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.594, \"y\": 4.794}, {\"title\": \"Enhancing Retrieval-Augmented LMs with a Two-stage Consistency Learning  Compressor\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.304, \"y\": 4.38}, {\"title\": \"Understanding Retrieval Robustness for Retrieval-Augmented Image  Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.479, \"y\": 7.348}, {\"title\": \"Modeling Emotional Trajectories in Written Stories Utilizing  Transformers and Weakly-Supervised Learning\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.666, \"y\": 5.345}, {\"title\": \"Description Boosting for Zero-Shot Entity and Relation Classification\", \"topic\": \"Named Entity Recognition\", \"x\": 6.333, \"y\": 6.63}, {\"title\": \"Self-Modifying State Modeling for Simultaneous Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.909, \"y\": 4.721}, {\"title\": \"Why Only Text: Empowering Vision-and-Language Navigation with  Multi-modal Prompts\", \"topic\": \"Multimodal Language Models\", \"x\": 7.98, \"y\": 7.02}, {\"title\": \"A multilingual dataset for offensive language and hate speech detection  for hausa, yoruba and igbo languages\", \"topic\": \"Bias in Language Models\", \"x\": 2.457, \"y\": 3.361}, {\"title\": \"Whistle: Data-Efficient Multilingual and Crosslingual Speech Recognition  via Weakly Phonetic Supervision\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.471, \"y\": 5.626}, {\"title\": \"Reinforcement Tuning for Detecting Stances and Debunking Rumors Jointly  with Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.549, \"y\": 3.954}, {\"title\": \"The current status of large language models in summarizing radiology  report impressions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.15, \"y\": 7.81}, {\"title\": \"SimulTron: On-Device Simultaneous Speech to Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.058, \"y\": 5.588}, {\"title\": \"MARS: Benchmarking the Metaphysical Reasoning Abilities of Language  Models with a Multi-task Evaluation Dataset\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.459, \"y\": 2.398}, {\"title\": \"Exploring Mathematical Extrapolation of Large Language Models with  Synthetic Data\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.752, \"y\": 1.36}, {\"title\": \"LongSSM: On the Length Extension of State-space Models in Language  Modelling\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.636, \"y\": 3.136}, {\"title\": \"Assessing the Performance of Chinese Open Source Large Language Models  in Information Extraction Tasks\", \"topic\": \"Named Entity Recognition\", \"x\": 6.261, \"y\": 6.661}, {\"title\": \"PyramidKV: Dynamic KV Cache Compression based on Pyramidal Information  Funneling\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.258, \"y\": 2.914}, {\"title\": \"Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown  in State-Of-the-Art Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.404, \"y\": 2.548}, {\"title\": \"Analyzing Social Biases in Japanese Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.535, \"y\": 2.584}, {\"title\": \"QROA: A Black-Box Query-Response Optimization Attack on LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.152, \"y\": 0.674}, {\"title\": \"Multimodal Reasoning with Multimodal Knowledge Graph\", \"topic\": \"Multimodal Language Models\", \"x\": 7.965, \"y\": 7.463}, {\"title\": \"Phonetic Enhanced Language Modeling for Text-to-Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.157, \"y\": 5.895}, {\"title\": \"Efficiently Train ASR Models that Memorize Less and Perform Better with  Per-core Clipping\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.664, \"y\": 5.554}, {\"title\": \"Position Debiasing Fine-Tuning for Causal Perception in Long-Term  Dialogue\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.212, \"y\": 3.456}, {\"title\": \"Personalized Topic Selection Model for Topic-Grounded Dialogue\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.124, \"y\": 3.47}, {\"title\": \"RKLD: Reverse KL-Divergence-based Knowledge Distillation for Unlearning  Personal Information in Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.996, \"y\": 0.527}, {\"title\": \"Conditional Language Learning with Context\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.787, \"y\": 2.404}, {\"title\": \"OccamLLM: Fast and Exact Language Model Arithmetic in a Single Step\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.773, \"y\": 1.276}, {\"title\": \"Process-Driven Autoformalization in Lean 4\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.621, \"y\": 1.107}, {\"title\": \"Dishonesty in Helpful and Harmless Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 4.999, \"y\": 1.09}, {\"title\": \"OTTAWA: Optimal TransporT Adaptive Word Aligner for Hallucination and  Omission Translation Errors Detection\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.756, \"y\": 4.727}, {\"title\": \"HPE-CogVLM: New Head Pose Grounding Task Exploration on Vision Language  Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.313, \"y\": 7.603}, {\"title\": \"GRAM: Generative Retrieval Augmented Matching of Data Schemas in the  Context of Data Security\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.688, \"y\": 0.429}, {\"title\": \"CR-UTP: Certified Robustness against Universal Text Perturbations on  Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.128, \"y\": 0.924}, {\"title\": \"#EpiTwitter: Public Health Messaging During the COVID-19 Pandemic\", \"topic\": \"Bias in Language Models\", \"x\": 3.284, \"y\": 4.322}, {\"title\": \"TruthEval: A Dataset to Evaluate LLM Truthfulness and Reliability\", \"topic\": \"Large Language Models in Education\", \"x\": 6.998, \"y\": 2.965}, {\"title\": \"Contextualized Sequence Likelihood: Enhanced Confidence Scores for  Natural Language Generation\", \"topic\": \"Large Language Models in Education\", \"x\": 6.458, \"y\": 3.559}, {\"title\": \"OLoRA: Orthonormal Low-Rank Adaptation of Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.873, \"y\": 1.786}, {\"title\": \"LLMs Beyond English: Scaling the Multilingual Capability of LLMs with  Cross-Lingual Feedback\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.918, \"y\": 3.914}, {\"title\": \"Ask-EDA: A Design Assistant Empowered by LLM, Hybrid RAG and  Abbreviation De-hallucination\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.003, \"y\": 4.203}, {\"title\": \"Towards Harnessing Large Language Models for Comprehension of  Conversational Grounding\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.241, \"y\": 3.185}, {\"title\": \"MedFuzz: Exploring the Robustness of Large Language Models in Medical  Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.968, \"y\": 7.297}, {\"title\": \"Text-guided Controllable Mesh Refinement for Interactive 3D Modeling\", \"topic\": \"Multimodal Language Models\", \"x\": 8.242, \"y\": 6.806}, {\"title\": \"Helix: Distributed Serving of Large Language Models via Max-Flow on  Heterogeneous GPUs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.466, \"y\": 2.833}, {\"title\": \"Long and Short Guidance in Score identity Distillation for One-Step  Text-to-Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.613, \"y\": 6.74}, {\"title\": \"An Information Bottleneck Perspective for Effective Noise Filtering on  Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.288, \"y\": 4.257}, {\"title\": \"Decoupled Alignment for Robust Plug-and-Play Adaptation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.29, \"y\": 0.997}, {\"title\": \"SUBLLM: A Novel Efficient Architecture with Token Sequence Subsampling  for LLM\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.234, \"y\": 2.949}, {\"title\": \"The Geometry of Categorical and Hierarchical Concepts in Large Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.42, \"y\": 3.097}, {\"title\": \"Understanding Preference Fine-Tuning Through the Lens of Coverage\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.471, \"y\": 0.475}, {\"title\": \"Enhancing Clinical Documentation with Synthetic Data: Leveraging  Generative Models for Improved Accuracy\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.127, \"y\": 7.674}, {\"title\": \"Differentially Private Tabular Data Synthesis using Large Language  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.838, \"y\": 0.26}, {\"title\": \"Enabling ASR for Low-Resource Languages: A Comprehensive Dataset  Creation Approach\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.316, \"y\": 5.742}, {\"title\": \"LexMatcher: Dictionary-centric Data Collection for LLM-based Machine  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.557, \"y\": 4.572}, {\"title\": \"Superhuman performance in urology board questions by an explainable  large language model enabled for context integration of the European  Association of Urology guidelines: the UroBot study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.748, \"y\": 7.292}, {\"title\": \"Universal In-Context Approximation By Prompting Fully Recurrent Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.463, \"y\": 2.834}, {\"title\": \"How to Understand Whole Software Repository?\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.017, \"y\": 0.133}, {\"title\": \"Sparsity-Accelerated Training for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.025, \"y\": 2.291}, {\"title\": \"Do Large Language Models Perform the Way People Expect? Measuring the  Human Generalization Function\", \"topic\": \"Large Language Models in Education\", \"x\": 6.637, \"y\": 2.814}, {\"title\": \"D-CPT Law: Domain-specific Continual Pre-Training Scaling Law for Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.308, \"y\": 2.588}, {\"title\": \"BELLS: A Framework Towards Future Proof Benchmarks for the Evaluation of  LLM Safeguards\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.624, \"y\": 0.972}, {\"title\": \"Privacy in LLM-based Recommendation: Recent Advances and Future  Directions\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.629, \"y\": 0.261}, {\"title\": \"R2C2-Coder: Enhancing and Benchmarking Real-world Repository-level Code  Completion Abilities of Code Large Language Models\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.05, \"y\": 0.052}, {\"title\": \"DHA: Learning Decoupled-Head Attention from Transformer Checkpoints via  Adaptive Heads Fusion\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.055, \"y\": 2.818}, {\"title\": \"CodeR: Issue Resolving with Multi-Agent and Task Graphs\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.978, \"y\": 0.164}, {\"title\": \"Improved Few-Shot Jailbreaking Can Circumvent Aligned Language Models  and Their Defenses\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.052, \"y\": 0.502}, {\"title\": \"Focus on the Core: Efficient Attention via Pruned Token Compression for  Document Classification\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.436, \"y\": 3.334}, {\"title\": \"EduNLP: Towards a Unified and Modularized Library for Educational  Resources\", \"topic\": \"Large Language Models in Education\", \"x\": 6.495, \"y\": 2.311}, {\"title\": \"Towards Scalable Automated Alignment of LLMs: A Survey\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.652, \"y\": 0.953}, {\"title\": \"A Survey of Generative Information Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.044, \"y\": 4.58}, {\"title\": \"Are AI-Generated Text Detectors Robust to Adversarial Perturbations?\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.885, \"y\": 1.409}, {\"title\": \"TCMBench: A Comprehensive Benchmark for Evaluating Large Language Models  in Traditional Chinese Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.026, \"y\": 7.283}, {\"title\": \"Latent Logic Tree Extraction for Event Sequence Explanation from LLMs\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.417, \"y\": 2.291}, {\"title\": \"Synergizing Unsupervised and Supervised Learning: A Hybrid Approach for  Accurate Natural Language Task Modeling\", \"topic\": \"Named Entity Recognition\", \"x\": 6.247, \"y\": 6.758}, {\"title\": \"RAG Enabled Conversations about Household Electricity Monitoring\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.167, \"y\": 4.3}, {\"title\": \"Guiding ChatGPT to Generate Salient Domain Summaries\", \"topic\": \"Text Summarization\", \"x\": 5.32, \"y\": 5.036}, {\"title\": \"Combining Qualitative and Computational Approaches for Literary Analysis  of Finnish Novels\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.805, \"y\": 5.254}, {\"title\": \"Mobile-Agent-v2: Mobile Device Operation Assistant with Effective  Navigation via Multi-Agent Collaboration\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.246, \"y\": 1.66}, {\"title\": \"MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures\", \"topic\": \"Large Language Models in Education\", \"x\": 6.382, \"y\": 3.182}, {\"title\": \"Scalable Ensembling For Mitigating Reward Overoptimisation\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.554, \"y\": 0.569}, {\"title\": \"Revolutionizing Large Language Model Training through Dynamic Parameter  Adjustment\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.625, \"y\": 2.01}, {\"title\": \"SemCoder: Training Code Language Models with Comprehensive Semantics\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.08, \"y\": 0.233}, {\"title\": \"Seeing the Forest through the Trees: Data Leakage from Partial  Transformer Gradients\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.826, \"y\": 0.192}, {\"title\": \"Predicting Drug-Gene Relations via Analogy Tasks with Word Embeddings\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.852, \"y\": 6.966}, {\"title\": \"Take its Essence, Discard its Dross! Debiasing for Toxic Language  Detection via Counterfactual Causal Effect\", \"topic\": \"Bias in Language Models\", \"x\": 2.737, \"y\": 2.972}, {\"title\": \"Selectively Answering Visual Questions\", \"topic\": \"Multimodal Language Models\", \"x\": 7.948, \"y\": 7.683}, {\"title\": \"Generative Pre-trained Speech Language Model with Efficient Hierarchical  Transformer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.943, \"y\": 6.039}, {\"title\": \"Skywork-MoE: A Deep Dive into Training Techniques for Mixture-of-Experts  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.852, \"y\": 2.348}, {\"title\": \"Using RL to Identify Divisive Perspectives Improves LLMs Abilities to  Identify Communities on Social Media\", \"topic\": \"Bias in Language Models\", \"x\": 3.336, \"y\": 4.016}, {\"title\": \"Achieving Sparse Activation in Small Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.018, \"y\": 2.358}, {\"title\": \"Unveil the Duality of Retrieval-Augmented Generation: Theoretical  Analysis and Practical Solution\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.317, \"y\": 4.177}, {\"title\": \"BadRAG: Identifying Vulnerabilities in Retrieval Augmented Generation of  Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.4, \"y\": 0.834}, {\"title\": \"MEDIQ: Question-Asking LLMs for Adaptive and Reliable Clinical Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.732, \"y\": 7.459}, {\"title\": \"YODAS: Youtube-Oriented Dataset for Audio and Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.235, \"y\": 5.903}, {\"title\": \"Phonetic Error Analysis of Raw Waveform Acoustic Models with Parametric  and Non-Parametric CNNs\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.568, \"y\": 5.85}, {\"title\": \"Pretrained Hybrids with MAD Skills\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.842, \"y\": 2.425}, {\"title\": \"Show, Don't Tell: Aligning Language Models with Demonstrated Feedback\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.776, \"y\": 0.795}, {\"title\": \"The Power of Summary-Source Alignments\", \"topic\": \"Text Summarization\", \"x\": 5.108, \"y\": 5.118}, {\"title\": \"Early Detection of Misinformation for Infodemic Management: A Domain  Adaptation Approach\", \"topic\": \"Bias in Language Models\", \"x\": 3.502, \"y\": 4.41}, {\"title\": \"BoNBoN Alignment for Large Language Models and the Sweetness of  Best-of-n Sampling\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.593, \"y\": 0.505}, {\"title\": \"Towards a copilot in BIM authoring tool using a large language  model-based agent for intelligent human-machine interaction\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.118, \"y\": 1.778}, {\"title\": \"Are you still on track!? Catching LLM Task Drift with Activations\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.468, \"y\": 0.664}, {\"title\": \"Developing an efficient corpus using Ensemble Data cleaning approach\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.22, \"y\": 7.349}, {\"title\": \"Applying Intrinsic Debiasing on Downstream Tasks: Challenges and  Considerations for Machine Translation\", \"topic\": \"Bias in Language Models\", \"x\": 3.203, \"y\": 2.643}, {\"title\": \"The Embodied World Model Based on LLM with Visual Information and  Prediction-Oriented Prompts\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.183, \"y\": 1.433}, {\"title\": \"Brainstorming Brings Power to Large Language Models of Knowledge  Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 6.996, \"y\": 1.935}, {\"title\": \"Evaluating Mathematical Reasoning of Large Language Models: A Focus on  Error Identification and Correction\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.561, \"y\": 1.362}, {\"title\": \"Enhancing Zero-shot Text-to-Speech Synthesis with Human Feedback\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.799, \"y\": 6.105}, {\"title\": \"Transforming Computer Security and Public Trust Through the Exploration  of Fine-Tuning Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.352, \"y\": 0.934}, {\"title\": \"LIDAO: Towards Limited Interventions for Debiasing (Large) Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.441, \"y\": 2.446}, {\"title\": \"A Survey on Large Language Models for Code Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.102, \"y\": 0.107}, {\"title\": \"Prompt Chaining or Stepwise Prompt? Refinement in Text Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.247, \"y\": 5.029}, {\"title\": \"Recent Advances in End-to-End Simultaneous Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.027, \"y\": 5.449}, {\"title\": \"Mix-of-Granularity: Optimize the Chunking Granularity for  Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.272, \"y\": 4.487}, {\"title\": \"Gender Bias Detection in Court Decisions: A Brazilian Case Study\", \"topic\": \"Legal NLP\", \"x\": 4.237, \"y\": 4.39}, {\"title\": \"RoBERTa-BiLSTM: A Context-Aware Hybrid Model for Sentiment Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.144, \"y\": 5.065}, {\"title\": \"An Evaluation Benchmark for Autoformalization in Lean4\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.56, \"y\": 1.033}, {\"title\": \"CASE: Efficient Curricular Data Pre-training for Building Assistive  Psychology Expert Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.319, \"y\": 6.437}, {\"title\": \"Multi-Dimensional Optimization for Text Summarization via Reinforcement  Learning\", \"topic\": \"Text Summarization\", \"x\": 5.193, \"y\": 5.138}, {\"title\": \"A Closer Look at Logical Reasoning with LLMs: The Choice of Tool Matters\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.349, \"y\": 1.848}, {\"title\": \"Large Language Model Confidence Estimation via Black-Box Access\", \"topic\": \"Large Language Models in Education\", \"x\": 6.57, \"y\": 3.074}, {\"title\": \"Are Large Vision Language Models up to the Challenge of Chart  Comprehension and Reasoning? An Extensive Investigation into the Capabilities  and Limitations of LVLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.443, \"y\": 7.43}, {\"title\": \"Multi-Modal and Multi-Agent Systems Meet Rationality: A Survey\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.844, \"y\": 1.963}, {\"title\": \"Unveiling Hidden Factors: Explainable AI for Feature Boosting in Speech  Emotion Recognition\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.503, \"y\": 5.444}, {\"title\": \"Controlling Large Language Model Agents with Entropic Activation  Steering\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.017, \"y\": 1.293}, {\"title\": \"Exploring Vulnerabilities and Protections in Large Language Models: A  Survey\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.313, \"y\": 0.617}, {\"title\": \"LLM-RankFusion: Mitigating Intrinsic Inconsistency in LLM-based Ranking\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.792, \"y\": 4.552}, {\"title\": \"Learning to Clarify: Multi-turn Conversations with Action-Based  Contrastive Self-Training\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.359, \"y\": 3.084}, {\"title\": \"Exfiltration of personal information from ChatGPT via prompt injection\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.282, \"y\": 0.577}, {\"title\": \"LOLAMEME: Logic, Language, Memory, Mechanistic Framework\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.111, \"y\": 2.778}, {\"title\": \"SocialNLP Fake-EmoReact 2021 Challenge Overview: Predicting Fake Tweets  from Their Replies and GIFs\", \"topic\": \"Bias in Language Models\", \"x\": 3.337, \"y\": 3.651}, {\"title\": \"Long-Span Question-Answering: Automatic Question Generation and  QA-System Ranking via Side-by-Side Evaluation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.638, \"y\": 4.249}, {\"title\": \"Video-MME: The First-Ever Comprehensive Evaluation Benchmark of  Multi-modal LLMs in Video Analysis\", \"topic\": \"Multimodal Language Models\", \"x\": 8.807, \"y\": 7.469}, {\"title\": \"Generalization Beyond Data Imbalance: A Controlled Study on CLIP for  Transferable Insights\", \"topic\": \"Multimodal Language Models\", \"x\": 8.427, \"y\": 7.472}, {\"title\": \"Exploratory Preference Optimization: Harnessing Implicit  Q*-Approximation for Sample-Efficient RLHF\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.567, \"y\": 0.668}, {\"title\": \"Direct Alignment of Language Models via Quality-Aware Self-Refinement\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.565, \"y\": 0.622}, {\"title\": \"You Only Scan Once: Efficient Multi-dimension Sequential Modeling with  LightNet\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.764, \"y\": 3.197}, {\"title\": \"Improved Techniques for Optimization-Based Jailbreaking on Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.111, \"y\": 0.557}, {\"title\": \"CWRCzech: 100M Query-Document Czech Click Dataset and Its Application to  Web Relevance Ranking\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.99, \"y\": 4.628}, {\"title\": \"LCQ: Low-Rank Codebook based Quantization for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.543, \"y\": 2.204}, {\"title\": \"A Robot Walks into a Bar: Can Language Models Serve as Creativity  Support Tools for Comedy? An Evaluation of LLMs' Humour Alignment with  Comedians\", \"topic\": \"Bias in Language Models\", \"x\": 3.861, \"y\": 2.42}, {\"title\": \"OR-Bench: An Over-Refusal Benchmark for Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.79, \"y\": 1.234}, {\"title\": \"Enhancing Vision Models for Text-Heavy Content Understanding and  Interaction\", \"topic\": \"Multimodal Language Models\", \"x\": 7.607, \"y\": 7.207}, {\"title\": \"Preemptive Answer \\\"Attacks\\\" on Chain-of-Thought Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.106, \"y\": 2.29}, {\"title\": \"Large Language Models: A New Approach for Privacy Policy Analysis at  Scale\", \"topic\": \"Legal NLP\", \"x\": 3.795, \"y\": 1.738}, {\"title\": \"clembench-2024: A Challenging, Dynamic, Complementary, Multilingual  Benchmark and Underlying Flexible Framework for LLMs as Multi-Action Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.987, \"y\": 1.857}, {\"title\": \"Improving Reward Models with Synthetic Critiques\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.56, \"y\": 0.861}, {\"title\": \"Don't Buy it! Reassessing the Ad Understanding Abilities of Contrastive  Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.94, \"y\": 7.702}, {\"title\": \"Outliers and Calibration Sets have Diminishing Effect on Quantization of  Modern LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.559, \"y\": 2.205}, {\"title\": \"Self-Augmented Preference Optimization: Off-Policy Paradigms for  Language Model Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.522, \"y\": 0.529}, {\"title\": \"Ovis: Structural Embedding Alignment for Multimodal Large Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.282, \"y\": 7.414}, {\"title\": \"Improving code-mixed hate detection by native sample mixing: A case  study for Hindi-English code-mixed scenario\", \"topic\": \"Bias in Language Models\", \"x\": 2.479, \"y\": 3.634}, {\"title\": \"Joint Embeddings for Graph Instruction Tuning\", \"topic\": \"Named Entity Recognition\", \"x\": 6.619, \"y\": 5.909}, {\"title\": \"Unraveling and Mitigating Retriever Inconsistencies in  Retrieval-Augmented Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.408, \"y\": 4.428}, {\"title\": \"Position Coupling: Leveraging Task Structure for Improved Length  Generalization of Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.587, \"y\": 2.717}, {\"title\": \"Passage-specific Prompt Tuning for Passage Reranking in Question  Answering with Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.506, \"y\": 4.421}, {\"title\": \"Reward-based Input Construction for Cross-document Relation Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.249, \"y\": 6.497}, {\"title\": \"Shotluck Holmes: A Family of Efficient Small-Scale Large Language Vision  Models For Video Captioning and Summarization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.783, \"y\": 7.406}, {\"title\": \"ToxVidLLM: A Multimodal LLM-based Framework for Toxicity Detection in  Code-Mixed Videos\", \"topic\": \"Bias in Language Models\", \"x\": 2.599, \"y\": 3.274}, {\"title\": \"Leveraging Large Language Models for Entity Matching\", \"topic\": \"Named Entity Recognition\", \"x\": 6.397, \"y\": 6.198}, {\"title\": \"FineRadScore: A Radiology Report Line-by-Line Evaluation Technique  Generating Corrections with Severity Scores\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.162, \"y\": 7.95}, {\"title\": \"Bi-Directional Transformers vs. word2vec: Discovering Vulnerabilities in  Lifted Compiled Code\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.603, \"y\": 0.781}, {\"title\": \"Masked Language Modeling Becomes Conditional Density Estimation for  Tabular Data Synthesis\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.96, \"y\": 0.521}, {\"title\": \"GAMedX: Generative AI-based Medical Entity Data Extractor Using Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.378, \"y\": 7.387}, {\"title\": \"The Point of View of a Sentiment: Towards Clinician Bias Detection in  Psychiatric Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.499, \"y\": 6.621}, {\"title\": \"Perplexed by Perplexity: Perplexity-Based Data Pruning With Small  Reference Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.636, \"y\": 2.369}, {\"title\": \"An Automatic Question Usability Evaluation Toolkit\", \"topic\": \"Large Language Models in Education\", \"x\": 6.521, \"y\": 2.625}, {\"title\": \"Automated Generation and Tagging of Knowledge Components from  Multiple-Choice Questions\", \"topic\": \"Large Language Models in Education\", \"x\": 6.537, \"y\": 2.383}, {\"title\": \"How Multilingual Are Large Language Models Fine-Tuned for Translation?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.591, \"y\": 4.578}, {\"title\": \"SPOT: Text Source Prediction from Originality Score Thresholding\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.896, \"y\": 1.538}, {\"title\": \"Deep Learning Approaches for Detecting Adversarial Cyberbullying and  Hate Speech in Social Networks\", \"topic\": \"Bias in Language Models\", \"x\": 2.453, \"y\": 3.35}, {\"title\": \"Transfer Q Star: Principled Decoding for LLM Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.703, \"y\": 0.591}, {\"title\": \"Phantom: General Trigger Attacks on Retrieval Augmented Language  Generation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.269, \"y\": 0.763}, {\"title\": \"Enhancing Antibiotic Stewardship using a Natural Language Approach for  Better Feature Representation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.21, \"y\": 7.215}, {\"title\": \"Jailbreaking Large Language Models Against Moderation Guardrails via  Cipher Characters\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.048, \"y\": 0.478}, {\"title\": \"SeamlessExpressiveLM: Speech Language Model for Expressive  Speech-to-Speech Translation with Chain-of-Thought\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.041, \"y\": 5.771}, {\"title\": \"Investigating the Robustness of LLMs on Math Word Problems\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.665, \"y\": 1.209}, {\"title\": \"From Zero to Hero: Cold-Start Anomaly Detection\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.553, \"y\": 1.154}, {\"title\": \"Xwin-LM: Strong and Scalable Alignment Practice for LLMs\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.643, \"y\": 0.605}, {\"title\": \"Hallucination-Free? Assessing the Reliability of Leading AI Legal  Research Tools\", \"topic\": \"Legal NLP\", \"x\": 4.388, \"y\": 4.481}, {\"title\": \"S3D: A Simple and Cost-Effective Self-Speculative Decoding Scheme for  Low-Memory GPUs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.541, \"y\": 3.059}, {\"title\": \"Large Language Models Can Self-Improve At Web Agent Tasks\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.338, \"y\": 1.633}, {\"title\": \"Group Robust Preference Optimization in Reward-free RLHF\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.409, \"y\": 0.52}, {\"title\": \"ETHER: Efficient Finetuning of Large-Scale Models with Hyperplane  Reflections\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.728, \"y\": 1.85}, {\"title\": \"IsraParlTweet: The Israeli Parliamentary and Twitter Resource\", \"topic\": \"Bias in Language Models\", \"x\": 3.42, \"y\": 3.757}, {\"title\": \"Evaluating Large Language Model Biases in Persona-Steered Generation\", \"topic\": \"Bias in Language Models\", \"x\": 3.909, \"y\": 2.833}, {\"title\": \"TS-Align: A Teacher-Student Collaborative Framework for Scalable  Iterative Finetuning of Large Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.966, \"y\": 1.102}, {\"title\": \"PostDoc: Generating Poster from a Long Multimodal Document Using Deep  Submodular Optimization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.185, \"y\": 7.004}, {\"title\": \"Jina CLIP: Your CLIP Model Is Also Your Text Retriever\", \"topic\": \"Multimodal Language Models\", \"x\": 8.401, \"y\": 7.132}, {\"title\": \"TAIA: Large Language Models are Out-of-Distribution Data Learners\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.787, \"y\": 2.442}, {\"title\": \"Iterative Feature Boosting for Explainable Speech Emotion Recognition\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.511, \"y\": 5.344}, {\"title\": \"Language Models Need Inductive Biases to Count Inductively\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.402, \"y\": 2.872}, {\"title\": \"Fill in the Gap! Combining Self-supervised Representation Learning with  Neural Audio Synthesis for Speech Inpainting\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.394, \"y\": 6.01}, {\"title\": \"Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in  Code Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.121, \"y\": 0.098}, {\"title\": \"The Fine-Tuning Paradox: Boosting Translation Quality Without  Sacrificing LLM Abilities\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.692, \"y\": 4.494}, {\"title\": \"Student Answer Forecasting: Transformer-Driven Answer Choice Prediction  for Language Learning\", \"topic\": \"Large Language Models in Education\", \"x\": 6.581, \"y\": 2.333}, {\"title\": \"Would I Lie To You? Inference Time Alignment of Language Models using  Direct Preference Heads\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.511, \"y\": 0.679}, {\"title\": \"Safe Multi-agent Reinforcement Learning with Natural Language  Constraints\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.9, \"y\": 1.196}, {\"title\": \"Efficient LLM-Jailbreaking by Introducing Visual Modality\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.045, \"y\": 0.558}, {\"title\": \"Kernel Language Entropy: Fine-grained Uncertainty Quantification for  LLMs from Semantic Similarities\", \"topic\": \"Large Language Models in Education\", \"x\": 6.403, \"y\": 3.113}, {\"title\": \"Improved Out-of-Scope Intent Classification with Dual Encoding and  Threshold-based Re-Classification\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.395, \"y\": 3.47}, {\"title\": \"GenKubeSec: LLM-Based Kubernetes Misconfiguration Detection,  Localization, Reasoning, and Remediation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.463, \"y\": 0.743}, {\"title\": \"ExU: AI Models for Examining Multilingual Disinformation Narratives and  Understanding their Spread\", \"topic\": \"Bias in Language Models\", \"x\": 3.537, \"y\": 3.844}, {\"title\": \"Similarity is Not All You Need: Endowing Retrieval Augmented Generation  with Multi Layered Thoughts\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.194, \"y\": 4.476}, {\"title\": \"From Words to Actions: Unveiling the Theoretical Underpinnings of  LLM-Driven Autonomous Systems\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.969, \"y\": 1.256}, {\"title\": \"DevEval: A Manually-Annotated Code Generation Benchmark Aligned with  Real-World Code Repositories\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.152, \"y\": 0.035}, {\"title\": \"Improve Student's Reasoning Generalizability through Cascading  Decomposed CoTs Distillation\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.546, \"y\": 1.876}, {\"title\": \"Just Rewrite It Again: A Post-Processing Method for Enhanced Semantic  Similarity and Privacy Preservation of Differentially Private Rewritten Text\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.64, \"y\": 0.389}, {\"title\": \"SLM as Guardian: Pioneering AI Safety with Small Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.791, \"y\": 1.212}, {\"title\": \"PDDLEGO: Iterative Planning in Textual Environments\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.326, \"y\": 1.431}, {\"title\": \"From Symbolic Tasks to Code Generation: Diversification Yields Better  Task Performers\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.25, \"y\": 0.447}, {\"title\": \"Dataflow-Guided Retrieval Augmentation for Repository-Level Code  Completion\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.024, \"y\": 0.109}, {\"title\": \"Enhancing Reinforcement Learning with Label-Sensitive Reward for Natural  Language Understanding\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.669, \"y\": 0.974}, {\"title\": \"Beyond Imitation: Learning Key Reasoning Steps from Dual  Chain-of-Thoughts in Reasoning Distillation\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.442, \"y\": 1.82}, {\"title\": \"Enhancing Large Vision Language Models with Self-Training on Image  Comprehension\", \"topic\": \"Multimodal Language Models\", \"x\": 8.099, \"y\": 7.737}, {\"title\": \"Significance of Chain of Thought in Gender Bias Mitigation for  English-Dravidian Machine Translation\", \"topic\": \"Bias in Language Models\", \"x\": 3.211, \"y\": 2.699}, {\"title\": \"One Token Can Help! Learning Scalable and Pluggable Virtual Tokens for  Retrieval-Augmented Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.422, \"y\": 4.498}, {\"title\": \"Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.194, \"y\": 7.959}, {\"title\": \"Unlearning Climate Misinformation in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.717, \"y\": 3.778}, {\"title\": \"Unlocking the Potential of Large Language Models for Clinical Text  Anonymization: A Comparative Study\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.661, \"y\": 0.348}, {\"title\": \"STAT: Shrinking Transformers After Training\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.98, \"y\": 2.57}, {\"title\": \"Cascade-Aware Training of Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.218, \"y\": 2.77}, {\"title\": \"Stress-Testing Capability Elicitation With Password-Locked Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.593, \"y\": 0.779}, {\"title\": \"One-Shot Safety Alignment for Large Language Models via Optimal  Dualization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.166, \"y\": 0.642}, {\"title\": \"CheXpert Plus: Augmenting a Large Chest X-ray Dataset with Text  Radiology Reports, Patient Demographics and Additional Image Formats\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.303, \"y\": 8.115}, {\"title\": \"Preference Learning Algorithms Do Not Learn Preference Rankings\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.416, \"y\": 0.54}, {\"title\": \"Conveyor: Efficient Tool-aware LLM Serving with Tool Partial Execution\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.451, \"y\": 2.839}, {\"title\": \"A Full-duplex Speech Dialogue Scheme Based On Large Language Models\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.156, \"y\": 3.227}, {\"title\": \"Critical Learning Periods: Leveraging Early Training Dynamics for  Efficient Data Pruning\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.715, \"y\": 4.493}, {\"title\": \"Deep Learning for Assessment of Oral Reading Fluency\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.27, \"y\": 5.819}, {\"title\": \"Adaptive In-conversation Team Building for Language Model Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.945, \"y\": 1.66}, {\"title\": \"X-VILA: Cross-Modality Alignment for Large Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.568, \"y\": 7.08}, {\"title\": \"LLMs Meet Multimodal Generation and Editing: A Survey\", \"topic\": \"Multimodal Language Models\", \"x\": 8.487, \"y\": 7.005}, {\"title\": \"MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model  Series\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.179, \"y\": 3.857}, {\"title\": \"Are Large Language Models Chameleons?\", \"topic\": \"Bias in Language Models\", \"x\": 4.195, \"y\": 2.621}, {\"title\": \"Robust Preference Optimization through Reward Model Distillation\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.496, \"y\": 0.515}, {\"title\": \"Matryoshka Query Transformer for Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.207, \"y\": 7.513}, {\"title\": \"Integrating Multi-scale Contextualized Information for Byte-based Neural  Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.816, \"y\": 4.424}, {\"title\": \"PediatricsGPT: Large Language Models as Chinese Medical Assistants for  Pediatric Applications\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.023, \"y\": 7.601}, {\"title\": \"AlchemistCoder: Harmonizing and Eliciting Code Capability by Hindsight  Tuning on Multi-source Data\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.15, \"y\": 0.092}, {\"title\": \"Weak-to-Strong Search: Align Large Language Models via Searching over  Small Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.568, \"y\": 0.741}, {\"title\": \"Faster Cascades via Speculative Decoding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.481, \"y\": 3.25}, {\"title\": \"Lower Bounds on the Expressivity of Recurrent Neural Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.209, \"y\": 2.9}, {\"title\": \"WRDScore: New Metric for Evaluation of Natural Language Generation  Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.4, \"y\": 3.666}, {\"title\": \"VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on  Long Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.758, \"y\": 7.449}, {\"title\": \"MetaToken: Detecting Hallucination in Image Descriptions by Meta  Classification\", \"topic\": \"Multimodal Language Models\", \"x\": 8.358, \"y\": 8.046}, {\"title\": \"PathReasoner: Modeling Reasoning Path with Equivalent Extension for  Logical Question Answering\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.362, \"y\": 1.92}, {\"title\": \"Faithful Chart Summarization with ChaTS-Pi\", \"topic\": \"Multimodal Language Models\", \"x\": 7.401, \"y\": 7.255}, {\"title\": \"Multi-stage Retrieve and Re-rank Model for Automatic Medical Coding  Recommendation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.219, \"y\": 7.558}, {\"title\": \"Auxiliary Knowledge-Induced Learning for Automatic Multi-Label Medical  Document Classification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.281, \"y\": 7.564}, {\"title\": \"Cephalo: Multi-Modal Vision-Language Models for Bio-Inspired Materials  Analysis and Design\", \"topic\": \"Multimodal Language Models\", \"x\": 7.099, \"y\": 7.206}, {\"title\": \"DiveR-CT: Diversity-enhanced Red Teaming with Relaxing Constraints\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.396, \"y\": 0.777}, {\"title\": \"EasyAnimate: A High-Performance Long Video Generation Method based on  Transformer Architecture\", \"topic\": \"Multimodal Language Models\", \"x\": 8.747, \"y\": 6.9}, {\"title\": \"Encoding Hierarchical Schema via Concept Flow for Multifaceted Ideology  Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.299, \"y\": 3.701}, {\"title\": \"Are You Sure? Rank Them Again: Repeated Ranking For Better Preference  Datasets\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.343, \"y\": 0.763}, {\"title\": \"Kestrel: Point Grounding Multimodal LLM for Part-Aware 3D  Vision-Language Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.038, \"y\": 7.318}, {\"title\": \"Understanding and Addressing the Under-Translation Problem from the  Perspective of Decoding Objective\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.944, \"y\": 4.826}, {\"title\": \"Towards Faithful Chain-of-Thought: Large Language Models are Bridging  Reasoners\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.363, \"y\": 2.215}, {\"title\": \"Are queries and keys always relevant? A case study on Transformer wave  functions\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.463, \"y\": 2.723}, {\"title\": \"Toxicity Detection for Free\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.754, \"y\": 1.111}, {\"title\": \"LMO-DP: Optimizing the Randomization Mechanism for Differentially  Private Fine-Tuning (Large) Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.846, \"y\": 0.186}, {\"title\": \"Genshin: General Shield for Natural Language Processing with Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.023, \"y\": 1.335}, {\"title\": \"Reverse Image Retrieval Cues Parametric Memory in Multimodal LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.861, \"y\": 7.507}, {\"title\": \"CtrlA: Adaptive Retrieval-Augmented Generation via Probe-Guided Control\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.231, \"y\": 4.039}, {\"title\": \"Contextual Position Encoding: Learning to Count What's Important\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.566, \"y\": 3.117}, {\"title\": \"Efficient Model-agnostic Alignment via Bayesian Persuasion\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.753, \"y\": 0.828}, {\"title\": \"Calibrating Reasoning in Language Models with Internal Consistency\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.192, \"y\": 2.366}, {\"title\": \"Efficient Preference-based Reinforcement Learning via Aligned Experience  Estimation\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.536, \"y\": 0.644}, {\"title\": \"Can GPT Redefine Medical Understanding? Evaluating GPT on Biomedical  Machine Reading Comprehension\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.063, \"y\": 7.117}, {\"title\": \"LLM-based Hierarchical Concept Decomposition for Interpretable  Fine-Grained Image Classification\", \"topic\": \"Multimodal Language Models\", \"x\": 8.02, \"y\": 7.635}, {\"title\": \"Understanding Intrinsic Socioeconomic Biases in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.328, \"y\": 2.771}, {\"title\": \"Are PPO-ed Language Models Hackable?\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.158, \"y\": 0.75}, {\"title\": \"Training LLMs to Better Self-Debug and Explain Code\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.052, \"y\": 0.258}, {\"title\": \"JADS: A Framework for Self-supervised Joint Aspect Discovery and  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.007, \"y\": 5.126}, {\"title\": \"Hardware-Aware Parallel Prompt Decoding for Memory-Efficient  Acceleration of LLM Inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.486, \"y\": 3.162}, {\"title\": \"BioBERT-based Deep Learning and Merged ChemProt-DrugProt for Enhanced  Biomedical Relation Extraction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.108, \"y\": 7.0}, {\"title\": \"Low-rank finetuning for LLMs: A fairness perspective\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.559, \"y\": 1.937}, {\"title\": \"Decoding moral judgement from text: a pilot study\", \"topic\": \"Bias in Language Models\", \"x\": 4.0, \"y\": 2.201}, {\"title\": \"It's Not a Modality Gap: Characterizing and Addressing the Contrastive  Gap\", \"topic\": \"Multimodal Language Models\", \"x\": 8.31, \"y\": 7.3}, {\"title\": \"Automatic detection of cognitive impairment in elderly people using an  entertainment chatbot with Natural Language Processing capabilities\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.366, \"y\": 6.764}, {\"title\": \"Learning diverse attacks on large language models for robust red-teaming  and safety tuning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.385, \"y\": 0.865}, {\"title\": \"LLMs and Memorization: On Quality and Specificity of Copyright  Compliance\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.419, \"y\": 1.186}, {\"title\": \"Why are Visually-Grounded Language Models Bad at Image Classification?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.271, \"y\": 7.641}, {\"title\": \"Don't Forget to Connect! Improving RAG with Graph-based Reranking\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.214, \"y\": 4.625}, {\"title\": \"RACCooN: Remove, Add, and Change Video Content with Auto-Generated  Narratives\", \"topic\": \"Multimodal Language Models\", \"x\": 8.594, \"y\": 6.927}, {\"title\": \"QUEST: Quality-Aware Metropolis-Hastings Sampling for Machine  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.753, \"y\": 4.758}, {\"title\": \"OwLore: Outlier-weighed Layerwise Sampled Low-Rank Projection for  Memory-Efficient LLM Fine-tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.72, \"y\": 1.849}, {\"title\": \"Towards a theory of how the structure of language is acquired by deep  neural networks\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.931, \"y\": 2.909}, {\"title\": \"MMCTAgent: Multi-modal Critical Thinking Agent Framework for Complex  Visual Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.77, \"y\": 7.583}, {\"title\": \"Faithful Logical Reasoning via Symbolic Chain-of-Thought\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.341, \"y\": 1.829}, {\"title\": \"Can Automatic Metrics Assess High-Quality Translations?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.591, \"y\": 4.934}, {\"title\": \"Semantic are Beacons: A Semantic Perspective for Unveiling  Parameter-Efficient Fine-Tuning in Knowledge Learning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.342, \"y\": 2.062}, {\"title\": \"Text-only Synthesis for Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.487, \"y\": 7.266}, {\"title\": \"Active Use of Latent Constituency Representation in both Humans and  Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.521, \"y\": 3.109}, {\"title\": \"A Human-Like Reasoning Framework for Multi-Phases Planning Task with  Large Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.424, \"y\": 1.501}, {\"title\": \"Hate Speech Detection with Generalizable Target-aware Fairness\", \"topic\": \"Bias in Language Models\", \"x\": 2.485, \"y\": 3.303}, {\"title\": \"The Knesset Corpus: An Annotated Corpus of Hebrew Parliamentary  Proceedings\", \"topic\": \"Bias in Language Models\", \"x\": 3.688, \"y\": 3.564}, {\"title\": \"ATM: Adversarial Tuning Multi-agent System Makes a Robust  Retrieval-Augmented Generator\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.084, \"y\": 4.158}, {\"title\": \"Context is Important in Depressive Language: A Study of the Interaction  Between the Sentiments and Linguistic Markers in Reddit Discussions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.149, \"y\": 6.093}, {\"title\": \"PRFashion24: A Dataset for Sentiment Analysis of Fashion Products  Reviews in Persian\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.988, \"y\": 4.958}, {\"title\": \"Spanish and LLM Benchmarks: is MMLU Lost in Translation?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.014, \"y\": 4.231}, {\"title\": \"Edinburgh Clinical NLP at MEDIQA-CORR 2024: Guiding Large Language  Models with Hints\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.052, \"y\": 7.35}, {\"title\": \"MultiADE: A Multi-domain Benchmark for Adverse Drug Event Extraction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.161, \"y\": 6.917}, {\"title\": \"Exploring Context Window of Large Language Models via Decomposed  Positional Vectors\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.373, \"y\": 3.121}, {\"title\": \"Source Echo Chamber: Exploring the Escalation of Source Bias in User,  Data, and Recommender System Feedback Loop\", \"topic\": \"Bias in Language Models\", \"x\": 3.508, \"y\": 2.99}, {\"title\": \"Aligning to Thousands of Preferences via System Message Generalization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.502, \"y\": 0.771}, {\"title\": \"Yuan 2.0-M32: Mixture of Experts with Attention Router\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.844, \"y\": 2.237}, {\"title\": \"Recent Trends in Personalized Dialogue Generation: A Review of Datasets,  Methodologies, and Evaluations\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.187, \"y\": 3.344}, {\"title\": \"Knowledge Circuits in Pretrained Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.586, \"y\": 2.638}, {\"title\": \"Online Merging Optimizers for Boosting Rewards and Mitigating Tax in  Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.593, \"y\": 0.583}, {\"title\": \"The Evolution of Multimodal Model Architectures\", \"topic\": \"Multimodal Language Models\", \"x\": 8.299, \"y\": 7.34}, {\"title\": \"Enhancing Emotion Recognition in Conversation through Emotional  Cross-Modal Fusion and Inter-class Contrastive Learning\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.507, \"y\": 5.335}, {\"title\": \"Arithmetic Reasoning with LLM: Prolog Generation & Permutation\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.67, \"y\": 1.254}, {\"title\": \"Seeing the Image: Prioritizing Visual Correlation by Contrastive  Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.324, \"y\": 7.433}, {\"title\": \"I-LLM: Efficient Integer-Only Inference for Fully-Quantized Low-Bit  Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.542, \"y\": 2.305}, {\"title\": \"Benchmarks Underestimate the Readiness of Multi-lingual Dialogue Agents\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.202, \"y\": 3.296}, {\"title\": \"Personalized Steering of Large Language Models: Versatile Steering  Vectors Through Bi-directional Preference Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.263, \"y\": 1.134}, {\"title\": \"More Than Catastrophic Forgetting: Integrating General Capabilities For  Domain-Specific LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.98, \"y\": 2.003}, {\"title\": \"Conv-CoA: Improving Open-domain Question Answering in Large Language  Models via Conversational Chain-of-Action\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.646, \"y\": 4.486}, {\"title\": \"The Impossibility of Fair LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.393, \"y\": 2.666}, {\"title\": \"Judgement Citation Retrieval using Contextual Similarity\", \"topic\": \"Legal NLP\", \"x\": 4.453, \"y\": 4.676}, {\"title\": \"TransVIP: Speech to Speech Translation System with Voice and Isochrony  Preservation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.046, \"y\": 5.644}, {\"title\": \"Exploring Activation Patterns of Parameters in Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.908, \"y\": 2.768}, {\"title\": \"Multi-objective Representation for Numbers in Clinical Narratives Using  CamemBERT-bio\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.138, \"y\": 7.431}, {\"title\": \"Stochastic Adversarial Networks for Multi-Domain Text Classification\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.059, \"y\": 1.377}, {\"title\": \"Generative Query Reformulation Using Ensemble Prompting, Document  Fusion, and Relevance Feedback\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.01, \"y\": 4.611}, {\"title\": \"InversionView: A General-Purpose Method for Reading Information from  Neural Activations\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.287, \"y\": 2.742}, {\"title\": \"Cross-Modal Safety Alignment: Is textual unlearning all you need?\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.427, \"y\": 0.804}, {\"title\": \"A Framework for Multi-modal Learning: Jointly Modeling Inter- &  Intra-Modality Dependencies\", \"topic\": \"Multimodal Language Models\", \"x\": 8.272, \"y\": 7.346}, {\"title\": \"Explainable machine learning multi-label classification of Spanish legal  judgements\", \"topic\": \"Legal NLP\", \"x\": 4.325, \"y\": 4.528}, {\"title\": \"LoRA-XS: Low-Rank Adaptation with Extremely Small Number of Parameters\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.826, \"y\": 1.755}, {\"title\": \"RAGSys: Item-Cold-Start Recommender as RAG System\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.436, \"y\": 4.234}, {\"title\": \"Matryoshka Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.972, \"y\": 7.656}, {\"title\": \"Privacy-Aware Visual Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.817, \"y\": 0.178}, {\"title\": \"BIOSCAN-CLIP: Bridging Vision and Genomics for Biodiversity Monitoring  at Scale\", \"topic\": \"Multimodal Language Models\", \"x\": 7.842, \"y\": 7.247}, {\"title\": \"QUB-Cirdan at \\\"Discharge Me!\\\": Zero shot discharge letter generation by  open-source LLM\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.136, \"y\": 7.271}, {\"title\": \"The Expressive Capacity of State Space Models: A Formal Language  Perspective\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.519, \"y\": 2.986}, {\"title\": \"MindMerger: Efficient Boosting LLM Reasoning in non-English Languages\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.429, \"y\": 2.175}, {\"title\": \"Unlocking the Secrets of Linear Complexity Sequence Model from A Unified  Perspective\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.83, \"y\": 3.086}, {\"title\": \"Various Lengths, Constant Speed: Efficient Language Modeling with  Lightning Attention\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.904, \"y\": 2.976}, {\"title\": \"Federating Dynamic Models using Early-Exit Architectures for Automatic  Speech Recognition on Heterogeneous Clients\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.086, \"y\": 0.051}, {\"title\": \"A One-Layer Decoder-Only Transformer is a Two-Layer RNN: With an  Application to Certified Robustness\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.676, \"y\": 2.811}, {\"title\": \"Exploring and steering the moral compass of Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.092, \"y\": 2.223}, {\"title\": \"Detecting Deceptive Dark Patterns in E-commerce Platforms\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.218, \"y\": 1.237}, {\"title\": \"An NLP Crosswalk Between the Common Core State Standards and NAEP Item  Specifications\", \"topic\": \"Large Language Models in Education\", \"x\": 6.463, \"y\": 2.552}, {\"title\": \"ViSpeR: Multilingual Audio-Visual Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.055, \"y\": 6.294}, {\"title\": \"RLAIF-V: Aligning MLLMs through Open-Source AI Feedback for Super GPT-4V  Trustworthiness\", \"topic\": \"Multimodal Language Models\", \"x\": 8.299, \"y\": 8.044}, {\"title\": \"Aligning LLMs through Multi-perspective User Preference Ranking-based  Feedback for Programming Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.314, \"y\": 4.089}, {\"title\": \"Stop! In the Name of Flaws: Disentangling Personal Names and  Sociodemographic Attributes in NLP\", \"topic\": \"Bias in Language Models\", \"x\": 3.243, \"y\": 2.793}, {\"title\": \"Exploiting the Layered Intrinsic Dimensionality of Deep Models for  Practical Adversarial Training\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.999, \"y\": 1.136}, {\"title\": \"TEII: Think, Explain, Interact and Iterate with Large Language Models to  Solve Cross-lingual Emotion Detection\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.572, \"y\": 5.309}, {\"title\": \"LLM-Optic: Unveiling the Capabilities of Large Language Models for  Universal Visual Grounding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.017, \"y\": 7.373}, {\"title\": \"ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off  Code Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.147, \"y\": 0.115}, {\"title\": \"Generation and human-expert evaluation of interesting research ideas  using knowledge graphs and large language models\", \"topic\": \"Text Summarization\", \"x\": 5.103, \"y\": 6.056}, {\"title\": \"EMERGE: Integrating RAG for Improved Multimodal EHR Predictive Modeling\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.205, \"y\": 7.593}, {\"title\": \"The Multi-Range Theory of Translation Quality Measurement: MQM scoring  models and Statistical Quality Control\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.621, \"y\": 4.965}, {\"title\": \"Empowering Large Language Models to Set up a Knowledge Retrieval Indexer  via Self-Learning\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.46, \"y\": 4.665}, {\"title\": \"VoCoT: Unleashing Visually Grounded Multi-Step Reasoning in Large  Multi-Modal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.647, \"y\": 7.67}, {\"title\": \"Can Large Language Models Faithfully Express Their Intrinsic Uncertainty  in Words?\", \"topic\": \"Large Language Models in Education\", \"x\": 6.515, \"y\": 2.99}, {\"title\": \"Match, Compare, or Select? An Investigation of Large Language Models for  Entity Matching\", \"topic\": \"Named Entity Recognition\", \"x\": 6.352, \"y\": 6.299}, {\"title\": \"Mixture of Modality Knowledge Experts for Robust Multi-modal Knowledge  Graph Completion\", \"topic\": \"Named Entity Recognition\", \"x\": 6.713, \"y\": 6.006}, {\"title\": \"On Mesa-Optimization in Autoregressively Trained Transformers: Emergence  and Capability\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.341, \"y\": 2.779}, {\"title\": \"Performance evaluation of Reddit Comments using Machine Learning and  Natural Language Processing methods in Sentiment Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.128, \"y\": 4.838}, {\"title\": \"Entity Alignment with Noisy Annotations from Large Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.487, \"y\": 6.278}, {\"title\": \"AutoCV: Empowering Reasoning with Automated Process Labeling via  Confidence Variation\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.349, \"y\": 1.64}, {\"title\": \"LLM-Based Cooperative Agents using Information Relevance and Plan  Validation\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.087, \"y\": 1.414}, {\"title\": \"Large Scale Knowledge Washing\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.022, \"y\": 0.564}, {\"title\": \"Zamba: A Compact 7B SSM Hybrid Model\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.98, \"y\": 2.693}, {\"title\": \"SymTax: Symbiotic Relationship and Taxonomy Fusion for Effective  Citation Recommendation\", \"topic\": \"Text Summarization\", \"x\": 5.099, \"y\": 5.945}, {\"title\": \"Implicit Multimodal Alignment: On the Generalization of Frozen LLMs to  Multimodal Inputs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.314, \"y\": 7.495}, {\"title\": \"A Systematic Review of Federated Generative Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.945, \"y\": 0.133}, {\"title\": \"Triple Preference Optimization: Achieving Better Alignment with Less  Data in a Single Step Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.534, \"y\": 0.514}, {\"title\": \"Crossmodal ASR Error Correction with Discrete Speech Units\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.551, \"y\": 5.785}, {\"title\": \"Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal  Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.066, \"y\": 0.6}, {\"title\": \"A Survey of Multimodal Large Language Model from A Data-centric  Perspective\", \"topic\": \"Multimodal Language Models\", \"x\": 8.289, \"y\": 7.331}, {\"title\": \"Let Silence Speak: Enhancing Fake News Detection with Generated Comments  from Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.465, \"y\": 3.718}, {\"title\": \"Cocktail: A Comprehensive Information Retrieval Benchmark with  LLM-Generated Documents Integration\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.021, \"y\": 4.601}, {\"title\": \"Chain of Tools: Large Language Model is an Automatic Multi-tool Learner\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.588, \"y\": 1.348}, {\"title\": \"LoQT: Low Rank Adapters for Quantized Training\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.309, \"y\": 2.109}, {\"title\": \"Meta-Task Planning for Language Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.232, \"y\": 1.436}, {\"title\": \"M$^3$CoT: A Novel Benchmark for Multi-Domain Multi-step Multi-modal  Chain-of-Thought\", \"topic\": \"Multimodal Language Models\", \"x\": 7.793, \"y\": 7.621}, {\"title\": \"Development of an open education resources (OER) system: a comparative  analysis and implementation approach\", \"topic\": \"Large Language Models in Education\", \"x\": 6.236, \"y\": 2.316}, {\"title\": \"CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and  Evaluation Framework for Chinese Psychological Counseling\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 2.988, \"y\": 6.406}, {\"title\": \"M-RAG: Reinforcing Large Language Model Performance through  Retrieval-Augmented Generation with Multiple Partitions\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.347, \"y\": 4.13}, {\"title\": \"Code Repair with LLMs gives an Exploration-Exploitation Tradeoff\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.207, \"y\": 0.033}, {\"title\": \"Augmented Risk Prediction for the Onset of Alzheimer's Disease from  Electronic Health Records with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.094, \"y\": 7.249}, {\"title\": \"KG-FIT: Knowledge Graph Fine-Tuning Upon Open-World Knowledge\", \"topic\": \"Named Entity Recognition\", \"x\": 6.661, \"y\": 5.93}, {\"title\": \"Tensor Attention Training: Provably Efficient Learning of Higher-order  Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.809, \"y\": 2.814}, {\"title\": \"SpinQuant: LLM quantization with learned rotations\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.611, \"y\": 2.267}, {\"title\": \"Multi-Reference Preference Optimization for Large Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.495, \"y\": 0.569}, {\"title\": \"STRIDE: A Tool-Assisted LLM Agent Framework for Strategic and  Interactive Decision-Making\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.68, \"y\": 1.803}, {\"title\": \"Comparative Analysis of Open-Source Language Models in Summarizing  Medical Text Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.142, \"y\": 7.233}, {\"title\": \"Confidence Under the Hood: An Investigation into the  Confidence-Probability Alignment in Large Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.608, \"y\": 2.872}, {\"title\": \"Picturing Ambiguity: A Visual Twist on the Winograd Schema Challenge\", \"topic\": \"Multimodal Language Models\", \"x\": 8.071, \"y\": 7.476}, {\"title\": \"AutoManual: Generating Instruction Manuals by LLM Agents via Interactive  Environmental Learning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.094, \"y\": 1.397}, {\"title\": \"No Two Devils Alike: Unveiling Distinct Mechanisms of Fine-tuning  Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.487, \"y\": 0.7}, {\"title\": \"Towards Unlocking Insights from Logbooks Using AI\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.882, \"y\": 4.651}, {\"title\": \"GeneAgent: Self-verification Language Agent for Gene Set Knowledge  Discovery using Domain Databases\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.891, \"y\": 6.913}, {\"title\": \"InstructPatentGPT: Training patent language models to follow  instructions with human feedback\", \"topic\": \"Legal NLP\", \"x\": 4.643, \"y\": 4.715}, {\"title\": \"Accelerating Inference of Retrieval-Augmented Generation via Sparse  Context Selection\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.332, \"y\": 4.342}, {\"title\": \"iREL at SemEval-2024 Task 9: Improving Conventional Prompting Methods  for Brain Teasers\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.263, \"y\": 2.097}, {\"title\": \"How Well Do Deep Learning Models Capture Human Concepts? The Case of the  Typicality Effect\", \"topic\": \"Multimodal Language Models\", \"x\": 8.146, \"y\": 7.715}, {\"title\": \"SNOBERT: A Benchmark for clinical notes entity linking in the SNOMED CT  clinical terminology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.321, \"y\": 7.44}, {\"title\": \"Keypoint-based Progressive Chain-of-Thought Distillation for LLMs\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.514, \"y\": 1.884}, {\"title\": \"SPP: Sparsity-Preserved Parameter-Efficient Fine-Tuning for Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.014, \"y\": 2.133}, {\"title\": \"Evaluating the Adversarial Robustness of Retrieval-Based In-Context  Learning for Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.205, \"y\": 0.911}, {\"title\": \"Enhancing Visual-Language Modality Alignment in Large Vision Language  Models via Self-Improvement\", \"topic\": \"Multimodal Language Models\", \"x\": 8.051, \"y\": 7.755}, {\"title\": \"Transformers represent belief state geometry in their residual stream\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.964, \"y\": 2.903}, {\"title\": \"SLIDE: A Framework Integrating Small and Large Language Models for  Open-Domain Dialogues Evaluation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.319, \"y\": 3.342}, {\"title\": \"AMGPT: a Large Language Model for Contextual Querying in Additive  Manufacturing\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.038, \"y\": 4.724}, {\"title\": \"Hacc-Man: An Arcade Game for Jailbreaking LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.049, \"y\": 0.416}, {\"title\": \"Basis Selection: Low-Rank Decomposition of Pretrained Large Language  Models for Target Applications\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.184, \"y\": 2.331}, {\"title\": \"Large Language Model Pruning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.927, \"y\": 2.383}, {\"title\": \"Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus  Creation and Model Development\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.234, \"y\": 7.358}, {\"title\": \"GPT is Not an Annotator: The Necessity of Human Annotation in Fairness  Benchmark Construction\", \"topic\": \"Bias in Language Models\", \"x\": 3.19, \"y\": 2.768}, {\"title\": \"Optimizing Large Language Models for OpenAPI Code Completion\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.102, \"y\": 0.086}, {\"title\": \"Clustered Retrieved Augmented Generation (CRAG)\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.25, \"y\": 4.391}, {\"title\": \"VDGD: Mitigating LVLM Hallucinations in Cognitive Prompts by Bridging  the Visual Perception Gap\", \"topic\": \"Multimodal Language Models\", \"x\": 8.363, \"y\": 8.118}, {\"title\": \"GECKO: Generative Language Model for English, Code and Korean\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.975, \"y\": 3.873}, {\"title\": \"M4U: Evaluating Multilingual Understanding and Reasoning for Large  Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.769, \"y\": 7.618}, {\"title\": \"Profiling checkpointing schedules in adjoint ST-AD\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.194, \"y\": 0.141}, {\"title\": \"Synergizing In-context Learning with Hints for End-to-end Task-oriented  Dialog Systems\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.188, \"y\": 3.263}, {\"title\": \"Certifiably Robust RAG against Retrieval Corruption\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.37, \"y\": 0.786}, {\"title\": \"Adapting PromptORE for Modern History: Information Extraction from  Hispanic Monarchy Documents of the XVIth Century\", \"topic\": \"Named Entity Recognition\", \"x\": 6.208, \"y\": 6.553}, {\"title\": \"Sparse Matrix in Large Language Model Fine-tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.803, \"y\": 1.847}, {\"title\": \"Mosaic Memory: Fuzzy Duplication in Copyright Traps for Large Language  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.281, \"y\": 0.988}, {\"title\": \"Learning Beyond Pattern Matching? Assaying Mathematical Understanding in  LLMs\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.686, \"y\": 1.182}, {\"title\": \"Emergence of a High-Dimensional Abstraction Phase in Language  Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.996, \"y\": 2.941}, {\"title\": \"Benchmarking Pre-trained Large Language Models' Potential Across Urdu  NLP tasks\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.916, \"y\": 4.342}, {\"title\": \"Leveraging Large Language Models for Semantic Query Processing in a  Scholarly Knowledge Graph\", \"topic\": \"Text Summarization\", \"x\": 5.268, \"y\": 5.875}, {\"title\": \"Pipeline Parallelism with Controllable Memory\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.315, \"y\": 2.768}, {\"title\": \"SCALM: Towards Semantic Caching for Automated Chat Services with Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.345, \"y\": 2.881}, {\"title\": \"Decompose and Aggregate: A Step-by-Step Interpretable Evaluation  Framework\", \"topic\": \"Large Language Models in Education\", \"x\": 6.42, \"y\": 3.197}, {\"title\": \"Stacking Your Transformers: A Closer Look at Model Growth for Efficient  LLM Pre-Training\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.437, \"y\": 2.509}, {\"title\": \"DeTikZify: Synthesizing Graphics Programs for Scientific Figures and  Sketches with TikZ\", \"topic\": \"Multimodal Language Models\", \"x\": 7.776, \"y\": 7.16}, {\"title\": \"Towards Understanding How Transformer Perform Multi-step Reasoning with  Matching Operation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.815, \"y\": 2.605}, {\"title\": \"Large Language Model Sentinel: Advancing Adversarial Robustness by LLM  Agent\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.132, \"y\": 1.025}, {\"title\": \"DEEM: Diffusion Models Serve as the Eyes of Large Language Models for  Image Perception\", \"topic\": \"Multimodal Language Models\", \"x\": 8.49, \"y\": 7.581}, {\"title\": \"Denoising LM: Pushing the Limits of Error Correction Models for Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.672, \"y\": 5.682}, {\"title\": \"How Culturally Aware are Vision-Language Models?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.25, \"y\": 7.661}, {\"title\": \"Decoding at the Speed of Thought: Harnessing Parallel Decoding of  Lexical Units for LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.373, \"y\": 3.283}, {\"title\": \"Cross-Task Defense: Instruction-Tuning LLMs for Content Safety\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.768, \"y\": 1.187}, {\"title\": \"SOAP: Enhancing Efficiency of Generated Code via Self-Optimization\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.126, \"y\": 0.079}, {\"title\": \"VB-LoRA: Extreme Parameter Efficient Fine-Tuning with Vector Banks\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.831, \"y\": 1.77}, {\"title\": \"Athena: Efficient Block-Wise Post-Training Quantization for Large  Language Models Using Second-Order Matrix Derivative Information\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.511, \"y\": 2.244}, {\"title\": \"LocMoE+: Enhanced Router with Token Feature Awareness for Efficient LLM  Pre-Training\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.834, \"y\": 2.234}, {\"title\": \"Machine Unlearning in Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.977, \"y\": 0.776}, {\"title\": \"CulturePark: Boosting Cross-cultural Understanding in Large Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.07, \"y\": 2.684}, {\"title\": \"Intelligent Go-Explore: Standing on the Shoulders of Giant Foundation  Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.304, \"y\": 1.371}, {\"title\": \"Efficient Biomedical Entity Linking: Clinical Text Standardization with  Low-Resource Techniques\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.63, \"y\": 7.23}, {\"title\": \"Generalizable and Scalable Multistage Biomedical Concept Normalization  Leveraging Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.306, \"y\": 7.259}, {\"title\": \"Towards Better Understanding of In-Context Learning Ability from  In-Context Uncertainty Quantification\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.915, \"y\": 2.713}, {\"title\": \"CHARP: Conversation History AwaReness Probing for Knowledge-grounded  Dialogue Systems\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.504, \"y\": 3.394}, {\"title\": \"Contrastive and Consistency Learning for Neural Noisy-Channel Model in  Spoken Language Understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.273, \"y\": 5.508}, {\"title\": \"Dissociation of Faithful and Unfaithful Reasoning in LLMs\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.206, \"y\": 2.214}, {\"title\": \"Optimizing example selection for retrieval-augmented machine translation  with translation memories\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.826, \"y\": 4.644}, {\"title\": \"Promoting Constructive Deliberation: Reframing for Receptiveness\", \"topic\": \"Bias in Language Models\", \"x\": 3.842, \"y\": 3.745}, {\"title\": \"Multilingual Prosody Transfer: Comparing Supervised & Transfer Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.089, \"y\": 5.871}, {\"title\": \"CrossVoice: Crosslingual Prosody Preserving Cascade-S2ST using Transfer  Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.162, \"y\": 5.82}, {\"title\": \"Aya 23: Open Weight Releases to Further Multilingual Progress\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.206, \"y\": 4.001}, {\"title\": \"AGRaME: Any-Granularity Ranking with Multi-Vector Embeddings\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.201, \"y\": 4.557}, {\"title\": \"OAC: Output-adaptive Calibration for Accurate Post-training Quantization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.597, \"y\": 2.203}, {\"title\": \"Extracting Prompts by Inverting LLM Outputs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.333, \"y\": 0.668}, {\"title\": \"Linking In-context Learning in Transformers to Human Episodic Memory\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.594, \"y\": 2.8}, {\"title\": \"LOVA3: Learning to Visual Question Answering, Asking and Assessment\", \"topic\": \"Multimodal Language Models\", \"x\": 7.873, \"y\": 7.66}, {\"title\": \"Harmful Speech Detection by Language Models Exhibits Gender-Queer  Dialect Bias\", \"topic\": \"Bias in Language Models\", \"x\": 2.673, \"y\": 3.237}, {\"title\": \"A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image  Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.301, \"y\": 8.067}, {\"title\": \"From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by  Step\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.559, \"y\": 1.712}, {\"title\": \"HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language  Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.561, \"y\": 4.53}, {\"title\": \"Implicit Personalization in Language Models: A Systematic Study\", \"topic\": \"Bias in Language Models\", \"x\": 3.527, \"y\": 2.545}, {\"title\": \"Can LLMs Solve longer Math Word Problems Better?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.702, \"y\": 1.221}, {\"title\": \"Smart Bilingual Focused Crawling of Parallel Documents\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.939, \"y\": 4.653}, {\"title\": \"Pragmatic Feature Preferences: Learning Reward-Relevant Preferences from  Human Input\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.498, \"y\": 0.841}, {\"title\": \"Evaluating Large Language Models for Public Health Classification and  Extraction Tasks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.028, \"y\": 6.764}, {\"title\": \"SliM-LLM: Salience-Driven Mixed-Precision Quantization for Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.617, \"y\": 2.308}, {\"title\": \"SimPO: Simple Preference Optimization with a Reference-Free Reward\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.478, \"y\": 0.503}, {\"title\": \"CAPE: Context-Adaptive Positional Encoding for Length Extrapolation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.569, \"y\": 3.057}, {\"title\": \"Efficient Medical Question Answering with Knowledge-Augmented Question  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.785, \"y\": 7.279}, {\"title\": \"Calibrated Self-Rewarding Vision Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.226, \"y\": 7.947}, {\"title\": \"A FAIR and Free Prompt-based Research Assistant\", \"topic\": \"Text Summarization\", \"x\": 4.943, \"y\": 5.853}, {\"title\": \"Data Augmentation Techniques for Process Extraction from Scientific  Publications\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.165, \"y\": 6.515}, {\"title\": \"Representation noising effectively prevents harmful fine-tuning on LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.34, \"y\": 0.618}, {\"title\": \"Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating  Representative and Affinity Bias in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.619, \"y\": 2.801}, {\"title\": \"Exploring Alignment in Shared Cross-lingual Spaces\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.251, \"y\": 4.33}, {\"title\": \"Synthetic Data Generation for Intersectional Fairness by Leveraging  Hierarchical Group Structure\", \"topic\": \"Bias in Language Models\", \"x\": 3.128, \"y\": 2.785}, {\"title\": \"Unchosen Experts Can Contribute Too: Unleashing MoE Models' Power by  Self-Contrast\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.886, \"y\": 2.476}, {\"title\": \"Impact of Non-Standard Unicode Characters on Security and Comprehension  in Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.543, \"y\": 0.919}, {\"title\": \"MoGU: A Framework for Enhancing Safety of Open-Sourced LLMs While  Preserving Their Usability\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.3, \"y\": 0.568}, {\"title\": \"Which Information Matters? Dissecting Human-written Multi-document  Summaries with Partial Information Decomposition\", \"topic\": \"Text Summarization\", \"x\": 5.129, \"y\": 5.178}, {\"title\": \"Worldwide Federated Training of Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.087, \"y\": 0.059}, {\"title\": \"Exploring the use of a Large Language Model for data extraction in  systematic reviews: a rapid feasibility study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.341, \"y\": 6.785}, {\"title\": \"RaFe: Ranking Feedback Improves Query Rewriting for RAG\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.094, \"y\": 4.552}, {\"title\": \"Evaluation of the Programming Skills of Large Language Models\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.981, \"y\": 0.192}, {\"title\": \"Emotion Identification for French in Written Texts: Considering their  Modes of Expression as a Step Towards Text Complexity Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.724, \"y\": 5.251}, {\"title\": \"Data Mixing Made Efficient: A Bivariate Scaling Law for Language Model  Pretraining\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.353, \"y\": 2.767}, {\"title\": \"MiniCache: KV Cache Compression in Depth Dimension for Large Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.378, \"y\": 2.843}, {\"title\": \"JiuZhang3.0: Efficiently Improving Mathematical Reasoning by Training  Small Data Synthesis Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.75, \"y\": 1.167}, {\"title\": \"Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.995, \"y\": 1.35}, {\"title\": \"Improving Language Models Trained with Translated Data via Continual  Pre-Training and Dictionary Learning Analysis\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.342, \"y\": 4.401}, {\"title\": \"Let's Fuse Step by Step: A Generative Fusion Decoding Algorithm with  LLMs for Multi-modal Text Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.528, \"y\": 5.745}, {\"title\": \"EHR-SeqSQL : A Sequential Text-to-SQL Dataset For Interactively  Exploring Electronic Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.383, \"y\": 7.428}, {\"title\": \"Large Language Models' Detection of Political Orientation in Newspapers\", \"topic\": \"Bias in Language Models\", \"x\": 3.544, \"y\": 3.571}, {\"title\": \"From Text to Pixel: Advancing Long-Context Understanding in MLLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.075, \"y\": 7.31}, {\"title\": \"Federated Domain-Specific Knowledge Transfer on Large Language Models  Using Synthetic Data\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.01, \"y\": 0.085}, {\"title\": \"ChronosLex: Time-aware Incremental Training for Temporal Generalization  of Legal Classification Tasks\", \"topic\": \"Legal NLP\", \"x\": 4.424, \"y\": 4.565}, {\"title\": \"Agent Planning with World Knowledge Model\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.156, \"y\": 1.367}, {\"title\": \"S-Eval: Automatic and Adaptive Test Generation for Benchmarking Safety  Evaluation of Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.634, \"y\": 1.116}, {\"title\": \"Semantic-guided Prompt Organization for Universal Goal Hijacking against  LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.325, \"y\": 0.651}, {\"title\": \"Large Language Models-guided Dynamic Adaptation for Temporal Knowledge  Graph Reasoning\", \"topic\": \"Named Entity Recognition\", \"x\": 6.526, \"y\": 5.411}, {\"title\": \"Self-Taught Recognizer: Toward Unsupervised Adaptation for Speech  Foundation Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.596, \"y\": 5.799}, {\"title\": \"Super Tiny Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.798, \"y\": 2.892}, {\"title\": \"ViHateT5: Enhancing Hate Speech Detection in Vietnamese With A Unified  Text-to-Text Transformer Model\", \"topic\": \"Bias in Language Models\", \"x\": 2.437, \"y\": 3.423}, {\"title\": \"AlignGPT: Multi-modal Large Language Models with Adaptive Alignment  Capability\", \"topic\": \"Multimodal Language Models\", \"x\": 8.444, \"y\": 7.209}, {\"title\": \"Integrating Medical Imaging and Clinical Reports Using Multimodal Deep  Learning for Advanced Disease Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.408, \"y\": 8.05}, {\"title\": \"Distributed Speculative Inference of Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.508, \"y\": 3.055}, {\"title\": \"Large Language Models Can Self-Correct with Minimal Effort\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.052, \"y\": 2.136}, {\"title\": \"Structural Entities Extraction and Patient Indications Incorporation for  Chest X-ray Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.207, \"y\": 7.989}, {\"title\": \"PTA: Enhancing Multimodal Sentiment Analysis through Pipelined  Prediction and Translation-based Alignment\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.649, \"y\": 5.095}, {\"title\": \"$T^2$ of Thoughts: Temperature Tree Elicits Reasoning in Large Language  Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 6.976, \"y\": 1.715}, {\"title\": \"Exploration of Attention Mechanism-Enhanced Deep Learning Models in the  Mining of Medical Textual Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.173, \"y\": 7.456}, {\"title\": \"Your Large Language Models Are Leaving Fingerprints\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.778, \"y\": 1.691}, {\"title\": \"Use of natural language processing to extract and classify papillary  thyroid cancer features from surgical pathology reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.257, \"y\": 7.278}, {\"title\": \"Trajectory Volatility for Out-of-Distribution Detection in Mathematical  Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.731, \"y\": 1.249}, {\"title\": \"Refining Skewed Perceptions in Vision-Language Models through Visual  Representations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.3, \"y\": 7.621}, {\"title\": \"CIVICS: Building a Dataset for Examining Culturally-Informed Values in  Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.876, \"y\": 2.663}, {\"title\": \"DeTox: Toxic Subspace Projection for Model Editing\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.289, \"y\": 0.617}, {\"title\": \"On the Brittle Foundations of ReAct Prompting for Agentic Large Language  Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.48, \"y\": 1.781}, {\"title\": \"What is Your Data Worth to GPT? LLM-Scale Data Valuation with Influence  Functions\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.524, \"y\": 2.531}, {\"title\": \"Vikhr: The Family of Open-Source Instruction-Tuned Large Language Models  for Russian\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.885, \"y\": 3.955}, {\"title\": \"Why Not Transform Chat Large Language Models to Non-English?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.995, \"y\": 3.808}, {\"title\": \"TOPA: Extend Large Language Models for Video Understanding via Text-Only  Pre-Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.823, \"y\": 7.409}, {\"title\": \"Just rephrase it! Uncertainty estimation in closed-source language  models via multiple rephrased queries\", \"topic\": \"Large Language Models in Education\", \"x\": 6.62, \"y\": 3.027}, {\"title\": \"Image-of-Thought Prompting for Visual Reasoning Refinement in Multimodal  Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.755, \"y\": 7.669}, {\"title\": \"Automatically Identifying Local and Global Circuits with Linear  Computation Graphs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.053, \"y\": 2.683}, {\"title\": \"Semantic Density: Uncertainty Quantification in Semantic Space for Large  Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.425, \"y\": 3.151}, {\"title\": \"Towards Comprehensive and Efficient Post Safety Alignment of Large  Language Models via Safety Patching\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.033, \"y\": 1.139}, {\"title\": \"Getting More from Less: Large Language Models are Good Spontaneous  Multilingual Learners\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.976, \"y\": 4.045}, {\"title\": \"xRAG: Extreme Context Compression for Retrieval-augmented Generation  with One Token\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.468, \"y\": 4.339}, {\"title\": \"Grounding Toxicity in Real-World Events across Languages\", \"topic\": \"Bias in Language Models\", \"x\": 2.793, \"y\": 3.62}, {\"title\": \"CrossCheckGPT: Universal Hallucination Ranking for Multimodal Foundation  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.383, \"y\": 8.051}, {\"title\": \"Automated Evaluation of Retrieval-Augmented Language Models with  Task-Specific Exam Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.302, \"y\": 4.264}, {\"title\": \"COTET: Cross-view Optimal Transport for Knowledge Graph Entity Typing\", \"topic\": \"Named Entity Recognition\", \"x\": 6.639, \"y\": 5.943}, {\"title\": \"ConTrans: Weak-to-Strong Alignment Engineering via Concept  Transplantation\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.628, \"y\": 0.778}, {\"title\": \"FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation  Research\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.261, \"y\": 4.322}, {\"title\": \"CPE-Identifier: Automated CPE identification and CVE summaries  annotation with Deep Learning and NLP\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.415, \"y\": 1.166}, {\"title\": \"Annotation-Efficient Preference Optimization for Language Model  Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.389, \"y\": 0.575}, {\"title\": \"LIRE: listwise reward enhancement for preference alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.45, \"y\": 0.62}, {\"title\": \"Joint Optimization of Streaming and Non-Streaming Automatic Speech  Recognition with Multi-Decoder and Knowledge Distillation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.57, \"y\": 5.696}, {\"title\": \"Latent Space Alignment for Semantic Channel Equalization\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.892, \"y\": 1.576}, {\"title\": \"TrojanRAG: Retrieval-Augmented Generation Can Be Backdoor Driver in  Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.312, \"y\": 0.718}, {\"title\": \"360Zhinao Technical Report\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.695, \"y\": 2.09}, {\"title\": \"You don't understand me!: Comparing ASR results for L1 and L2 speakers  of Swedish\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.614, \"y\": 5.794}, {\"title\": \"AdpQ: A Zero-shot Calibration Free Adaptive Post Training Quantization  Method for LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.528, \"y\": 2.208}, {\"title\": \"Efficacy of ByT5 in Multilingual Translation of Biblical Texts for  Underrepresented Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.47, \"y\": 4.771}, {\"title\": \"Contextualized Automatic Speech Recognition with Dynamic Vocabulary\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.595, \"y\": 5.649}, {\"title\": \"''You should probably read this'': Hedge Detection in Text\", \"topic\": \"Bias in Language Models\", \"x\": 3.74, \"y\": 4.193}, {\"title\": \"KU-DMIS at EHRSQL 2024:Generating SQL query via question templatization  in EHR\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.471, \"y\": 7.384}, {\"title\": \"DiffNorm: Self-Supervised Normalization for Non-autoregressive  Speech-to-speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.303, \"y\": 5.804}, {\"title\": \"A Multilingual Similarity Dataset for News Article Frame\", \"topic\": \"Bias in Language Models\", \"x\": 3.349, \"y\": 4.01}, {\"title\": \"MELD-ST: An Emotion-aware Speech Translation Dataset\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.476, \"y\": 5.415}, {\"title\": \"Dataset Decomposition: Faster LLM Training with Variable Sequence Length  Curriculum\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.427, \"y\": 3.161}, {\"title\": \"How Reliable AI Chatbots are for Disease Prediction from Patient  Complaints?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.738, \"y\": 7.324}, {\"title\": \"Investigating Symbolic Capabilities of Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.743, \"y\": 1.419}, {\"title\": \"Modeling Real-Time Interactive Conversations as Timed Diarized  Transcripts\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.367, \"y\": 3.143}, {\"title\": \"Comparative Analysis of Different Efficient Fine Tuning Methods of Large  Language Models (LLMs) in Low-Resource Setting\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.348, \"y\": 2.084}, {\"title\": \"Mamo: a Mathematical Modeling Benchmark with Solvers\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.629, \"y\": 1.203}, {\"title\": \"Atomic Self-Consistency for Better Long Form Generations\", \"topic\": \"Large Language Models in Education\", \"x\": 6.122, \"y\": 3.414}, {\"title\": \"Towards Retrieval-Augmented Architectures for Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.363, \"y\": 7.448}, {\"title\": \"Reducing Transformer Key-Value Cache Size with Cross-Layer Attention\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.159, \"y\": 2.907}, {\"title\": \"Aggregation of Reasoning: A Hierarchical Framework for Enhancing Answer  Selection in Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.191, \"y\": 2.132}, {\"title\": \"G-DIG: Towards Gradient-based DIverse and hiGh-quality Instruction Data  Selection for Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.638, \"y\": 4.384}, {\"title\": \"Topic Modelling Case Law Using a Large Language Model and a New Taxonomy  for UK Law: AI Insights into Summary Judgment\", \"topic\": \"Legal NLP\", \"x\": 4.415, \"y\": 4.615}, {\"title\": \"Adversarial DPO: Harnessing Harmful Data for Reducing Toxicity with  Minimal Impact on Coherence and Evasiveness in Dialogue Agents\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.861, \"y\": 1.362}, {\"title\": \"Investigating Persuasion Techniques in Arabic: An Empirical Study  Leveraging Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.227, \"y\": 3.492}, {\"title\": \"Diffusion-RSCC: Diffusion Probabilistic Model for Change Captioning in  Remote Sensing Images\", \"topic\": \"Multimodal Language Models\", \"x\": 8.493, \"y\": 7.099}, {\"title\": \"Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple  Candidates for Efficient and Effective Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.337, \"y\": 4.711}, {\"title\": \"What Have We Achieved on Non-autoregressive Translation?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.814, \"y\": 4.741}, {\"title\": \"Unsupervised Multimodal Clustering for Semantics Discovery in Multimodal  Utterances\", \"topic\": \"Multimodal Language Models\", \"x\": 8.222, \"y\": 7.273}, {\"title\": \"The Echoes of Multilinguality: Tracing Cultural Value Shifts during LM  Fine-tuning\", \"topic\": \"Bias in Language Models\", \"x\": 4.035, \"y\": 2.646}, {\"title\": \"OLAPH: Improving Factuality in Biomedical Long-form Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.967, \"y\": 7.226}, {\"title\": \"A Survey on Multi-modal Machine Translation: Tasks, Methods and  Challenges\", \"topic\": \"Multimodal Language Models\", \"x\": 8.911, \"y\": 6.499}, {\"title\": \"Retrieval-Augmented Language Model for Extreme Multi-Label Knowledge  Graph Link Prediction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.651, \"y\": 5.672}, {\"title\": \"MentalQA: An Annotated Arabic Corpus for Questions and Answers of Mental  Healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.404, \"y\": 6.648}, {\"title\": \"Quantifying Emergence in Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.764, \"y\": 3.051}, {\"title\": \"Tiny Refinements Elicit Resilience: Toward Efficient Prefix-Model  Against LLM Red-Teaming\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.769, \"y\": 0.988}, {\"title\": \"Unlocking Data-free Low-bit Quantization with Matrix Decomposition for  KV Cache Compression\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.57, \"y\": 2.372}, {\"title\": \"Multi-domain Knowledge Graph Collaborative Pre-training and Prompt  Tuning for Diverse Downstream Tasks\", \"topic\": \"Named Entity Recognition\", \"x\": 6.783, \"y\": 5.443}, {\"title\": \"The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented  Generation (FutureDial-RAG)\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.385, \"y\": 3.584}, {\"title\": \"PyramidInfer: Pyramid KV Cache Compression for High-throughput LLM  Inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.357, \"y\": 2.844}, {\"title\": \"Sparse Autoencoders Enable Scalable and Reliable Circuit Identification  in Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.315, \"y\": 2.658}, {\"title\": \"GPT-4 Jailbreaks Itself with Near-Perfect Success Using Self-Explanation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.01, \"y\": 0.431}, {\"title\": \"Diverse and Effective Synthetic Data Generation for Adaptable Zero-Shot  Dialogue State Tracking\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.168, \"y\": 3.296}, {\"title\": \"Resolving Word Vagueness with Scenario-guided Adapter for Natural  Language Inference\", \"topic\": \"Multimodal Language Models\", \"x\": 7.883, \"y\": 7.529}, {\"title\": \"Targeted Multilingual Adaptation for Low-resource Language Families\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.205, \"y\": 4.133}, {\"title\": \"Thesis: Document Summarization with applications to Keyword extraction  and Image Retrieval\", \"topic\": \"Text Summarization\", \"x\": 5.092, \"y\": 5.173}, {\"title\": \"Question-Based Retrieval using Atomic Units for Enterprise RAG\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.241, \"y\": 4.428}, {\"title\": \"MathBench: Evaluating the Theory and Application Proficiency of LLMs  with a Hierarchical Mathematics Benchmark\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.696, \"y\": 1.195}, {\"title\": \"Modeling citation worthiness by using attention-based bidirectional long  short-term memory networks and interpretable models\", \"topic\": \"Text Summarization\", \"x\": 5.008, \"y\": 5.894}, {\"title\": \"Eliciting Problem Specifications via Large Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.336, \"y\": 1.715}, {\"title\": \"MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.787, \"y\": 1.732}, {\"title\": \"Imp: Highly Capable Large Multimodal Models for Mobile Devices\", \"topic\": \"Multimodal Language Models\", \"x\": 8.417, \"y\": 7.152}, {\"title\": \"DOP: Diagnostic-Oriented Prompting for Large Language Models in  Mathematical Correction\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.611, \"y\": 1.295}, {\"title\": \"Unveiling factors influencing judgment variation in Sentiment Analysis  with Natural Language Processing and Statistics\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.079, \"y\": 4.846}, {\"title\": \"Can AI Relate: Testing Large Language Model Response for Mental Health  Support\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.068, \"y\": 6.405}, {\"title\": \"A review on the use of large language models as virtual tutors\", \"topic\": \"Large Language Models in Education\", \"x\": 6.393, \"y\": 2.376}, {\"title\": \"RNG: Reducing Multi-level Noise and Multi-grained Semantic Gap for Joint  Multimodal Aspect-Sentiment Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.776, \"y\": 5.068}, {\"title\": \"Multiple-Choice Questions are Efficient and Robust LLM Evaluators\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.424, \"y\": 1.491}, {\"title\": \"FAME-MT Dataset: Formality Awareness Made Easy for Machine Translation  Purposes\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.408, \"y\": 4.829}, {\"title\": \"Biomedical Entity Linking for Dutch: Fine-tuning a Self-alignment BERT  Model on an Automatically Generated Wikipedia Corpus\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.642, \"y\": 7.218}, {\"title\": \"Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving  Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.72, \"y\": 4.795}, {\"title\": \"A Constraint-Enforcing Reward for Adversarial Attacks on Text  Classifiers\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.029, \"y\": 1.18}, {\"title\": \"Intuitive Fine-Tuning: Towards Simplifying Alignment into a Single  Process\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.484, \"y\": 0.474}, {\"title\": \"CoNLL#: Fine-grained Error Analysis and a Corrected Test Set for  CoNLL-03 English\", \"topic\": \"Named Entity Recognition\", \"x\": 6.155, \"y\": 6.853}, {\"title\": \"Large language models for sentiment analysis of newspaper articles  during COVID-19: The Guardian\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.478, \"y\": 4.693}, {\"title\": \"Beyond MLE: Investigating SEARNN for Low-Resourced Neural Machine  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.639, \"y\": 4.648}, {\"title\": \"Systematic Review on Healthcare Systems Engineering utilizing ChatGPT\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.048, \"y\": 6.958}, {\"title\": \"(Perhaps) Beyond Human Translation: Harnessing Multi-Agent Collaboration  for Translating Ultra-Long Literary Texts\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.535, \"y\": 4.887}, {\"title\": \"Large Language Models for Medicine: A Survey\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.069, \"y\": 7.325}, {\"title\": \"Token-wise Influential Training Data Retrieval for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.993, \"y\": 2.868}, {\"title\": \"OpenRLHF: An Easy-to-use, Scalable and High-performance RLHF Framework\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.534, \"y\": 2.077}, {\"title\": \"Your Transformer is Secretly Linear\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.862, \"y\": 2.707}, {\"title\": \"ColorFoil: Investigating Color Blindness in Large Vision and Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.167, \"y\": 7.904}, {\"title\": \"MeteoRA: Multiple-tasks Embedded LoRA for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.536, \"y\": 1.881}, {\"title\": \"Cyber Risks of Machine Translation Critical Errors : Arabic Mental  Health Tweets as a Case Study\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.923, \"y\": 1.894}, {\"title\": \"Inquire, Interact, and Integrate: A Proactive Agent Collaborative  Framework for Zero-Shot Multimodal Medical Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.455, \"y\": 8.117}, {\"title\": \"Continuous Predictive Modeling of Clinical Notes and ICD Codes in  Patient Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.118, \"y\": 7.528}, {\"title\": \"SLAB: Efficient Transformers with Simplified Linear Attention and  Progressive Re-parameterized Batch Normalization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.973, \"y\": 2.694}, {\"title\": \"Exploring the Capabilities of Prompted Large Language Models in  Educational and Assessment Applications\", \"topic\": \"Large Language Models in Education\", \"x\": 6.38, \"y\": 2.536}, {\"title\": \"SEEP: Training Dynamics Grounds Latent Representation Search for  Mitigating Backdoor Poisoning Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.176, \"y\": 0.957}, {\"title\": \"DaVinci at SemEval-2024 Task 9: Few-shot prompting GPT-3.5 for  Unconventional Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.315, \"y\": 2.011}, {\"title\": \"MSNER: A Multilingual Speech Dataset for Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 6.155, \"y\": 6.871}, {\"title\": \"SemEval-2024 Task 3: Multimodal Emotion Cause Analysis in Conversations\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.495, \"y\": 5.3}, {\"title\": \"DocReLM: Mastering Document Retrieval with Language Model\", \"topic\": \"Text Summarization\", \"x\": 5.198, \"y\": 5.941}, {\"title\": \"MAML-en-LLM: Model Agnostic Meta-Training of LLMs for Improved  In-Context Learning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.032, \"y\": 2.237}, {\"title\": \"MHPP: Exploring the Capabilities and Limitations of Language Models  Beyond Basic Code Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.094, \"y\": 0.169}, {\"title\": \"Large Language Models are Biased Reinforcement Learners\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.501, \"y\": 0.85}, {\"title\": \"Can Public LLMs be used for Self-Diagnosis of Medical Conditions ?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.815, \"y\": 7.234}, {\"title\": \"LeaPformer: Enabling Linear Transformers for Autoregressive and  Simultaneous Tasks via Learned Proportions\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.784, \"y\": 3.014}, {\"title\": \"MapCoder: Multi-Agent Code Generation for Competitive Problem Solving\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.061, \"y\": 0.303}, {\"title\": \"Enhancing Fine-Grained Image Classifications via Cascaded Vision  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.324, \"y\": 7.775}, {\"title\": \"EnterpriseEM: Fine-tuned Embeddings for Enterprise Semantic Search\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.346, \"y\": 4.859}, {\"title\": \"MBIAS: Mitigating Bias in Large Language Models While Retaining Context\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.832, \"y\": 1.599}, {\"title\": \"Uni-MoE: Scaling Unified Multimodal LLMs with Mixture of Experts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.348, \"y\": 7.246}, {\"title\": \"Cross-Language Assessment of Mathematical Capability of ChatGPT\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.575, \"y\": 1.359}, {\"title\": \"WisPerMed at \\\"Discharge Me!\\\": Advancing Text Generation in Healthcare  with Large Language Models, Dynamic Expert Selection, and Priming Techniques  on MIMIC-IV\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.063, \"y\": 7.534}, {\"title\": \"BadActs: A Universal Backdoor Defense in the Activation Space\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.194, \"y\": 0.896}, {\"title\": \"Transformer based neural networks for emotion recognition in  conversations\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.58, \"y\": 5.451}, {\"title\": \"Identifying and Aligning Medical Claims Made on Social Media with  Medical Evidence\", \"topic\": \"Bias in Language Models\", \"x\": 3.758, \"y\": 4.185}, {\"title\": \"MemeMQA: Multimodal Question Answering for Memes via Rationale-Based  Inferencing\", \"topic\": \"Multimodal Language Models\", \"x\": 7.668, \"y\": 7.574}, {\"title\": \"LexGen: Domain-aware Multilingual Lexicon Generation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.299, \"y\": 4.378}, {\"title\": \"Designing NLP Systems That Adapt to Diverse Worldviews\", \"topic\": \"Bias in Language Models\", \"x\": 3.795, \"y\": 2.857}, {\"title\": \"Towards Knowledge-Infused Automated Disease Diagnosis Assistant\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.714, \"y\": 7.323}, {\"title\": \"Automating PTSD Diagnostics in Clinical Interviews: Leveraging Large  Language Models for Trauma Assessments\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.233, \"y\": 6.759}, {\"title\": \"LG AI Research & KAIST at EHRSQL 2024: Self-Training Large Language  Models with Pseudo-Labeled Unanswerable Questions for a Reliable Text-to-SQL  System on EHRs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.282, \"y\": 7.446}, {\"title\": \"Towards Modular LLMs by Building and Reusing a Library of LoRAs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.372, \"y\": 1.927}, {\"title\": \"A Reproducibility Study on Quantifying Language Similarity: The Impact  of Missing Values in the URIEL Knowledge Base\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.793, \"y\": 4.47}, {\"title\": \"LLM-based Multi-Agent Reinforcement Learning: Current and Future  Directions\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.919, \"y\": 1.279}, {\"title\": \"Are Large Language Models Moral Hypocrites? A Study Based on Moral  Foundations\", \"topic\": \"Bias in Language Models\", \"x\": 4.077, \"y\": 2.194}, {\"title\": \"AudioSetMix: Enhancing Audio-Language Datasets with LLM-Assisted  Augmentations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.7, \"y\": 6.266}, {\"title\": \"Leveraging Discourse Structure for Extractive Meeting Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.098, \"y\": 4.932}, {\"title\": \"From Generalist to Specialist: Improving Large Language Models for  Medical Physics Using ARCoT\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.894, \"y\": 7.251}, {\"title\": \"The Unappreciated Role of Intent in Algorithmic Moderation of Social  Media Content\", \"topic\": \"Bias in Language Models\", \"x\": 2.443, \"y\": 3.223}, {\"title\": \"Generative Artificial Intelligence: A Systematic Review and Applications\", \"topic\": \"Large Language Models in Education\", \"x\": 6.573, \"y\": 3.796}, {\"title\": \"A Survey on Large Language Models with Multilingualism: Recent Advances  and New Frontiers\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.05, \"y\": 4.355}, {\"title\": \"COGNET-MD, an evaluation framework and dataset for Large Language Model  benchmarks in the medical domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.938, \"y\": 7.311}, {\"title\": \"Tailoring Vaccine Messaging with Common-Ground Opinions\", \"topic\": \"Bias in Language Models\", \"x\": 3.635, \"y\": 4.225}, {\"title\": \"ECR-Chain: Advancing Generative Language Models to Better Emotion-Cause  Reasoners through Reasoning Chains\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.518, \"y\": 5.41}, {\"title\": \"Petri nets in modelling glucose regulating processes in the liver\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.708, \"y\": 6.903}, {\"title\": \"Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging  General-Purpose Knowledge Graphs for Enriched Embeddings\", \"topic\": \"Named Entity Recognition\", \"x\": 6.706, \"y\": 5.821}, {\"title\": \"SBAAM! Eliminating Transcript Dependency in Automatic Subtitling\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.644, \"y\": 5.837}, {\"title\": \"Empowering Prior to Court Legal Analysis: A Transparent and Accessible  Dataset for Defensive Statement Classification and Interpretation\", \"topic\": \"Legal NLP\", \"x\": 4.36, \"y\": 4.501}, {\"title\": \"SynDy: Synthetic Dynamic Dataset Generation Framework for Misinformation  Tasks\", \"topic\": \"Bias in Language Models\", \"x\": 3.627, \"y\": 3.85}, {\"title\": \"Revolutionizing Process Mining: A Novel Architecture for ChatGPT  Integration and Enhanced User Experience through Optimized Prompt Engineering\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.103, \"y\": 2.014}, {\"title\": \"Realistic Evaluation of Toxicity in Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.768, \"y\": 1.357}, {\"title\": \"Layer-Condensed KV Cache for Efficient Inference of Large Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.222, \"y\": 2.844}, {\"title\": \"Medical Dialogue: A Survey of Categories, Methods, Evaluation and  Challenges\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.78, \"y\": 7.379}, {\"title\": \"Dynamic data sampler for cross-language transfer learning in large  language models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.042, \"y\": 3.999}, {\"title\": \"Feature-based Low-Rank Compression of Large Language Models via Bayesian  Optimization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.249, \"y\": 2.276}, {\"title\": \"Surgical Feature-Space Decomposition of LLMs: Why, When and How?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.041, \"y\": 2.426}, {\"title\": \"Enhancing Dialogue State Tracking Models through LLM-backed User-Agents  Simulation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.213, \"y\": 3.17}, {\"title\": \"Automatic News Generation and Fact-Checking System Based on Language  Processing\", \"topic\": \"Bias in Language Models\", \"x\": 3.633, \"y\": 3.769}, {\"title\": \"CNER: A tool Classifier of Named-Entity Relationships\", \"topic\": \"Named Entity Recognition\", \"x\": 6.135, \"y\": 6.683}, {\"title\": \"Rethinking ChatGPT's Success: Usability and Cognitive Behaviors Enabled  by Auto-regressive LLMs' Prompting\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.808, \"y\": 2.158}, {\"title\": \"Simultaneous Masking, Not Prompting Optimization: A Paradigm Shift in  Fine-tuning LLMs for Simultaneous Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.763, \"y\": 4.433}, {\"title\": \"Retrieving and Refining: A Hybrid Framework with Large Language Models  for Rare Disease Identification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.143, \"y\": 7.257}, {\"title\": \"Thinking Fair and Slow: On the Efficacy of Structured Prompts for  Debiasing Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.807, \"y\": 2.588}, {\"title\": \"Memory-efficient Energy-adaptive Inference of Pre-Trained Models on  Batteryless Embedded Systems\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.264, \"y\": 2.603}, {\"title\": \"AmazUtah_NLP at SemEval-2024 Task 9: A MultiChoice Question Answering  System for Commonsense Defying Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.348, \"y\": 2.059}, {\"title\": \"Fine-Tuning Large Vision-Language Models as Decision-Making Agents via  Reinforcement Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.816, \"y\": 7.376}, {\"title\": \"Keep It Private: Unsupervised Privatization of Online Text\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.571, \"y\": 0.335}, {\"title\": \"A Systematic Evaluation of Large Language Models for Natural Language  Generation Tasks\", \"topic\": \"Large Language Models in Education\", \"x\": 6.594, \"y\": 3.652}, {\"title\": \"Words as Trigger Points in Social Media Discussions\", \"topic\": \"Bias in Language Models\", \"x\": 3.07, \"y\": 3.622}, {\"title\": \"Building a Luganda Text-to-Speech Model From Crowdsourced Data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.039, \"y\": 5.941}, {\"title\": \"Hierarchical Attention Graph for Scientific Document Summarization in  Global and Local Level\", \"topic\": \"Text Summarization\", \"x\": 5.129, \"y\": 5.387}, {\"title\": \"Distilling Implicit Multimodal Knowledge into LLMs for Zero-Resource  Dialogue Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.02, \"y\": 7.328}, {\"title\": \"PyTorch-IE: Fast and Reproducible Prototyping for Information Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.64, \"y\": 6.566}, {\"title\": \"Listen Again and Choose the Right Answer: A New Paradigm for Automatic  Speech Recognition with Large Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.589, \"y\": 5.716}, {\"title\": \"TransMI: A Framework to Create Strong Baselines from Multilingual  Pretrained Language Models for Transliterated Data\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.297, \"y\": 4.467}, {\"title\": \"Crowdsourcing with Enhanced Data Quality Assurance: An Efficient  Approach to Mitigate Resource Scarcity Challenges in Training Large Language  Models for Healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.808, \"y\": 7.143}, {\"title\": \"Learnable Privacy Neurons Localization in Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.86, \"y\": 0.239}, {\"title\": \"On the relevance of pre-neural approaches in natural language processing  pedagogy\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.649, \"y\": 3.011}, {\"title\": \"DuetSim: Building User Simulator with Dual Large Language Models for  Task-Oriented Dialogues\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.225, \"y\": 3.208}, {\"title\": \"Chameleon: Mixed-Modal Early-Fusion Foundation Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.204, \"y\": 7.245}, {\"title\": \"SecureLLM: Using Compositionality to Build Provably Secure Language  Models for Private, Sensitive, and Secret Data\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.594, \"y\": 0.399}, {\"title\": \"Many-Shot In-Context Learning in Multimodal Foundation Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.355, \"y\": 7.467}, {\"title\": \"Optimization Techniques for Sentiment Analysis Based on LLM (GPT-3)\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.283, \"y\": 5.022}, {\"title\": \"Unsupervised Extractive Dialogue Summarization in Hyperdimensional Space\", \"topic\": \"Text Summarization\", \"x\": 5.174, \"y\": 4.966}, {\"title\": \"Leveraging Human Revisions for Improving Text-to-Layout Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.3, \"y\": 6.734}, {\"title\": \"Many Hands Make Light Work: Task-Oriented Dialogue System with  Module-Based Mixture-of-Experts\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.237, \"y\": 3.314}, {\"title\": \"A survey on fairness of large language models in e-commerce: progress,  application, and challenge\", \"topic\": \"Bias in Language Models\", \"x\": 3.327, \"y\": 2.679}, {\"title\": \"Spectral Editing of Activations for Large Language Model Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.551, \"y\": 0.958}, {\"title\": \"SOK-Bench: A Situated Video Reasoning Benchmark with Aligned Open-World  Knowledge\", \"topic\": \"Multimodal Language Models\", \"x\": 8.034, \"y\": 7.653}, {\"title\": \"STAR: A Benchmark for Situated Reasoning in Real-World Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.217, \"y\": 7.626}, {\"title\": \"Simulating Policy Impacts: Developing a Generative Scenario Writing  Method to Evaluate the Perceived Effects of Regulation\", \"topic\": \"Bias in Language Models\", \"x\": 4.009, \"y\": 2.662}, {\"title\": \"LoRA Learns Less and Forgets Less\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.674, \"y\": 1.83}, {\"title\": \"ParaNames 1.0: Creating an Entity Name Corpus for 400+ Languages using  Wikidata\", \"topic\": \"Named Entity Recognition\", \"x\": 6.174, \"y\": 6.789}, {\"title\": \"Beyond Flesch-Kincaid: Prompt-based Metrics Improve Difficulty  Classification of Educational Texts\", \"topic\": \"Large Language Models in Education\", \"x\": 6.498, \"y\": 2.692}, {\"title\": \"Facilitating Opinion Diversity through Hybrid NLP Approaches\", \"topic\": \"Bias in Language Models\", \"x\": 3.743, \"y\": 3.793}, {\"title\": \"PolygloToxicityPrompts: Multilingual Evaluation of Neural Toxic  Degeneration in Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.779, \"y\": 1.425}, {\"title\": \"Large Language Model Bias Mitigation from the Perspective of Knowledge  Editing\", \"topic\": \"Bias in Language Models\", \"x\": 3.167, \"y\": 2.664}, {\"title\": \"Prompting-based Synthetic Data Generation for Few-Shot Question  Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.819, \"y\": 4.339}, {\"title\": \"Comparing the Efficacy of GPT-4 and Chat-GPT in Mental Health Care: A  Blind Assessment of Large Language Models for Psychological Support\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.05, \"y\": 6.561}, {\"title\": \"IM-RAG: Multi-Round Retrieval-Augmented Generation Through Learning  Inner Monologues\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.1, \"y\": 4.112}, {\"title\": \"A Survey on Transformers in NLP with Focus on Efficiency\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.345, \"y\": 2.986}, {\"title\": \"Unveiling Hallucination in Text, Image, Video, and Audio Foundation  Models: A Comprehensive Survey\", \"topic\": \"Multimodal Language Models\", \"x\": 8.378, \"y\": 8.107}, {\"title\": \"Word Alignment as Preference for Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.691, \"y\": 4.795}, {\"title\": \"Bridging the gap in online hate speech detection: a comparative analysis  of BERT and traditional models for homophobic content identification on  X/Twitter\", \"topic\": \"Bias in Language Models\", \"x\": 2.501, \"y\": 3.445}, {\"title\": \"ALPINE: Unveiling the Planning Capability of Autoregressive Learning in  Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.522, \"y\": 1.508}, {\"title\": \"Adapting Abstract Meaning Representation Parsing to the Clinical  Narrative -- the SPRING THYME parser\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.313, \"y\": 7.397}, {\"title\": \"Continued Pretraining for Domain Adaptation of Wav2vec2.0 in Automatic  Speech Recognition for Elementary Math Classroom Settings\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.563, \"y\": 5.763}, {\"title\": \"A safety realignment framework via subspace-oriented model fusion for  large language models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.936, \"y\": 1.022}, {\"title\": \"A Japanese-Chinese Parallel Corpus Using Crowdsourcing for Web Mining\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.004, \"y\": 4.588}, {\"title\": \"Spatial Semantic Recurrent Mining for Referring Image Segmentation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.323, \"y\": 7.256}, {\"title\": \"LLM-Assisted Rule Based Machine Translation for Low/No-Resource  Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.502, \"y\": 4.568}, {\"title\": \"Challenges in Deploying Long-Context Transformers: A Theoretical Peak  Performance Analysis\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.363, \"y\": 2.877}, {\"title\": \"Refinement of an Epilepsy Dictionary through Human Annotation of  Health-related posts on Instagram\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.76, \"y\": 6.738}, {\"title\": \"From Text to Context: An Entailment Approach for News Stakeholder  Classification\", \"topic\": \"Bias in Language Models\", \"x\": 3.397, \"y\": 4.236}, {\"title\": \"Thinking Tokens for Language Modeling\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.84, \"y\": 1.466}, {\"title\": \"A Comprehensive Survey of Large Language Models and Multimodal Large  Language Models in Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.994, \"y\": 7.257}, {\"title\": \"QCRD: Quality-guided Contrastive Rationale Distillation for Large  Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.521, \"y\": 2.048}, {\"title\": \"Rethinking the adaptive relationship between Encoder Layers and Decoder  Layers\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.757, \"y\": 4.403}, {\"title\": \"Sonos Voice Control Bias Assessment Dataset: A Methodology for  Demographic Bias Assessment in Voice Assistants\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.404, \"y\": 6.002}, {\"title\": \"The Unseen Targets of Hate -- A Systematic Review of Hateful  Communication Datasets\", \"topic\": \"Bias in Language Models\", \"x\": 2.49, \"y\": 3.375}, {\"title\": \"Improving Transformers with Dynamically Composable Multi-Head Attention\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.863, \"y\": 2.931}, {\"title\": \"A Prompt-driven Task Planning Method for Multi-drones based on Large  Language Model\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.197, \"y\": 1.49}, {\"title\": \"Archimedes-AUEB at SemEval-2024 Task 5: LLM explains Civil Procedure\", \"topic\": \"Legal NLP\", \"x\": 4.437, \"y\": 4.326}, {\"title\": \"When Large Language Models Meet Optical Networks: Paving the Way for  Automation\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.411, \"y\": 1.605}, {\"title\": \"Enhancing Gender-Inclusive Machine Translation with Neomorphemes and  Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.103, \"y\": 2.641}, {\"title\": \"Impact of Stickers on Multimodal Chat Sentiment Analysis and Intent  Recognition: A New Task, Dataset and Baseline\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.551, \"y\": 5.022}, {\"title\": \"Investigating the 'Autoencoder Behavior' in Speech Self-Supervised  Models: a focus on HuBERT's Pretraining\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.726, \"y\": 5.878}, {\"title\": \"PromptMind Team at EHRSQL-2024: Improving Reliability of SQL Generation  using Ensemble LLMs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.429, \"y\": 7.459}, {\"title\": \"PromptMind Team at MEDIQA-CORR 2024: Improving Clinical Text Correction  with Error Categorization and LLM Ensembles\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.088, \"y\": 7.366}, {\"title\": \"Seal-Tools: Self-Instruct Tool Learning Dataset for Agent Tuning and  Detailed Benchmark\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.559, \"y\": 1.279}, {\"title\": \"SpeechGuard: Exploring the Adversarial Robustness of Multimodal Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.203, \"y\": 0.866}, {\"title\": \"A Decoupling and Aggregating Framework for Joint Extraction of Entities  and Relations\", \"topic\": \"Named Entity Recognition\", \"x\": 6.44, \"y\": 6.528}, {\"title\": \"SpeechVerse: A Large-scale Generalizable Audio Language Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.717, \"y\": 6.001}, {\"title\": \"Detecting Fallacies in Climate Misinformation: A Technocognitive  Approach to Identifying Misleading Argumentation\", \"topic\": \"Bias in Language Models\", \"x\": 3.719, \"y\": 3.95}, {\"title\": \"Silver-Tongued and Sundry: Exploring Intersectional Pronouns with  ChatGPT\", \"topic\": \"Bias in Language Models\", \"x\": 3.815, \"y\": 2.717}, {\"title\": \"Who's in and who's out? A case study of multimodal CLIP-filtering in  DataComp\", \"topic\": \"Bias in Language Models\", \"x\": 2.869, \"y\": 2.996}, {\"title\": \"CANTONMT: Investigating Back-Translation and Model-Switch Mechanisms for  Cantonese-English Neural Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.69, \"y\": 4.65}, {\"title\": \"Benchmarking Retrieval-Augmented Large Language Models in Biomedical  NLP: Application, Robustness, and Self-Awareness\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.298, \"y\": 7.168}, {\"title\": \"Discursive objection strategies in online comments: Developing a  classification schema and validating its training\", \"topic\": \"Bias in Language Models\", \"x\": 2.58, \"y\": 3.407}, {\"title\": \"Unveiling Social Media Comments with a Novel Named Entity Recognition  System for Identity Groups\", \"topic\": \"Bias in Language Models\", \"x\": 2.513, \"y\": 3.407}, {\"title\": \"Many-Shot Regurgitation (MSR) Prompting\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.376, \"y\": 1.231}, {\"title\": \"Multilingual Entity Linking Using Dense Retrieval\", \"topic\": \"Named Entity Recognition\", \"x\": 6.355, \"y\": 6.463}, {\"title\": \"Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large  Language Models in Code Generation from Scientific Plots\", \"topic\": \"Multimodal Language Models\", \"x\": 7.526, \"y\": 7.308}, {\"title\": \"AgentClinic: a multimodal agent benchmark to evaluate AI in simulated  clinical environments\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.787, \"y\": 7.553}, {\"title\": \"RAID: A Shared Benchmark for Robust Evaluation of Machine-Generated Text  Detectors\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.77, \"y\": 1.6}, {\"title\": \"PARDEN, Can You Repeat That? Defending against Jailbreaks via Repetition\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.221, \"y\": 0.76}, {\"title\": \"Russian-Language Multimodal Dataset for Automatic Summarization of  Scientific Papers\", \"topic\": \"Text Summarization\", \"x\": 5.198, \"y\": 5.361}, {\"title\": \"RLHF Workflow: From Reward Modeling to Online RLHF\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.648, \"y\": 0.759}, {\"title\": \"LGDE: Local Graph-based Dictionary Expansion\", \"topic\": \"Bias in Language Models\", \"x\": 3.291, \"y\": 4.125}, {\"title\": \"LlamaTurk: Adapting Open-Source Generative Large Language Models for  Low-Resource Language\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.18, \"y\": 3.882}, {\"title\": \"OpenLLM-Ro -- Technical Report on Open-source Romanian LLMs\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.05, \"y\": 3.882}, {\"title\": \"FastSAG: Towards Fast Non-Autoregressive Singing Accompaniment  Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.889, \"y\": 6.111}, {\"title\": \"An Empirical Study on the Robustness of Massively Multilingual Neural  Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.64, \"y\": 4.717}, {\"title\": \"Backdoor Removal for Generative Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.386, \"y\": 0.83}, {\"title\": \"METAREFLECTION: Learning Instructions for Language Agents using Past  Reflections\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.137, \"y\": 1.78}, {\"title\": \"ViWikiFC: Fact-Checking for Vietnamese Wikipedia-Based Textual Knowledge  Source\", \"topic\": \"Bias in Language Models\", \"x\": 3.805, \"y\": 3.863}, {\"title\": \"NoiseBench: Benchmarking the Impact of Real Label Noise on Named Entity  Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 6.165, \"y\": 6.817}, {\"title\": \"Control Token with Dense Passage Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.252, \"y\": 4.508}, {\"title\": \"MuMath-Code: Combining Tool-Use Large Language Models with  Multi-perspective Data Augmentation for Mathematical Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.681, \"y\": 1.247}, {\"title\": \"PromptLink: Leveraging Large Language Models for Cross-Source Biomedical  Concept Linking\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.542, \"y\": 7.153}, {\"title\": \"Evaluating large language models in medical applications: a survey\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.887, \"y\": 7.236}, {\"title\": \"Evaluation of Retrieval-Augmented Generation: A Survey\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.238, \"y\": 4.352}, {\"title\": \"Understanding the Rare Inflammatory Disease Using Large Language Models  and Social Media Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.536, \"y\": 6.521}, {\"title\": \"MathDivide: Improved mathematical reasoning by large language models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.688, \"y\": 1.206}, {\"title\": \"MedConceptsQA: Open Source Medical Concepts QA Benchmark\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.972, \"y\": 7.374}, {\"title\": \"Bottleneck-Minimal Indexing for Generative Document Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.983, \"y\": 4.632}, {\"title\": \"A Survey on Recent Advances in Conversational Data Generation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.191, \"y\": 3.358}, {\"title\": \"DuetRAG: Collaborative Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.232, \"y\": 4.475}, {\"title\": \"Large Language Models for Education: A Survey\", \"topic\": \"Large Language Models in Education\", \"x\": 6.412, \"y\": 2.263}, {\"title\": \"Advanced Natural-based interaction for the ITAlian language:  LLaMAntino-3-ANITA\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.384, \"y\": 0.746}, {\"title\": \"Survey on Reasoning Capabilities and Accessibility of Large Language  Models Using Biology-related Questions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.29, \"y\": 6.991}, {\"title\": \"A Turkish Educational Crossword Puzzle Generator\", \"topic\": \"Large Language Models in Education\", \"x\": 6.468, \"y\": 2.358}, {\"title\": \"Word-specific tonal realizations in Mandarin\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.289, \"y\": 5.835}, {\"title\": \"Evaluating Task-based Effectiveness of MLLMs on Charts\", \"topic\": \"Multimodal Language Models\", \"x\": 7.431, \"y\": 7.438}, {\"title\": \"Quite Good, but Not Enough: Nationality Bias in Large Language Models --  A Case Study of ChatGPT\", \"topic\": \"Bias in Language Models\", \"x\": 3.791, \"y\": 2.72}, {\"title\": \"EmoMix-3L: A Code-Mixed Dataset for Bangla-English-Hindi Emotion  Detection\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.588, \"y\": 5.102}, {\"title\": \"AIOS Compiler: LLM as Interpreter for Natural Language Programming and  Flow Programming of AI Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.966, \"y\": 0.558}, {\"title\": \"The Ghanaian NLP Landscape: A First Look\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.25, \"y\": 4.731}, {\"title\": \"Tackling Execution-Based Evaluation for NL2Bash\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.008, \"y\": 0.311}, {\"title\": \"Summarizing Radiology Reports Findings into Impressions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.175, \"y\": 7.888}, {\"title\": \"CANAL -- Cyber Activity News Alerting Language Model: Empirical Approach  vs. Expensive LLM\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.357, \"y\": 1.417}, {\"title\": \"Linearizing Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.848, \"y\": 2.887}, {\"title\": \"Value Augmented Sampling for Language Model Alignment and  Personalization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.498, \"y\": 0.625}, {\"title\": \"Federated Document Visual Question Answering: A Pilot Study\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.015, \"y\": 0.084}, {\"title\": \"Multimodal LLMs Struggle with Basic Visual Network Analysis: a VNA  Benchmark\", \"topic\": \"Multimodal Language Models\", \"x\": 7.614, \"y\": 7.475}, {\"title\": \"Characterizing the Accuracy - Efficiency Trade-off of Low-rank  Decomposition in Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.133, \"y\": 2.213}, {\"title\": \"What Can Natural Language Processing Do for Peer Review?\", \"topic\": \"Text Summarization\", \"x\": 4.886, \"y\": 5.803}, {\"title\": \"ATSumm: Auxiliary information enhanced approach for abstractive disaster  Tweet Summarization with sparse training data\", \"topic\": \"Text Summarization\", \"x\": 4.79, \"y\": 5.129}, {\"title\": \"LyS at SemEval-2024 Task 3: An Early Prototype for End-to-End Multimodal  Emotion Linking as Graph-Based Parsing\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.472, \"y\": 5.317}, {\"title\": \"Pseudo-Prompt Generating in Pre-trained Vision-Language Models for  Multi-Label Medical Image Classification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.35, \"y\": 8.17}, {\"title\": \"Improving Instruction Following in Language Models through Proxy-Based  Uncertainty Estimation\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.553, \"y\": 0.709}, {\"title\": \"Akal Badi ya Bias: An Exploratory Study of Gender Bias in Hindi Language  Technology\", \"topic\": \"Bias in Language Models\", \"x\": 3.322, \"y\": 2.723}, {\"title\": \"Decoding Emotions in Abstract Art: Cognitive Plausibility of CLIP in  Recognizing Color-Emotion Associations\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.604, \"y\": 5.217}, {\"title\": \"Aspect-oriented Consumer Health Answer Summarization\", \"topic\": \"Text Summarization\", \"x\": 4.979, \"y\": 5.329}, {\"title\": \"Pruning as a Domain-specific LLM Extractor\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.725, \"y\": 2.338}, {\"title\": \"XAI4LLM. Let Machine Learning Models and LLMs Collaborate for Enhanced  In-Context Learning in Healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.795, \"y\": 7.359}, {\"title\": \"For the Misgendered Chinese in Gender Bias Research: Multi-Task Learning  with Knowledge Distillation for Pinyin Name-Gender Prediction\", \"topic\": \"Bias in Language Models\", \"x\": 3.072, \"y\": 2.652}, {\"title\": \"SKVQ: Sliding-window Key and Value Cache Quantization for Large Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.604, \"y\": 2.492}, {\"title\": \"A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language  Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.164, \"y\": 4.379}, {\"title\": \"Lost in Transcription: Identifying and Quantifying the Accuracy Biases  of Automatic Speech Recognition Systems Against Disfluent Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.511, \"y\": 6.009}, {\"title\": \"Reddit-Impacts: A Named Entity Recognition Dataset for Analyzing  Clinical and Social Effects of Substance Use Derived from Social Media\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.544, \"y\": 6.513}, {\"title\": \"Muting Whisper: A Universal Acoustic Adversarial Attack on Speech  Foundation Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.238, \"y\": 0.911}, {\"title\": \"Selective Fine-tuning on LLM-labeled Data May Reduce Reliance on Human  Annotation: A Case Study Using Schedule-of-Event Table Detection\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.3, \"y\": 7.189}, {\"title\": \"HMT: Hierarchical Memory Transformer for Long Context Language  Processing\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.476, \"y\": 3.08}, {\"title\": \"A Mixture-of-Experts Approach to Few-Shot Task Transfer in Open-Ended  Text Worlds\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.927, \"y\": 1.36}, {\"title\": \"OpenBA-V2: Reaching 77.3% High Compression Ratio with Fast Multi-Stage  Pruning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.064, \"y\": 2.421}, {\"title\": \"Smurfs: Leveraging Multiple Proficiency Agents with Context-Efficiency  for Tool Planning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.446, \"y\": 1.413}, {\"title\": \"Efficient LLM Comparative Assessment: a Product of Experts Framework for  Pairwise Comparisons\", \"topic\": \"Large Language Models in Education\", \"x\": 6.365, \"y\": 3.125}, {\"title\": \"Towards a Path Dependent Account of Category Fluency\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.372, \"y\": 3.153}, {\"title\": \"Digital Diagnostics: The Potential Of Large Language Models In  Recognizing Symptoms Of Common Illnesses\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.844, \"y\": 7.206}, {\"title\": \"Towards a More Inclusive AI: Progress and Perspectives in Large Language  Model Training for the S\\u00e1mi Language\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.203, \"y\": 4.194}, {\"title\": \"Experimental Pragmatics with Machines: Testing LLM Predictions for the  Inferences of Plain and Embedded Disjunctions\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.507, \"y\": 2.692}, {\"title\": \"Similarity Guided Multimodal Fusion Transformer for Semantic Location  Prediction in Social Media\", \"topic\": \"Multimodal Language Models\", \"x\": 8.055, \"y\": 7.287}, {\"title\": \"Exploring the Potential of Human-LLM Synergy in Advancing Qualitative  Analysis: A Case Study on Mental-Illness Stigma\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.247, \"y\": 6.392}, {\"title\": \"Detecting Statements in Text: A Domain-Agnostic Few-Shot Solution\", \"topic\": \"Bias in Language Models\", \"x\": 3.628, \"y\": 4.199}, {\"title\": \"Evaluating the Efficacy of AI Techniques in Textual Anonymization: A  Comparative Study\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.668, \"y\": 0.362}, {\"title\": \"LangCell: Language-Cell Pre-training for Cell Identity Understanding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.89, \"y\": 7.046}, {\"title\": \"Hypothesis Testing Prompting Improves Deductive Reasoning in Large  Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.274, \"y\": 2.038}, {\"title\": \"G-SAP: Graph-based Structure-Aware Prompt Learning over Heterogeneous  Knowledge for Commonsense Reasoning\", \"topic\": \"Named Entity Recognition\", \"x\": 6.671, \"y\": 5.381}, {\"title\": \"Memory-Space Visual Prompting for Efficient Vision-Language Fine-Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.268, \"y\": 7.596}, {\"title\": \"Chain of Attack: a Semantic-Driven Contextual Multi-Turn attacker for  LLM\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.451, \"y\": 1.008}, {\"title\": \"Exploring the Capabilities of Large Multimodal Models on Dense Text\", \"topic\": \"Multimodal Language Models\", \"x\": 7.79, \"y\": 7.273}, {\"title\": \"Can We Use Large Language Models to Fill Relevance Judgment Holes?\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.954, \"y\": 4.588}, {\"title\": \"LLMs can Find Mathematical Reasoning Mistakes by Pedagogical  Chain-of-Thought\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.52, \"y\": 1.412}, {\"title\": \"Automatic question generation for propositional logical equivalences\", \"topic\": \"Large Language Models in Education\", \"x\": 6.598, \"y\": 2.221}, {\"title\": \"Special Characters Attack: Toward Scalable Training Data Extraction From  Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.64, \"y\": 0.677}, {\"title\": \"Cross-Care: Assessing the Healthcare Implications of Pre-training Data  on Language Model Bias\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.924, \"y\": 6.961}, {\"title\": \"Parameter-Efficient Fine-Tuning With Adapters\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.316, \"y\": 2.039}, {\"title\": \"Enhanced Review Detection and Recognition: A Platform-Agnostic Approach  with Application to Online Commerce\", \"topic\": \"Bias in Language Models\", \"x\": 3.184, \"y\": 4.283}, {\"title\": \"Using Machine Translation to Augment Multilingual Classification\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.435, \"y\": 4.684}, {\"title\": \"Poser: Unmasking Alignment Faking LLMs by Manipulating Their Internals\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.868, \"y\": 0.779}, {\"title\": \"Vidur: A Large-Scale Simulation Framework For LLM Inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.508, \"y\": 2.789}, {\"title\": \"Evaluating Students' Open-ended Written Responses with LLMs: Using the  RAG Framework for GPT-3.5, GPT-4, Claude-3, and Mistral-Large\", \"topic\": \"Large Language Models in Education\", \"x\": 6.396, \"y\": 2.602}, {\"title\": \"Analysis and prevention of AI-based phishing email attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.075, \"y\": 1.576}, {\"title\": \"Mitigating Exaggerated Safety in Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.074, \"y\": 1.209}, {\"title\": \"Interpretable Cross-Examination Technique (ICE-T): Using highly  informative features to boost LLM performance\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.934, \"y\": 7.054}, {\"title\": \"\\\"They are uncultured\\\": Unveiling Covert Harms and Social Threats in LLM  Generated Conversations\", \"topic\": \"Bias in Language Models\", \"x\": 3.325, \"y\": 2.798}, {\"title\": \"Krey\\u00f2l-MT: Building MT for Latin American, Caribbean and Colonial  African Creole Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.33, \"y\": 4.707}, {\"title\": \"Benchmarking Educational Program Repair\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.219, \"y\": 0.4}, {\"title\": \"QuaLLM: An LLM-based Framework to Extract Quantitative Insights from  Online Forums\", \"topic\": \"Bias in Language Models\", \"x\": 3.567, \"y\": 4.218}, {\"title\": \"KV-Runahead: Scalable Causal LLM Inference by Parallel Key-Value Cache  Generation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.426, \"y\": 2.877}, {\"title\": \"You Only Cache Once: Decoder-Decoder Architectures for Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.357, \"y\": 2.882}, {\"title\": \"CARE-SD: Classifier-based analysis for recognizing and eliminating  stigmatizing and doubt marker labels in electronic health records: model  development and validation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.676, \"y\": 6.884}, {\"title\": \"Air Gap: Protecting Privacy-Conscious Conversational Agents\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.393, \"y\": 0.489}, {\"title\": \"Seeds of Stereotypes: A Large-Scale Textual Analysis of Race and Gender  Associations with Diseases in Online Sources\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.667, \"y\": 6.61}, {\"title\": \"P-ICL: Point In-Context Learning for Named Entity Recognition with Large  Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.258, \"y\": 6.878}, {\"title\": \"Improving Long Text Understanding with Knowledge Distilled from  Summarization Model\", \"topic\": \"Text Summarization\", \"x\": 5.565, \"y\": 4.929}, {\"title\": \"VisionGraph: Leveraging Large Multimodal Models for Graph Theory  Problems in Visual Context\", \"topic\": \"Multimodal Language Models\", \"x\": 7.443, \"y\": 7.49}, {\"title\": \"ChatSOS: Vector Database Augmented Generative Question Answering  Assistant in Safety Engineering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.967, \"y\": 4.564}, {\"title\": \"Fine-tuning Pre-trained Named Entity Recognition Models For Indian  Languages\", \"topic\": \"Named Entity Recognition\", \"x\": 6.254, \"y\": 6.894}, {\"title\": \"Automated Conversion of Static to Dynamic Scheduler via Natural Language\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.546, \"y\": 1.157}, {\"title\": \"Multi-level Shared Knowledge Guided Learning for Knowledge Graph  Completion\", \"topic\": \"Named Entity Recognition\", \"x\": 6.689, \"y\": 5.917}, {\"title\": \"Utilizing Large Language Models to Generate Synthetic Data to Increase  the Performance of BERT-Based Neural Networks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.964, \"y\": 7.045}, {\"title\": \"Honeyfile Camouflage: Hiding Fake Files in Plain Sight\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.442, \"y\": 1.052}, {\"title\": \"Bridging the Bosphorus: Advancing Turkish Large Language Models through  Strategies for Low-Resource Language Adaptation and Benchmarking\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.675, \"y\": 4.127}, {\"title\": \"Towards a Theoretical Understanding of the 'Reversal Curse' via Training  Dynamics\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.815, \"y\": 2.779}, {\"title\": \"Folded context condensation in Path Integral formalism for infinite  context transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.704, \"y\": 2.986}, {\"title\": \"Language Modeling Using Tensor Trains\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.952, \"y\": 2.638}, {\"title\": \"QServe: W4A8KV4 Quantization and System Co-design for Efficient LLM  Serving\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.603, \"y\": 2.488}, {\"title\": \"NaturalCodeBench: Examining Coding Performance Mismatch on HumanEval and  Natural User Prompts\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.071, \"y\": 0.101}, {\"title\": \"A Transformer with Stack Attention\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.445, \"y\": 2.915}, {\"title\": \"Switchable Decision: Dynamic Neural Generation Networks\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.844, \"y\": 4.328}, {\"title\": \"Fast Exact Retrieval for Nearest-neighbor Lookup (FERN)\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.177, \"y\": 4.808}, {\"title\": \"DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts  Language Model\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.792, \"y\": 2.546}, {\"title\": \"The Silicon Ceiling: Auditing GPT's Race and Gender Biases in Hiring\", \"topic\": \"Bias in Language Models\", \"x\": 3.247, \"y\": 2.82}, {\"title\": \"Vision Mamba: A Comprehensive Survey and Taxonomy\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.849, \"y\": 3.273}, {\"title\": \"Learning To See But Forgetting To Follow: Visual Instruction Tuning  Makes LLMs More Prone To Jailbreak Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.075, \"y\": 0.776}, {\"title\": \"Revisiting character-level adversarial attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.06, \"y\": 1.101}, {\"title\": \"Granite Code Models: A Family of Open Foundation Models for Code  Intelligence\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.116, \"y\": 0.047}, {\"title\": \"Open Implementation and Study of BEST-RQ for Speech Processing\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.686, \"y\": 5.893}, {\"title\": \"Who Wrote This? The Key to Zero-Shot LLM-Generated Text Detection Is  GECScore\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.728, \"y\": 1.656}, {\"title\": \"Generating Feature Vectors from Phonetic Transcriptions in  Cross-Linguistic Data Formats\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.142, \"y\": 5.808}, {\"title\": \"Iterative Experience Refinement of Software-Developing Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.392, \"y\": 1.278}, {\"title\": \"D-NLP at SemEval-2024 Task 2: Evaluating Clinical Inference Capabilities  of Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.046, \"y\": 7.233}, {\"title\": \"LingML: Linguistic-Informed Machine Learning for Enhanced Fake News  Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.437, \"y\": 3.725}, {\"title\": \"MEDVOC: Vocabulary Adaptation for Fine-tuning Pre-trained Language  Models on Medical Text Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.403, \"y\": 7.046}, {\"title\": \"Fleet of Agents: Coordinated Problem Solving with Large Language Models  using Genetic Particle Filtering\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.461, \"y\": 1.49}, {\"title\": \"Enriched BERT Embeddings for Scholarly Publication Classification\", \"topic\": \"Text Summarization\", \"x\": 5.127, \"y\": 6.071}, {\"title\": \"Fine-grained Speech Sentiment Analysis in Chinese Psychological Support  Hotlines Based on Large-scale Pre-trained Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.293, \"y\": 6.369}, {\"title\": \"Policy Learning with a Language Bottleneck\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.877, \"y\": 1.322}, {\"title\": \"Optimizing Language Model's Reasoning Abilities with Weak Supervision\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.395, \"y\": 1.976}, {\"title\": \"FlashBack:Efficient Retrieval-Augmented Language Modeling for Long  Context Inference\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.441, \"y\": 4.353}, {\"title\": \"Evaluating Text Summaries Generated by Large Language Models Using  OpenAI's GPT\", \"topic\": \"Text Summarization\", \"x\": 5.188, \"y\": 5.089}, {\"title\": \"Utilizing GPT to Enhance Text Summarization: A Strategy to Minimize  Hallucinations\", \"topic\": \"Text Summarization\", \"x\": 5.151, \"y\": 5.078}, {\"title\": \"Sketch Then Generate: Providing Incremental User Feedback and Guiding  LLM Code Generation through Language-Oriented Code Sketches\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.915, \"y\": 0.284}, {\"title\": \"ESIHGNN: Event-State Interactions Infused Heterogeneous Graph Neural  Network for Conversational Emotion Recognition\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.486, \"y\": 5.281}, {\"title\": \"HAFFormer: A Hierarchical Attention-Free Framework for Alzheimer's  Disease Detection From Spontaneous Speech\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.926, \"y\": 2.849}, {\"title\": \"CleanGraph: Human-in-the-loop Knowledge Graph Refinement and Completion\", \"topic\": \"Named Entity Recognition\", \"x\": 6.46, \"y\": 5.485}, {\"title\": \"A Roadmap for Multilingual, Multimodal Domain Independent Deception  Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.51, \"y\": 3.593}, {\"title\": \"Guylingo: The Republic of Guyana Creole Corpora\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.187, \"y\": 4.681}, {\"title\": \"Detecting Anti-Semitic Hate Speech using Transformer-based Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 2.475, \"y\": 3.428}, {\"title\": \"On Adversarial Examples for Text Classification by Perturbing Latent  Representations\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.997, \"y\": 1.22}, {\"title\": \"Hire Me or Not? Examining Language Model's Behavior with Occupation  Attributes\", \"topic\": \"Bias in Language Models\", \"x\": 3.262, \"y\": 2.831}, {\"title\": \"Pose Priors from Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.432, \"y\": 6.994}, {\"title\": \"Large Language Models Reveal Information Operation Goals, Tactics, and  Narrative Frames\", \"topic\": \"Bias in Language Models\", \"x\": 3.39, \"y\": 3.798}, {\"title\": \"Language-Image Models with 3D Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 7.893, \"y\": 7.399}, {\"title\": \"GREEN: Generative Radiology Report Evaluation and Error Notation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.165, \"y\": 7.984}, {\"title\": \"Enabling High-Sparsity Foundational Llama Models with Efficient  Pretraining and Deployment\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.215, \"y\": 2.308}, {\"title\": \"AlphaMath Almost Zero: process Supervision without process\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.379, \"y\": 1.508}, {\"title\": \"Gaussian Stochastic Weight Averaging for Bayesian Low-Rank Adaptation of  Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.668, \"y\": 1.859}, {\"title\": \"The high dimensional psychological profile and cultural bias of ChatGPT\", \"topic\": \"Bias in Language Models\", \"x\": 4.321, \"y\": 2.513}, {\"title\": \"Explainable Fake News Detection With Large Language Model via Defense  Among Competing Wisdom\", \"topic\": \"Bias in Language Models\", \"x\": 3.549, \"y\": 3.773}, {\"title\": \"MedDoc-Bot: A Chat Tool for Comparative Analysis of Large Language  Models in the Context of the Pediatric Hypertension Guideline\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.886, \"y\": 7.178}, {\"title\": \"Visual Language Model based Cross-modal Semantic Communication Systems\", \"topic\": \"Multimodal Language Models\", \"x\": 8.1, \"y\": 7.577}, {\"title\": \"Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice  Questions\", \"topic\": \"Large Language Models in Education\", \"x\": 6.881, \"y\": 2.92}, {\"title\": \"ERAGent: Enhancing Retrieval-Augmented Language Models with Improved  Accuracy, Efficiency, and Personalization\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.343, \"y\": 4.347}, {\"title\": \"Exploring the Potential of the Large Language Models (LLMs) in  Identifying Misleading News Headlines\", \"topic\": \"Bias in Language Models\", \"x\": 3.597, \"y\": 3.777}, {\"title\": \"Quantifying the Capabilities of LLMs across Scale and Precision\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.4, \"y\": 2.235}, {\"title\": \"CRAFT: Extracting and Tuning Cultural Instructions from the Wild\", \"topic\": \"Bias in Language Models\", \"x\": 4.061, \"y\": 2.688}, {\"title\": \"Lory: Fully Differentiable Mixture-of-Experts for Autoregressive  Language Model Pre-training\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.782, \"y\": 2.17}, {\"title\": \"An Active Inference Agent for Simulating Human Translation Processes in  a Hierarchical Architecture: Integrating the Task Segment Framework and the  HOF taxonomy\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.123, \"y\": 1.805}, {\"title\": \"FairMonitor: A Dual-framework for Detecting Stereotypes and Biases in  Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.305, \"y\": 2.727}, {\"title\": \"To Each (Textual Sequence) Its Own: Improving Memorized-Data Unlearning  in Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.865, \"y\": 0.407}, {\"title\": \"Compressing Long Context for Enhancing RAG with AMR-based Concept  Distillation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.388, \"y\": 4.503}, {\"title\": \"On the performativity of SDG classifications in large bibliometric  databases\", \"topic\": \"Text Summarization\", \"x\": 4.857, \"y\": 6.008}, {\"title\": \"Exploring prompts to elicit memorization in masked language model-based  named entity recognition\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.848, \"y\": 0.482}, {\"title\": \"Parameter-Efficient Fine-Tuning with Discrete Fourier Transform\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.814, \"y\": 1.767}, {\"title\": \"MedAdapter: Efficient Test-Time Adaptation of Large Language Models  towards Medical Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.1, \"y\": 7.179}, {\"title\": \"Exploring the Compositional Deficiency of Large Language Models in  Mathematical Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.714, \"y\": 1.416}, {\"title\": \"Can Large Language Models Make the Grade? An Empirical Study Evaluating  LLMs Ability to Mark Short Answer Questions in K-12 Education\", \"topic\": \"Large Language Models in Education\", \"x\": 6.412, \"y\": 2.556}, {\"title\": \"Enabling Patient-side Disease Prediction via the Integration of Patient  Narratives\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.814, \"y\": 7.443}, {\"title\": \"Relay Decoding: Concatenating Large Language Models for Machine  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.66, \"y\": 4.704}, {\"title\": \"Overconfidence is Key: Verbalized Uncertainty Evaluation in Large  Language and Vision-Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.599, \"y\": 2.86}, {\"title\": \"Sentiment Analysis Across Languages: Evaluation Before and After Machine  Translation to English\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.906, \"y\": 4.698}, {\"title\": \"Language Evolution for Evading Social Media Regulation via LLM-based  Multi-agent Simulation\", \"topic\": \"Bias in Language Models\", \"x\": 4.253, \"y\": 2.631}, {\"title\": \"Stochastic RAG: End-to-End Retrieval-Augmented Generation through  Expected Utility Maximization\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.222, \"y\": 4.441}, {\"title\": \"NegativePrompt: Leveraging Psychology for Large Language Models  Enhancement via Negative Emotional Stimuli\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.637, \"y\": 5.559}, {\"title\": \"ImageInWords: Unlocking Hyper-Detailed Image Descriptions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.453, \"y\": 7.399}, {\"title\": \"ATG: Benchmarking Automated Theorem Generation for Generative Language  Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.587, \"y\": 1.182}, {\"title\": \"Get more for less: Principled Data Selection for Warming Up Fine-Tuning  in LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.28, \"y\": 2.286}, {\"title\": \"Detecting Edited Knowledge in Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.763, \"y\": 0.834}, {\"title\": \"Assessing Adversarial Robustness of Large Language Models: An Empirical  Study\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.095, \"y\": 1.07}, {\"title\": \"Enhancing Contextual Understanding in Large Language Models through  Contrastive Decoding\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.471, \"y\": 3.946}, {\"title\": \"Beyond Performance: Quantifying and Mitigating Label Bias in LLMs\", \"topic\": \"Large Language Models in Education\", \"x\": 6.958, \"y\": 3.007}, {\"title\": \"Relations Prediction for Knowledge Graph Completion using Large Language  Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.663, \"y\": 5.825}, {\"title\": \"Recall Them All: Retrieval-Augmented Language Models for Long Object  List Extraction from Long Documents\", \"topic\": \"Named Entity Recognition\", \"x\": 6.283, \"y\": 6.478}, {\"title\": \"Beyond Relevance: Evaluate and Improve Retrievers on Perspective  Awareness\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.022, \"y\": 4.582}, {\"title\": \"Enhancing News Summarization with ELearnFit through Efficient In-Context  Learning and Efficient Fine-Tuning\", \"topic\": \"Text Summarization\", \"x\": 5.276, \"y\": 5.192}, {\"title\": \"Evaluating the Ability of Computationally Extracted Narrative Maps to  Encode Media Framing\", \"topic\": \"Bias in Language Models\", \"x\": 3.485, \"y\": 4.058}, {\"title\": \"On the Information Redundancy in Non-Autoregressive Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.68, \"y\": 4.846}, {\"title\": \"R4: Reinforced Retriever-Reorder-Responder for Retrieval-Augmented Large  Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.083, \"y\": 4.439}, {\"title\": \"Identifying Narrative Patterns and Outliers in Holocaust Testimonies  Using Topic Modeling\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.525, \"y\": 4.417}, {\"title\": \"Astro-NER -- Astronomy Named Entity Recognition: Is GPT a Good Domain  Expert Annotator?\", \"topic\": \"Text Summarization\", \"x\": 5.227, \"y\": 6.203}, {\"title\": \"Random Masking Finds Winning Tickets for Parameter Efficient Fine-tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.63, \"y\": 2.043}, {\"title\": \"Mixat: A Data Set of Bilingual Emirati-English Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.253, \"y\": 5.586}, {\"title\": \"A Literature Review and Framework for Human Evaluation of Generative  Large Language Models in Healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.896, \"y\": 7.42}, {\"title\": \"Overview of the EHRSQL 2024 Shared Task on Reliable Text-to-SQL Modeling  on Electronic Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.374, \"y\": 7.467}, {\"title\": \"Mothman at SemEval-2024 Task 9: An Iterative System for Chain-of-Thought  Prompt Optimization\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.267, \"y\": 2.103}, {\"title\": \"What is Sentiment Meant to Mean to Language Models?\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.07, \"y\": 4.826}, {\"title\": \"Combining X-Vectors and Bayesian Batch Active Learning: Two-Stage Active  Learning Pipeline for Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.644, \"y\": 5.58}, {\"title\": \"The Call for Socially Aware Language Technologies\", \"topic\": \"Bias in Language Models\", \"x\": 3.627, \"y\": 2.843}, {\"title\": \"Vibe-Eval: A hard evaluation suite for measuring progress of multimodal  language models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.99, \"y\": 7.316}, {\"title\": \"Structural Pruning of Pre-trained Language Models via Neural  Architecture Search\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.094, \"y\": 2.359}, {\"title\": \"REASONS: A benchmark for REtrieval and Automated citationS Of scieNtific  Sentences using Public and Proprietary LLMs\", \"topic\": \"Text Summarization\", \"x\": 5.093, \"y\": 5.818}, {\"title\": \"Instruction-Guided Bullet Point Summarization of Long Financial Earnings  Call Transcripts\", \"topic\": \"Text Summarization\", \"x\": 5.023, \"y\": 5.17}, {\"title\": \"Impact of emoji exclusion on the performance of Arabic sarcasm detection  models\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.537, \"y\": 4.823}, {\"title\": \"Assessing and Verifying Task Utility in LLM-Powered Applications\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.32, \"y\": 1.79}, {\"title\": \"Hoaxpedia: A Unified Wikipedia Hoax Articles Dataset\", \"topic\": \"Bias in Language Models\", \"x\": 3.473, \"y\": 3.762}, {\"title\": \"Exposing and Explaining Fake News On-the-Fly\", \"topic\": \"Bias in Language Models\", \"x\": 3.389, \"y\": 3.731}, {\"title\": \"MedReadMe: A Systematic Study for Fine-grained Sentence Readability in  Medical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.339, \"y\": 7.205}, {\"title\": \"Optimising Calls to Large Language Models with Uncertainty-Based  Two-Tier Selection\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.369, \"y\": 2.23}, {\"title\": \"Unveiling the Potential of LLM-Based ASR on Chinese Open-Source Datasets\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.577, \"y\": 5.699}, {\"title\": \"TIPAA-SSL: Text Independent Phone-to-Audio Alignment based on  Self-Supervised Learning and Knowledge Transfer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.432, \"y\": 5.746}, {\"title\": \"Evaluating Large Language Models for Structured Science Summarization in  the Open Research Knowledge Graph\", \"topic\": \"Text Summarization\", \"x\": 5.064, \"y\": 5.951}, {\"title\": \"Large Multimodal Model based Standardisation of Pathology Reports with  Confidence and their Prognostic Significance\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.284, \"y\": 8.085}, {\"title\": \"The Trade-off between Performance, Efficiency, and Fairness in Adapter  Modules for Text Classification\", \"topic\": \"Bias in Language Models\", \"x\": 3.1, \"y\": 2.512}, {\"title\": \"Exploring Combinatorial Problem Solving with Large Language Models: A  Case Study on the Travelling Salesman Problem Using GPT-3.5 Turbo\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.279, \"y\": 1.633}, {\"title\": \"Joint sentiment analysis of lyrics and audio in music\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.742, \"y\": 5.258}, {\"title\": \"Conformal Prediction for Natural Language Processing: A Survey\", \"topic\": \"Large Language Models in Education\", \"x\": 6.587, \"y\": 3.327}, {\"title\": \"Dependency-Aware Semi-Structured Sparsity: Declining Roles of Outliers  in Pruning GLU-based LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.055, \"y\": 2.313}, {\"title\": \"CRCL at SemEval-2024 Task 2: Simple prompt optimizations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.283, \"y\": 7.02}, {\"title\": \"OARelatedWork: A Large-Scale Dataset of Related Work Sections with  Full-texts from Open Access Sources\", \"topic\": \"Text Summarization\", \"x\": 5.095, \"y\": 5.248}, {\"title\": \"Semi-Parametric Retrieval via Binary Token Index\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.494, \"y\": 4.736}, {\"title\": \"Aloe: A Family of Fine-tuned Open Healthcare LLMs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.263, \"y\": 7.095}, {\"title\": \"Enhancing Bangla Language Next Word Prediction and Sentence Completion  through Extended RNN with Bi-LSTM Model On N-gram Language\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.867, \"y\": 3.974}, {\"title\": \"LLM as Dataset Analyst: Subpopulation Structure Discovery with Large  Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.321, \"y\": 7.078}, {\"title\": \"SGHateCheck: Functional Tests for Detecting Hate Speech in Low-Resource  Languages of Singapore\", \"topic\": \"Bias in Language Models\", \"x\": 2.406, \"y\": 3.425}, {\"title\": \"SoftMCL: Soft Momentum Contrastive Learning for Fine-grained  Sentiment-aware Pre-training\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.976, \"y\": 4.994}, {\"title\": \"Exploring Speech Pattern Disorders in Autism using Machine Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.39, \"y\": 6.294}, {\"title\": \"Exploiting ChatGPT for Diagnosing Autism-Associated Language Disorders  and Identifying Distinct Features\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.953, \"y\": 6.905}, {\"title\": \"Understanding Position Bias Effects on Fairness in Social Multi-Document  Summarization\", \"topic\": \"Text Summarization\", \"x\": 4.959, \"y\": 5.101}, {\"title\": \"Layers of technology in pluriversal design. Decolonising language  technology with the LiveLanguage initiative\", \"topic\": \"Bias in Language Models\", \"x\": 4.061, \"y\": 2.619}, {\"title\": \"TextAge: A Curated and Diverse Text Dataset for Age Classification\", \"topic\": \"Bias in Language Models\", \"x\": 2.892, \"y\": 3.183}, {\"title\": \"Early Transformers: A study on Efficient Training of Transformer Models  through Early-Bird Lottery Tickets\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.81, \"y\": 2.71}, {\"title\": \"CoS: Enhancing Personalization and Mitigating Bias with Context Steering\", \"topic\": \"Bias in Language Models\", \"x\": 3.285, \"y\": 2.688}, {\"title\": \"The Psychosocial Impacts of Generative AI Harms\", \"topic\": \"Bias in Language Models\", \"x\": 3.5, \"y\": 2.7}, {\"title\": \"Large Language Models are Inconsistent and Biased Evaluators\", \"topic\": \"Large Language Models in Education\", \"x\": 6.165, \"y\": 3.157}, {\"title\": \"Automatically Extracting Numerical Results from Randomized Controlled  Trials with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.21, \"y\": 6.973}, {\"title\": \"Leveraging Prompt-Learning for Structured Information Extraction from  Crohn's Disease Radiology Reports in a Low-Resource Language\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.251, \"y\": 7.612}, {\"title\": \"1-Diffractor: Efficient and Utility-Preserving Text Obfuscation  Leveraging Word-Level Metric Differential Privacy\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.801, \"y\": 0.226}, {\"title\": \"Prometheus 2: An Open Source Language Model Specialized in Evaluating  Other Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.455, \"y\": 3.079}, {\"title\": \"FLAME: Factuality-Aware Alignment for Large Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.577, \"y\": 0.761}, {\"title\": \"D2PO: Discriminator-Guided DPO with Response Evaluation Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.469, \"y\": 0.574}, {\"title\": \"MANTIS: Interleaved Multi-Image Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.143, \"y\": 7.332}, {\"title\": \"NeMo-Aligner: Scalable Toolkit for Efficient Model Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.604, \"y\": 0.586}, {\"title\": \"V-FLUTE: Visual Figurative Language Understanding with Textual  Explanations\", \"topic\": \"Multimodal Language Models\", \"x\": 7.773, \"y\": 7.563}, {\"title\": \"UQA: Corpus for Urdu Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.232, \"y\": 4.244}, {\"title\": \"MiniGPT-3D: Efficiently Aligning 3D Point Clouds with Large Language  Models using 2D Priors\", \"topic\": \"Multimodal Language Models\", \"x\": 8.118, \"y\": 7.295}, {\"title\": \"Unsupervised Flow Discovery from Task-oriented Dialogues\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.13, \"y\": 3.286}, {\"title\": \"Topics in the Study of the Pragmatic Functions of Phonetic Reduction in  Dialog\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.106, \"y\": 5.933}, {\"title\": \"GAIA: A General AI Assistant for Intelligent Accelerator Operations\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.515, \"y\": 1.597}, {\"title\": \"The Power of Question Translation Training in Multilingual Reasoning:  Broadened Scope and Deepened Insights\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.662, \"y\": 2.419}, {\"title\": \"Sequence-to-sequence models in peer-to-peer learning: A practical  application\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.568, \"y\": 5.722}, {\"title\": \"Enhancing Language Models for Financial Relation Extraction with Named  Entities and Part-of-Speech\", \"topic\": \"Named Entity Recognition\", \"x\": 6.106, \"y\": 6.687}, {\"title\": \"Low-resource speech recognition and dialect identification of Irish in a  multi-task framework\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.581, \"y\": 5.664}, {\"title\": \"Reinforcement Learning for Edit-Based Non-Autoregressive Neural Machine  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.901, \"y\": 4.586}, {\"title\": \"Prompt engineering paradigms for medical applications: scoping review  and recommendations for better practices\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.953, \"y\": 7.376}, {\"title\": \"Boosting Jailbreak Attack with Momentum\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.089, \"y\": 0.586}, {\"title\": \"TartuNLP at EvaLatin 2024: Emotion Polarity Detection\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.64, \"y\": 5.214}, {\"title\": \"It Couldn't Help But Overhear: On the Limits of Modelling  Meta-Communicative Grounding Acts with Supervised Learning\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.248, \"y\": 3.037}, {\"title\": \"Efficient Data Generation for Source-grounded Information-seeking  Dialogs: A Use Case for Meeting Transcripts\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.357, \"y\": 3.482}, {\"title\": \"Silencing the Risk, Not the Whistle: A Semi-automated Text Sanitization  Tool for Mitigating the Risk of Whistleblower Re-Identification\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.606, \"y\": 0.361}, {\"title\": \"Few Shot Class Incremental Learning using Vision-Language models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.391, \"y\": 7.603}, {\"title\": \"The IgboAPI Dataset: Empowering Igbo Language Technologies through  Multi-dialectal Enrichment\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.217, \"y\": 4.694}, {\"title\": \"On the Evaluation of Machine-Generated Reports\", \"topic\": \"Text Summarization\", \"x\": 5.25, \"y\": 5.151}, {\"title\": \"Language Fairness in Multilingual Information Retrieval\", \"topic\": \"Bias in Language Models\", \"x\": 3.321, \"y\": 2.906}, {\"title\": \"PLAID SHIRTTT for Large-Scale Streaming Dense Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.054, \"y\": 4.719}, {\"title\": \"Efficient Compression of Multitask Multilingual Speech Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.598, \"y\": 5.596}, {\"title\": \"LLaVA Finds Free Lunch: Teaching Human Behavior Improves Content  Understanding Abilities Of LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.562, \"y\": 7.271}, {\"title\": \"Math Multiple Choice Question Generation via Human-Large Language Model  Collaboration\", \"topic\": \"Large Language Models in Education\", \"x\": 6.461, \"y\": 2.28}, {\"title\": \"WorkBench: a Benchmark Dataset for Agents in a Realistic Workplace  Setting\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.989, \"y\": 1.542}, {\"title\": \"Uncovering Agendas: A Novel French & English Dataset for Agenda  Detection on Social Media\", \"topic\": \"Bias in Language Models\", \"x\": 3.255, \"y\": 3.897}, {\"title\": \"Self-Play Preference Optimization for Language Model Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.606, \"y\": 0.437}, {\"title\": \"RST-LoRA: A Discourse-Aware Low-Rank Adaptation for Long Document  Abstractive Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.192, \"y\": 5.196}, {\"title\": \"When Quantization Affects Confidence of Large Language Models?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.556, \"y\": 2.233}, {\"title\": \"Investigating Automatic Scoring and Feedback using Large Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.351, \"y\": 2.687}, {\"title\": \"Are Models Biased on Text without Gender-related Language?\", \"topic\": \"Bias in Language Models\", \"x\": 3.141, \"y\": 2.773}, {\"title\": \"The Real, the Better: Aligning Large Language Models with Online Human  Behaviors\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.437, \"y\": 0.696}, {\"title\": \"New Benchmark Dataset and Fine-Grained Cross-Modal Fusion Framework for  Vietnamese Multimodal Aspect-Category Sentiment Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.708, \"y\": 5.052}, {\"title\": \"A Legal Framework for Natural Language Processing Model Training in  Portugal\", \"topic\": \"Legal NLP\", \"x\": 4.311, \"y\": 4.275}, {\"title\": \"Navigating WebAI: Training Agents to Complete Web Tasks with Large  Language Models and Reinforcement Learning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.07, \"y\": 1.526}, {\"title\": \"GOLD: Geometry Problem Solver with Natural Language Description\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.608, \"y\": 1.214}, {\"title\": \"Explainable Automatic Grading with Neural Additive Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.743, \"y\": 2.322}, {\"title\": \"Harnessing the Power of Multiple Minds: Lessons Learned from LLM Routing\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 6.962, \"y\": 1.767}, {\"title\": \"BiomedRAG: A Retrieval Augmented Large Language Model for Biomedicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.357, \"y\": 7.101}, {\"title\": \"Enhancing Surgical Robots with Embodied Intelligence for Autonomous  Ultrasound Scanning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.857, \"y\": 7.517}, {\"title\": \"MetaRM: Shifted Distributions Alignment via Meta-Learning\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.579, \"y\": 0.637}, {\"title\": \"Self-Refine Instruction-Tuning for Aligning Reasoning in Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.445, \"y\": 1.589}, {\"title\": \"Efficient Sample-Specific Encoder Perturbations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.485, \"y\": 5.161}, {\"title\": \"CofiPara: A Coarse-to-fine Paradigm for Multimodal Sarcasm Target  Identification with Large Multimodal Models\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.489, \"y\": 4.855}, {\"title\": \"AdaMoLE: Fine-Tuning Large Language Models with Adaptive Mixture of  Low-Rank Adaptation Experts\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.611, \"y\": 1.858}, {\"title\": \"A Careful Examination of Large Language Model Performance on Grade  School Arithmetic\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.697, \"y\": 1.26}, {\"title\": \"DFKI-NLP at SemEval-2024 Task 2: Towards Robust LLMs Using Data  Perturbations and MinMax Training\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.196, \"y\": 7.105}, {\"title\": \"Enhanced Language Model Truthfulness with Learnable Intervention and  Uncertainty Expression\", \"topic\": \"Large Language Models in Education\", \"x\": 6.064, \"y\": 3.181}, {\"title\": \"Adversarial Attacks and Defense for Conversation Entailment Task\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.176, \"y\": 1.119}, {\"title\": \"Clover: Regressive Lightweight Speculative Decoding with Sequential  Knowledge\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.563, \"y\": 3.231}, {\"title\": \"CodeHalu: Code Hallucinations in LLMs Driven by Execution-based  Verification\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.066, \"y\": 0.103}, {\"title\": \"A Primer on the Inner Workings of Transformer-based Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.242, \"y\": 3.012}, {\"title\": \"General Purpose Verification for Chain of Thought Prompting\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.19, \"y\": 1.968}, {\"title\": \"SPAFIT: Stratified Progressive Adaptation Fine-tuning for Pre-trained  Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.476, \"y\": 2.111}, {\"title\": \"Towards a Search Engine for Machines: Unified Ranking for Multiple  Retrieval-Augmented Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.236, \"y\": 4.525}, {\"title\": \"HistNERo: Historical Named Entity Recognition for the Romanian Language\", \"topic\": \"Named Entity Recognition\", \"x\": 6.15, \"y\": 6.801}, {\"title\": \"Transforming Dutch: Debiasing Dutch Coreference Resolution Systems for  Non-binary Pronouns\", \"topic\": \"Bias in Language Models\", \"x\": 3.129, \"y\": 2.695}, {\"title\": \"DOCCI: Descriptions of Connected and Contrasting Images\", \"topic\": \"Multimodal Language Models\", \"x\": 8.34, \"y\": 7.13}, {\"title\": \"Iterative Reasoning Preference Optimization\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.44, \"y\": 1.515}, {\"title\": \"ThangDLU at #SMM4H 2024: Encoder-decoder models for classifying text  data on social disorders in children and adolescents\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.5, \"y\": 6.321}, {\"title\": \"Automated Generation of High-Quality Medical Simulation Scenarios  Through Integration of Semi-Structured Data and Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.797, \"y\": 7.256}, {\"title\": \"When to Retrieve: Teaching LLMs to Utilize Information Retrieval  Effectively\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.582, \"y\": 4.452}, {\"title\": \"Naturally Supervised 3D Visual Grounding with Language-Regularized  Concept Learners\", \"topic\": \"Multimodal Language Models\", \"x\": 7.897, \"y\": 7.399}, {\"title\": \"Transferring Troubles: Cross-Lingual Transferability of Backdoor Attacks  in LLMs with Instruction Tuning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.255, \"y\": 0.654}, {\"title\": \"RepEval: Effective Text Evaluation with LLM Representation\", \"topic\": \"Large Language Models in Education\", \"x\": 6.229, \"y\": 3.52}, {\"title\": \"RAG and RAU: A Survey on Retrieval-Augmented Language Model in Natural  Language Processing\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.145, \"y\": 4.468}, {\"title\": \"Do Large Language Models Understand Conversational Implicature -- A case  study with a chinese sitcom\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.266, \"y\": 2.898}, {\"title\": \"Context-Aware Machine Translation with Source Coreference Explanation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.74, \"y\": 4.716}, {\"title\": \"Safe Training with Sensitive In-domain Data: Leveraging Data  Fragmentation To Mitigate Linkage Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.775, \"y\": 0.584}, {\"title\": \"FactCheck Editor: Multilingual Text Editor with End-to-End fact-checking\", \"topic\": \"Bias in Language Models\", \"x\": 3.89, \"y\": 3.888}, {\"title\": \"Which Nigerian-Pidgin does Generative AI speak?: Issues about  Representativeness and Bias for Multilingual and Low Resource Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.106, \"y\": 4.305}, {\"title\": \"Can Large Language Models put 2 and 2 together? Probing for Entailed  Arithmetical Relationships\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.639, \"y\": 1.681}, {\"title\": \"Countering Reward Over-optimization in LLM with Demonstration-Guided  Reinforcement Learning\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.756, \"y\": 0.829}, {\"title\": \"Large Language Model Informed Patent Image Retrieval\", \"topic\": \"Legal NLP\", \"x\": 7.791, \"y\": 7.357}, {\"title\": \"Evaluating Lexicon Incorporation for Depression Symptom Estimation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.332, \"y\": 6.218}, {\"title\": \"Enhancing Trust in LLM-Generated Code Summaries with Calibrated  Confidence Scores\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.006, \"y\": 0.186}, {\"title\": \"QLSC: A Query Latent Semantic Calibrator for Robust Extractive Question  Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.757, \"y\": 4.327}, {\"title\": \"Modeling Orthographic Variation in Occitan's Dialects\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.958, \"y\": 4.418}, {\"title\": \"Does Whisper understand Swiss German? An automatic, qualitative, and  human evaluation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.483, \"y\": 5.8}, {\"title\": \"Large Language Model Agent for Fake News Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.561, \"y\": 3.684}, {\"title\": \"Exploiting Hatred by Targets for Hate Speech Detection on Vietnamese  Social Media Texts\", \"topic\": \"Bias in Language Models\", \"x\": 2.447, \"y\": 3.373}, {\"title\": \"HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.522, \"y\": 1.951}, {\"title\": \"GRAMMAR: Grounded and Modular Methodology for Assessment of  Domain-Specific Retrieval-Augmented Language Model\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.301, \"y\": 4.364}, {\"title\": \"Transcrib3D: 3D Referring Expression Resolution through Large Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.082, \"y\": 7.26}, {\"title\": \"Mix of Experts Language Model for Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 6.154, \"y\": 6.845}, {\"title\": \"Modeling Caption Diversity in Contrastive Vision-Language Pretraining\", \"topic\": \"Multimodal Language Models\", \"x\": 8.505, \"y\": 7.465}, {\"title\": \"Revenge of the Fallen? Recurrent Models Match Transformers at Predicting  Human Language Comprehension Metrics\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.209, \"y\": 2.876}, {\"title\": \"What Drives Performance in Multilingual Language Models?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.087, \"y\": 4.248}, {\"title\": \"Q-GroundCAM: Quantifying Grounding in Vision Language Models via GradCAM\", \"topic\": \"Multimodal Language Models\", \"x\": 8.308, \"y\": 7.567}, {\"title\": \"Text and Audio Simplification: Human vs. ChatGPT\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.389, \"y\": 7.042}, {\"title\": \"Blind Spots and Biases: Exploring the Role of Annotator Cognitive Biases  in NLP\", \"topic\": \"Bias in Language Models\", \"x\": 3.449, \"y\": 2.717}, {\"title\": \"A Framework for Real-time Safeguarding the Text Generation of Large  Language Model\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.596, \"y\": 1.575}, {\"title\": \"Stylus: Automatic Adapter Selection for Diffusion Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.519, \"y\": 6.859}, {\"title\": \"DPO Meets PPO: Reinforced Token Optimization for RLHF\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.576, \"y\": 0.68}, {\"title\": \"Markovian Agents for Informative Language Modeling\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.256, \"y\": 1.801}, {\"title\": \"A Comprehensive Rubric for Annotating Pathological Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.53, \"y\": 6.118}, {\"title\": \"FeDeRA:Efficient Fine-tuning of Language Models in Federated Learning  Leveraging Weight Decomposition\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.139, \"y\": -0.001}, {\"title\": \"It's Difficult to be Neutral -- Human and LLM-based Sentiment Annotation  of Patient Comments\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.749, \"y\": 6.733}, {\"title\": \"Unknown Script: Impact of Script on Cross-Lingual Transfer\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.29, \"y\": 4.323}, {\"title\": \"Replacing Judges with Juries: Evaluating LLM Generations with a Panel of  Diverse Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.628, \"y\": 3.003}, {\"title\": \"Towards A Structured Overview of Use Cases for Natural Language  Processing in the Legal Domain: A German Perspective\", \"topic\": \"Legal NLP\", \"x\": 4.359, \"y\": 4.508}, {\"title\": \"Foundations of Multisensory Artificial Intelligence\", \"topic\": \"Multimodal Language Models\", \"x\": 8.153, \"y\": 7.039}, {\"title\": \"Towards Dog Bark Decoding: Leveraging Human Speech Processing for  Automated Bark Classification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.333, \"y\": 5.956}, {\"title\": \"The Constant in HATE: Analyzing Toxicity in Reddit across Topics and  Languages\", \"topic\": \"Bias in Language Models\", \"x\": 2.571, \"y\": 3.444}, {\"title\": \"Credible, Unreliable or Leaked?: Evidence Verification for Enhanced  Automated Fact-checking\", \"topic\": \"Bias in Language Models\", \"x\": 3.704, \"y\": 3.881}, {\"title\": \"A cost minimization approach to fix the vocabulary size in a tokenizer  for an End-to-End ASR system\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.403, \"y\": 5.726}, {\"title\": \"Reinforcement Learning Problem Solving with Large Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.001, \"y\": 1.427}, {\"title\": \"Do Vision & Language Decoders use Images and Text equally? How  Self-consistent are their Explanations?\", \"topic\": \"Multimodal Language Models\", \"x\": 7.975, \"y\": 7.763}, {\"title\": \"PoPE: Legendre Orthogonal Polynomials Based Position Encoding for Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.632, \"y\": 3.136}, {\"title\": \"Injecting Salesperson's Dialogue Strategies in Large Language Models  with Chain-of-Thought Reasoning\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.192, \"y\": 3.058}, {\"title\": \"MileBench: Benchmarking MLLMs in Long Context\", \"topic\": \"Multimodal Language Models\", \"x\": 8.419, \"y\": 7.149}, {\"title\": \"GPT-4 passes most of the 297 written Polish Board Certification  Examinations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.029, \"y\": 7.478}, {\"title\": \"HFT: Half Fine-Tuning for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.296, \"y\": 2.016}, {\"title\": \"Ethical Reasoning and Moral Value Alignment of LLMs Depend on the  Language we Prompt them in\", \"topic\": \"Bias in Language Models\", \"x\": 4.066, \"y\": 2.239}, {\"title\": \"BMRetriever: Tuning Large Language Models as Better Biomedical Text  Retrievers\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.431, \"y\": 7.179}, {\"title\": \"Capabilities of Gemini Models in Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.334, \"y\": 8.012}, {\"title\": \"LoRA Land: 310 Fine-tuned LLMs that Rival GPT-4, A Technical Report\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.911, \"y\": 1.887}, {\"title\": \"Exploring the Limits of Fine-grained LLM-based Physics Inference via  Premise Removal Interventions\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.75, \"y\": 1.394}, {\"title\": \"Towards Unbiased Evaluation of Detecting Unanswerable Questions in  EHRSQL\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.825, \"y\": 7.286}, {\"title\": \"Comparing LLM prompting with Cross-lingual transfer performance on  Indigenous and Low-resource Brazilian Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.208, \"y\": 4.075}, {\"title\": \"Improve Academic Query Resolution through BERT-based Question Extraction  from Images\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.565, \"y\": 4.175}, {\"title\": \"Bias Neutralization Framework: Measuring Fairness in Large Language  Models with Bias Intelligence Quotient (BiQ)\", \"topic\": \"Bias in Language Models\", \"x\": 3.287, \"y\": 2.772}, {\"title\": \"CLARINET: Augmenting Language Models to Ask Clarification Questions for  Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.194, \"y\": 4.541}, {\"title\": \"Modeling Orthographic Variation Improves NLP Performance for Nigerian  Pidgin\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.07, \"y\": 4.796}, {\"title\": \"PatentGPT: A Large Language Model for Intellectual Property\", \"topic\": \"Legal NLP\", \"x\": 4.723, \"y\": 4.893}, {\"title\": \"SOUL: Unlocking the Power of Second-Order Optimization for LLM  Unlearning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.111, \"y\": 0.584}, {\"title\": \"EkoHate: Abusive Language and Hate Speech Detection for Code-switched  Political Discussions on Nigerian Twitter\", \"topic\": \"Bias in Language Models\", \"x\": 2.492, \"y\": 3.366}, {\"title\": \"Logic Agent: Enhancing Validity with Logic Rule Invocation\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.084, \"y\": 1.708}, {\"title\": \"USAT: A Universal Speaker-Adaptive Text-to-Speech Approach\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.092, \"y\": 5.939}, {\"title\": \"CRE-LLM: A Domain-Specific Chinese Relation Extraction Framework with  Fine-tuned Large Language Model\", \"topic\": \"Named Entity Recognition\", \"x\": 6.308, \"y\": 6.515}, {\"title\": \"Efficient LLM Inference with Kcache\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.355, \"y\": 2.89}, {\"title\": \"Fashion Recommendation: Outfit Compatibility using GNN\", \"topic\": \"Named Entity Recognition\", \"x\": 6.549, \"y\": 5.85}, {\"title\": \"Leveraging Prompts in LLMs to Overcome Imbalances in Complex Educational  Text Data\", \"topic\": \"Large Language Models in Education\", \"x\": 6.408, \"y\": 2.591}, {\"title\": \"Quality Estimation with $k$-nearest Neighbors and Automatic Evaluation  for Model-specific Quality Estimation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.624, \"y\": 4.963}, {\"title\": \"MediFact at MEDIQA-CORR 2024: Why AI Needs a Human Touch\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.145, \"y\": 7.335}, {\"title\": \"MediFact at MEDIQA-M3G 2024: Medical Question Answering in Dermatology  with Multimodal Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.227, \"y\": 7.964}, {\"title\": \"Enhancing Pre-Trained Generative Language Models with Question Attended  Span Extraction on Machine Reading Comprehension\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.898, \"y\": 4.233}, {\"title\": \"Detection of Conspiracy Theories Beyond Keyword Bias in German-Language  Telegram Using Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.323, \"y\": 3.744}, {\"title\": \"TI-ASU: Toward Robust Automatic Speech Understanding through  Text-to-speech Imputation Against Missing Speech Modality\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.471, \"y\": 5.854}, {\"title\": \"Usefulness of Emotional Prosody in Neural Machine Translation\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.452, \"y\": 5.516}, {\"title\": \"Spatio-Temporal Side Tuning Pre-trained Foundation Models for  Video-based Pedestrian Attribute Recognition\", \"topic\": \"Multimodal Language Models\", \"x\": 8.63, \"y\": 7.552}, {\"title\": \"I Have an Attention Bridge to Sell You: Generalization Capabilities of  Modular Translation Architectures\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.74, \"y\": 4.415}, {\"title\": \"From Languages to Geographies: Towards Evaluating Cultural Bias in Hate  Speech Datasets\", \"topic\": \"Bias in Language Models\", \"x\": 2.577, \"y\": 3.432}, {\"title\": \"Revisiting Multimodal Emotion Recognition in Conversation from the  Perspective of Graph Spectrum\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.555, \"y\": 5.236}, {\"title\": \"Revisiting Multi-modal Emotion Learning with Broad State Space Models  and Probability-guidance Fusion\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.483, \"y\": 5.343}, {\"title\": \"Toxicity Classification in Ukrainian\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.79, \"y\": 1.66}, {\"title\": \"Evaluation of Few-Shot Learning for Classification Tasks in the Polish  Language\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.738, \"y\": 4.241}, {\"title\": \"Recall, Retrieve and Reason: Towards Better In-Context Relation  Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.309, \"y\": 6.486}, {\"title\": \"Meta In-Context Learning Makes Large Language Models Better Zero and  Few-Shot Relation Extractors\", \"topic\": \"Named Entity Recognition\", \"x\": 6.33, \"y\": 6.558}, {\"title\": \"T-CLAP: Temporal-Enhanced Contrastive Language-Audio Pretraining\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.675, \"y\": 6.237}, {\"title\": \"Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing  Japanese Language Capabilities\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.611, \"y\": 4.006}, {\"title\": \"Temporal Scaling Law for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.414, \"y\": 2.669}, {\"title\": \"MRScore: Evaluating Radiology Report Generation with LLM-based Reward  System\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.119, \"y\": 7.958}, {\"title\": \"Evaluating the Application of ChatGPT in Outpatient Triage Guidance: A  Comparative Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.789, \"y\": 7.221}, {\"title\": \"UMass-BioNLP at MEDIQA-M3G 2024: DermPrompt -- A Systematic Exploration  of Prompt Engineering with GPT-4V for Dermatological Diagnosis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.787, \"y\": 7.612}, {\"title\": \"Building a Large Japanese Web Corpus for Large Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.601, \"y\": 4.155}, {\"title\": \"Retrieval-Augmented Generation with Knowledge Graphs for Customer  Service Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.223, \"y\": 4.558}, {\"title\": \"PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction  in Murder Mystery Games\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.771, \"y\": 1.856}, {\"title\": \"A Semi-Automatic Approach to Create Large Gender- and Age-Balanced  Speaker Corpora: Usefulness of Speaker Diarization & Identification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.382, \"y\": 5.931}, {\"title\": \"Probabilistic Inference in Language Models via Twisted Sequential Monte  Carlo\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.482, \"y\": 0.766}, {\"title\": \"Large Language Model Agent as a Mechanical Designer\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.259, \"y\": 1.723}, {\"title\": \"Ruffle&Riley: Insights from Designing and Evaluating a Large Language  Model-Based Conversational Tutoring System\", \"topic\": \"Large Language Models in Education\", \"x\": 6.165, \"y\": 2.359}, {\"title\": \"Language Interaction Network for Clinical Trial Approval Estimation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.412, \"y\": 7.014}, {\"title\": \"Child Speech Recognition in Human-Robot Interaction: Problem Solved?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.638, \"y\": 5.803}, {\"title\": \"A Bionic Natural Language Parser Equivalent to a Pushdown Automaton\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.197, \"y\": 2.937}, {\"title\": \"Can a Multichoice Dataset be Repurposed for Extractive Question  Answering?\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.102, \"y\": 4.316}, {\"title\": \"Introducing cosmosGPT: Monolingual Training for Turkish Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.901, \"y\": 4.344}, {\"title\": \"Speech Technology Services for Oral History Research\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.195, \"y\": 5.83}, {\"title\": \"Prompting Techniques for Reducing Social Bias in LLMs through System 1  and System 2 Cognitive Processes\", \"topic\": \"Bias in Language Models\", \"x\": 3.593, \"y\": 2.694}, {\"title\": \"Prompting Towards Alleviating Code-Switched Data Scarcity in  Under-Resourced Languages with GPT as a Pivot\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.167, \"y\": 4.735}, {\"title\": \"TIGQA:An Expert Annotated Question Answering Dataset in Tigrinya\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.921, \"y\": 4.384}, {\"title\": \"Prevalent Frequency of Emotional and Physical Symptoms in Social Anxiety  using Zero Shot Classification: An Observational Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.295, \"y\": 6.422}, {\"title\": \"A Unified Label-Aware Contrastive Learning Framework for Few-Shot Named  Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 6.333, \"y\": 6.903}, {\"title\": \"HateTinyLLM : Hate Speech Detection Using Tiny Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 2.443, \"y\": 3.385}, {\"title\": \"Small Language Models Need Strong Verifiers to Self-Correct Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.142, \"y\": 1.745}, {\"title\": \"Text Sentiment Analysis and Classification Based on Bidirectional Gated  Recurrent Units (GRUs) Model\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.126, \"y\": 4.918}, {\"title\": \"Talking Nonsense: Probing Large Language Models' Understanding of  Adversarial Gibberish Inputs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.247, \"y\": 0.94}, {\"title\": \"Evaluating Class Membership Relations in Knowledge Graphs using Large  Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.551, \"y\": 5.654}, {\"title\": \"Make-it-Real: Unleashing Large Multimodal Model for Painting 3D Objects  with Realistic Materials\", \"topic\": \"Multimodal Language Models\", \"x\": 8.161, \"y\": 6.93}, {\"title\": \"A Survey of Generative Search and Recommendation in the Era of Large  Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.905, \"y\": 4.464}, {\"title\": \"Weak-to-Strong Extrapolation Expedites Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.776, \"y\": 0.576}, {\"title\": \"Can't say cant? Measuring and Reasoning of Dark Jargons in Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.688, \"y\": 1.274}, {\"title\": \"Exploring News Summarization and Enrichment in a Highly Resource-Scarce  Indian Language: A Case Study of Mizo\", \"topic\": \"Text Summarization\", \"x\": 5.241, \"y\": 5.187}, {\"title\": \"REBEL: Reinforcement Learning via Regressing Relative Rewards\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.711, \"y\": 0.737}, {\"title\": \"Prefix Text as a Yarn: Eliciting Non-English Alignment in Foundation  Language Model\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.343, \"y\": 4.249}, {\"title\": \"Automatic Speech Recognition System-Independent Word Error Rate  Estimation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.656, \"y\": 5.696}, {\"title\": \"LayerSkip: Enabling Early Exit Inference and Self-Speculative Decoding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.403, \"y\": 3.08}, {\"title\": \"Influence of Solution Efficiency and Valence of Instruction on Additive  and Subtractive Solution Strategies in Humans and GPT-4\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.194, \"y\": 1.708}, {\"title\": \"Large Language Models in the Clinic: A Comprehensive Benchmark\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.851, \"y\": 7.24}, {\"title\": \"Prediction Is All MoE Needs: Expert Load Distribution Goes from  Fluctuating to Stabilizing\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.854, \"y\": 2.232}, {\"title\": \"Adapting Open-Source Large Language Models for Cost-Effective,  Expert-Level Clinical Note Generation with On-Policy Reinforcement Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.009, \"y\": 7.344}, {\"title\": \"ProbGate at EHRSQL 2024: Enhancing SQL Query Generation Accuracy through  Probabilistic Threshold Filtering and Error Handling\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.295, \"y\": 7.468}, {\"title\": \"Tele-FLM Technical Report\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.245, \"y\": 3.733}, {\"title\": \"Hippocrates: An Open-Source Framework for Advancing Large Language  Models in Healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.183, \"y\": 7.362}, {\"title\": \"Understanding Privacy Risks of Embeddings Induced by Large Language  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.669, \"y\": 0.27}, {\"title\": \"Exploring Internal Numeracy in Language Models: A Case Study on ALBERT\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.698, \"y\": 2.653}, {\"title\": \"Samsung Research China-Beijing at SemEval-2024 Task 3: A multi-stage  framework for Emotion-Cause Pair Extraction in Conversations\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.468, \"y\": 5.371}, {\"title\": \"Building a Japanese Document-Level Relation Extraction Dataset Assisted  by Cross-Lingual Transfer\", \"topic\": \"Named Entity Recognition\", \"x\": 6.3, \"y\": 6.493}, {\"title\": \"Evaluating Consistency and Reasoning Capabilities of Large Language  Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.476, \"y\": 3.12}, {\"title\": \"Large Language Models Perform on Par with Experts Identifying Mental  Health Factors in Adolescent Online Forums\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.441, \"y\": 6.51}, {\"title\": \"U2++ MoE: Scaling 4.7x parameters with minimal impact on RTF\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.666, \"y\": 5.178}, {\"title\": \"List Items One by One: A New Data Source and Learning Paradigm for  Multimodal LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.924, \"y\": 7.643}, {\"title\": \"Don't Say No: Jailbreaking LLM by Suppressing Refusal\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.441, \"y\": 0.877}, {\"title\": \"Learning Syntax Without Planting Trees: Understanding When and Why  Transformers Generalize Hierarchically\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.893, \"y\": 2.958}, {\"title\": \"VISLA Benchmark: Evaluating Embedding Sensitivity to Semantic and  Lexical Alterations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.425, \"y\": 7.611}, {\"title\": \"Digital ASIC Design with Ongoing LLMs: Strategies and Prospects\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.253, \"y\": 0.385}, {\"title\": \"WorldValuesBench: A Large-Scale Benchmark Dataset for Multi-Cultural  Value Awareness of Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.087, \"y\": 2.526}, {\"title\": \"LLM-Based Section Identifiers Excel on Open Source but Stumble in Real  World Applications\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.255, \"y\": 7.294}, {\"title\": \"Interpreting Answers to Yes-No Questions in Dialogues from Multiple  Domains\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.281, \"y\": 3.436}, {\"title\": \"Translation of Multifaceted Data without Re-Training of Machine  Translation Systems\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.685, \"y\": 4.578}, {\"title\": \"Investigating the prompt leakage effect and black-box defenses for  multi-turn LLM interactions\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.37, \"y\": 0.698}, {\"title\": \"Computational analysis of the language of pain: a systematic review\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.671, \"y\": 7.055}, {\"title\": \"Knowledge Graph Completion using Structural and Textual Embeddings\", \"topic\": \"Named Entity Recognition\", \"x\": 6.555, \"y\": 5.819}, {\"title\": \"Towards Efficient Patient Recruitment for Clinical Trials: Application  of a Prompt-Based Learning Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.22, \"y\": 7.233}, {\"title\": \"Fusion of Domain-Adapted Vision and Language Models for Medical Visual  Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.404, \"y\": 8.095}, {\"title\": \"Attacks on Third-Party APIs of Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.419, \"y\": 0.642}, {\"title\": \"From Local to Global: A Graph RAG Approach to Query-Focused  Summarization\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.226, \"y\": 4.703}, {\"title\": \"FairDeDup: Detecting and Mitigating Vision-Language Fairness Disparities  in Semantic Dataset Deduplication\", \"topic\": \"Bias in Language Models\", \"x\": 3.019, \"y\": 2.666}, {\"title\": \"Integrating LSTM and BERT for Long-Sequence Data Analysis in Intelligent  Tutoring Systems\", \"topic\": \"Large Language Models in Education\", \"x\": 6.556, \"y\": 2.356}, {\"title\": \"Classifying Human-Generated and AI-Generated Election Claims in Social  Media\", \"topic\": \"Bias in Language Models\", \"x\": 3.454, \"y\": 3.807}, {\"title\": \"Evolution of Voices in French Audiovisual Media Across Genders and Age  in a Diachronic Perspective\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.254, \"y\": 5.921}, {\"title\": \"Cantor: Inspiring Multimodal Chain-of-Thought of MLLM\", \"topic\": \"Multimodal Language Models\", \"x\": 7.762, \"y\": 7.666}, {\"title\": \"MoDE: CLIP Data Experts via Clustering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.414, \"y\": 7.42}, {\"title\": \"Universal Adversarial Triggers Are Not Universal\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.231, \"y\": 0.767}, {\"title\": \"The PRISM Alignment Project: What Participatory, Representative and  Individualised Human Feedback Reveals About the Subjective and Multicultural  Alignment of Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.062, \"y\": 2.587}, {\"title\": \"Uncertainty Estimation and Quantification for LLMs: A Simple Supervised  Approach\", \"topic\": \"Large Language Models in Education\", \"x\": 6.646, \"y\": 2.855}, {\"title\": \"CORM: Cache Optimization with Recent Message for Large Language Model  Inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.328, \"y\": 2.799}, {\"title\": \"Generalization Measures for Zero-Shot Cross-Lingual Transfer\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.288, \"y\": 4.346}, {\"title\": \"Inside the echo chamber: Linguistic underpinnings of misinformation on  Twitter\", \"topic\": \"Bias in Language Models\", \"x\": 3.216, \"y\": 3.656}, {\"title\": \"KGValidator: A Framework for Automatic Validation of Knowledge Graph  Construction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.487, \"y\": 5.371}, {\"title\": \"Assessing The Potential Of Mid-Sized Language Models For Clinical QA\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.902, \"y\": 7.403}, {\"title\": \"One Subgraph for All: Efficient Reasoning on Opening Subgraphs for  Inductive Knowledge Graph Completion\", \"topic\": \"Named Entity Recognition\", \"x\": 6.675, \"y\": 5.89}, {\"title\": \"BASS: Batched Attention-optimized Speculative Sampling\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.494, \"y\": 3.125}, {\"title\": \"A Comprehensive Survey on Evaluating Large Language Model Applications  in the Medical Industry\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.081, \"y\": 7.34}, {\"title\": \"ChEX: Interactive Localization and Region Description in Chest X-rays\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.287, \"y\": 8.067}, {\"title\": \"Let's Think Dot by Dot: Hidden Computation in Transformer Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.82, \"y\": 2.701}, {\"title\": \"No Train but Gain: Language Arithmetic for training-free Language  Adapters enhancement\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.356, \"y\": 4.142}, {\"title\": \"Nyonic Technical Report\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.282, \"y\": 3.82}, {\"title\": \"Beyond Chain-of-Thought: A Survey of Chain-of-X Paradigms for LLMs\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.236, \"y\": 1.994}, {\"title\": \"KS-LLM: Knowledge Selection of Large Language Models with Evidence  Document for Question Answering\", \"topic\": \"Named Entity Recognition\", \"x\": 6.645, \"y\": 4.629}, {\"title\": \"CatLIP: CLIP-level Visual Recognition Accuracy with 2.7x Faster  Pre-training on Web-scale Image-Text Data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.354, \"y\": 7.333}, {\"title\": \"Semantic Evolvement Enhanced Graph Autoencoder for Rumor Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.37, \"y\": 3.841}, {\"title\": \"ImplicitAVE: An Open-Source Dataset and Multimodal LLMs Benchmark for  Implicit Attribute Value Extraction\", \"topic\": \"Multimodal Language Models\", \"x\": 8.049, \"y\": 7.444}, {\"title\": \"Minimal Evidence Group Identification for Claim Verification\", \"topic\": \"Bias in Language Models\", \"x\": 3.849, \"y\": 4.009}, {\"title\": \"Gated Low-rank Adaptation for personalized Code-Switching Automatic  Speech Recognition on the low-spec devices\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.545, \"y\": 5.684}, {\"title\": \"Can Foundational Large Language Models Assist with Conducting  Pharmaceuticals Manufacturing Investigations?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.76, \"y\": 6.83}, {\"title\": \"CASPR: Automated Evaluation Metric for Contrastive Summarization\", \"topic\": \"Text Summarization\", \"x\": 4.992, \"y\": 5.199}, {\"title\": \"PRISM: Patient Records Interpretation for Semantic Clinical Trial  Matching using Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.214, \"y\": 7.132}, {\"title\": \"DreamCraft: Text-Guided Generation of Functional 3D Environments in  Minecraft\", \"topic\": \"Multimodal Language Models\", \"x\": 8.199, \"y\": 6.813}, {\"title\": \"LogicBench: Towards Systematic Evaluation of Logical Reasoning Ability  of Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.45, \"y\": 1.984}, {\"title\": \"Killkan: The Automatic Speech Recognition Dataset for Kichwa with  Morphosyntactic Information\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.347, \"y\": 5.625}, {\"title\": \"IryoNLP at MEDIQA-CORR 2024: Tackling the Medical Error Detection &  Correction Task On the Shoulders of Medical Agents\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.049, \"y\": 7.355}, {\"title\": \"Evaluating the Efficacy of Large Language Models in Identifying Phishing  Attempts\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.184, \"y\": 1.547}, {\"title\": \"Evaluating LLMs for Hardware Design and Test\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.259, \"y\": 0.44}, {\"title\": \"Wiki-LLaVA: Hierarchical Retrieval-Augmented Generation for Multimodal  LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.807, \"y\": 7.355}, {\"title\": \"Automatic Layout Planning for Visually-Rich Documents with  Instruction-Following Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.011, \"y\": 6.786}, {\"title\": \"XFT: Unlocking the Power of Code Instruction Tuning by Simply Merging  Upcycled Mixture-of-Experts\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.307, \"y\": 0.231}, {\"title\": \"CultureBank: An Online Community-Driven Knowledge Base Towards  Culturally Aware Language Technologies\", \"topic\": \"Bias in Language Models\", \"x\": 4.047, \"y\": 2.728}, {\"title\": \"Software Mention Recognition with a Three-Stage Framework Based on  BERTology Models at SOMD 2024\", \"topic\": \"Named Entity Recognition\", \"x\": 5.762, \"y\": 6.51}, {\"title\": \"Re-Thinking Inverse Graphics With Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.035, \"y\": 7.218}, {\"title\": \"The Power of the Noisy Channel: Unsupervised End-to-End Task-Oriented  Dialogue with LLMs\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.218, \"y\": 3.086}, {\"title\": \"Setting up the Data Printer with Improved English to Ukrainian Machine  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.707, \"y\": 4.586}, {\"title\": \"Bias patterns in the application of LLMs for clinical decision support:  A comprehensive study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.688, \"y\": 7.02}, {\"title\": \"Rethinking LLM Memorization through the Lens of Adversarial Compression\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.805, \"y\": 0.694}, {\"title\": \"Multi-view Content-aware Indexing for Long Document Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.367, \"y\": 4.694}, {\"title\": \"Multi-Head Mixture-of-Experts\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.772, \"y\": 2.162}, {\"title\": \"Transformers Can Represent $n$-gram Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.117, \"y\": 2.971}, {\"title\": \"A Reproducibility Study of PLAID\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.044, \"y\": 4.822}, {\"title\": \"Achieving >97% on GSM8K: Deeply Understanding the Problems Makes LLMs  Better Solvers for Math Word Problems\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.624, \"y\": 1.266}, {\"title\": \"Beyond the Speculative Game: A Survey of Speculative Execution in Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.575, \"y\": 3.147}, {\"title\": \"From Matching to Generation: A Survey on Generative Information  Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.947, \"y\": 4.484}, {\"title\": \"Towards Universal Dense Blocking for Entity Resolution\", \"topic\": \"Named Entity Recognition\", \"x\": 6.305, \"y\": 6.85}, {\"title\": \"Pattern-Aware Chain-of-Thought Prompting in Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.226, \"y\": 1.882}, {\"title\": \"A Survey of Large Language Models on Generative Graph Analytics: Query,  Learning, and Applications\", \"topic\": \"Named Entity Recognition\", \"x\": 6.566, \"y\": 5.782}, {\"title\": \"Talk Too Much: Poisoning Large Language Models under Token Limit\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.275, \"y\": 0.658}, {\"title\": \"Med42 -- Evaluating Fine-Tuning Strategies for Medical LLMs:  Full-Parameter vs. Parameter-Efficient Approaches\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.972, \"y\": 7.35}, {\"title\": \"CT-Agent: Clinical Trial Multi-Agent with Large Language Model-based  Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.143, \"y\": 7.102}, {\"title\": \"Simulating Task-Oriented Dialogues with State Transition Graphs and  Large Language Models\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.255, \"y\": 3.302}, {\"title\": \"Retrieval Augmented Generation for Domain-specific Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.212, \"y\": 4.596}, {\"title\": \"Modeling the Sacred: Considerations when Using Religious Texts in  Natural Language Processing\", \"topic\": \"Bias in Language Models\", \"x\": 3.921, \"y\": 2.322}, {\"title\": \"Insights into Alignment: Evaluating DPO and its Variants Across Multiple  Tasks\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.495, \"y\": 0.595}, {\"title\": \"FINEMATCH: Aspect-based Fine-grained Image and Text Mismatch Detection  and Correction\", \"topic\": \"Multimodal Language Models\", \"x\": 8.485, \"y\": 7.446}, {\"title\": \"FlashSpeech: Efficient Zero-Shot Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.011, \"y\": 6.078}, {\"title\": \"MisgenderMender: A Community-Informed Approach to Interventions for  Misgendering\", \"topic\": \"Bias in Language Models\", \"x\": 2.85, \"y\": 3.053}, {\"title\": \"Pegasus-v1 Technical Report\", \"topic\": \"Multimodal Language Models\", \"x\": 8.745, \"y\": 7.442}, {\"title\": \"Automated Multi-Language to English Machine Translation Using Generative  Pre-Trained Transformers\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.791, \"y\": 4.698}, {\"title\": \"NExT: Teaching Large Language Models to Reason about Code Execution\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.038, \"y\": 0.485}, {\"title\": \"Describe-then-Reason: Improving Multimodal Mathematical Reasoning  through Visual Comprehension Training\", \"topic\": \"Multimodal Language Models\", \"x\": 7.609, \"y\": 7.602}, {\"title\": \"Planning Ahead in Generative Retrieval: Guiding Autoregressive  Generation through Simultaneous Decoding\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.023, \"y\": 4.605}, {\"title\": \"WangLab at MEDIQA-M3G 2024: Multimodal Medical Answer Generation using  Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.295, \"y\": 8.001}, {\"title\": \"WangLab at MEDIQA-CORR 2024: Optimized LLM-based Programs for Medical  Error Detection and Correction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.137, \"y\": 7.338}, {\"title\": \"RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.763, \"y\": 1.719}, {\"title\": \"PARAMANU-GANITA: Language Model with Mathematical Capabilities\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.876, \"y\": 1.054}, {\"title\": \"A Multimodal Automated Interpretability Agent\", \"topic\": \"Multimodal Language Models\", \"x\": 7.765, \"y\": 7.549}, {\"title\": \"SnapKV: LLM Knows What You are Looking for Before Generation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.353, \"y\": 3.022}, {\"title\": \"Less Peaky and More Accurate CTC Forced Alignment by Label Priors\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.522, \"y\": 5.613}, {\"title\": \"Beyond Scaling: Predicting Patent Approval with Domain-specific  Fine-grained Claim Dependency Graph\", \"topic\": \"Legal NLP\", \"x\": 4.704, \"y\": 4.906}, {\"title\": \"Graphic Design with Large Multimodal Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.208, \"y\": 6.782}, {\"title\": \"Expert Router: Orchestrating Efficient Language Model Inference through  Prompt Classification\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.475, \"y\": 2.785}, {\"title\": \"Automated Long Answer Grading with RiceChem Dataset\", \"topic\": \"Large Language Models in Education\", \"x\": 6.405, \"y\": 2.622}, {\"title\": \"Self-Supervised Alignment with Mutual Information: Learning to Follow  Principles without Preference Labels\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.686, \"y\": 0.776}, {\"title\": \"Marking: Visual Grading with Highlighting Errors and Annotating Missing  Bits\", \"topic\": \"Large Language Models in Education\", \"x\": 6.393, \"y\": 2.621}, {\"title\": \"A Survey on Efficient Inference for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.369, \"y\": 3.004}, {\"title\": \"What do Transformers Know about Government?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.03, \"y\": 3.111}, {\"title\": \"Detecting and Mitigating Hallucination in Large Vision Language Models  via Fine-Grained AI Feedback\", \"topic\": \"Multimodal Language Models\", \"x\": 8.283, \"y\": 8.052}, {\"title\": \"EnzChemRED, a rich enzyme chemistry relation extraction dataset\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 5.173, \"y\": 6.851}, {\"title\": \"Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy  Data in Misaligned Languages Suffice?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.711, \"y\": 4.517}, {\"title\": \"Benchmarking Advanced Text Anonymisation Methods: A Comparative Study on  Novel and Traditional Approaches\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.653, \"y\": 0.319}, {\"title\": \"Bored to Death: Artificial Intelligence Research Reveals the Role of  Boredom in Suicide Behavior\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.309, \"y\": 6.376}, {\"title\": \"LLMs Know What They Need: Leveraging a Missing Information Guided  Framework to Empower Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.143, \"y\": 4.567}, {\"title\": \"DAIC-WOZ: On the Validity of Using the Therapist's prompts in Automatic  Depression Detection from Clinical Interviews\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.05, \"y\": 6.362}, {\"title\": \"Information Re-Organization Improves Reasoning in Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.47, \"y\": 2.127}, {\"title\": \"Do not think pink elephant!\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.403, \"y\": 0.802}, {\"title\": \"Protecting Your LLMs with Information Bottleneck\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.326, \"y\": 0.955}, {\"title\": \"Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by  Simulating Documents in the Wild via Low-level Perturbations\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.502, \"y\": 0.729}, {\"title\": \"SemEval-2024 Task 9: BRAINTEASER: A Novel Task Defying Common Sense\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.283, \"y\": 2.03}, {\"title\": \"MARIO Eval: Evaluate Your Math LLM with your Math LLM--A mathematical  dataset evaluation toolkit\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.697, \"y\": 1.228}, {\"title\": \"Adaptive Collaboration Strategy for LLMs in Medical Decision Making\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.666, \"y\": 7.487}, {\"title\": \"Towards Better Text-to-Image Generation Alignment via Attention  Modulation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.468, \"y\": 6.884}, {\"title\": \"Surveying Attitudinal Alignment Between Large Language Models Vs. Humans  Towards 17 Sustainable Development Goals\", \"topic\": \"Bias in Language Models\", \"x\": 4.002, \"y\": 2.653}, {\"title\": \"Competition Report: Finding Universal Jailbreak Backdoors in Aligned  LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.32, \"y\": 0.611}, {\"title\": \"VALOR-EVAL: Holistic Coverage and Faithfulness Evaluation of Large  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.361, \"y\": 8.064}, {\"title\": \"Context-Enhanced Language Models for Generating Multi-Paper Citations\", \"topic\": \"Text Summarization\", \"x\": 5.097, \"y\": 5.861}, {\"title\": \"EventLens: Leveraging Event-Aware Pretraining and Cross-modal Linking  Enhances Visual Commonsense Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.868, \"y\": 7.562}, {\"title\": \"Filtered Direct Preference Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.426, \"y\": 0.572}, {\"title\": \"MixLoRA: Enhancing Large Language Models Fine-Tuning with LoRA-based  Mixture of Experts\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.946, \"y\": 2.052}, {\"title\": \"From LLM to NMT: Advancing Low-Resource Machine Translation with Claude\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.721, \"y\": 4.701}, {\"title\": \"AdvPrompter: Fast Adaptive Adversarial Prompting for LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.305, \"y\": 0.906}, {\"title\": \"Iteratively Prompting Multimodal LLMs to Reproduce Natural and  AI-Generated Images\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.799, \"y\": 1.252}, {\"title\": \"Evaluating Retrieval Quality in Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.139, \"y\": 4.493}, {\"title\": \"How to Encode Domain Information in Relation Classification\", \"topic\": \"Named Entity Recognition\", \"x\": 6.354, \"y\": 6.591}, {\"title\": \"Trojan Detection in Large Language Models: Insights from The Trojan  Detection Challenge\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.237, \"y\": 0.743}, {\"title\": \"Utilizing Deep Learning to Optimize Software Development Processes\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.035, \"y\": 0.133}, {\"title\": \"Mixture of LoRA Experts\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.441, \"y\": 1.982}, {\"title\": \"Video sentence grounding with temporally global textual knowledge\", \"topic\": \"Multimodal Language Models\", \"x\": 8.663, \"y\": 7.297}, {\"title\": \"Reinforcement of Explainability of ChatGPT Prompts by Embedding Breast  Cancer Self-Screening Rules into AI Responses\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.83, \"y\": 7.655}, {\"title\": \"Exploring Diverse Methods in Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 7.727, \"y\": 7.775}, {\"title\": \"Listen Then See: Video Alignment with Speaker Attention\", \"topic\": \"Multimodal Language Models\", \"x\": 8.739, \"y\": 7.462}, {\"title\": \"Parameter Efficient Fine Tuning: A Comprehensive Analysis Across  Applications\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.756, \"y\": 1.837}, {\"title\": \"Fine-Grained Named Entities for Corona News\", \"topic\": \"Named Entity Recognition\", \"x\": 6.104, \"y\": 6.791}, {\"title\": \"Intrusion Detection at Scale with the Assistance of a Command-line  Language Model\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.528, \"y\": 0.969}, {\"title\": \"Retrieval-Augmented Generation-based Relation Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.266, \"y\": 6.531}, {\"title\": \"Movie101v2: Improved Movie Narration Benchmark\", \"topic\": \"Multimodal Language Models\", \"x\": 8.78, \"y\": 7.324}, {\"title\": \"Semantically Corrected Amharic Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.096, \"y\": 5.485}, {\"title\": \"UnibucLLM: Harnessing LLMs for Automated Prediction of Item Difficulty  and Response Time for Multiple-Choice Questions\", \"topic\": \"Large Language Models in Education\", \"x\": 6.543, \"y\": 2.697}, {\"title\": \"Beyond Accuracy: Investigating Error Types in GPT-4 Responses to USMLE  Questions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.805, \"y\": 7.288}, {\"title\": \"Evaluation of Machine Translation Based on Semantic Dependencies and  Keywords\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.523, \"y\": 4.966}, {\"title\": \"ISQA: Informative Factuality Feedback for Scientific Summarization\", \"topic\": \"Text Summarization\", \"x\": 4.925, \"y\": 5.551}, {\"title\": \"Personalized Wireless Federated Learning for Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.125, \"y\": 0.01}, {\"title\": \"The Instruction Hierarchy: Training LLMs to Prioritize Privileged  Instructions\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.203, \"y\": 0.446}, {\"title\": \"Heterogeneous Subgraph Transformer for Fake News Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.396, \"y\": 3.75}, {\"title\": \"Beyond Self-Consistency: Ensemble Reasoning Boosts Consistency and  Accuracy of LLMs in Cancer Staging\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.001, \"y\": 7.335}, {\"title\": \"Data Alignment for Zero-Shot Concept Generation in Dermatology AI\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.367, \"y\": 7.969}, {\"title\": \"LaPA: Latent Prompt Assist Model For Medical Visual Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.382, \"y\": 8.133}, {\"title\": \"Groma: Localized Visual Tokenization for Grounding Multimodal Large  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.097, \"y\": 7.405}, {\"title\": \"Rethinking the Evaluation of Dialogue Systems: Effects of User Feedback  on Crowdworkers and LLMs\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.654, \"y\": 2.965}, {\"title\": \"MAiDE-up: Multilingual Deception Detection of GPT-generated Hotel  Reviews\", \"topic\": \"Bias in Language Models\", \"x\": 3.489, \"y\": 3.66}, {\"title\": \"Unlocking Multi-View Insights in Knowledge-Dense Retrieval-Augmented  Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.036, \"y\": 4.581}, {\"title\": \"How Does the Textual Information Affect the Retrieval of Multimodal  In-Context Learning?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.323, \"y\": 7.518}, {\"title\": \"Multi Class Depression Detection Through Tweets using Artificial  Intelligence\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.295, \"y\": 6.355}, {\"title\": \"TartuNLP @ SIGTYP 2024 Shared Task: Adapting XLM-RoBERTa for Ancient and  Historical Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.044, \"y\": 4.287}, {\"title\": \"Towards Logically Consistent Language Models via Probabilistic Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 6.904, \"y\": 2.617}, {\"title\": \"CT-ADE: An Evaluation Benchmark for Adverse Drug Event Prediction from  Clinical Trial Results\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.339, \"y\": 6.958}, {\"title\": \"REXEL: An End-to-end Model for Document-Level Relation Extraction and  Entity Linking\", \"topic\": \"Named Entity Recognition\", \"x\": 6.262, \"y\": 6.5}, {\"title\": \"AutoCrawler: A Progressive Understanding Web Agent for Web Crawler  Generation\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.096, \"y\": 1.493}, {\"title\": \"Beyond Human Norms: Unveiling Unique Values of Large Language Models  through Interdisciplinary Approaches\", \"topic\": \"Bias in Language Models\", \"x\": 4.194, \"y\": 2.29}, {\"title\": \"PDF-MVQA: A Dataset for Multimodal Information Retrieval in PDF-based  Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 7.643, \"y\": 7.293}, {\"title\": \"Mathify: Evaluating Large Language Models on Mathematical Problem  Solving Tasks\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.741, \"y\": 1.185}, {\"title\": \"Towards Human-centered Proactive Conversational Agents\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.238, \"y\": 2.635}, {\"title\": \"SOS-1K: A Fine-grained Suicide Risk Classification Dataset for Chinese  Social Media Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.319, \"y\": 6.378}, {\"title\": \"Pre-trained Vision-Language Models Learn Discoverable Visual Concepts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.028, \"y\": 7.811}, {\"title\": \"Cooperative Sentiment Agents for Multimodal Sentiment Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.559, \"y\": 5.217}, {\"title\": \"Efficient infusion of self-supervised representations in Automatic  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.558, \"y\": 5.83}, {\"title\": \"CORI: CJKV Benchmark with Romanization Integration -- A step towards  Cross-lingual Transfer Beyond Textual Scripts\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.32, \"y\": 4.496}, {\"title\": \"HalluciBot: Is There No Such Thing as a Bad Question?\", \"topic\": \"Large Language Models in Education\", \"x\": 6.074, \"y\": 3.392}, {\"title\": \"BIRD: A Trustworthy Bayesian Inference Framework for Large Language  Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.052, \"y\": 2.491}, {\"title\": \"NormAd: A Benchmark for Measuring the Cultural Adaptability of Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.042, \"y\": 2.703}, {\"title\": \"Characterizing LLM Abstention Behavior in Science QA with Context  Perturbations\", \"topic\": \"Large Language Models in Education\", \"x\": 6.888, \"y\": 2.847}, {\"title\": \"mOthello: When Do Cross-Lingual Representation Alignment and  Cross-Lingual Transfer Emerge in Multilingual Models?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.328, \"y\": 4.266}, {\"title\": \"BLINK: Multimodal Large Language Models Can See but Not Perceive\", \"topic\": \"Multimodal Language Models\", \"x\": 7.955, \"y\": 7.589}, {\"title\": \"Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.962, \"y\": 7.454}, {\"title\": \"Large Language Models in Targeted Sentiment Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.212, \"y\": 4.862}, {\"title\": \"Reuse Your Rewards: Reward Model Transfer for Zero-Shot Cross-Lingual  Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.629, \"y\": 0.676}, {\"title\": \"Simultaneous Interpretation Corpus Construction by Large Language Models  in Distant Language Pair\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.822, \"y\": 4.8}, {\"title\": \"Augmenting emotion features in irony detection with Large language  modeling\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.567, \"y\": 4.961}, {\"title\": \"Resilience through Scene Context in Visual Referring Expression  Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.329, \"y\": 7.743}, {\"title\": \"Advancing the Robustness of Large Language Models through Self-Denoised  Smoothing\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.048, \"y\": 1.057}, {\"title\": \"FedEval-LLM: Federated Evaluation of Large Language Models on Downstream  Tasks with Collective Wisdom\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.213, \"y\": 0.085}, {\"title\": \"Introducing v0.5 of the AI Safety Benchmark from MLCommons\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.956, \"y\": 1.327}, {\"title\": \"Length Generalization of Causal Transformers without Position Encoding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.62, \"y\": 3.08}, {\"title\": \"Claim Check-Worthiness Detection: How Well do LLMs Grasp Annotation  Guidelines?\", \"topic\": \"Bias in Language Models\", \"x\": 3.87, \"y\": 3.969}, {\"title\": \"FecTek: Enhancing Term Weight in Lexicon-Based Retrieval with Feature  Context and Term-level Knowledge\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.398, \"y\": 4.807}, {\"title\": \"Aligning language models with human preferences\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.352, \"y\": 0.655}, {\"title\": \"Enhancing Suicide Risk Assessment: A Speech-Based Automated Approach in  Emergency Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.312, \"y\": 6.42}, {\"title\": \"TIMIT Speaker Profiling: A Comparison of Multi-task learning and  Single-task learning Approaches\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.556, \"y\": 5.945}, {\"title\": \"RAGAR, Your Falsehood RADAR: RAG-Augmented Reasoning for Political  Fact-Checking using Multimodal Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.705, \"y\": 3.788}, {\"title\": \"emrQA-msquad: A Medical Dataset Structured with the SQuAD V2.0  Framework, Enriched with emrQA Medical Information\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.934, \"y\": 7.251}, {\"title\": \"RAM: Towards an Ever-Improving Memory System by Learning from  Communications\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.998, \"y\": 4.007}, {\"title\": \"Exploring Boundaries and Intensities in Offensive and Hate Speech:  Unveiling the Complex Spectrum of Social Media Discourse\", \"topic\": \"Bias in Language Models\", \"x\": 2.492, \"y\": 3.396}, {\"title\": \"Uncovering Safety Risks of Large Language Models through Concept  Activation Vector\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.494, \"y\": 0.997}, {\"title\": \"Parallel Decoding via Hidden Transfer for Lossless Large Language Model  Acceleration\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.473, \"y\": 3.168}, {\"title\": \"Enhance Robustness of Language Models Against Variation Attack through  Graph Integration\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.953, \"y\": 1.213}, {\"title\": \"Sequential Compositional Generalization in Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.405, \"y\": 7.343}, {\"title\": \"Token-level Direct Preference Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.464, \"y\": 0.617}, {\"title\": \"CrossIn: An Efficient Instruction Tuning Approach for Cross-Lingual  Knowledge Alignment\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.072, \"y\": 4.003}, {\"title\": \"SKIP: Skill-Localized Prompt Tuning for Inference Speed Boost-Up\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.379, \"y\": 2.182}, {\"title\": \"TriForce: Lossless Acceleration of Long Sequence Generation with  Hierarchical Speculative Decoding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.53, \"y\": 3.145}, {\"title\": \"Large Language Models Can Plan Your Travels Rigorously with Formal  Verification Tools\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.315, \"y\": 1.552}, {\"title\": \"Enhancing Length Extrapolation in Sequential Models with  Pointer-Augmented Neural Memory\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.676, \"y\": 2.89}, {\"title\": \"Challenging Negative Gender Stereotypes: A Study on the Effectiveness of  Automated Counter-Stereotypes\", \"topic\": \"Bias in Language Models\", \"x\": 3.168, \"y\": 2.743}, {\"title\": \"Sharing Parameter by Conjugation for Knowledge Graph Embeddings in  Complex Space\", \"topic\": \"Named Entity Recognition\", \"x\": 6.686, \"y\": 5.787}, {\"title\": \"REQUAL-LM: Reliability and Equity through Aggregation in Large Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.316, \"y\": 2.716}, {\"title\": \"Mapping Violence: Developing an Extensive Framework to Build a Bangla  Sectarian Expression Dataset from Social Media Interactions\", \"topic\": \"Bias in Language Models\", \"x\": 2.517, \"y\": 3.445}, {\"title\": \"Missed Connections: Lateral Thinking Puzzles for Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.27, \"y\": 2.246}, {\"title\": \"Investigating Gender Bias in Turkish Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.227, \"y\": 2.696}, {\"title\": \"Demystifying Legalese: An Automated Approach for Summarizing and  Analyzing Overlaps in Privacy Policies and Terms of Service\", \"topic\": \"Legal NLP\", \"x\": 4.378, \"y\": 4.438}, {\"title\": \"Improvement in Semantic Address Matching using Natural Language  Processing\", \"topic\": \"Named Entity Recognition\", \"x\": 6.101, \"y\": 6.516}, {\"title\": \"How Well Can You Articulate that Idea? Insights from Automated Formative  Assessment\", \"topic\": \"Large Language Models in Education\", \"x\": 6.524, \"y\": 2.343}, {\"title\": \"Related Work and Citation Text Generation: A Survey\", \"topic\": \"Text Summarization\", \"x\": 5.021, \"y\": 5.75}, {\"title\": \"The Landscape of Emerging AI Agent Architectures for Reasoning,  Planning, and Tool Calling: A Survey\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.877, \"y\": 1.483}, {\"title\": \"Quantifying Multilingual Performance of Large Language Models Across  Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.095, \"y\": 4.321}, {\"title\": \"GenFighter: A Generative and Evolutive Textual Attack Removal\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.046, \"y\": 1.136}, {\"title\": \"Pack of LLMs: Model Fusion at Test-Time via Perplexity Optimization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.478, \"y\": 1.99}, {\"title\": \"Towards Coarse-to-Fine Evaluation of Inference Efficiency for Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.367, \"y\": 2.79}, {\"title\": \"Paraphrase and Solve: Exploring and Exploiting the Impact of Surface  Form on Mathematical Reasoning in Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.594, \"y\": 1.281}, {\"title\": \"A Federated Learning Approach to Privacy Preserving Offensive Language  Identification\", \"topic\": \"Bias in Language Models\", \"x\": 2.392, \"y\": 3.268}, {\"title\": \"Unifying Bias and Unfairness in Information Retrieval: A Survey of  Challenges and Opportunities with Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.313, \"y\": 2.842}, {\"title\": \"AI-Enhanced Cognitive Behavioral Therapy: Deep Learning and Large  Language Models for Extracting Cognitive Pathways from Social Media Texts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.241, \"y\": 6.326}, {\"title\": \"Research on emotionally intelligent dialogue generation based on  automatic dialogue system\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.645, \"y\": 5.705}, {\"title\": \"Open-Ended Wargames with Large Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.538, \"y\": 1.81}, {\"title\": \"TeClass: A Human-Annotated Relevance-based Headline Classification and  Generation Dataset for Telugu\", \"topic\": \"Text Summarization\", \"x\": 5.611, \"y\": 5.029}, {\"title\": \"A Preference-driven Paradigm for Enhanced Translation with Large  Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.75, \"y\": 4.548}, {\"title\": \"Sampling-based Pseudo-Likelihood for Membership Inference Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.622, \"y\": 0.772}, {\"title\": \"Position Engineering: Boosting Large Language Models through Positional  Information Manipulation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.347, \"y\": 4.151}, {\"title\": \"Prompt-tuning for Clickbait Detection via Text Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.254, \"y\": 5.033}, {\"title\": \"Neuron Specialization: Leveraging intrinsic task modularity for  multilingual machine translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.53, \"y\": 4.175}, {\"title\": \"FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out  Document\", \"topic\": \"Text Summarization\", \"x\": 5.154, \"y\": 4.997}, {\"title\": \"Context-Aware Siamese Networks for Efficient Emotion Recognition in  Conversation\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.444, \"y\": 5.371}, {\"title\": \"A Novel ICD Coding Framework Based on Associated and Hierarchical Code  Description Distillation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.205, \"y\": 7.551}, {\"title\": \"What's under the hood: Investigating Automatic Metrics on Meeting  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.229, \"y\": 4.882}, {\"title\": \"Inductive-Deductive Strategy Reuse for Multi-Turn Instructional  Dialogues\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.379, \"y\": 2.835}, {\"title\": \"Unified Examination of Entity Linking in Absence of Candidate Sets\", \"topic\": \"Named Entity Recognition\", \"x\": 6.295, \"y\": 6.305}, {\"title\": \"Stepwise Alignment for Constrained Language Model Policy Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.255, \"y\": 0.726}, {\"title\": \"Offset Unlearning for Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.045, \"y\": 0.494}, {\"title\": \"Cross-Platform Hate Speech Detection with Weakly Supervised Causal  Disentanglement\", \"topic\": \"Bias in Language Models\", \"x\": 2.482, \"y\": 3.386}, {\"title\": \"Advancing Social Intelligence in AI Agents: Technical Challenges and  Open Questions\", \"topic\": \"Bias in Language Models\", \"x\": 4.937, \"y\": 2.38}, {\"title\": \"A Survey on Retrieval-Augmented Text Generation for Large Language  Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.202, \"y\": 4.412}, {\"title\": \"SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA  of LLMs\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.505, \"y\": 4.48}, {\"title\": \"Uncertainty-Based Abstention in LLMs Improves Safety and Reduces  Hallucinations\", \"topic\": \"Large Language Models in Education\", \"x\": 6.435, \"y\": 3.001}, {\"title\": \"Can Language Models Solve Olympiad Programming?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.099, \"y\": 1.606}, {\"title\": \"More Room for Language: Investigating the Effect of Retrieval on  Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.558, \"y\": 4.283}, {\"title\": \"Shears: Unstructured Sparsity with Neural Low-rank Adapter Search\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.976, \"y\": 1.982}, {\"title\": \"LLMem: Estimating GPU Memory Usage for Fine-Tuning Pre-Trained LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.281, \"y\": 2.327}, {\"title\": \"Which questions should I answer? Salience Prediction of Inquisitive  Questions\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.223, \"y\": 4.281}, {\"title\": \"Search Beyond Queries: Training Smaller Language Models for Web  Interactions via Reinforcement Learning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.082, \"y\": 1.61}, {\"title\": \"D3CODE: Disentangling Disagreements in Data across Cultures on  Offensiveness Detection and Evaluation\", \"topic\": \"Bias in Language Models\", \"x\": 2.502, \"y\": 3.339}, {\"title\": \"Dynamic Self-adaptive Multiscale Distillation from Pre-trained  Multimodal Large Model for Efficient Cross-modal Representation Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.26, \"y\": 7.187}, {\"title\": \"LaDiC: Are Diffusion Models Really Inferior to Autoregressive  Counterparts for Image-to-Text Generation?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.53, \"y\": 6.816}, {\"title\": \"Deep Learning and LLM-based Methods Applied to Stellar Lightcurve  Classification\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.633, \"y\": 2.658}, {\"title\": \"Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.54, \"y\": 0.56}, {\"title\": \"Dual Modalities of Text: Visual and Textual Generative Pre-training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.291, \"y\": 7.339}, {\"title\": \"Cross-Language Evolution of Divergent Collective Memory Around the Arab  Spring\", \"topic\": \"Bias in Language Models\", \"x\": 3.356, \"y\": 4.071}, {\"title\": \"ViTextVQA: A Large-Scale Visual Question Answering Dataset for  Evaluating Vietnamese Text Comprehension in Images\", \"topic\": \"Multimodal Language Models\", \"x\": 7.753, \"y\": 7.445}, {\"title\": \"Self-playing Adversarial Language Game Enhances LLM Reasoning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.338, \"y\": 0.927}, {\"title\": \"HLAT: High-quality Large Language Model Pre-trained on AWS Trainium\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.125, \"y\": 2.534}, {\"title\": \"Unveiling the Misuse Potential of Base Large Language Models via  In-Context Learning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.503, \"y\": 0.882}, {\"title\": \"White Men Lead, Black Women Help? Benchmarking Language Agency Social  Biases in LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.369, \"y\": 2.767}, {\"title\": \"Self-Supervised Visual Preference Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.124, \"y\": 7.722}, {\"title\": \"DESTEIN: Navigating Detoxification of Language Models via Universal  Steering Pairs and Head-wise Activation Fusion\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.841, \"y\": 1.38}, {\"title\": \"Language Proficiency and F0 Entrainment: A Study of L2 English Imitation  in Italian, French, and Slovak Speakers\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.248, \"y\": 5.786}, {\"title\": \"MAD Speech: Measures of Acoustic Diversity of Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.104, \"y\": 6.016}, {\"title\": \"Self-Explore to Avoid the Pit: Improving the Reasoning Capabilities of  Language Models with Fine-grained Rewards\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.324, \"y\": 1.778}, {\"title\": \"Enhancing Confidence Expression in Large Language Models Through  Learning from Past Experience\", \"topic\": \"Large Language Models in Education\", \"x\": 6.689, \"y\": 2.887}, {\"title\": \"Balancing Speciality and Versatility: a Coarse to Fine Framework for  Supervised Fine-tuning Large Language Model\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.351, \"y\": 2.041}, {\"title\": \"Exploring Social Media Posts for Depression Identification: A Study on  Reddit Dataset\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.311, \"y\": 6.32}, {\"title\": \"Empowering Interdisciplinary Research with BERT-Based Models: An  Approach Through SciBERT-CNN with Topic Modeling\", \"topic\": \"Text Summarization\", \"x\": 5.069, \"y\": 6.118}, {\"title\": \"Modeling Low-Resource Health Coaching Dialogues via Neuro-Symbolic Goal  Summarization and Text-Units-Text Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.82, \"y\": 7.264}, {\"title\": \"Uncovering Latent Arguments in Social Media Messaging by Employing  LLMs-in-the-Loop Strategy\", \"topic\": \"Bias in Language Models\", \"x\": 3.443, \"y\": 4.122}, {\"title\": \"Med-MoE: Mixture of Domain-Specific Experts for Lightweight Medical  Vision-Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.386, \"y\": 8.086}, {\"title\": \"Generative Text Steganography with Large Language Model\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.584, \"y\": 0.966}, {\"title\": \"Two-Stage Stance Labeling: User-Hashtag Heuristics with Graph Neural  Networks\", \"topic\": \"Bias in Language Models\", \"x\": 3.173, \"y\": 4.123}, {\"title\": \"Find The Gap: Knowledge Base Reasoning For Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 7.839, \"y\": 7.72}, {\"title\": \"CULTURE-GEN: Revealing Global Cultural Perception in Language Models  through Natural Language Prompting\", \"topic\": \"Bias in Language Models\", \"x\": 3.966, \"y\": 2.695}, {\"title\": \"Deferred NAM: Low-latency Top-K Context Injection via Deferred Context  Encoding for Non-Streaming ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.584, \"y\": 5.626}, {\"title\": \"On the Effects of Fine-tuning Language Models for Text-Based  Reinforcement Learning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.882, \"y\": 1.352}, {\"title\": \"ANCHOR: LLM-driven News Subject Conditioning for Text-to-Image Synthesis\", \"topic\": \"Multimodal Language Models\", \"x\": 8.374, \"y\": 7.186}, {\"title\": \"PRODIS -- a speech database and a phoneme-based language model for the  study of predictability effects in Polish\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.247, \"y\": 5.766}, {\"title\": \"Tango 2: Aligning Diffusion-based Text-to-Audio Generations through  Direct Preference Optimization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.726, \"y\": 6.186}, {\"title\": \"ChatShop: Interactive Information Seeking with Language Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.924, \"y\": 1.808}, {\"title\": \"Progressive Knowledge Graph Completion\", \"topic\": \"Named Entity Recognition\", \"x\": 6.662, \"y\": 5.687}, {\"title\": \"Software Engineering Methods For AI-Driven Deductive Legal Reasoning\", \"topic\": \"Legal NLP\", \"x\": 4.44, \"y\": 4.431}, {\"title\": \"Anatomy of Industrial Scale Multilingual ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.518, \"y\": 5.674}, {\"title\": \"Impact of Preference Noise on the Alignment Performance of Generative  Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.642, \"y\": 0.798}, {\"title\": \"KG-CTG: Citation Generation through Knowledge Graph-guided Large  Language Models\", \"topic\": \"Text Summarization\", \"x\": 5.051, \"y\": 5.759}, {\"title\": \"Personalized Collaborative Fine-Tuning for On-Device Large Language  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.201, \"y\": -0.017}, {\"title\": \"Quantization of Large Language Models with an Overdetermined Basis\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.521, \"y\": 2.249}, {\"title\": \"LoRAP: Transformer Sub-Layers Deserve Differentiated Structured  Compression for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.042, \"y\": 2.536}, {\"title\": \"Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration\", \"topic\": \"Multimodal Language Models\", \"x\": 7.813, \"y\": 7.64}, {\"title\": \"Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data  Annotation\", \"topic\": \"Text Summarization\", \"x\": 5.274, \"y\": 5.081}, {\"title\": \"Learn Your Reference Model for Real Good Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.509, \"y\": 0.625}, {\"title\": \"If there's a Trigger Warning, then where's the Trigger? Investigating  Trigger Warnings at the Passage Level\", \"topic\": \"Bias in Language Models\", \"x\": 3.057, \"y\": 3.741}, {\"title\": \"Improving Recall of Large Language Models: A Model Collaboration  Approach for Relational Triple Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.377, \"y\": 6.467}, {\"title\": \"Reliability Estimation of News Media Sources: Birds of a Feather Flock  Together\", \"topic\": \"Bias in Language Models\", \"x\": 3.603, \"y\": 3.76}, {\"title\": \"Prepacking: A Simple Method for Fast Prefilling and Increased Throughput  in Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.229, \"y\": 2.96}, {\"title\": \"State Space Model for New-Generation Network Alternative to  Transformers: A Survey\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.805, \"y\": 3.001}, {\"title\": \"MMCode: Evaluating Multi-Modal Code Large Language Models with Visually  Rich Programming Problems\", \"topic\": \"Multimodal Language Models\", \"x\": 7.729, \"y\": 7.569}, {\"title\": \"Mitigating Hallucination in Abstractive Summarization with  Domain-Conditional Mutual Information\", \"topic\": \"Text Summarization\", \"x\": 5.168, \"y\": 5.071}, {\"title\": \"Modeling Emotions and Ethics with Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.037, \"y\": 2.209}, {\"title\": \"Automatic Knowledge Graph Construction for Judicial Cases\", \"topic\": \"Legal NLP\", \"x\": 4.442, \"y\": 4.592}, {\"title\": \"Few-shot Name Entity Recognition on StackOverflow\", \"topic\": \"Named Entity Recognition\", \"x\": 6.205, \"y\": 6.824}, {\"title\": \"A Large-Scale Evaluation of Speech Foundation Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.367, \"y\": 5.626}, {\"title\": \"Tasks People Prompt: A Taxonomy of LLM Downstream Tasks in Software  Verification and Falsification Approaches\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.935, \"y\": 0.305}, {\"title\": \"Low-Resource Named Entity Recognition with Cross-Lingual,  Character-Level Neural Conditional Random Fields\", \"topic\": \"Named Entity Recognition\", \"x\": 6.263, \"y\": 6.851}, {\"title\": \"Understanding the Role of Temperature in Diverse Question Generation by  GPT-4\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.281, \"y\": 4.071}, {\"title\": \"LLeMpower: Understanding Disparities in the Control and Access of Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.16, \"y\": 2.295}, {\"title\": \"Self-Selected Attention Span for Accelerating Large Language Model  Inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.174, \"y\": 2.845}, {\"title\": \"Reap the Wild Wind: Detecting Media Storms in Large-Scale News Corpora\", \"topic\": \"Bias in Language Models\", \"x\": 3.4, \"y\": 4.108}, {\"title\": \"TrafficVLM: A Controllable Visual Language Model for Traffic Video  Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.54, \"y\": 7.444}, {\"title\": \"Test Code Generation for Telecom Software Systems using Two-Stage  Generative Model\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.994, \"y\": 0.202}, {\"title\": \"Knowledgeable Agents by Offline Reinforcement Learning from Large  Language Model Rollouts\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.148, \"y\": 1.343}, {\"title\": \"Exploring and Improving Drafts in Blockwise Parallel Decoding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.502, \"y\": 3.217}, {\"title\": \"DKE-Research at SemEval-2024 Task 2: Incorporating Data Augmentation  with Generative Models and Biomedical Knowledge to Enhance Inference  Robustness\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.329, \"y\": 7.095}, {\"title\": \"TransformerFAM: Feedback attention is working memory\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.78, \"y\": 3.005}, {\"title\": \"Post-Semantic-Thinking: A Robust Strategy to Distill Reasoning Capacity  from Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.391, \"y\": 1.973}, {\"title\": \"Mitigating Heterogeneity among Factor Tensors via Lie Group Manifolds  for Tensor Decomposition Based Temporal Knowledge Graph Embedding\", \"topic\": \"Named Entity Recognition\", \"x\": 6.579, \"y\": 5.745}, {\"title\": \"ToNER: Type-oriented Named Entity Recognition with Generative Language  Model\", \"topic\": \"Named Entity Recognition\", \"x\": 6.206, \"y\": 6.828}, {\"title\": \"From Bytes to Borsch: Fine-Tuning Gemma and Mistral for the Ukrainian  Language Representation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.999, \"y\": 4.056}, {\"title\": \"TLDR at SemEval-2024 Task 2: T5-generated clinical-Language summaries  for DeBERTa Report Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.227, \"y\": 7.118}, {\"title\": \"When Hindsight is Not 20/20: Testing Limits on Reflective Thinking in  Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 6.909, \"y\": 2.195}, {\"title\": \"Provable Interactive Learning with Hindsight Instruction Feedback\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.894, \"y\": 1.063}, {\"title\": \"CodeCloak: A Method for Evaluating and Mitigating Code Leakage by LLM  Code Assistants\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.933, \"y\": 0.113}, {\"title\": \"Adapting Mental Health Prediction Tasks for Cross-lingual Learning via  Meta-Training and In-context Learning with Large Language Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.299, \"y\": 6.4}, {\"title\": \"Do LLMs Play Dice? Exploring Probability Distribution Sampling in Large  Language Models for Behavioral Simulation\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.362, \"y\": 1.817}, {\"title\": \"MING-MOE: Enhancing Medical Multi-Task Learning in Large Language Models  with Sparse Mixture of Low-Rank Adapter Experts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.165, \"y\": 7.572}, {\"title\": \"Navigating the Landscape of Large Language Models: A Comprehensive  Review and Analysis of Paradigms and Fine-Tuning Strategies\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.432, \"y\": 2.043}, {\"title\": \"AMU-Tuning: Effective Logit Bias for CLIP-based Few-shot Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.433, \"y\": 7.566}, {\"title\": \"Introducing Super RAGs in Mistral 8x7B-v1\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.245, \"y\": 4.239}, {\"title\": \"Leveraging Large Language Model as Simulated Patients for Clinical  Education\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.676, \"y\": 7.37}, {\"title\": \"Towards Enhancing Health Coaching Dialogue in Low-Resource Settings\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.044, \"y\": 6.479}, {\"title\": \"EIVEN: Efficient Implicit Attribute Value Extraction using Multimodal  LLM\", \"topic\": \"Multimodal Language Models\", \"x\": 7.954, \"y\": 7.316}, {\"title\": \"Is Next Token Prediction Sufficient for GPT? Exploration on Code Logic  Comprehension\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.213, \"y\": 0.201}, {\"title\": \"Aligning LLMs for FL-free Program Repair\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.091, \"y\": 0.223}, {\"title\": \"On Speculative Decoding for Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.467, \"y\": 7.182}, {\"title\": \"BERT-LSH: Reducing Absolute Compute For Attention\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.774, \"y\": 2.856}, {\"title\": \"Constrained C-Test Generation via Mixed-Integer Programming\", \"topic\": \"Large Language Models in Education\", \"x\": 6.533, \"y\": 2.737}, {\"title\": \"The Illusion of State in State-Space Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.508, \"y\": 2.933}, {\"title\": \"Revisiting Code Similarity Evaluation with Abstract Syntax Tree Edit  Distance\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.079, \"y\": 0.07}, {\"title\": \"CreativEval: Evaluating Creativity of LLM-Based Hardware Code Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.192, \"y\": 0.287}, {\"title\": \"Megalodon: Efficient LLM Pretraining and Inference with Unlimited  Context Length\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.819, \"y\": 3.0}, {\"title\": \"JailbreakLens: Visual Analysis of Jailbreak Attacks Against Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.959, \"y\": 0.37}, {\"title\": \"CATS: Contextually-Aware Thresholding for Sparsity in Large Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.178, \"y\": 2.717}, {\"title\": \"The Generation Gap:Exploring Age Bias in the Underlying Value Systems of  Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.12, \"y\": 2.553}, {\"title\": \"Pre-training Small Base LMs with Fewer Tokens\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.605, \"y\": 2.587}, {\"title\": \"MoPE: Mixture of Prefix Experts for Zero-Shot Dialogue State Tracking\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.19, \"y\": 3.305}, {\"title\": \"RLHF Deciphered: A Critical Analysis of Reinforcement Learning from  Human Feedback for LLMs\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.589, \"y\": 0.761}, {\"title\": \"VertAttack: Taking advantage of Text Classifiers' horizontal vision\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.92, \"y\": 1.255}, {\"title\": \"Online Safety Analysis for LLMs: a Benchmark, an Assessment, and a Path  Forward\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.754, \"y\": 1.071}, {\"title\": \"Efficient Interactive LLM Serving with Proxy Model-based Sequence Length  Prediction\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.491, \"y\": 2.881}, {\"title\": \"Dataset Reset Policy Optimization for RLHF\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.586, \"y\": 0.615}, {\"title\": \"Mitigating Language-Level Performance Disparity in mPLMs via Teacher  Language Selection and Cross-lingual Self-Distillation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.103, \"y\": 4.033}, {\"title\": \"Thematic Analysis with Large Language Models: does it work with  languages other than English? A targeted test in Italian\", \"topic\": \"Bias in Language Models\", \"x\": 4.132, \"y\": 2.907}, {\"title\": \"AIMDiT: Modality Augmentation and Interaction via Multimodal Dimension  Transformation for Emotion Recognition in Conversations\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.504, \"y\": 5.316}, {\"title\": \"Look at the Text: Instruction-Tuned Language Models are More Robust  Multiple Choice Selectors than You Think\", \"topic\": \"Large Language Models in Education\", \"x\": 6.639, \"y\": 2.94}, {\"title\": \"ASR advancements for indigenous languages: Quechua, Guarani, Bribri,  Kotiria, and Wa'ikhana\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.439, \"y\": 5.684}, {\"title\": \"Improving Health Question Answering with Reliable and Time-Aware  Evidence Retrieval\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.166, \"y\": 6.822}, {\"title\": \"Toward a Theory of Tokenization in LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.253, \"y\": 3.211}, {\"title\": \"The Integration of Semantic and Structural Knowledge in Knowledge Graph  Entity Typing\", \"topic\": \"Named Entity Recognition\", \"x\": 6.603, \"y\": 5.882}, {\"title\": \"Subtoxic Questions: Dive Into Attitude Change of LLM's Response in  Jailbreak Attempts\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.975, \"y\": 0.373}, {\"title\": \"Investigating Neural Machine Translation for Low-Resource Languages:  Using Bavarian as a Case Study\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.63, \"y\": 4.616}, {\"title\": \"Measuring Cross-lingual Transfer in Bytes\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.265, \"y\": 4.228}, {\"title\": \"Reducing hallucination in structured outputs via Retrieval-Augmented  Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.12, \"y\": 3.652}, {\"title\": \"Multimodal Contextual Dialogue Breakdown Detection for Conversational AI  Models\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.241, \"y\": 3.382}, {\"title\": \"Graph Integrated Language Transformers for Next Action Prediction in  Complex Phone Calls\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.191, \"y\": 3.189}, {\"title\": \"Distilling Algorithmic Reasoning from LLMs via Explaining Solution  Programs\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.207, \"y\": 1.539}, {\"title\": \"Extending Translate-Train for ColBERT-X to African Language CLIR\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.327, \"y\": 4.712}, {\"title\": \"S3Editor: A Sparse Semantic-Disentangled Self-Training Framework for  Face Video Editing\", \"topic\": \"Multimodal Language Models\", \"x\": 8.512, \"y\": 6.796}, {\"title\": \"Human Latency Conversational Turns for Spoken Avatar Systems\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.155, \"y\": 3.194}, {\"title\": \"Rumour Evaluation with Very Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.619, \"y\": 3.839}, {\"title\": \"Data-Augmentation-Based Dialectal Adaptation for LLMs\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.874, \"y\": 4.134}, {\"title\": \"Variance-reduced Zeroth-Order Methods for Fine-Tuning Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.795, \"y\": 2.09}, {\"title\": \"Any2Point: Empowering Any-modality Large Models for Efficient 3D  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.05, \"y\": 7.299}, {\"title\": \"Language Imbalance Can Boost Cross-lingual Generalisation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.196, \"y\": 4.206}, {\"title\": \"OSWorld: Benchmarking Multimodal Agents for Open-Ended Tasks in Real  Computer Environments\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.005, \"y\": 1.657}, {\"title\": \"Rho-1: Not All Tokens Are What You Need\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.169, \"y\": 2.926}, {\"title\": \"LaVy: Vietnamese Multimodal Large Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.05, \"y\": 7.577}, {\"title\": \"AmpleGCG: Learning a Universal and Transferable Generative Model of  Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.129, \"y\": 0.663}, {\"title\": \"DesignQA: A Multimodal Benchmark for Evaluating Large Language Models'  Understanding of Engineering Documentation\", \"topic\": \"Multimodal Language Models\", \"x\": 7.548, \"y\": 7.388}, {\"title\": \"HGRN2: Gated Linear RNNs with State Expansion\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.885, \"y\": 2.867}, {\"title\": \"High-Dimension Human Value Representation in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.213, \"y\": 2.346}, {\"title\": \"Analyzing Toxicity in Deep Conversations: A Reddit Case Study\", \"topic\": \"Bias in Language Models\", \"x\": 2.561, \"y\": 3.389}, {\"title\": \"Guiding Large Language Models to Post-Edit Machine Translation with  Error Annotations\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.543, \"y\": 4.897}, {\"title\": \"RecurrentGemma: Moving Past Transformers for Efficient Open Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.836, \"y\": 3.02}, {\"title\": \"Heron-Bench: A Benchmark for Evaluating Vision Language Models in  Japanese\", \"topic\": \"Multimodal Language Models\", \"x\": 8.065, \"y\": 7.718}, {\"title\": \"Nostra Domina at EvaLatin 2024: Improving Latin Polarity Detection  through Data Augmentation\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.825, \"y\": 4.996}, {\"title\": \"AnnoCTR: A Dataset for Detecting and Linking Entities, Tactics, and  Techniques in Cyber Threat Reports\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.358, \"y\": 1.354}, {\"title\": \"ResearchAgent: Iterative Research Idea Generation over Scientific  Literature with Large Language Models\", \"topic\": \"Text Summarization\", \"x\": 5.072, \"y\": 5.862}, {\"title\": \"Automatic Generation and Evaluation of Reading Comprehension Test Items  with Large Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.54, \"y\": 2.652}, {\"title\": \"Curated Datasets and Neural Models for Machine Translation of Informal  Registers between Mayan and Spanish Vernaculars\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.437, \"y\": 4.617}, {\"title\": \"rollama: An R package for using generative large language models through  Ollama\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.945, \"y\": 3.564}, {\"title\": \"Multi-Image Visual Question Answering for Unsupervised Anomaly Detection\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.541, \"y\": 8.142}, {\"title\": \"Audio Dialogues: Dialogues dataset for audio and music understanding\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.672, \"y\": 6.171}, {\"title\": \"Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The  Medical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.164, \"y\": 7.448}, {\"title\": \"NoticIA: A Clickbait Article Summarization Dataset in Spanish\", \"topic\": \"Text Summarization\", \"x\": 5.341, \"y\": 5.074}, {\"title\": \"UltraEval: A Lightweight Platform for Flexible and Comprehensive  Evaluation for LLMs\", \"topic\": \"Large Language Models in Education\", \"x\": 6.897, \"y\": 3.049}, {\"title\": \"Comments as Natural Logic Pivots: Improve Code Generation via Comment  Perspective\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.074, \"y\": 0.139}, {\"title\": \"Introducing L2M3, A Multilingual Medical Large Language Model to Advance  Health Equity in Low-Resource Regions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.069, \"y\": 7.266}, {\"title\": \"PromptSync: Bridging Domain Gaps in Vision-Language Models through  Class-Aware Prototype Alignment and Discrimination\", \"topic\": \"Multimodal Language Models\", \"x\": 8.437, \"y\": 7.53}, {\"title\": \"MM-PhyQA: Multimodal Physics Question-Answering With Multi-Image CoT  Prompting\", \"topic\": \"Multimodal Language Models\", \"x\": 7.684, \"y\": 7.581}, {\"title\": \"Augmenting Knowledge Graph Hierarchies Using Neural Transformers\", \"topic\": \"Named Entity Recognition\", \"x\": 6.66, \"y\": 5.215}, {\"title\": \"Laissez-Faire Harms: Algorithmic Biases in Generative Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.345, \"y\": 2.697}, {\"title\": \"Structure-aware Fine-tuning for Code Pre-trained Models\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.209, \"y\": 0.001}, {\"title\": \"Behavior Trees Enable Structured Programming of Language Model Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.2, \"y\": 1.39}, {\"title\": \"JetMoE: Reaching Llama2 Performance with 0.1M Dollars\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.773, \"y\": 2.655}, {\"title\": \"Analyzing the Performance of Large Language Models on Code Summarization\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.113, \"y\": 0.071}, {\"title\": \"Deep Generative Sampling in the Dual Divergence Space: A Data-efficient  & Interpretative Approach for Generative AI\", \"topic\": \"Multimodal Language Models\", \"x\": 8.618, \"y\": 6.597}, {\"title\": \"LLMs in Biomedicine: A study on clinical Named Entity Recognition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.402, \"y\": 7.263}, {\"title\": \"Conformer-1: Robust ASR via Large-Scale Semisupervised Bootstrapping\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.67, \"y\": 5.669}, {\"title\": \"We're Calling an Intervention: Exploring the Fundamental Hurdles in  Adapting Language Models to Nonstandard Text\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.811, \"y\": 3.831}, {\"title\": \"UMBRAE: Unified Multimodal Decoding of Brain Signals\", \"topic\": \"Multimodal Language Models\", \"x\": 8.16, \"y\": 7.209}, {\"title\": \"Analyzing the Impact of Data Selection and Fine-Tuning on Economic and  Political Biases in LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.786, \"y\": 2.969}, {\"title\": \"Leave No Context Behind: Efficient Infinite Context Transformers with  Infini-attention\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.749, \"y\": 3.129}, {\"title\": \"Lossless Acceleration of Large Language Model via Adaptive N-gram  Parallel Decoding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.461, \"y\": 3.216}, {\"title\": \"Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on  Graphs\", \"topic\": \"Named Entity Recognition\", \"x\": 6.638, \"y\": 5.713}, {\"title\": \"Exploring Concept Depth: How Large Language Models Acquire Knowledge at  Different Layers?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.234, \"y\": 2.793}, {\"title\": \"Groundedness in Retrieval-augmented Long-form Generation: An Empirical  Study\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.322, \"y\": 3.99}, {\"title\": \"A Computational Analysis of the Dehumanisation of Migrants from Syria  and Ukraine in Slovene News Media\", \"topic\": \"Bias in Language Models\", \"x\": 2.908, \"y\": 3.724}, {\"title\": \"Improving Language Model Reasoning with Self-motivated Learning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.222, \"y\": 2.042}, {\"title\": \"A Mathematical Theory for Learning Semantic Languages by Abstract  Learners\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.575, \"y\": 3.141}, {\"title\": \"LM Transparency Tool: Interactive Tool for Analyzing Transformer  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.078, \"y\": 2.807}, {\"title\": \"Event Grounded Criminal Court View Generation with Cooperative (Large)  Language Models\", \"topic\": \"Legal NLP\", \"x\": 4.464, \"y\": 4.601}, {\"title\": \"XNLIeu: a dataset for cross-lingual NLI in Basque\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.088, \"y\": 4.31}, {\"title\": \"Hybrid Multi-stage Decoding for Few-shot NER with Entity-aware  Contrastive Learning\", \"topic\": \"Named Entity Recognition\", \"x\": 6.252, \"y\": 6.847}, {\"title\": \"Charles Translator: A Machine Translation System between Ukrainian and  Czech\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.51, \"y\": 4.771}, {\"title\": \"Accelerating Inference in Large Language Models with a Unified Layer  Skipping Strategy\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.424, \"y\": 3.042}, {\"title\": \"Superposition Prompting: Improving and Accelerating Retrieval-Augmented  Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.369, \"y\": 4.207}, {\"title\": \"Enhancing Question Answering for Enterprise Knowledge Bases using Large  Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.28, \"y\": 4.772}, {\"title\": \"Does Mapo Tofu Contain Coffee? Probing LLMs for Food-related Cultural  Knowledge\", \"topic\": \"Bias in Language Models\", \"x\": 4.067, \"y\": 2.743}, {\"title\": \"Emotion-cause pair extraction method based on multi-granularity  information and multi-module interaction\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.562, \"y\": 5.336}, {\"title\": \"DiffusionDialog: A Diffusion Model for Diverse Dialog Generation with  Latent Space\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.188, \"y\": 3.426}, {\"title\": \"Global Contrastive Training for Multimodal Electronic Health Records  with Language Supervision\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.238, \"y\": 7.692}, {\"title\": \"Apollonion: Profile-centric Dialog Agent\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.124, \"y\": 2.682}, {\"title\": \"CQIL: Inference Latency Optimization with Concurrent Computation of  Quasi-Independent Layers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.315, \"y\": 2.547}, {\"title\": \"CoVoMix: Advancing Zero-Shot Speech Generation for Human-like  Multi-talker Conversations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.003, \"y\": 6.069}, {\"title\": \"Onco-Retriever: Generative Classifier for Retrieval of EHR Records in  Oncology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.274, \"y\": 7.294}, {\"title\": \"Sample-Efficient Human Evaluation of Large Language Models via Maximum  Discrepancy Competition\", \"topic\": \"Large Language Models in Education\", \"x\": 6.639, \"y\": 3.063}, {\"title\": \"SafeGen: Mitigating Unsafe Content Generation in Text-to-Image Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.346, \"y\": 1.611}, {\"title\": \"CulturalTeaming: AI-Assisted Interactive Red-Teaming for Challenging  LLMs' (Lack of) Multicultural Knowledge\", \"topic\": \"Bias in Language Models\", \"x\": 4.141, \"y\": 2.672}, {\"title\": \"Leveraging Interesting Facts to Enhance User Engagement with  Conversational Interfaces\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.152, \"y\": 2.908}, {\"title\": \"What is Your Favorite Gender, MLM? Gender Bias Evaluation in  Multilingual Masked Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.197, \"y\": 2.723}, {\"title\": \"FairPair: A Robust Evaluation of Biases in Language Models through  Paired Perturbations\", \"topic\": \"Bias in Language Models\", \"x\": 3.323, \"y\": 2.7}, {\"title\": \"Sandwich attack: Multi-language Mixture Adaptive Attack on LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.42, \"y\": 0.849}, {\"title\": \"InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model  Handling Resolutions from 336 Pixels to 4K HD\", \"topic\": \"Multimodal Language Models\", \"x\": 8.2, \"y\": 7.571}, {\"title\": \"Comparing Two Model Designs for Clinical Note Generation; Is an LLM a  Useful Evaluator of Consistency?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.992, \"y\": 7.358}, {\"title\": \"Text-Based Reasoning About Vector Graphics\", \"topic\": \"Multimodal Language Models\", \"x\": 7.804, \"y\": 7.448}, {\"title\": \"Large Language Models to the Rescue: Deadlock Resolution in Multi-Robot  Systems\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.125, \"y\": 1.378}, {\"title\": \"AgentQuest: A Modular Benchmark Framework to Measure Progress and  Improve LLM Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.58, \"y\": 1.743}, {\"title\": \"Rethinking How to Evaluate Language Model Jailbreak\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.056, \"y\": 0.541}, {\"title\": \"Wu's Method can Boost Symbolic AI to Rival Silver Medalists and  AlphaGeometry to Outperform Gold Medalists at IMO Geometry\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.67, \"y\": 1.203}, {\"title\": \"MiniCPM: Unveiling the Potential of Small Language Models with Scalable  Training Strategies\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.492, \"y\": 2.542}, {\"title\": \"Event Extraction in Basque: Typologically motivated Cross-Lingual  Transfer-Learning Analysis\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.908, \"y\": 4.576}, {\"title\": \"Latent Distance Guided Alignment Training for Large Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.828, \"y\": 0.734}, {\"title\": \"ClinLinker: Medical Entity Linking of Clinical Concept Mentions in  Spanish\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.536, \"y\": 7.274}, {\"title\": \"SurveyAgent: A Conversational System for Personalized and Efficient  Research Survey\", \"topic\": \"Text Summarization\", \"x\": 5.042, \"y\": 5.899}, {\"title\": \"Generalizable Sarcasm Detection Is Just Around The Corner, Of Course!\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.528, \"y\": 4.851}, {\"title\": \"RAR-b: Reasoning as Retrieval Benchmark\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.479, \"y\": 4.438}, {\"title\": \"Finding fake reviews in e-commerce platforms by using hybrid algorithms\", \"topic\": \"Bias in Language Models\", \"x\": 3.271, \"y\": 3.876}, {\"title\": \"nEMO: Dataset of Emotional Speech in Polish\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.463, \"y\": 5.453}, {\"title\": \"Dimensionality Reduction in Sentence Transformer Vector Databases with  Fast Fourier Transform\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.574, \"y\": 4.588}, {\"title\": \"Understanding Cross-Lingual Alignment -- A Survey\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.195, \"y\": 4.331}, {\"title\": \"[Call for Papers] The 2nd BabyLM Challenge: Sample-efficient pretraining  on a developmentally plausible corpus\", \"topic\": \"Multimodal Language Models\", \"x\": 8.254, \"y\": 7.419}, {\"title\": \"Clue-Instruct: Text-Based Clue Generation for Educational Crossword  Puzzles\", \"topic\": \"Large Language Models in Education\", \"x\": 6.562, \"y\": 2.585}, {\"title\": \"Characterizing Multimodal Long-form Summarization: A Case Study on  Financial Reports\", \"topic\": \"Text Summarization\", \"x\": 5.188, \"y\": 5.105}, {\"title\": \"Cendol: Open Instruction-tuned Generative Large Language Models for  Indonesian Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.125, \"y\": 4.091}, {\"title\": \"Exploring the Necessity of Visual Modality in Multimodal Machine  Translation using Authentic Datasets\", \"topic\": \"Multimodal Language Models\", \"x\": 8.85, \"y\": 6.594}, {\"title\": \"Traitement quantique des langues : {\\u00e9}tat de l'art\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.316, \"y\": 2.656}, {\"title\": \"Extractive text summarisation of Privacy Policy documents using machine  learning approaches\", \"topic\": \"Legal NLP\", \"x\": 4.508, \"y\": 4.651}, {\"title\": \"AiSAQ: All-in-Storage ANNS with Product Quantization for DRAM-free  Information Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.122, \"y\": 4.709}, {\"title\": \"Privacy Preserving Prompt Engineering: A Survey\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.76, \"y\": 0.332}, {\"title\": \"AEGIS: Online Adaptive AI Content Safety Moderation with Ensemble of LLM  Experts\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.758, \"y\": 1.208}, {\"title\": \"Event-enhanced Retrieval in Real-time Search\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.171, \"y\": 4.782}, {\"title\": \"Does Transformer Interpretability Transfer to RNNs?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.395, \"y\": 2.815}, {\"title\": \"Optimization Methods for Personalizing Large Language Models through  Retrieval Augmentation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.98, \"y\": 4.374}, {\"title\": \"JSTR: Judgment Improves Scene Text Recognition\", \"topic\": \"Multimodal Language Models\", \"x\": 8.24, \"y\": 7.174}, {\"title\": \"VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page  Understanding and Grounding?\", \"topic\": \"Multimodal Language Models\", \"x\": 7.937, \"y\": 7.172}, {\"title\": \"Interplay of Machine Translation, Diacritics, and Diacritization\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.41, \"y\": 4.746}, {\"title\": \"WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.133, \"y\": 1.584}, {\"title\": \"Use of a Structured Knowledge Base Enhances Metadata Curation by Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.529, \"y\": 6.878}, {\"title\": \"Eagle and Finch: RWKV with Matrix-Valued States and Dynamic Recurrence\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.837, \"y\": 3.104}, {\"title\": \"Eraser: Jailbreaking Defense in Large Language Models via Unlearning  Harmful Knowledge\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.17, \"y\": 0.495}, {\"title\": \"Negative Preference Optimization: From Catastrophic Collapse to  Effective Unlearning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.066, \"y\": 0.489}, {\"title\": \"GeniL: A Multilingual Dataset on Generalizing Language\", \"topic\": \"Bias in Language Models\", \"x\": 3.158, \"y\": 2.784}, {\"title\": \"Softmax Attention with Constant Cost per Token\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.741, \"y\": 2.92}, {\"title\": \"Neural Sequence-to-Sequence Modeling with Attention by Leveraging Deep  Learning Architectures for Enhanced Contextual Understanding in Abstractive  Text Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.152, \"y\": 5.181}, {\"title\": \"Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.902, \"y\": 7.095}, {\"title\": \"Responsible Generative AI: What to Generate and What Not\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.615, \"y\": 1.759}, {\"title\": \"Comprehensive Study on German Language Models for Clinical and  Biomedical Text Understanding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.404, \"y\": 7.323}, {\"title\": \"Evaluating Mathematical Reasoning Beyond Accuracy\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.613, \"y\": 1.321}, {\"title\": \"VietMed: A Dataset and Benchmark for Automatic Speech Recognition of  Vietnamese in the Medical Domain\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.458, \"y\": 5.817}, {\"title\": \"Text clustering applied to data augmentation in legal contexts\", \"topic\": \"Legal NLP\", \"x\": 4.331, \"y\": 4.551}, {\"title\": \"LTNER: Large Language Model Tagging for Named Entity Recognition with  Contextualized Entity Marking\", \"topic\": \"Named Entity Recognition\", \"x\": 6.165, \"y\": 6.809}, {\"title\": \"How to Evaluate Entity Resolution Systems: An Entity-Centric Framework  with Application to Inventor Name Disambiguation\", \"topic\": \"Named Entity Recognition\", \"x\": 6.258, \"y\": 6.362}, {\"title\": \"SpeechAlign: Aligning Speech Generation to Human Preferences\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.998, \"y\": 5.957}, {\"title\": \"MedExpQA: Multilingual Benchmarking of Large Language Models for Medical  Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.902, \"y\": 7.312}, {\"title\": \"360$^\\\\circ$REA: Towards A Reusable Experience Accumulation with  360\\u00b0 Assessment for Multi-Agent System\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.143, \"y\": 1.528}, {\"title\": \"Dense Training, Sparse Inference: Rethinking Training of  Mixture-of-Experts Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.933, \"y\": 2.34}, {\"title\": \"OPSD: an Offensive Persian Social media Dataset and its baseline  evaluations\", \"topic\": \"Bias in Language Models\", \"x\": 2.51, \"y\": 3.41}, {\"title\": \"Best-of-Venom: Attacking RLHF by Injecting Poisoned Preference Data\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.963, \"y\": 0.99}, {\"title\": \"PetKaz at SemEval-2024 Task 3: Advancing Emotion Classification with an  LLM for Emotion-Cause Pair Extraction in Conversations\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.477, \"y\": 5.344}, {\"title\": \"Language Models on a Diet: Cost-Efficient Development of Encoders for  Closely-Related Languages via Additional Pretraining\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.222, \"y\": 4.159}, {\"title\": \"Relation Extraction Using Large Language Models: A Case Study on  Acupuncture Point Locations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.279, \"y\": 7.344}, {\"title\": \"SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and  Improving Large Language Model Safety\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.858, \"y\": 1.242}, {\"title\": \"PORTULAN ExtraGLUE Datasets and Models: Kick-starting a Benchmark for  the Neural Processing of Portuguese\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.455, \"y\": 4.159}, {\"title\": \"Product Description and QA Assisted Self-Supervised Opinion  Summarization\", \"topic\": \"Text Summarization\", \"x\": 4.951, \"y\": 5.119}, {\"title\": \"LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step  Reasoning with Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.099, \"y\": 2.014}, {\"title\": \"Bidirectional Long-Range Parser for Sequential Data Understanding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.745, \"y\": 3.142}, {\"title\": \"Have You Merged My Model? On The Robustness of Large Language Model IP  Protection Methods Against Model Merging\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.708, \"y\": 0.926}, {\"title\": \"DLoRA: Distributed Parameter-Efficient Fine-Tuning Solution for Large  Language Model\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.092, \"y\": 0.037}, {\"title\": \"Linguistic Changes in Spontaneous Speech for Detecting Parkinsons  Disease Using Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.097, \"y\": 7.068}, {\"title\": \"Semantic Stealth: Adversarial Text Attacks on NLP Using Several Methods\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.015, \"y\": 1.186}, {\"title\": \"Enhancing Clinical Efficiency through LLM: Discharge Note Generation for  Cardiac Patients\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.033, \"y\": 7.414}, {\"title\": \"Automating Research Synthesis with Domain-Specific Large Language Model  Fine-Tuning\", \"topic\": \"Text Summarization\", \"x\": 4.84, \"y\": 5.995}, {\"title\": \"MM-MATH: Advancing Multimodal Math Evaluation with Process Evaluation  and Fine-grained Classification\", \"topic\": \"Multimodal Language Models\", \"x\": 7.587, \"y\": 7.632}, {\"title\": \"SEER-MoE: Sparse Expert Efficiency through Regularization for  Mixture-of-Experts\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.922, \"y\": 2.205}, {\"title\": \"How much reliable is ChatGPT's prediction on Information Extraction  under Input Perturbations?\", \"topic\": \"Named Entity Recognition\", \"x\": 6.01, \"y\": 6.919}, {\"title\": \"A Note on LoRA\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.824, \"y\": 1.777}, {\"title\": \"HaVTR: Improving Video-Text Retrieval Through Augmentation Using Large  Foundation Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.714, \"y\": 7.41}, {\"title\": \"FGAIF: Aligning Large Vision-Language Models with Fine-grained AI  Feedback\", \"topic\": \"Multimodal Language Models\", \"x\": 8.328, \"y\": 8.016}, {\"title\": \"Shortcut-connected Expert Parallelism for Accelerating  Mixture-of-Experts\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.89, \"y\": 2.165}, {\"title\": \"Towards Reliable and Empathetic Depression-Diagnosis-Oriented Chats\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.02, \"y\": 6.399}, {\"title\": \"SemEval-2024 Task 2: Safe Biomedical Natural Language Inference for  Clinical Trials\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.164, \"y\": 7.021}, {\"title\": \"A Two Dimensional Feature Engineering Method for Relation Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.375, \"y\": 6.473}, {\"title\": \"Towards Understanding the Influence of Reward Margin on Preference Model  Performance\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.448, \"y\": 0.648}, {\"title\": \"Multilingual Large Language Model: A Survey of Resources, Taxonomy and  Frontiers\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.865, \"y\": 4.347}, {\"title\": \"Your Finetuned Large Language Model is Already a Powerful  Out-of-distribution Detector\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.742, \"y\": 4.32}, {\"title\": \"Radial Networks: Dynamic Layer Routing for High-Performance Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.035, \"y\": 2.495}, {\"title\": \"Ethos and Pathos in Online Group Discussions: Corpora for Polarisation  Issues in Social Media\", \"topic\": \"Bias in Language Models\", \"x\": 3.306, \"y\": 3.678}, {\"title\": \"Lucky 52: How Many Languages Are Needed to Instruction Fine-Tune Large  Language Models?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.023, \"y\": 3.84}, {\"title\": \"Data Bias According to Bipol: Men are Naturally Right and It is the Role  of Women to Follow Their Lead\", \"topic\": \"Bias in Language Models\", \"x\": 3.187, \"y\": 2.891}, {\"title\": \"DWE+: Dual-Way Matching Enhanced Framework for Multimodal Entity Linking\", \"topic\": \"Named Entity Recognition\", \"x\": 6.656, \"y\": 6.421}, {\"title\": \"Low-Resource Machine Translation through Retrieval-Augmented LLM  Prompting: A Study on the Mambai Language\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.46, \"y\": 4.639}, {\"title\": \"SqueezeAttention: 2D Management of KV-Cache in LLM Inference via  Layer-wise Optimal Budget\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.294, \"y\": 2.825}, {\"title\": \"A Multi-Level Framework for Accelerating Training Transformer Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.851, \"y\": 2.636}, {\"title\": \"What Happens When Small Is Made Smaller? Exploring the Impact of  Compression on Small Data Pretrained Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.01, \"y\": 2.456}, {\"title\": \"Multilingual Brain Surgeon: Large Language Models Can be Compressed  Leaving No Language Behind\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.98, \"y\": 2.534}, {\"title\": \"MACM: Utilizing a Multi-Agent System for Condition Mining in Solving  Complex Mathematical Problems\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.508, \"y\": 1.481}, {\"title\": \"Navigating the Landscape of Hint Generation Research: From the Past to  the Future\", \"topic\": \"Large Language Models in Education\", \"x\": 6.326, \"y\": 2.318}, {\"title\": \"Multicalibration for Confidence Scoring in LLMs\", \"topic\": \"Large Language Models in Education\", \"x\": 6.617, \"y\": 3.185}, {\"title\": \"Multilingual Pretraining and Instruction Tuning Improve Cross-Lingual  Knowledge Alignment, But Only Shallowly\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.041, \"y\": 4.005}, {\"title\": \"Binary Classifier Optimization for Large Language Model Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.413, \"y\": 0.514}, {\"title\": \"ALERT: A Comprehensive Benchmark for Assessing Large Language Models'  Safety through Red Teaming\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.604, \"y\": 1.138}, {\"title\": \"HyperTTS: Parameter Efficient Adaptation in Text to Speech using  Hypernetworks\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.201, \"y\": 5.779}, {\"title\": \"Context versus Prior Knowledge in Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.779, \"y\": 2.93}, {\"title\": \"Towards Analyzing and Understanding the Limitations of DPO: A  Theoretical Perspective\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.458, \"y\": 0.563}, {\"title\": \"TCAN: Text-oriented Cross Attention Network for Multimodal Sentiment  Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.619, \"y\": 5.166}, {\"title\": \"Soft-Prompting with Graph-of-Thought for Multi-modal Representation  Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.599, \"y\": 7.587}, {\"title\": \"IITK at SemEval-2024 Task 10: Who is the speaker? Improving Emotion  Recognition and Flip Reasoning in Conversations via Speaker Embeddings\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.517, \"y\": 5.34}, {\"title\": \"Q-PEFT: Query-dependent Parameter Efficient Fine-tuning for Text  Reranking with Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.992, \"y\": 4.678}, {\"title\": \"Goal-guided Generative Prompt Injection Attack on Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.24, \"y\": 0.743}, {\"title\": \"Joint Visual and Text Prompting for Improved Object-Centric Perception  with Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.985, \"y\": 7.585}, {\"title\": \"IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe  Biomedical Natural Language Inference for Clinical Trials\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.269, \"y\": 6.991}, {\"title\": \"KazQAD: Kazakh Open-Domain Question Answering Dataset\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.966, \"y\": 4.298}, {\"title\": \"Towards Realistic Few-Shot Relation Extraction: A New Meta Dataset and  Evaluation\", \"topic\": \"Named Entity Recognition\", \"x\": 6.299, \"y\": 6.539}, {\"title\": \"Counting Like Transformers: Compiling Temporal Counting Logic Into  Softmax Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.393, \"y\": 2.918}, {\"title\": \"Deciphering Political Entity Sentiment in News with Large Language  Models: Zero-Shot and Few-Shot Strategies\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.116, \"y\": 4.575}, {\"title\": \"Prompt Public Large Language Models to Synthesize Data for Private  On-device Applications\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.914, \"y\": 0.141}, {\"title\": \"Assisting humans in complex comparisons: automated information  comparison at scale\", \"topic\": \"Text Summarization\", \"x\": 5.126, \"y\": 5.588}, {\"title\": \"Watermark-based Detection and Attribution of AI-Generated Content\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.522, \"y\": 1.151}, {\"title\": \"Who Evaluates the Evaluations? Objectively Scoring Text-to-Image Prompt  Coherence Metrics with T2IScoreScore (TS2)\", \"topic\": \"Multimodal Language Models\", \"x\": 8.439, \"y\": 7.277}, {\"title\": \"Physical Property Understanding from Language-Embedded Feature Fields\", \"topic\": \"Multimodal Language Models\", \"x\": 7.879, \"y\": 7.317}, {\"title\": \"Cleared for Takeoff? Compositional & Conditional Reasoning may be the  Achilles Heel to (Flight-Booking) Language Agents\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 6.991, \"y\": 2.015}, {\"title\": \"How Lexical is Bilingual Lexicon Induction?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.153, \"y\": 4.498}, {\"title\": \"Unlocking Parameter-Efficient Fine-Tuning for Low-Resource Language  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.738, \"y\": 4.452}, {\"title\": \"Parameter Efficient Quasi-Orthogonal Fine-Tuning via Givens Rotation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.676, \"y\": 1.863}, {\"title\": \"Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.728, \"y\": 3.861}, {\"title\": \"ROPO: Robust Preference Optimization for Large Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.423, \"y\": 0.587}, {\"title\": \"Assessing the quality of information extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.224, \"y\": 6.493}, {\"title\": \"CLUE: A Clinical Language Understanding Evaluation for LLMs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.008, \"y\": 7.328}, {\"title\": \"Teaching Llama a New Language Through Cross-Lingual Knowledge Transfer\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.904, \"y\": 3.906}, {\"title\": \"A Dataset for Physical and Abstract Plausibility and Sources of Human  Disagreement\", \"topic\": \"Bias in Language Models\", \"x\": 4.014, \"y\": 3.806}, {\"title\": \"Willkommens-Merkel, Chaos-Johnson, and Tore-Klose: Modeling the  Evaluative Meaning of German Personal Name Compounds\", \"topic\": \"Bias in Language Models\", \"x\": 3.316, \"y\": 2.957}, {\"title\": \"SEME at SemEval-2024 Task 2: Comparing Masked and Generative Language  Models on Natural Language Inference for Clinical Trials\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.272, \"y\": 7.052}, {\"title\": \"Data Augmentation with In-Context Learning and Comparative Evaluation in  Math Word Problem Solving\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.645, \"y\": 1.225}, {\"title\": \"AuditGPT: Auditing Smart Contracts with ChatGPT\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.159, \"y\": 0.717}, {\"title\": \"SAAS: Solving Ability Amplification Strategy for Enhanced Mathematical  Reasoning in Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.548, \"y\": 1.39}, {\"title\": \"A Bi-consolidating Model for Joint Relational Triple Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.456, \"y\": 6.54}, {\"title\": \"FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed  Forward Skipping\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.414, \"y\": 3.195}, {\"title\": \"An Investigation into Misuse of Java Security APIs by Large Language  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.297, \"y\": 0.478}, {\"title\": \"CantTalkAboutThis: Aligning Language Models to Stay on Topic in  Dialogues\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.373, \"y\": 3.057}, {\"title\": \"CBR-RAG: Case-Based Reasoning for Retrieval Augmented Generation in LLMs  for Legal Question Answering\", \"topic\": \"Legal NLP\", \"x\": 4.528, \"y\": 4.626}, {\"title\": \"GenQREnsemble: Zero-Shot LLM Ensemble Prompting for Generative Query  Reformulation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.061, \"y\": 4.548}, {\"title\": \"CoMat: Aligning Text-to-Image Diffusion Model with Image-to-Text Concept  Matching\", \"topic\": \"Multimodal Language Models\", \"x\": 8.491, \"y\": 6.949}, {\"title\": \"AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web  Navigating Agent\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.105, \"y\": 1.562}, {\"title\": \"No \\\"Zero-Shot\\\" Without Exponential Data: Pretraining Concept Frequency  Determines Multimodal Model Performance\", \"topic\": \"Multimodal Language Models\", \"x\": 8.354, \"y\": 7.339}, {\"title\": \"Direct Nash Optimization: Teaching Language Models to Self-Improve with  General Preferences\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.556, \"y\": 0.546}, {\"title\": \"WorDepth: Variational Language Prior for Monocular Depth Estimation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.183, \"y\": 7.312}, {\"title\": \"Training LLMs over Neurally Compressed Text\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.623, \"y\": 3.004}, {\"title\": \"Mind's Eye of LLMs: Visualization-of-Thought Elicits Spatial Reasoning  in Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.645, \"y\": 7.251}, {\"title\": \"Sailor: Open Language Models for South-East Asia\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.889, \"y\": 3.885}, {\"title\": \"Mitigating the Impact of Outlier Channels for Language Model  Quantization with Activation Regularization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.566, \"y\": 2.19}, {\"title\": \"Evaluating LLMs at Detecting Errors in LLM Responses\", \"topic\": \"Large Language Models in Education\", \"x\": 6.539, \"y\": 2.886}, {\"title\": \"Intent Detection and Entity Extraction from BioMedical Literature\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.534, \"y\": 7.205}, {\"title\": \"Transducers with Pronunciation-aware Embeddings for Automatic Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.574, \"y\": 5.789}, {\"title\": \"ReFT: Representation Finetuning for Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.311, \"y\": 2.093}, {\"title\": \"Personalized LLM Response Generation with Parameterized Memory Injection\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.056, \"y\": 4.052}, {\"title\": \"Select and Summarize: Scene Saliency for Movie Script Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.324, \"y\": 5.169}, {\"title\": \"From News to Summaries: Building a Hungarian Corpus for Extractive and  Abstractive Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.128, \"y\": 5.153}, {\"title\": \"CodeEditorBench: Evaluating Code Editing Capability of Large Language  Models\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.098, \"y\": 0.101}, {\"title\": \"BanglaAutoKG: Automatic Bangla Knowledge Graph Construction with  Semantic Neural Graph Filtering\", \"topic\": \"Named Entity Recognition\", \"x\": 6.709, \"y\": 5.7}, {\"title\": \"Learn When (not) to Trust Language Models: A Privacy-Centric Adaptive  Model-Aware Approach\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.771, \"y\": 0.28}, {\"title\": \"A Cause-Effect Look at Alleviating Hallucination of Knowledge-grounded  Dialogue Generation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.603, \"y\": 3.429}, {\"title\": \"Generative AI and Teachers -- For Us or Against Us? A Case Study\", \"topic\": \"Large Language Models in Education\", \"x\": 6.211, \"y\": 2.419}, {\"title\": \"The Impact of Unstated Norms in Bias Analysis of Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.217, \"y\": 2.794}, {\"title\": \"Benchmarking ChatGPT on Algorithmic Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.637, \"y\": 1.848}, {\"title\": \"Knowledge Graph Representation for Political Information Sources\", \"topic\": \"Bias in Language Models\", \"x\": 3.277, \"y\": 3.776}, {\"title\": \"Can Small Language Models Help Large Language Models Reason Better?:  LM-Guided Chain-of-Thought\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.403, \"y\": 2.086}, {\"title\": \"Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak  Attacks?\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.062, \"y\": 0.688}, {\"title\": \"Mitigating LLM Hallucinations via Conformal Abstention\", \"topic\": \"Large Language Models in Education\", \"x\": 6.241, \"y\": 3.252}, {\"title\": \"nicolay-r at SemEval-2024 Task 3: Using Flan-T5 for Reasoning Emotion  Cause in Conversations with Chain-of-Thought on Emotion States\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.561, \"y\": 5.385}, {\"title\": \"Towards Pareto Optimal Throughput in Small Language Model Serving\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.369, \"y\": 2.744}, {\"title\": \"Using Large Language Models to Enrich the Documentation of Datasets for  Machine Learning\", \"topic\": \"Text Summarization\", \"x\": 5.115, \"y\": 6.002}, {\"title\": \"A Comparative Analysis of Word-Level Metric Differential Privacy:  Benchmarking The Privacy-Utility Trade-off\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.804, \"y\": 0.219}, {\"title\": \"M3TCM: Multi-modal Multi-task Context Model for Utterance Classification  in Motivational Interviews\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 2.997, \"y\": 6.331}, {\"title\": \"How Easily do Irrelevant Inputs Skew the Responses of Large Language  Models?\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.278, \"y\": 4.457}, {\"title\": \"Reason from Fallacy: Enhancing Large Language Models' Logical Reasoning  through Logical Fallacy Understanding\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.261, \"y\": 2.229}, {\"title\": \"Conversational Disease Diagnosis via External Planner-Controlled Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.744, \"y\": 7.417}, {\"title\": \"RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting  for Text-to-Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.991, \"y\": 5.958}, {\"title\": \"Do Large Language Models Rank Fairly? An Empirical Study on the Fairness  of LLMs as Rankers\", \"topic\": \"Bias in Language Models\", \"x\": 3.466, \"y\": 3.141}, {\"title\": \"The Death of Feature Engineering? BERT with Linguistic Features on SQuAD  2.0\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.542, \"y\": 4.382}, {\"title\": \"CONFLARE: CONFormal LArge language model REtrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.215, \"y\": 4.288}, {\"title\": \"BioVL-QR: Egocentric Biochemical Video-and-Language Dataset Using Micro  QR Codes\", \"topic\": \"Multimodal Language Models\", \"x\": 7.599, \"y\": 7.295}, {\"title\": \"NLP at UC Santa Cruz at SemEval-2024 Task 5: Legal Answer Validation  using Few-Shot Multi-Choice QA\", \"topic\": \"Legal NLP\", \"x\": 4.463, \"y\": 4.548}, {\"title\": \"MIMIR: A Streamlined Platform for Personalized Agent Tuning in Domain  Expertise\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.348, \"y\": 1.479}, {\"title\": \"Testing the Effect of Code Documentation on Large Language Model Code  Understanding\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.001, \"y\": 0.126}, {\"title\": \"Auditing the Use of Language Models to Guide Hiring Decisions\", \"topic\": \"Bias in Language Models\", \"x\": 3.233, \"y\": 2.752}, {\"title\": \"Mai Ho'om\\u0101una i ka 'Ai: Language Models Improve Automatic Speech  Recognition in Hawaiian\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.468, \"y\": 5.756}, {\"title\": \"Decentralised Moderation for Interoperable Social Networks: A  Conversation-based Approach for Pleroma and the Fediverse\", \"topic\": \"Bias in Language Models\", \"x\": 3.014, \"y\": 3.761}, {\"title\": \"Assessing ML Classification Algorithms and NLP Techniques for Depression  Detection: An Experimental Case Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.239, \"y\": 6.323}, {\"title\": \"An Incomplete Loop: Deductive, Inductive, and Abductive Learning in  Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.499, \"y\": 2.19}, {\"title\": \"JailBreakV-28K: A Benchmark for Assessing the Robustness of MultiModal  Large Language Models against Jailbreak Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.114, \"y\": 0.637}, {\"title\": \"Blessing or curse? A survey on the Impact of Generative AI on Fake News\", \"topic\": \"Bias in Language Models\", \"x\": 3.422, \"y\": 3.647}, {\"title\": \"ALOHa: A New Measure for Hallucination in Captioning Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.386, \"y\": 7.917}, {\"title\": \"ChatGLM-Math: Improving Math Problem-Solving in Large Language Models  with a Self-Critique Pipeline\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.674, \"y\": 1.236}, {\"title\": \"Linear Attention Sequence Parallelism\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.013, \"y\": 2.846}, {\"title\": \"Cherry on Top: Parameter Heterogeneity and Quantization in Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.52, \"y\": 2.257}, {\"title\": \"Retrieving Examples from Memory for Retrieval Augmented Neural Machine  Translation: A Systematic Comparison\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.788, \"y\": 4.557}, {\"title\": \"AQuA -- Combining Experts' and Non-Experts' Views To Assess Deliberation  Quality in Online Discussions Using LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.748, \"y\": 3.832}, {\"title\": \"ART: The Alternating Reading Task Corpus for Speech Entrainment and  Imitation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.254, \"y\": 5.739}, {\"title\": \"Attributions toward Artificial Agents in a modified Moral Turing Test\", \"topic\": \"Bias in Language Models\", \"x\": 4.01, \"y\": 2.231}, {\"title\": \"Attention is Naturally Sparse with Gaussian Distributed Input\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.657, \"y\": 2.76}, {\"title\": \"Cross-Architecture Transfer Learning for Linear-Cost Inference  Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.871, \"y\": 2.848}, {\"title\": \"PejorativITy: Disambiguating Pejorative Epithets to Improve Misogyny  Detection in Italian Tweets\", \"topic\": \"Bias in Language Models\", \"x\": 2.516, \"y\": 3.389}, {\"title\": \"The VoicePrivacy 2024 Challenge Evaluation Plan\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.416, \"y\": 6.155}, {\"title\": \"Calibrating the Confidence of Large Language Models by Eliciting  Fidelity\", \"topic\": \"Large Language Models in Education\", \"x\": 6.708, \"y\": 3.051}, {\"title\": \"Towards detecting unanticipated bias in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.301, \"y\": 2.723}, {\"title\": \"A Differentiable Integer Linear Programming Solver for Explanation-Based  Natural Language Inference\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.432, \"y\": 2.372}, {\"title\": \"Improving Topic Relevance Model by Mix-structured Summarization and  LLM-based Data Augmentation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.892, \"y\": 4.707}, {\"title\": \"Leveraging the Interplay Between Syntactic and Acoustic Cues for  Optimizing Korean TTS Pause Formation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.025, \"y\": 5.975}, {\"title\": \"Large Language Models for Expansion of Spoken Language Understanding  Systems to New Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.14, \"y\": 5.522}, {\"title\": \"Multi-Granularity Guided Fusion-in-Decoder\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.61, \"y\": 4.43}, {\"title\": \"Personality-affected Emotion Generation in Dialog Systems\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.699, \"y\": 5.565}, {\"title\": \"CSEPrompts: A Benchmark of Introductory Computer Science Prompts\", \"topic\": \"Large Language Models in Education\", \"x\": 6.382, \"y\": 2.282}, {\"title\": \"ANGOFA: Leveraging OFA Embedding Initialization and Synthetic Data for  Angolan Language Model\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.33, \"y\": 4.014}, {\"title\": \"Learn to Disguise: Avoid Refusal Responses in LLM's Defense via a  Multi-agent Attacker-Disguiser Game\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.361, \"y\": 0.728}, {\"title\": \"Towards Large Language Model driven Reference-less Translation  Evaluation for English and Indian Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.54, \"y\": 4.829}, {\"title\": \"Measuring Social Norms of Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.41, \"y\": 2.515}, {\"title\": \"DUQGen: Effective Unsupervised Domain Adaptation of Neural Rankers by  Diversifying Synthetic Query Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.997, \"y\": 4.706}, {\"title\": \"uTeBC-NLP at SemEval-2024 Task 9: Can LLMs be Lateral Thinkers?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.249, \"y\": 2.062}, {\"title\": \"Adaptive Cross-lingual Text Classification through In-Context One-Shot  Demonstrations\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.691, \"y\": 4.228}, {\"title\": \"The Promises and Pitfalls of Using Language Models to Measure  Instruction Quality in Education\", \"topic\": \"Large Language Models in Education\", \"x\": 6.291, \"y\": 2.467}, {\"title\": \"From Narratives to Numbers: Valid Inference Using Language Model  Predictions from Verbal Autopsy Narratives\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.941, \"y\": 6.943}, {\"title\": \"On the Multilingual Ability of Decoder-based Pre-trained Language  Models: Finding and Controlling Language-Specific Neurons\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.328, \"y\": 3.956}, {\"title\": \"Exploring Backdoor Vulnerabilities of Chat Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.299, \"y\": 0.647}, {\"title\": \"Token Trails: Navigating Contextual Depths in Conversational AI with  ChatLLM\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.197, \"y\": 3.318}, {\"title\": \"Backdoor Attack on Multilingual Machine Translation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.289, \"y\": 0.734}, {\"title\": \"Low-resource neural machine translation with morphological modeling\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.681, \"y\": 4.551}, {\"title\": \"Obfuscated Malware Detection: Investigating Real-world Scenarios through  Memory Analysis\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.104, \"y\": 0.925}, {\"title\": \"Enhancing Human-Computer Interaction in Chest X-ray Analysis using  Vision and Language Model with Eye Gaze Patterns\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.227, \"y\": 8.063}, {\"title\": \"Two Heads are Better than One: Nested PoE for Robust Defense Against  Multi-Backdoors\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.272, \"y\": 0.857}, {\"title\": \"Multi-BERT: Leveraging Adapters and Prompt Tuning for Low-Resource  Multi-Domain Adaptation\", \"topic\": \"Named Entity Recognition\", \"x\": 6.199, \"y\": 6.833}, {\"title\": \"Symbolic Prompt Program Search: A Structure-Aware Approach to Efficient  Compile-Time Prompt Optimization\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.155, \"y\": 0.279}, {\"title\": \"Enhancing Inference Efficiency of Large Language Models: Investigating  Optimization Strategies and Architectural Innovations\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.13, \"y\": 2.737}, {\"title\": \"Extracting Norms from Contracts Via ChatGPT: Opportunities and  Challenges\", \"topic\": \"Legal NLP\", \"x\": 4.503, \"y\": 4.239}, {\"title\": \"Large Language Models as Planning Domain Generators\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.355, \"y\": 1.515}, {\"title\": \"Mixture-of-Depths: Dynamically allocating compute in transformer-based  language models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.88, \"y\": 2.799}, {\"title\": \"$\\\\texttt{LM}^\\\\texttt{2}$: A Simple Society of Language Models Solves  Complex Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.371, \"y\": 1.708}, {\"title\": \"Emergent Abilities in Reduced-Scale Generative Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.932, \"y\": 2.794}, {\"title\": \"FLawN-T5: An Empirical Examination of Effective Instruction-Tuning Data  Mixtures for Legal Reasoning\", \"topic\": \"Legal NLP\", \"x\": 4.427, \"y\": 4.515}, {\"title\": \"Rematch: Robust and Efficient Matching of Local Knowledge Graphs to  Improve Structural and Semantic Similarity\", \"topic\": \"Named Entity Recognition\", \"x\": 6.669, \"y\": 5.48}, {\"title\": \"CLAPNQ: Cohesive Long-form Answers from Passages in Natural Questions  for RAG systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.234, \"y\": 4.404}, {\"title\": \"READ: Improving Relation Extraction from an ADversarial Perspective\", \"topic\": \"Named Entity Recognition\", \"x\": 6.31, \"y\": 6.493}, {\"title\": \"LastResort at SemEval-2024 Task 3: Exploring Multimodal Emotion Cause  Pair Extraction as Sequence Labelling Task\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.503, \"y\": 5.306}, {\"title\": \"Advancing LLM Reasoning Generalists with Preference Trees\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.302, \"y\": 1.574}, {\"title\": \"Ukrainian Texts Classification: Exploration of Cross-lingual Knowledge  Transfer Approaches\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.897, \"y\": 4.507}, {\"title\": \"Improving Retrieval Augmented Open-Domain Question-Answering with  Vectorized Contexts\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.704, \"y\": 4.336}, {\"title\": \"Risks from Language Models for Automated Mental Healthcare: Ethics and  Structure for Implementation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.157, \"y\": 6.515}, {\"title\": \"Breaking the Silence Detecting and Mitigating Gendered Abuse in Hindi,  Tamil, and Indian English Online Spaces\", \"topic\": \"Bias in Language Models\", \"x\": 2.463, \"y\": 3.37}, {\"title\": \"Africa-Centric Self-Supervised Pre-Training for Multilingual Speech  Representation in a Sub-Saharan Context\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.467, \"y\": 5.78}, {\"title\": \"DELAN: Dual-Level Alignment for Vision-and-Language Navigation by  Cross-Modal Contrastive Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.043, \"y\": 7.036}, {\"title\": \"Kallaama: A Transcribed Speech Dataset about Agriculture in the Three  Most Widely Spoken Languages in Senegal\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.148, \"y\": 5.587}, {\"title\": \"Team UTSA-NLP at SemEval 2024 Task 5: Prompt Ensembling for Argument  Reasoning in Civil Procedures with GPT4\", \"topic\": \"Legal NLP\", \"x\": 4.456, \"y\": 4.408}, {\"title\": \"Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra  Large-Scale Code Generation and Optimization\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.049, \"y\": 0.197}, {\"title\": \"Towards Better Understanding of Cybercrime: The Role of Fine-Tuned LLMs  in Translation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.246, \"y\": 1.257}, {\"title\": \"SGSH: Stimulate Large Language Models with Skeleton Heuristics for  Knowledge Base Question Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.378, \"y\": 4.083}, {\"title\": \"SCANNER: Knowledge-Enhanced Approach for Robust Multi-modal Named Entity  Recognition of Unseen Entities\", \"topic\": \"Named Entity Recognition\", \"x\": 6.341, \"y\": 6.887}, {\"title\": \"Humanizing Machine-Generated Content: Evading AI-Text Detection through  Adversarial Attack\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.948, \"y\": 1.324}, {\"title\": \"When Abel Kills Cain: What Machine Translation Cannot Capture\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.491, \"y\": 4.813}, {\"title\": \"Activation Steering for Robust Type Prediction in CodeLLMs\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.13, \"y\": 0.17}, {\"title\": \"Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language  Models -- A Survey\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.323, \"y\": 2.349}, {\"title\": \"Detecting Gender Bias in Course Evaluations\", \"topic\": \"Bias in Language Models\", \"x\": 3.191, \"y\": 2.787}, {\"title\": \"Poro 34B and the Blessing of Multilinguality\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.193, \"y\": 4.136}, {\"title\": \"A (More) Realistic Evaluation Setup for Generalisation of Community  Models on Malicious Content Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.293, \"y\": 3.81}, {\"title\": \"Sentiment Analysis of Citations in Scientific Articles Using ChatGPT:  Identifying Potential Biases and Conflicts of Interest\", \"topic\": \"Text Summarization\", \"x\": 4.911, \"y\": 5.819}, {\"title\": \"Auditing Large Language Models for Enhanced Text-Based Stereotype  Detection and Probing-Based Bias Evaluation\", \"topic\": \"Bias in Language Models\", \"x\": 3.17, \"y\": 2.708}, {\"title\": \"M2SA: Multimodal and Multilingual Model for Sentiment Analysis of Tweets\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.624, \"y\": 5.031}, {\"title\": \"Octopus v2: On-device language model for super agent\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.608, \"y\": 1.28}, {\"title\": \"Transfer Learning from Whisper for Microscopic Intelligibility  Prediction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.32, \"y\": 5.93}, {\"title\": \"Sentence-level Media Bias Analysis with Event Relation Graph\", \"topic\": \"Bias in Language Models\", \"x\": 3.413, \"y\": 3.929}, {\"title\": \"Effective internal language model training and fusion for factorized  transducer model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.537, \"y\": 5.666}, {\"title\": \"EMONA: Event-level Moral Opinions in News Articles\", \"topic\": \"Bias in Language Models\", \"x\": 3.337, \"y\": 3.525}, {\"title\": \"Polarity Calibration for Opinion Summarization\", \"topic\": \"Text Summarization\", \"x\": 4.898, \"y\": 5.139}, {\"title\": \"On the Role of Summary Content Units in Text Summarization Evaluation\", \"topic\": \"Text Summarization\", \"x\": 5.131, \"y\": 5.094}, {\"title\": \"Towards Generalizable and Faithful Logic Reasoning over Natural Language  via Resolution Refutation\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.405, \"y\": 1.986}, {\"title\": \"CMAT: A Multi-Agent Collaboration Tuning Framework for Enhancing Small  Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.274, \"y\": 1.682}, {\"title\": \"Towards Better Generalization in Open-Domain Question Answering by  Mitigating Context Memorization\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.641, \"y\": 4.54}, {\"title\": \"NLP Systems That Can't Tell Use from Mention Censor Counterspeech, but  Teaching the Distinction Helps\", \"topic\": \"Bias in Language Models\", \"x\": 2.555, \"y\": 3.381}, {\"title\": \"CATP: Cross-Attention Token Pruning for Accuracy Preserved Multimodal  Model Inference\", \"topic\": \"Multimodal Language Models\", \"x\": 8.1, \"y\": 7.624}, {\"title\": \"Entity Disambiguation via Fusion Entity Decoding\", \"topic\": \"Named Entity Recognition\", \"x\": 6.386, \"y\": 6.279}, {\"title\": \"Classifying Cancer Stage with Open-Source Clinical Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.273, \"y\": 7.455}, {\"title\": \"Hallucination Diversity-Aware Active Learning for Text Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.229, \"y\": 4.906}, {\"title\": \"Octopus: On-device language model for function calling of software APIs\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.96, \"y\": 0.457}, {\"title\": \"Set-Aligning Framework for Auto-Regressive Event Temporal Graph  Generation\", \"topic\": \"Named Entity Recognition\", \"x\": 6.303, \"y\": 5.565}, {\"title\": \"A Study on Scaling Up Multilingual News Framing Analysis\", \"topic\": \"Bias in Language Models\", \"x\": 3.361, \"y\": 3.979}, {\"title\": \"TraveLER: A Multi-LMM Agent Framework for Video Question-Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.695, \"y\": 7.49}, {\"title\": \"Creating emoji lexica from unsupervised sentiment analysis of their  descriptions\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.886, \"y\": 4.622}, {\"title\": \"Position-Aware Parameter Efficient Fine-Tuning Approach for Reducing  Positional Bias in LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.028, \"y\": 3.016}, {\"title\": \"Safe and Responsible Large Language Model : Can We Balance Bias  Reduction and Language Understanding in Large Language Models?\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.781, \"y\": 2.07}, {\"title\": \"CausalChaos! Dataset for Comprehensive Causal Action Question Answering  Over Longer Causal Chains Grounded in Dynamic Visual Scenes\", \"topic\": \"Multimodal Language Models\", \"x\": 8.389, \"y\": 7.649}, {\"title\": \"Towards Safety and Helpfulness Balanced Responses via Controllable Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.97, \"y\": 1.313}, {\"title\": \"Evaluating Text-to-Visual Generation with Image-to-Text Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.392, \"y\": 7.051}, {\"title\": \"Prompt-prompted Mixture of Experts for Efficient LLM Generation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.033, \"y\": 2.66}, {\"title\": \"TWIN-GPT: Digital Twins for Clinical Trials via Large Language Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.183, \"y\": 7.263}, {\"title\": \"IsoBench: Benchmarking Multimodal Foundation Models on Isomorphic  Representations\", \"topic\": \"Multimodal Language Models\", \"x\": 7.651, \"y\": 7.383}, {\"title\": \"FABLES: Evaluating faithfulness and content selection in book-length  summarization\", \"topic\": \"Text Summarization\", \"x\": 5.286, \"y\": 4.916}, {\"title\": \"An image speaks a thousand words, but can everyone listen? On image  transcreation for cultural relevance\", \"topic\": \"Multimodal Language Models\", \"x\": 8.557, \"y\": 6.879}, {\"title\": \"GFLean: An Autoformalisation Framework for Lean via GF\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.549, \"y\": 1.007}, {\"title\": \"Open-Vocabulary Federated Learning with Multimodal Prototyping\", \"topic\": \"Multimodal Language Models\", \"x\": 8.179, \"y\": 7.388}, {\"title\": \"LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language  Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.907, \"y\": 1.879}, {\"title\": \"Stable Code Technical Report\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.12, \"y\": 0.117}, {\"title\": \"The Fine Line: Navigating Large Language Model Pretraining with  Down-streaming Capability Analysis\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.54, \"y\": 2.456}, {\"title\": \"Estimating Lexical Complexity from Document-Level Distributions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.126, \"y\": 7.155}, {\"title\": \"Generating Faithful and Complete Hospital-Course Summaries from the  Electronic Health Record\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.181, \"y\": 7.446}, {\"title\": \"A Neuro-Symbolic Approach to Monitoring Salt Content in Food\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.816, \"y\": 7.366}, {\"title\": \"Exploring LLM Multi-Agents for ICD Coding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.109, \"y\": 7.522}, {\"title\": \"LITE: Modeling Environmental Ecosystems with Multimodal Large Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.009, \"y\": 6.92}, {\"title\": \"Dialogue with Robots: Proposals for Broadening Participation and  Research in the SLIVAR Community\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.134, \"y\": 2.827}, {\"title\": \"Structured Information Matters: Incorporating Abstract Meaning  Representation into LLMs for Improved Open-Domain Dialogue Evaluation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.258, \"y\": 3.368}, {\"title\": \"SentiCSE: A Sentiment-aware Contrastive Sentence Embedding Framework  with Sentiment-guided Textual Similarity\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 7.931, \"y\": 4.823}, {\"title\": \"What's in Your \\\"Safe\\\" Data?: Identifying Benign Data that Breaks Safety\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.893, \"y\": 1.096}, {\"title\": \"BERT-Enhanced Retrieval Tool for Homework Plagiarism Detection System\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.99, \"y\": 1.484}, {\"title\": \"Exploring the Mystery of Influential Data for Mathematical Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.742, \"y\": 1.153}, {\"title\": \"Regularized Best-of-N Sampling to Mitigate Reward Hacking for Language  Model Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.441, \"y\": 0.556}, {\"title\": \"ARAGOG: Advanced RAG Output Grading\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.132, \"y\": 4.544}, {\"title\": \"Utilizing AI and Social Media Analytics to Discover Adverse Side Effects  of GLP-1 Receptor Agonists\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.881, \"y\": 6.79}, {\"title\": \"PairEval: Open-domain Dialogue Evaluation with Pairwise Comparison\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.349, \"y\": 3.337}, {\"title\": \"Query Performance Prediction using Relevance Judgments Generated by  Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.012, \"y\": 4.638}, {\"title\": \"Constructing and Expanding Low-Resource and Underrepresented Parallel  Datasets for Indonesian Local Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.153, \"y\": 4.651}, {\"title\": \"LLM-RadJudge: Achieving Radiologist-Level Evaluation for X-Ray Report  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.201, \"y\": 7.97}, {\"title\": \"Exploring the Nexus of Large Language Models and Legal Systems: A Short  Survey\", \"topic\": \"Legal NLP\", \"x\": 4.37, \"y\": 4.501}, {\"title\": \"Prior Constraints-based Reward Model Training for Aligning Large  Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.489, \"y\": 0.613}, {\"title\": \"Efficiently Distilling LLMs for Edge Applications\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.21, \"y\": 2.462}, {\"title\": \"Evalverse: Unified and Accessible Library for Large Language Model  Evaluation\", \"topic\": \"Large Language Models in Education\", \"x\": 6.919, \"y\": 3.096}, {\"title\": \"ChatGLM-RLHF: Practices of Aligning Large Language Models with Human  Feedback\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.594, \"y\": 0.61}, {\"title\": \"A Survey on Multilingual Large Language Models: Corpora, Alignment, and  Bias\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.12, \"y\": 4.313}, {\"title\": \"Token-Efficient Leverage Learning in Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.403, \"y\": 2.338}, {\"title\": \"LLaMA-Excitor: General Instruction Tuning via Indirect Feature  Interaction\", \"topic\": \"Multimodal Language Models\", \"x\": 8.206, \"y\": 2.222}, {\"title\": \"Diverse Perspectives, Divergent Models: Cross-Cultural Evaluation of  Depression Detection on Twitter\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.247, \"y\": 6.278}, {\"title\": \"Bailong: Bilingual Transfer Learning based on QLoRA and Zip-tie  Embedding\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.141, \"y\": 4.091}, {\"title\": \"Do language models plan ahead for future tokens?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.864, \"y\": 2.798}, {\"title\": \"Extracting Social Determinants of Health from Pediatric Patient Notes  Using Large Language Models: Novel Corpus and Methods\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.859, \"y\": 6.872}, {\"title\": \"Fairness in Large Language Models: A Taxonomic Survey\", \"topic\": \"Bias in Language Models\", \"x\": 3.294, \"y\": 2.733}, {\"title\": \"From Robustness to Improved Generalization and Calibration in  Pre-trained Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.338, \"y\": 2.441}, {\"title\": \"Can Language Models Recognize Convincing Arguments?\", \"topic\": \"Bias in Language Models\", \"x\": 3.704, \"y\": 3.633}, {\"title\": \"The Larger the Better? Improved LLM Code-Generation via Budget  Reallocation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.116, \"y\": 0.066}, {\"title\": \"A General and Efficient Training for Transformer via Token Expansion\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.745, \"y\": 2.704}, {\"title\": \"Observations on Building RAG Systems for Technical Documents\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.067, \"y\": 4.586}, {\"title\": \"WavLLM: Towards Robust and Adaptive Speech Large Language Model\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.446, \"y\": 5.803}, {\"title\": \"Enhancing Bangla Fake News Detection Using Bidirectional Gated Recurrent  Units and Deep Learning Techniques\", \"topic\": \"Bias in Language Models\", \"x\": 3.338, \"y\": 3.715}, {\"title\": \"Against The Achilles' Heel: A Survey on Red Teaming for Generative  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.285, \"y\": 0.799}, {\"title\": \"Reporting Eye-Tracking Data Quality: Towards a New Standard\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.409, \"y\": 8.075}, {\"title\": \"RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.348, \"y\": 4.339}, {\"title\": \"Extensive Self-Contrast Enables Feedback-Free Language Model Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.466, \"y\": 0.619}, {\"title\": \"EvoCodeBench: An Evolving Code Generation Benchmark Aligned with  Real-World Code Repositories\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.098, \"y\": 0.107}, {\"title\": \"Mind Your Neighbours: Leveraging Analogous Instances for Rhetorical Role  Labeling for Legal Documents\", \"topic\": \"Legal NLP\", \"x\": 4.442, \"y\": 4.59}, {\"title\": \"ECtHR-PCR: A Dataset for Precedent Understanding and Prior Case  Retrieval in the European Court of Human Rights\", \"topic\": \"Legal NLP\", \"x\": 4.429, \"y\": 4.586}, {\"title\": \"Query-driven Relevant Paragraph Extraction from Legal Judgments\", \"topic\": \"Legal NLP\", \"x\": 4.444, \"y\": 4.607}, {\"title\": \"LexAbSumm: Aspect-based Summarization of Legal Decisions\", \"topic\": \"Text Summarization\", \"x\": 4.771, \"y\": 5.043}, {\"title\": \"CuSINeS: Curriculum-driven Structure Induced Negative Sampling for  Statutory Article Retrieval\", \"topic\": \"Legal NLP\", \"x\": 4.46, \"y\": 4.607}, {\"title\": \"Harnessing the Power of Large Language Model for Uncertainty Aware Graph  Processing\", \"topic\": \"Named Entity Recognition\", \"x\": 6.586, \"y\": 5.833}, {\"title\": \"CHOPS: CHat with custOmer Profile Systems for Customer Service with LLMs\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.955, \"y\": 1.918}, {\"title\": \"DiffAgent: Fast and Accurate Text-to-Image API Selection with Large  Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.427, \"y\": 6.925}, {\"title\": \"Explainable Multi-hop Question Generation: An End-to-End Approach  without Intermediate Question Labeling\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.432, \"y\": 4.138}, {\"title\": \"CM-TTS: Enhancing Real Time Text-to-Speech Synthesis Efficiency through  Weighted Samplers and Consistency Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.01, \"y\": 6.074}, {\"title\": \"CodeBenchGen: Creating Scalable Execution-based Code Generation  Benchmarks\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.09, \"y\": 0.102}, {\"title\": \"DivTOD: Unleashing the Power of LLMs for Diversifying Task-Oriented  Dialogue Representations\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.234, \"y\": 3.435}, {\"title\": \"Comparing Bad Apples to Good Oranges: Aligning Large Language Models via  Joint Preference Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.48, \"y\": 0.654}, {\"title\": \"MIPS at SemEval-2024 Task 3: Multimodal Emotion-Cause Pair Extraction in  Conversations with Multimodal Language Models\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.511, \"y\": 5.256}, {\"title\": \"Configurable Safety Tuning of Language Models with Synthetic Preference  Data\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.578, \"y\": 0.758}, {\"title\": \"Multi-hop Question Answering under Temporal Knowledge Editing\", \"topic\": \"Named Entity Recognition\", \"x\": 6.511, \"y\": 5.307}, {\"title\": \"Dialectical Alignment: Resolving the Tension of 3H and Security Threats  of LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.493, \"y\": 0.781}, {\"title\": \"Edinburgh Clinical NLP at SemEval-2024 Task 2: Fine-tune your model  unless you have access to GPT-4\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.227, \"y\": 7.108}, {\"title\": \"Linguistic Calibration of Long-Form Generations\", \"topic\": \"Large Language Models in Education\", \"x\": 6.241, \"y\": 3.282}, {\"title\": \"Addressing Both Statistical and Causal Gender Fairness in NLP Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.194, \"y\": 2.682}, {\"title\": \"Shortcuts Arising from Contrast: Effective and Covert Clean-Label  Attacks in Prompt-Based Learning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.306, \"y\": 0.957}, {\"title\": \"NumeroLogic: Number Encoding for Enhanced LLMs' Numerical Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.791, \"y\": 1.43}, {\"title\": \"MetaIE: Distilling a Meta Model from LLM for All Kinds of Information  Extraction Tasks\", \"topic\": \"Named Entity Recognition\", \"x\": 6.296, \"y\": 6.635}, {\"title\": \"Automatic explanation of the classification of Spanish legal judgments  in jurisdiction-dependent law categories with tree estimators\", \"topic\": \"Legal NLP\", \"x\": 4.387, \"y\": 4.554}, {\"title\": \"Do Vision-Language Models Understand Compound Nouns?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.481, \"y\": 7.501}, {\"title\": \"UniMEEC: Towards Unified Multimodal Emotion Recognition and Emotion  Cause\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.503, \"y\": 5.279}, {\"title\": \"An Analysis of BPE Vocabulary Trimming in Neural Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.847, \"y\": 4.456}, {\"title\": \"Jetsons at FinNLP 2024: Towards Understanding the ESG Impact of a News  Article using Transformer-based Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.239, \"y\": 4.529}, {\"title\": \"FineFake: A Knowledge-Enriched Dataset for Fine-Grained Multi-Domain  Fake News Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.476, \"y\": 3.735}, {\"title\": \"Small Language Models Learn Enhanced Reasoning Skills from Medical  Textbooks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.969, \"y\": 7.295}, {\"title\": \"Controllable and Diverse Data Augmentation with Large Language Model for  Low-Resource Open-Domain Dialogue Generation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.24, \"y\": 3.497}, {\"title\": \"Can LLMs Master Math? Investigating Large Language Models on Math Stack  Exchange\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.643, \"y\": 1.214}, {\"title\": \"Augmenting NER Datasets with LLMs: Towards Automated and Refined  Annotation\", \"topic\": \"Named Entity Recognition\", \"x\": 6.19, \"y\": 6.796}, {\"title\": \"A Comprehensive Study on NLP Data Augmentation for Hate Speech  Detection: Legacy Methods, BERT, and LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 2.449, \"y\": 3.399}, {\"title\": \"TRABSA: Interpretable Sentiment Analysis of Tweets using Attention-based  BiLSTM and Twitter-RoBERTa\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.146, \"y\": 5.089}, {\"title\": \"Survey on Large Language Model-Enhanced Reinforcement Learning: Concept,  Taxonomy, and Methods\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.022, \"y\": 1.286}, {\"title\": \"Your Co-Workers Matter: Evaluating Collaborative Capabilities of  Language Models in Blocks World\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.865, \"y\": 1.706}, {\"title\": \"DeFT: Decoding with Flash Tree-attention for Efficient Tree-structured  LLM Inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.404, \"y\": 2.864}, {\"title\": \"A Survey of using Large Language Models for Generating Infrastructure as  Code\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.075, \"y\": 0.135}, {\"title\": \"Design as Desired: Utilizing Visual Question Answering for Multimodal  Pre-training\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.393, \"y\": 8.106}, {\"title\": \"Classification and Clustering of Sentence-Level Embeddings of Scientific  Articles Generated by Contrastive Learning\", \"topic\": \"Text Summarization\", \"x\": 5.003, \"y\": 6.129}, {\"title\": \"Rationale-based Opinion Summarization\", \"topic\": \"Text Summarization\", \"x\": 4.989, \"y\": 5.157}, {\"title\": \"Conceptual and Unbiased Reasoning in Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.381, \"y\": 2.276}, {\"title\": \"LLaVA-Gemma: Accelerating Multimodal Foundation Models with a Compact  Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.35, \"y\": 7.327}, {\"title\": \"On-the-fly Definition Augmentation of LLMs for Biomedical NER\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.349, \"y\": 7.267}, {\"title\": \"Classifying Conspiratorial Narratives At Scale: False Alarms and  Erroneous Connections\", \"topic\": \"Bias in Language Models\", \"x\": 3.382, \"y\": 3.781}, {\"title\": \"Where Are You From? Let Me Guess! Subdialect Recognition of Speeches in  Sorani Kurdish\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.305, \"y\": 5.648}, {\"title\": \"Unsolvable Problem Detection: Evaluating Trustworthiness of Vision  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.944, \"y\": 7.784}, {\"title\": \"ReALM: Reference Resolution As Language Modeling\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.422, \"y\": 3.418}, {\"title\": \"Emotion-Anchored Contrastive Learning Framework for Emotion Recognition  in Conversation\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.564, \"y\": 5.363}, {\"title\": \"Can LLMs Correct Physicians, Yet? Investigating Effective Interaction  Methods in the Medical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.77, \"y\": 7.315}, {\"title\": \"LayerNorm: A key component in parameter-efficient fine-tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.388, \"y\": 2.463}, {\"title\": \"ELITR-Bench: A Meeting Assistant Benchmark for Long-Context Language  Models\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.353, \"y\": 3.554}, {\"title\": \"Using LLMs to Model the Beliefs and Preferences of Targeted Populations\", \"topic\": \"Bias in Language Models\", \"x\": 4.378, \"y\": 2.51}, {\"title\": \"Shallow Cross-Encoders for Low-Latency Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.298, \"y\": 4.734}, {\"title\": \"Exploring Pathological Speech Quality Assessment with ASR-Powered  Wav2Vec2 in Data-Scarce Context\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.505, \"y\": 6.131}, {\"title\": \"ChatGPT v.s. Media Bias: A Comparative Study of GPT-3.5 and Fine-tuned  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.222, \"y\": 3.505}, {\"title\": \"A Systematic Analysis of Subwords and Cross-Lingual Transfer in  Multilingual Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.433, \"y\": 4.503}, {\"title\": \"IndiBias: A Benchmark Dataset to Measure Social Biases in Language  Models for Indian Context\", \"topic\": \"Bias in Language Models\", \"x\": 3.294, \"y\": 2.743}, {\"title\": \"Fine-tuning Large Language Models for Automated Diagnostic Screening  Summaries\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.626, \"y\": 6.88}, {\"title\": \"Constructing Multilingual Visual-Text Datasets Revealing Visual  Multilingual Ability of Vision Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.966, \"y\": 7.76}, {\"title\": \"NLP for Counterspeech against Hate: A Survey and How-To Guide\", \"topic\": \"Bias in Language Models\", \"x\": 2.502, \"y\": 3.388}, {\"title\": \"RealKIE: Five Novel Datasets for Enterprise Key Information Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.089, \"y\": 6.527}, {\"title\": \"An Efficient Approach for Studying Cross-Lingual Transfer in  Multilingual Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.383, \"y\": 4.268}, {\"title\": \"IPA Transcription of Bengali Texts\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.12, \"y\": 5.548}, {\"title\": \"Cross-Lingual Transfer Robustness to Lower-Resource Languages on  Adversarial Datasets\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.104, \"y\": 4.429}, {\"title\": \"Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to  Boost for Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.203, \"y\": 2.122}, {\"title\": \"Transformer-Lite: High-efficiency Deployment of Large Language Models on  Mobile Phone GPUs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.475, \"y\": 2.688}, {\"title\": \"FSMR: A Feature Swapping Multi-modal Reasoning Approach with Joint  Textual and Visual Clues\", \"topic\": \"Multimodal Language Models\", \"x\": 8.085, \"y\": 7.485}, {\"title\": \"Large Language Model based Situational Dialogues for Second Language  Learning\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.329, \"y\": 2.979}, {\"title\": \"Enhancing the General Agent Capabilities of Low-Parameter LLMs through  Tuning and Multi-Branch Reasoning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.396, \"y\": 1.665}, {\"title\": \"SLFNet: Generating Semantic Logic Forms from Natural Language Using  Semantic Probability Graphs\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.479, \"y\": 2.298}, {\"title\": \"DiJiang: Efficient Large Language Models through Compact Kernelization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.826, \"y\": 2.646}, {\"title\": \"Towards a Robust Retrieval-Based Summarization System\", \"topic\": \"Text Summarization\", \"x\": 5.324, \"y\": 4.94}, {\"title\": \"A Backdoor Approach with Inverted Labels Using Dirty Label-Flipping  Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.18, \"y\": 0.846}, {\"title\": \"Jamba: A Hybrid Transformer-Mamba Language Model\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.017, \"y\": 2.571}, {\"title\": \"The New Agronomists: Language Models are Experts in Crop Management\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.052, \"y\": 1.239}, {\"title\": \"Concept-based Analysis of Neural Networks via Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.957, \"y\": 7.697}, {\"title\": \"Target Span Detection for Implicit Harmful Content\", \"topic\": \"Bias in Language Models\", \"x\": 2.475, \"y\": 3.408}, {\"title\": \"Language Models Learn Rare Phenomena from Less Rare Phenomena: The Case  of the Missing AANNs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.62, \"y\": 2.978}, {\"title\": \"Multi-Stage Multi-Modal Pre-Training for Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.448, \"y\": 5.766}, {\"title\": \"Developing Healthcare Language Model Embedding Spaces\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.308, \"y\": 7.383}, {\"title\": \"Quantum Natural Language Processing\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.238, \"y\": 2.641}, {\"title\": \"MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.062, \"y\": 7.226}, {\"title\": \"Asymmetric and trial-dependent modeling: the contribution of LIA to SdSV  Challenge Task 2\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.517, \"y\": 5.947}, {\"title\": \"Retrieval-Enhanced Knowledge Editing for Multi-Hop Question Answering in  Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.736, \"y\": 4.43}, {\"title\": \"Semantic Map-based Generation of Navigation Instructions\", \"topic\": \"Multimodal Language Models\", \"x\": 7.96, \"y\": 6.897}, {\"title\": \"Improving Adversarial Data Collection by Supporting Annotators: Lessons  from GAHD, a German Hate Speech Dataset\", \"topic\": \"Bias in Language Models\", \"x\": 2.475, \"y\": 3.37}, {\"title\": \"A Review of Multi-Modal Large Language and Vision Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.409, \"y\": 7.204}, {\"title\": \"Improving Clinical NLP Performance through Language Model-Generated  Synthetic Clinical Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.306, \"y\": 7.347}, {\"title\": \"Phonetic Segmentation of the UCLA Phonetics Lab Archive\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.18, \"y\": 5.713}, {\"title\": \"JDocQA: Japanese Document Question Answering Dataset for Generative  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.703, \"y\": 7.479}, {\"title\": \"Mixed Preference Optimization: Reinforcement Learning with Data  Selection and Better Reference Model\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.495, \"y\": 0.567}, {\"title\": \"Uncovering Misattributed Suicide Causes through Annotation Inconsistency  Detection in Death Investigation Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.428, \"y\": 6.548}, {\"title\": \"Echo-chambers and Idea Labs: Communication Styles on Twitter\", \"topic\": \"Bias in Language Models\", \"x\": 3.149, \"y\": 3.969}, {\"title\": \"BP4ER: Bootstrap Prompting for Explicit Reasoning in Medical Dialogue  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.803, \"y\": 7.406}, {\"title\": \"KazParC: Kazakh Parallel Corpus for Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.651, \"y\": 4.652}, {\"title\": \"Checkpoint Merging via Bayesian Optimization in LLM Pretraining\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.322, \"y\": 2.039}, {\"title\": \"EthioMT: Parallel Corpus for Low-resource Ethiopian Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.225, \"y\": 4.704}, {\"title\": \"Risk prediction of pathological gambling on social media\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.367, \"y\": 6.337}, {\"title\": \"Large Language Models Are Unconscious of Unreasonability in Math  Problems\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.595, \"y\": 1.311}, {\"title\": \"KazSAnDRA: Kazakh Sentiment Analysis Dataset of Reviews and Attitudes\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.073, \"y\": 4.862}, {\"title\": \"Plug-and-Play Grounding of Reasoning in Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.862, \"y\": 7.544}, {\"title\": \"Beyond Borders: Investigating Cross-Jurisdiction Transfer in Legal Case  Summarization\", \"topic\": \"Legal NLP\", \"x\": 4.478, \"y\": 4.679}, {\"title\": \"EmoScan: Automatic Screening of Depression Symptoms in Romanized Sinhala  Tweets\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.306, \"y\": 6.339}, {\"title\": \"Going Beyond Word Matching: Syntax Improves In-context Example Selection  for Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.388, \"y\": 4.51}, {\"title\": \"Fine-Tuning Language Models with Reward Learning on Policy\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.491, \"y\": 0.637}, {\"title\": \"sDPO: Don't Use Your Data All at Once\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.541, \"y\": 0.531}, {\"title\": \"NaijaHate: Evaluating Hate Speech Detection on Nigerian Twitter Using  Representative Data\", \"topic\": \"Bias in Language Models\", \"x\": 2.464, \"y\": 3.37}, {\"title\": \"J-CRe3: A Japanese Conversation Dataset for Real-world Reference  Resolution\", \"topic\": \"Multimodal Language Models\", \"x\": 8.349, \"y\": 7.275}, {\"title\": \"Dual-Personalizing Adapter for Federated Foundation Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.24, \"y\": 0.01}, {\"title\": \"A Benchmark Evaluation of Clinical Named Entity Recognition in French\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.654, \"y\": 7.306}, {\"title\": \"Mitigating Misleading Chain-of-Thought Reasoning with Selective  Filtering\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.328, \"y\": 2.049}, {\"title\": \"Improving Vietnamese-English Medical Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.64, \"y\": 4.776}, {\"title\": \"Disentangling Length from Quality in Direct Preference Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.406, \"y\": 0.732}, {\"title\": \"STaR-GATE: Teaching Language Models to Ask Clarifying Questions\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.495, \"y\": 2.769}, {\"title\": \"A Tulu Resource for Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.542, \"y\": 4.749}, {\"title\": \"Streamlining Redundant Layers to Compress Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.224, \"y\": 2.342}, {\"title\": \"Code Comparison Tuning for Code Large Language Models\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.149, \"y\": 0.089}, {\"title\": \"Top Leaderboard Ranking = Top Coding Proficiency, Always? EvoEval:  Evolving Coding Benchmarks via LLM\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.106, \"y\": 0.106}, {\"title\": \"Automated Black-box Prompt Engineering for Personalized Text-to-Image  Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.382, \"y\": 6.785}, {\"title\": \"Learning From Correctness Without Prompting Makes LLM Efficient Reasoner\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.161, \"y\": 1.945}, {\"title\": \"CAUSE: Counterfactual Assessment of User Satisfaction Estimation in  Task-Oriented Dialogue Systems\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.328, \"y\": 3.233}, {\"title\": \"ReflectSumm: A Benchmark for Course Reflection Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.07, \"y\": 5.11}, {\"title\": \"A Novel Corpus of Annotated Medical Imaging Reports and Information  Extraction Results Using BERT-based Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.237, \"y\": 7.776}, {\"title\": \"Conformal Intent Classification and Clarification for Fast and Accurate  Intent Recognition\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.367, \"y\": 3.223}, {\"title\": \"A Survey on Large Language Models from Concept to Implementation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.992, \"y\": 3.021}, {\"title\": \"The Comparison of Translationese in Machine Translation and Human  Transation in terms of Translation Relations\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.575, \"y\": 4.768}, {\"title\": \"Moderating Illicit Online Image Promotion for Unsafe User-Generated  Content Games Using Large Vision-Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 2.801, \"y\": 3.087}, {\"title\": \"Reshaping Free-Text Radiology Notes Into Structured Reports With  Generative Transformers\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.145, \"y\": 7.774}, {\"title\": \"What are human values, and how do we align AI to them?\", \"topic\": \"Bias in Language Models\", \"x\": 4.118, \"y\": 2.238}, {\"title\": \"Mini-Gemini: Mining the Potential of Multi-modality Vision Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.127, \"y\": 7.574}, {\"title\": \"Is Modularity Transferable? A Case Study through the Lens of Knowledge  Distillation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.545, \"y\": 2.158}, {\"title\": \"Projective Methods for Mitigating Gender Bias in Pre-trained Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.234, \"y\": 2.672}, {\"title\": \"Capability-aware Prompt Reformulation Learning for Text-to-Image  Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.388, \"y\": 6.783}, {\"title\": \"Towards a World-English Language Model for On-Device Virtual Assistants\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.977, \"y\": 2.852}, {\"title\": \"CheckEval: Robust Evaluation Framework using Large Language Model via  Checklist\", \"topic\": \"Large Language Models in Education\", \"x\": 6.434, \"y\": 2.97}, {\"title\": \"CYCLE: Learning to Self-Refine the Code Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.119, \"y\": 0.098}, {\"title\": \"Mitigating Hallucinations in Large Vision-Language Models with  Instruction Contrastive Decoding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.345, \"y\": 8.067}, {\"title\": \"The Invalsi Benchmarks: measuring Linguistic and Mathematical  understanding of Large Language Models in Italian\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.625, \"y\": 1.6}, {\"title\": \"Scaling Laws For Dense Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.444, \"y\": 4.336}, {\"title\": \"Non-Linear Inference Time Intervention: Improving LLM Truthfulness\", \"topic\": \"Large Language Models in Education\", \"x\": 6.746, \"y\": 3.015}, {\"title\": \"Fact Checking Beyond Training Set\", \"topic\": \"Bias in Language Models\", \"x\": 3.816, \"y\": 3.926}, {\"title\": \"Vulnerability Detection with Code Language Models: How Far Are We?\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.581, \"y\": 0.857}, {\"title\": \"A survey on learning models of spiking neural membrane systems and  spiking neural networks\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.64, \"y\": 2.861}, {\"title\": \"Debiasing Sentence Embedders through Contrastive Word Pairs\", \"topic\": \"Bias in Language Models\", \"x\": 3.354, \"y\": 2.688}, {\"title\": \"A Path Towards Legal Autonomy: An interoperable and explainable approach  to extracting, transforming, loading and computing legal information using  large language models, expert systems and Bayesian networks\", \"topic\": \"Legal NLP\", \"x\": 4.434, \"y\": 4.304}, {\"title\": \"PhoWhisper: Automatic Speech Recognition for Vietnamese\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.529, \"y\": 5.772}, {\"title\": \"Language Plays a Pivotal Role in the Object-Attribute Compositional  Generalization of CLIP\", \"topic\": \"Multimodal Language Models\", \"x\": 8.367, \"y\": 7.636}, {\"title\": \"Can Language Beat Numerical Regression? Language-Based Multimodal  Trajectory Prediction\", \"topic\": \"Multimodal Language Models\", \"x\": 8.011, \"y\": 6.681}, {\"title\": \"DELTA: Pre-train a Discriminative Encoder for Legal Case Retrieval via  Structural Word Alignment\", \"topic\": \"Legal NLP\", \"x\": 4.421, \"y\": 4.629}, {\"title\": \"SemRoDe: Macro Adversarial Training to Learn Representations That are  Robust to Word-Level Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.034, \"y\": 1.153}, {\"title\": \"BioMedLM: A 2.7B Parameter Language Model Trained On Biomedical Text\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.306, \"y\": 7.219}, {\"title\": \"An Image Grid Can Be Worth a Video: Zero-shot Video Question Answering  Using a VLM\", \"topic\": \"Multimodal Language Models\", \"x\": 8.745, \"y\": 7.436}, {\"title\": \"Evaluation of Semantic Search and its Role in  Retrieved-Augmented-Generation (RAG) for Arabic Language\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.334, \"y\": 4.454}, {\"title\": \"Quantifying and Mitigating Unimodal Biases in Multimodal Large Language  Models: A Causal Perspective\", \"topic\": \"Multimodal Language Models\", \"x\": 7.83, \"y\": 7.681}, {\"title\": \"A Dataset for Pharmacovigilance in German, French, and Japanese:  Annotating Adverse Drug Reactions across Languages\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.168, \"y\": 7.079}, {\"title\": \"Chinese Offensive Language Detection:Current Status and Future  Directions\", \"topic\": \"Bias in Language Models\", \"x\": 2.415, \"y\": 3.314}, {\"title\": \"Dual Instruction Tuning with Large Language Models for Mathematical  Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.668, \"y\": 1.3}, {\"title\": \"BlendX: Complex Multi-Intent Detection with Blended Patterns\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.314, \"y\": 3.401}, {\"title\": \"RankMamba: Benchmarking Mamba's Document Ranking Performance in the Era  of Transformers\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.198, \"y\": 4.707}, {\"title\": \"Toward Interactive Regional Understanding in Vision-Large Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.195, \"y\": 7.595}, {\"title\": \"Beyond Embeddings: The Promise of Visual Table in Visual Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.814, \"y\": 7.617}, {\"title\": \"Since the Scientific Literature Is Multilingual, Our Models Should Be  Too\", \"topic\": \"Text Summarization\", \"x\": 5.099, \"y\": 6.084}, {\"title\": \"Exploring the Deceptive Power of LLM-Generated Fake News: A Study of  Real-World Detection Challenges\", \"topic\": \"Bias in Language Models\", \"x\": 3.438, \"y\": 3.566}, {\"title\": \"ZAEBUC-Spoken: A Multilingual Multidialectal Arabic-English Speech  Corpus\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.043, \"y\": 5.505}, {\"title\": \"Oh! We Freeze: Improving Quantized Knowledge Distillation via Signal  Propagation Analysis for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.529, \"y\": 2.214}, {\"title\": \"Juru: Legal Brazilian Large Language Model from Reputable Sources\", \"topic\": \"Legal NLP\", \"x\": 4.452, \"y\": 4.602}, {\"title\": \"For those who don't know (how) to ask: Building a dataset of technology  questions for digital newcomers\", \"topic\": \"Large Language Models in Education\", \"x\": 6.221, \"y\": 2.58}, {\"title\": \"Don't Trust: Verify -- Grounding LLM Quantitative Reasoning with  Autoformalization\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.635, \"y\": 1.244}, {\"title\": \"GPTs and Language Barrier: A Cross-Lingual Legal QA Examination\", \"topic\": \"Legal NLP\", \"x\": 4.401, \"y\": 4.53}, {\"title\": \"Enhancing Legal Document Retrieval: A Multi-Phase Approach with Large  Language Models\", \"topic\": \"Legal NLP\", \"x\": 4.484, \"y\": 4.622}, {\"title\": \"Heracles: A Hybrid SSM-Transformer Model for High-Resolution Image and  Time-Series Analysis\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.575, \"y\": 6.291}, {\"title\": \"The Impact of Syntactic and Semantic Proximity on Machine Translation  with Back-Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.503, \"y\": 4.515}, {\"title\": \"Improving Pre-trained Language Model Sensitivity via Mask Specific  losses: A case study on Biomedical NER\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.449, \"y\": 7.336}, {\"title\": \"DORE: A Dataset For Portuguese Definition Generation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.133, \"y\": 4.199}, {\"title\": \"LISA: Layerwise Importance Sampling for Memory-Efficient Large Language  Model Fine-Tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.793, \"y\": 1.838}, {\"title\": \"The Unreasonable Ineffectiveness of the Deeper Layers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.996, \"y\": 2.248}, {\"title\": \"ChroniclingAmericaQA: A Large-scale Question Answering Dataset based on  Historical American Newspaper Pages\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.84, \"y\": 4.347}, {\"title\": \"Using Domain Knowledge to Guide Dialog Structure Induction via Neural  Probabilistic Soft Logic\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.129, \"y\": 3.406}, {\"title\": \"Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot  Navigation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.04, \"y\": 7.15}, {\"title\": \"Domain Adaptation in Intent Classification Systems: A Review\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.388, \"y\": 3.379}, {\"title\": \"Graph Language Model (GLM): A new graph-based approach to detect social  instabilities\", \"topic\": \"Bias in Language Models\", \"x\": 3.395, \"y\": 4.169}, {\"title\": \"Are Compressed Language Models Less Subgroup Robust?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.635, \"y\": 2.648}, {\"title\": \"Have Faith in Faithfulness: Going Beyond Circuit Overlap When Finding  Model Mechanisms\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.388, \"y\": 2.679}, {\"title\": \"Improving Text-to-Image Consistency via Automatic Prompt Optimization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.524, \"y\": 6.875}, {\"title\": \"Large Language Models for Human-Robot Interaction: Opportunities and  Risks\", \"topic\": \"Bias in Language Models\", \"x\": 4.736, \"y\": 2.331}, {\"title\": \"SciNews: From Scholarly Complexities to Public Narratives -- A Dataset  for Scientific News Report Generation\", \"topic\": \"Text Summarization\", \"x\": 4.999, \"y\": 5.836}, {\"title\": \"FastPerson: Enhancing Video Learning through Effective Video  Summarization that Preserves Linguistic and Visual Contexts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.948, \"y\": 7.041}, {\"title\": \"NJUST-KMG at TRAC-2024 Tasks 1 and 2: Offline Harm Potential  Identification\", \"topic\": \"Bias in Language Models\", \"x\": 2.626, \"y\": 3.375}, {\"title\": \"Not All Similarities Are Created Equal: Leveraging Data-Driven Biases to  Inform GenAI Copyright Disputes\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.37, \"y\": 1.335}, {\"title\": \"Intrinsic Subgraph Generation for Interpretable Graph based Visual  Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 7.547, \"y\": 7.501}, {\"title\": \"DANCER: Entity Description Augmented Named Entity Corrector for  Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.547, \"y\": 5.739}, {\"title\": \"Mix-Initiative Response Generation with Dynamic Prefix Tuning\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.206, \"y\": 3.383}, {\"title\": \"\\\"You are an expert annotator\\\": Automatic Best-Worst-Scaling Annotations  for Emotion Intensity Modeling\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.698, \"y\": 5.302}, {\"title\": \"Towards a Zero-Data, Controllable, Adaptive Dialog System\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.277, \"y\": 2.984}, {\"title\": \"m3P: Towards Multimodal Multilingual Translation with Multimodal Prompt\", \"topic\": \"Multimodal Language Models\", \"x\": 8.956, \"y\": 6.41}, {\"title\": \"RuBia: A Russian Language Bias Detection Dataset\", \"topic\": \"Bias in Language Models\", \"x\": 3.123, \"y\": 2.775}, {\"title\": \"A Gaze-grounded Visual Question Answering Dataset for Clarifying  Ambiguous Japanese Questions\", \"topic\": \"Multimodal Language Models\", \"x\": 7.873, \"y\": 7.745}, {\"title\": \"Provably Secure Disambiguating Neural Linguistic Steganography\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.763, \"y\": 0.828}, {\"title\": \"Sharing the Cost of Success: A Game for Evaluating and Learning  Collaborative Multi-Agent Instruction Giving and Following Policies\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.788, \"y\": 1.409}, {\"title\": \"DGoT: Dynamic Graph of Thoughts for Scientific Abstract Generation\", \"topic\": \"Text Summarization\", \"x\": 5.093, \"y\": 5.792}, {\"title\": \"Incorporating Exponential Smoothing into MLP: A Simple but Effective  Sequence Model\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.847, \"y\": 3.041}, {\"title\": \"Aligning Large Language Models for Enhancing Psychiatric Interviews  through Symptom Delineation and Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.065, \"y\": 6.47}, {\"title\": \"Transcribing Bengali Text with Regional Dialects to IPA using District  Guided Tokens\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.138, \"y\": 5.514}, {\"title\": \"ELLEN: Extremely Lightly Supervised Learning For Efficient Named Entity  Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 6.208, \"y\": 6.811}, {\"title\": \"Extracting Biomedical Entities from Noisy Audio Transcripts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.587, \"y\": 7.356}, {\"title\": \"Disambiguate Entity Matching using Large Language Models through  Relation Discovery\", \"topic\": \"Named Entity Recognition\", \"x\": 6.385, \"y\": 6.219}, {\"title\": \"Don't Listen To Me: Understanding and Exploring Jailbreak Prompts of  Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.077, \"y\": 0.429}, {\"title\": \"JMultiWOZ: A Large-Scale Japanese Multi-Domain Task-Oriented Dialogue  Dataset\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.198, \"y\": 3.265}, {\"title\": \"Decoding Probing: Revealing Internal Linguistic Structures in Neural  Language Models using Minimal Pairs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.804, \"y\": 3.014}, {\"title\": \"TwoStep: Multi-agent Task Planning using Classical Planners and Large  Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.3, \"y\": 1.397}, {\"title\": \"The Role of $n$-gram Smoothing in the Age of Neural Networks\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.5, \"y\": 2.651}, {\"title\": \"Extracting Social Support and Social Isolation Information from Clinical  Psychiatry Notes: Comparing a Rule-based NLP System and a Large Language  Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.394, \"y\": 6.631}, {\"title\": \"Advancing Speech Translation: A Corpus of Mandarin-English  Conversational Telephone Speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.025, \"y\": 5.459}, {\"title\": \"QuanTemp: A real-world open-domain benchmark for fact-checking numerical  claims\", \"topic\": \"Bias in Language Models\", \"x\": 3.859, \"y\": 3.965}, {\"title\": \"Reflecting the Male Gaze: Quantifying Female Objectification in 19th and  20th Century Novels\", \"topic\": \"Bias in Language Models\", \"x\": 3.356, \"y\": 2.682}, {\"title\": \"Task-Agnostic Detector for Insertion-Based Backdoor Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.229, \"y\": 0.856}, {\"title\": \"Outcome-Constrained Large Language Models for Countering Hate Speech\", \"topic\": \"Bias in Language Models\", \"x\": 2.501, \"y\": 3.388}, {\"title\": \"Guided Distant Supervision for Multilingual Relation Extraction Data:  Adapting to a New Language\", \"topic\": \"Named Entity Recognition\", \"x\": 6.284, \"y\": 6.513}, {\"title\": \"MetaAligner: Towards Generalizable Multi-Objective Alignment of Language  Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.549, \"y\": 0.557}, {\"title\": \"Exploring the Generalization of Cancer Clinical Trial Eligibility  Classifiers Across Diseases\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.308, \"y\": 7.041}, {\"title\": \"The Strong Pull of Prior Knowledge in Large Language Models and Its  Impact on Emotion Recognition\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.741, \"y\": 5.34}, {\"title\": \"STRUM-LLM: Attributed and Structured Contrastive Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.029, \"y\": 5.185}, {\"title\": \"A comparison of Human, GPT-3.5, and GPT-4 Performance in a  University-Level Coding Course\", \"topic\": \"Large Language Models in Education\", \"x\": 6.086, \"y\": 2.457}, {\"title\": \"VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.075, \"y\": 5.962}, {\"title\": \"AIOS: LLM Agent Operating System\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.265, \"y\": 1.544}, {\"title\": \"Deja vu: Contrastive Historical Modeling with Prefix-tuning for Temporal  Knowledge Graph Reasoning\", \"topic\": \"Named Entity Recognition\", \"x\": 6.455, \"y\": 5.489}, {\"title\": \"Hierarchical Recurrent Adapters for Efficient Multi-Task Adaptation of  Large Speech Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.48, \"y\": 5.568}, {\"title\": \"Data Mixing Laws: Optimizing Data Mixtures by Predicting Language  Modeling Performance\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.119, \"y\": 2.618}, {\"title\": \"Aligning with Human Judgement: The Role of Pairwise Preference in Large  Language Model Evaluators\", \"topic\": \"Large Language Models in Education\", \"x\": 6.235, \"y\": 3.072}, {\"title\": \"SPACE-IDEAS: A Dataset for Salient Information Detection in Space  Innovation\", \"topic\": \"Text Summarization\", \"x\": 5.028, \"y\": 5.897}, {\"title\": \"Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language  Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.106, \"y\": 4.659}, {\"title\": \"Towards Algorithmic Fidelity: Mental Health Representation across  Demographics in Synthetic vs. Human-generated Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.33, \"y\": 6.442}, {\"title\": \"State Space Models as Foundation Models: A Control Theoretic Overview\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.796, \"y\": 3.111}, {\"title\": \"Encoding of lexical tone in self-supervised models of spoken language\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.277, \"y\": 5.837}, {\"title\": \"Towards Explainability in Legal Outcome Prediction Models\", \"topic\": \"Legal NLP\", \"x\": 4.343, \"y\": 4.536}, {\"title\": \"Can ChatGPT predict article retraction based on Twitter mentions?\", \"topic\": \"Bias in Language Models\", \"x\": 3.541, \"y\": 3.933}, {\"title\": \"Iterative Refinement of Project-Level Code Context for Precise Code  Generation with Compiler Feedback\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.078, \"y\": 0.097}, {\"title\": \"Can Machine Translation Bridge Multilingual Pretraining and  Cross-lingual Transfer Learning?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.378, \"y\": 4.409}, {\"title\": \"Synthetic Data Generation and Joint Learning for Robust Code-Mixed  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.656, \"y\": 4.73}, {\"title\": \"ProCQA: A Large-scale Community-based Programming Question Answering  Dataset for Code Search\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.624, \"y\": 4.094}, {\"title\": \"ToXCL: A Unified Framework for Toxic Speech Detection and Explanation\", \"topic\": \"Bias in Language Models\", \"x\": 2.584, \"y\": 3.265}, {\"title\": \"RU22Fact: Optimizing Evidence for Multilingual Explainable Fact-Checking  on Russia-Ukraine Conflict\", \"topic\": \"Bias in Language Models\", \"x\": 3.741, \"y\": 3.832}, {\"title\": \"A comparative analysis of embedding models for patent similarity\", \"topic\": \"Legal NLP\", \"x\": 4.651, \"y\": 4.866}, {\"title\": \"Conversational Grounding: Annotation and Analysis of Grounding Acts and  Grounding Units\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.186, \"y\": 3.101}, {\"title\": \"TrustAI at SemEval-2024 Task 8: A Comprehensive Analysis of Multi-domain  Machine Generated Text Detection Techniques\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.744, \"y\": 1.742}, {\"title\": \"Efficient Information Extraction in Few-Shot Relation Classification  through Contrastive Representation Learning\", \"topic\": \"Named Entity Recognition\", \"x\": 6.329, \"y\": 6.549}, {\"title\": \"Hallucination Detection in Foundation Models for Decision-Making: A  Flexible Definition and Review of the State of the Art\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.117, \"y\": 1.958}, {\"title\": \"LLMs Are Few-Shot In-Context Low-Resource Language Learners\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.114, \"y\": 4.053}, {\"title\": \"LARA: Linguistic-Adaptive Retrieval-Augmented LLMs for Multi-Turn Intent  Classification\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.401, \"y\": 3.7}, {\"title\": \"Few-shot Named Entity Recognition via Superposition Concept  Discrimination\", \"topic\": \"Named Entity Recognition\", \"x\": 6.227, \"y\": 6.889}, {\"title\": \"A Study on How Attention Scores in the BERT Model are Aware of Lexical  Categories in Syntactic and Semantic Tasks on the GLUE Benchmark\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.685, \"y\": 2.877}, {\"title\": \"Towards Automatic Evaluation for LLMs' Clinical Capabilities: Metric,  Data, and Algorithm\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.781, \"y\": 7.289}, {\"title\": \"CodeS: Natural Language to Code Repository via Multi-Layer Sketch\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.027, \"y\": 0.118}, {\"title\": \"If CLIP Could Talk: Understanding Vision-Language Model Representations  Through Their Preferred Concept Descriptions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.247, \"y\": 7.728}, {\"title\": \"Reasoning Runtime Behavior of a Program with LLM: How Far Are We?\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.042, \"y\": 0.257}, {\"title\": \"InstUPR : Instruction-based Unsupervised Passage Reranking with Large  Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.907, \"y\": 4.523}, {\"title\": \"$\\\\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on  Prompt-based Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.177, \"y\": 0.875}, {\"title\": \"Is There a One-Model-Fits-All Approach to Information Extraction?  Revisiting Task Definition Biases\", \"topic\": \"Named Entity Recognition\", \"x\": 6.485, \"y\": 6.299}, {\"title\": \"Skews in the Phenomenon Space Hinder Generalization in Text-to-Image  Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.392, \"y\": 6.927}, {\"title\": \"Synthesize Step-by-Step: Tools, Templates and LLMs as Data Generators  for Reasoning-Based Chart VQA\", \"topic\": \"Multimodal Language Models\", \"x\": 7.398, \"y\": 7.373}, {\"title\": \"Enhanced Facet Generation with LLM Editing\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.051, \"y\": 4.627}, {\"title\": \"Large Language Models in Biomedical and Health Informatics: A  Bibliometric Review\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.929, \"y\": 6.98}, {\"title\": \"LexDrafter: Terminology Drafting for Legislative Documents using  Retrieval Augmented Generation\", \"topic\": \"Legal NLP\", \"x\": 4.606, \"y\": 4.584}, {\"title\": \"Improving Sequence-to-Sequence Models for Abstractive Text Summarization  Using Meta Heuristic Approaches\", \"topic\": \"Text Summarization\", \"x\": 5.18, \"y\": 5.156}, {\"title\": \"ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.828, \"y\": 1.773}, {\"title\": \"Subspace Defense: Discarding Adversarial Perturbations by Learning a  Subspace for Clean Signals\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.965, \"y\": 1.232}, {\"title\": \"Exploiting Semantic Reconstruction to Mitigate Hallucinations in  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.392, \"y\": 8.033}, {\"title\": \"Korean Bio-Medical Corpus (KBMC) for Medical Named Entity Recognition\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.609, \"y\": 7.312}, {\"title\": \"A Little Leak Will Sink a Great Ship: Survey of Transparency for Large  Language Models from Start to Finish\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.806, \"y\": 0.743}, {\"title\": \"A Multi-Label Dataset of French Fake News: Human and Machine Insights\", \"topic\": \"Bias in Language Models\", \"x\": 3.336, \"y\": 3.697}, {\"title\": \"LLMs as Compiler for Arabic Programming Language\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.839, \"y\": 0.518}, {\"title\": \"Qibo: A Large Language Model for Traditional Chinese Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.044, \"y\": 7.355}, {\"title\": \"CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral  Therapy-based Mental Health Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.197, \"y\": 6.616}, {\"title\": \"IllusionVQA: A Challenging Optical Illusion Dataset for Vision Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.264, \"y\": 8.019}, {\"title\": \"Geotokens and Geotransformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.437, \"y\": 3.159}, {\"title\": \"EduAgent: Generative Student Agents in Learning\", \"topic\": \"Large Language Models in Education\", \"x\": 6.224, \"y\": 2.349}, {\"title\": \"Leveraging Zero-Shot Prompting for Efficient Language Model Distillation\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.32, \"y\": 2.128}, {\"title\": \"STEntConv: Predicting Disagreement with Stance Detection and a Signed  Graph Convolutional Network\", \"topic\": \"Bias in Language Models\", \"x\": 3.204, \"y\": 4.012}, {\"title\": \"VLUE: A New Benchmark and Multi-task Knowledge Transfer Learning for  Vietnamese Natural Language Understanding\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.76, \"y\": 4.017}, {\"title\": \"RAAMove: A Corpus for Analyzing Moves in Research Article Abstracts\", \"topic\": \"Text Summarization\", \"x\": 5.059, \"y\": 5.782}, {\"title\": \"Centered Masking for Language-Image Pre-Training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.408, \"y\": 7.684}, {\"title\": \"MRC-based Nested Medical NER with Co-prediction and Adaptive  Pre-training\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.476, \"y\": 7.413}, {\"title\": \"Understanding Emergent Abilities of Language Models from the Loss  Perspective\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.789, \"y\": 2.776}, {\"title\": \"Cost-Efficient Large Language Model Serving for Multi-turn Conversations  with CachedAttention\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.367, \"y\": 2.905}, {\"title\": \"Modeling Unified Semantic Discourse Structure for High-quality Headline  Generation\", \"topic\": \"Text Summarization\", \"x\": 5.243, \"y\": 5.193}, {\"title\": \"Leveraging Large Language Models for Preliminary Security Risk Analysis:  A Mission-Critical Case Study\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.762, \"y\": 1.364}, {\"title\": \"Ghost Sentence: A Tool for Everyday Users to Copyright Data from Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.776, \"y\": 0.757}, {\"title\": \"Few-shot Dialogue Strategy Learning for Motivational Interviewing via  Inductive Reasoning\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.221, \"y\": 2.831}, {\"title\": \"LLMs Instruct LLMs:An Extraction and Editing Method\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.713, \"y\": 4.53}, {\"title\": \"FEEL: A Framework for Evaluating Emotional Support Capability with Large  Language Models\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.676, \"y\": 5.717}, {\"title\": \"MixRED: A Mix-lingual Relation Extraction Dataset\", \"topic\": \"Named Entity Recognition\", \"x\": 6.295, \"y\": 6.54}, {\"title\": \"EAGLE: A Domain Generalization Framework for AI-generated Text Detection\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.78, \"y\": 1.626}, {\"title\": \"AI for Biomedicine in the Era of Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.728, \"y\": 6.917}, {\"title\": \"Improving Retrieval for RAG based Question Answering Models on Financial  Documents\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.814, \"y\": 4.774}, {\"title\": \"Hear Me, See Me, Understand Me: Audio-Visual Autism Behavior Recognition\", \"topic\": \"Multimodal Language Models\", \"x\": 8.968, \"y\": 7.206}, {\"title\": \"Differentially Private Next-Token Prediction of Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.82, \"y\": 0.185}, {\"title\": \"NaturalTurn: A Method to Segment Transcripts into Naturalistic  Conversational Turns\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.099, \"y\": 3.363}, {\"title\": \"LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.999, \"y\": 7.629}, {\"title\": \"Can large language models explore in-context?\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.982, \"y\": 1.392}, {\"title\": \"LimGen: Probing the LLMs for Generating Suggestive Limitations of  Research Papers\", \"topic\": \"Text Summarization\", \"x\": 4.963, \"y\": 5.92}, {\"title\": \"Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy  with Semantic Search and Hybrid Query-Based Retrievers\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.286, \"y\": 4.577}, {\"title\": \"Multi-Review Fusion-in-Context\", \"topic\": \"Text Summarization\", \"x\": 5.259, \"y\": 5.039}, {\"title\": \"CO-Fun: A German Dataset on Company Outsourcing in Fund Prospectuses for  Named Entity Recognition and Relation Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.138, \"y\": 6.757}, {\"title\": \"Controlled Training Data Generation with Diffusion Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.512, \"y\": 6.733}, {\"title\": \"Imagination Augmented Generation: Learning to Imagine Richer Context for  Question Answering over Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.523, \"y\": 4.334}, {\"title\": \"FollowIR: Evaluating and Teaching Information Retrieval Models to Follow  Instructions\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.13, \"y\": 4.614}, {\"title\": \"Not All Attention is Needed: Parameter and Computation Efficient  Transfer Learning for Multi-modal Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.899, \"y\": 2.657}, {\"title\": \"Investigating the Performance of Language Models for Completing Code in  Functional Programming Languages: a Haskell Case Study\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.107, \"y\": 0.108}, {\"title\": \"CACA Agent: Capability Collaboration based AI Agent\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.072, \"y\": 1.593}, {\"title\": \"CTSM: Combining Trait and State Emotions for Empathetic Response Model\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.621, \"y\": 5.654}, {\"title\": \"CHisIEC: An Information Extraction Corpus for Ancient Chinese History\", \"topic\": \"Named Entity Recognition\", \"x\": 6.139, \"y\": 6.59}, {\"title\": \"Selecting Query-bag as Pseudo Relevance Feedback for Information-seeking  Conversations\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.047, \"y\": 4.511}, {\"title\": \"Risk and Response in Large Language Models: Evaluating Key Threat  Categories\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.718, \"y\": 1.284}, {\"title\": \"MasonTigers at SemEval-2024 Task 9: Solving Puzzles with an Ensemble of  Chain-of-Thoughts\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.214, \"y\": 1.874}, {\"title\": \"A Picture Is Worth a Graph: Blueprint Debate on Graph for Multimodal  Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.501, \"y\": 7.579}, {\"title\": \"Adapprox: Adaptive Approximation in Adam Optimization via Randomized  Low-Rank Matrices\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.016, \"y\": 2.003}, {\"title\": \"Evidence-Driven Retrieval Augmented Response Generation for Online  Misinformation\", \"topic\": \"Bias in Language Models\", \"x\": 3.744, \"y\": 3.888}, {\"title\": \"On Zero-Shot Counterspeech Generation by LLMs\", \"topic\": \"Large Language Models in Education\", \"x\": 6.697, \"y\": 3.562}, {\"title\": \"Extending Token Computation for LLM Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.576, \"y\": 2.031}, {\"title\": \"Optimal path for Biomedical Text Summarization Using Pointer GPT\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.164, \"y\": 7.345}, {\"title\": \"AutoRE: Document-Level Relation Extraction with Large Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.276, \"y\": 6.489}, {\"title\": \"VidLA: Video-Language Alignment at Scale\", \"topic\": \"Multimodal Language Models\", \"x\": 8.739, \"y\": 7.343}, {\"title\": \"Enhancing Medical Support in the Arabic Language Through Personalized  ChatGPT Assistance\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.802, \"y\": 7.204}, {\"title\": \"The opportunities and risks of large language models in mental health\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.041, \"y\": 6.472}, {\"title\": \"A Collection of Pragmatic-Similarity Judgments over Spoken Dialog  Utterances\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.925, \"y\": 6.004}, {\"title\": \"Multi-Agent VQA: Exploring Multi-Agent Foundation Models in Zero-Shot  Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 8.065, \"y\": 7.782}, {\"title\": \"Emergent World Models and Latent Variable Estimation in Chess-Playing  Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.824, \"y\": 1.564}, {\"title\": \"Few-Shot Adversarial Prompt Learning on Vision-Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.026, \"y\": 1.07}, {\"title\": \"StreamingT2V: Consistent, Dynamic, and Extendable Long Video Generation  from Text\", \"topic\": \"Multimodal Language Models\", \"x\": 8.605, \"y\": 6.987}, {\"title\": \"MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual  Math Problems?\", \"topic\": \"Multimodal Language Models\", \"x\": 7.562, \"y\": 7.603}, {\"title\": \"DreamReward: Text-to-3D Generation with Human Preference\", \"topic\": \"Multimodal Language Models\", \"x\": 8.446, \"y\": 6.827}, {\"title\": \"ReAct Meets ActRe: When Language Agents Enjoy Training Data Autonomy\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.05, \"y\": 1.511}, {\"title\": \"Large Language Models for Multi-Choice Question Classification of  Medical Subjects\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.877, \"y\": 7.296}, {\"title\": \"A Chain-of-Thought Prompting Approach with LLMs for Evaluating Students'  Formative Assessment Responses in Science\", \"topic\": \"Large Language Models in Education\", \"x\": 6.471, \"y\": 2.36}, {\"title\": \"The Era of Semantic Decoding\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.395, \"y\": 1.69}, {\"title\": \"Lexicon-Level Contrastive Visual-Grounding Improves Language Modeling\", \"topic\": \"Multimodal Language Models\", \"x\": 8.222, \"y\": 7.53}, {\"title\": \"Detoxifying Large Language Models via Knowledge Editing\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.669, \"y\": 0.953}, {\"title\": \"Prediction of Translation Techniques for the Translation Process\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.596, \"y\": 4.863}, {\"title\": \"A Multimodal Approach to Device-Directed Speech Detection with Large  Language Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.07, \"y\": 5.983}, {\"title\": \"Locating and Mitigating Gender Bias in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.272, \"y\": 2.747}, {\"title\": \"Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language  Models through Question Complexity\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.601, \"y\": 4.527}, {\"title\": \"XLAVS-R: Cross-Lingual Audio-Visual Speech Representation Learning for  Noise-Robust Speech Perception\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.137, \"y\": 6.119}, {\"title\": \"Building Accurate Translation-Tailored LLMs with Language Aware  Instruction Tuning\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.683, \"y\": 4.514}, {\"title\": \"From Large to Tiny: Distilling and Refining Mathematical Expertise for  Math Word Problems with Weakly Supervision\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.649, \"y\": 1.218}, {\"title\": \"FIT-RAG: Black-Box RAG with Factual Information and Token Reduction\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.359, \"y\": 4.538}, {\"title\": \"$\\\\nabla \\u03c4$: Gradient-based and Task-Agnostic machine Unlearning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.047, \"y\": 0.535}, {\"title\": \"ChainLM: Empowering Large Language Models with Improved Chain-of-Thought  Prompting\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.209, \"y\": 1.91}, {\"title\": \"Is Reference Necessary in the Evaluation of NLG Systems? When and Where?\", \"topic\": \"Large Language Models in Education\", \"x\": 6.142, \"y\": 3.477}, {\"title\": \"LLM-based Extraction of Contradictions from Patents\", \"topic\": \"Legal NLP\", \"x\": 4.703, \"y\": 4.811}, {\"title\": \"ERD: A Framework for Improving LLM Reasoning for Cognitive Distortion  Classification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.123, \"y\": 6.38}, {\"title\": \"K-Act2Emo: Korean Commonsense Knowledge Graph for Indirect Emotional  Expression\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.583, \"y\": 5.391}, {\"title\": \"Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large  Language Models with Machine Learning in tele-dermatology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.007, \"y\": 7.571}, {\"title\": \"Reinforcement Learning from Reflective Feedback (RLRF): Aligning and  Improving LLMs via Fine-Grained Self-Reflection\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.015, \"y\": 1.72}, {\"title\": \"A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.106, \"y\": 0.082}, {\"title\": \"Large-Scale Label Interpretation Learning for Few-Shot Named Entity  Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 6.271, \"y\": 6.757}, {\"title\": \"Improving the Robustness of Large Language Models via Consistency  Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.671, \"y\": 0.938}, {\"title\": \"Open Knowledge Base Canonicalization with Multi-task Learning\", \"topic\": \"Named Entity Recognition\", \"x\": 6.678, \"y\": 5.809}, {\"title\": \"Context Quality Matters in Training Fusion-in-Decoder for Extractive  Open-Domain Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.575, \"y\": 4.412}, {\"title\": \"MOGAM: A Multimodal Object-oriented Graph Attention Model for Depression  Detection\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.223, \"y\": 6.273}, {\"title\": \"RakutenAI-7B: Extending Large Language Models for Japanese\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.869, \"y\": 3.986}, {\"title\": \"MMIDR: Teaching Large Language Model to Interpret Multimodal  Misinformation via Knowledge Distillation\", \"topic\": \"Bias in Language Models\", \"x\": 3.637, \"y\": 3.813}, {\"title\": \"M$^3$AV: A Multimodal, Multigenre, and Multipurpose Audio-Visual  Academic Lecture Dataset\", \"topic\": \"Multimodal Language Models\", \"x\": 9.012, \"y\": 7.048}, {\"title\": \"Reversible Jump Attack to Textual Classifiers with Modification  Reduction\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.015, \"y\": 1.144}, {\"title\": \"Multi-Level Feedback Generation with Large Language Models for  Empowering Novice Peer Counselors\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 2.959, \"y\": 6.406}, {\"title\": \"From Handcrafted Features to LLMs: A Brief Survey for Machine  Translation Quality Estimation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.534, \"y\": 4.893}, {\"title\": \"Benchmarking Chinese Commonsense Reasoning of LLMs: From  Chinese-Specifics to Reasoning-Memorization Correlations\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.148, \"y\": 3.0}, {\"title\": \"Text-Enhanced Data-free Approach for Federated Class-Incremental  Learning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.21, \"y\": 0.218}, {\"title\": \"Protected group bias and stereotypes in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.349, \"y\": 2.675}, {\"title\": \"Extracting Emotion Phrases from Tweets using BART\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.862, \"y\": 5.145}, {\"title\": \"Ax-to-Grind Urdu: Benchmark Dataset for Urdu Fake News Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.482, \"y\": 3.683}, {\"title\": \"A New Massive Multilingual Dataset for High-Performance Language  Technologies\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.236, \"y\": 4.533}, {\"title\": \"On Prompt Sensitivity of ChatGPT in Affective Computing\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.698, \"y\": 5.667}, {\"title\": \"Multi-Modal Hallucination Control by Visual Information Grounding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.335, \"y\": 7.94}, {\"title\": \"Testing the Limits of Jailbreaking Defenses with the Purple Problem\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.084, \"y\": 0.495}, {\"title\": \"Integrating Supervised Extractive and Generative Language Models for  Suicide Risk Evidence Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.293, \"y\": 6.447}, {\"title\": \"Reducing Large Language Model Bias with Emphasis on 'Restricted  Industries': Automated Dataset Augmentation and Prejudice Quantification\", \"topic\": \"Bias in Language Models\", \"x\": 3.177, \"y\": 2.751}, {\"title\": \"Visually Grounded Speech Models have a Mutual Exclusivity Bias\", \"topic\": \"Multimodal Language Models\", \"x\": 8.341, \"y\": 7.498}, {\"title\": \"Leveraging Linguistically Enhanced Embeddings for Open Information  Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.47, \"y\": 6.368}, {\"title\": \"Learning from Models and Data for Visual Grounding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.058, \"y\": 7.297}, {\"title\": \"Natural Language as Policies: Reasoning for Coordinate-Level Embodied  Control with LLMs\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.34, \"y\": 1.279}, {\"title\": \"Chain-of-Interaction: Enhancing Large Language Models for Psychiatric  Behavior Understanding by Dyadic Contexts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.065, \"y\": 6.479}, {\"title\": \"Information-Theoretic Distillation for Reference-less Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.175, \"y\": 5.135}, {\"title\": \"EthioLLM: Multilingual Large Language Models for Ethiopian Languages  with Task Evaluation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.154, \"y\": 4.577}, {\"title\": \"PARAMANU-AYN: An Efficient Novel Generative and Instruction-tuned  Language Model for Indian Legal Case Documents\", \"topic\": \"Legal NLP\", \"x\": 4.404, \"y\": 4.569}, {\"title\": \"Defending Against Indirect Prompt Injection Attacks With Spotlighting\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.234, \"y\": 0.62}, {\"title\": \"Grounding Spatial Relations in Text-Only Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.734, \"y\": 7.151}, {\"title\": \"Do Not Worry if You Do Not Have Data: Building Pretrained Language  Models Using Translationese\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.299, \"y\": 4.309}, {\"title\": \"Teacher-Student Training for Debiasing: General Permutation Debiasing  for Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.353, \"y\": 2.487}, {\"title\": \"Genetic Auto-prompt Learning for Pre-trained Code Intelligence Language  Models\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.071, \"y\": 0.095}, {\"title\": \"CoCoST: Automatic Complex Code Generation with Online Searching and  Correctness Testing\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.07, \"y\": 0.146}, {\"title\": \"What explains the success of cross-modal fine-tuning with ORCA?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.452, \"y\": 7.244}, {\"title\": \"Motion Generation from Fine-grained Textual Descriptions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.543, \"y\": 6.988}, {\"title\": \"How Gender Interacts with Political Values: A Case Study on Czech BERT  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.204, \"y\": 2.739}, {\"title\": \"What if...?: Thinking Counterfactual Keywords Helps to Mitigate  Hallucination in Large Multi-modal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.299, \"y\": 8.052}, {\"title\": \"HyperLLaVA: Dynamic Visual and Language Expert Tuning for Multimodal  Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.272, \"y\": 7.308}, {\"title\": \"Isometric Neural Machine Translation using Phoneme Count Ratio  Reward-based Reinforcement Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.111, \"y\": 5.681}, {\"title\": \"Inserting Faces inside Captions: Image Captioning with Attention Guided  Merging\", \"topic\": \"Multimodal Language Models\", \"x\": 8.523, \"y\": 7.259}, {\"title\": \"Clinical information extraction for Low-resource languages with Few-shot  learning using Pre-trained language models and Prompting\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.302, \"y\": 7.403}, {\"title\": \"Incentivizing News Consumption on Social Media Platforms Using Large  Language Models and Realistic Bot Accounts\", \"topic\": \"Bias in Language Models\", \"x\": 3.342, \"y\": 3.554}, {\"title\": \"Hyacinth6B: A large language model for Traditional Chinese\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.636, \"y\": 2.311}, {\"title\": \"Don't be a Fool: Pooling Strategies in Offensive Language Detection from  User-Intended Adversarial Attacks\", \"topic\": \"Bias in Language Models\", \"x\": 2.415, \"y\": 3.25}, {\"title\": \"Polaris: A Safety-focused LLM Constellation Architecture for Healthcare\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.728, \"y\": 7.423}, {\"title\": \"LeanReasoner: Boosting Complex Logical Reasoning with Lean\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.396, \"y\": 1.66}, {\"title\": \"Community Needs and Assets: A Computational Analysis of Community  Conversations\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.33, \"y\": 4.547}, {\"title\": \"Arcee's MergeKit: A Toolkit for Merging Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.264, \"y\": 2.021}, {\"title\": \"SumTra: A Differentiable Pipeline for Few-Shot Cross-Lingual  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.349, \"y\": 5.09}, {\"title\": \"From Representational Harms to Quality-of-Service Harms: A Case Study on  Llama 2 Safety Safeguards\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.927, \"y\": 1.402}, {\"title\": \"A Big Data Analytics System for Predicting Suicidal Ideation in  Real-Time Based on Social Media Streaming Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.331, \"y\": 6.356}, {\"title\": \"Wav2Gloss: Generating Interlinear Glossed Text from Speech\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.236, \"y\": 4.561}, {\"title\": \"Efficient Encoder-Decoder Transformer Decoding for Decomposable Tasks\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.057, \"y\": 3.185}, {\"title\": \"Towards Unsupervised Question Answering System with Multi-level  Summarization for Legal Text\", \"topic\": \"Legal NLP\", \"x\": 4.403, \"y\": 4.624}, {\"title\": \"Automatic Summarization of Doctor-Patient Encounter Dialogues Using  Large Language Model through Prompt Tuning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.107, \"y\": 7.379}, {\"title\": \"LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach  Combining Predictive Agent Reasoning and Critical Agent Instruction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.836, \"y\": 7.434}, {\"title\": \"Negative Yields Positive: Unified Dual-Path Adapter for Vision-Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.413, \"y\": 7.581}, {\"title\": \"Automatic Information Extraction From Employment Tribunal Judgements  Using Large Language Models\", \"topic\": \"Legal NLP\", \"x\": 4.417, \"y\": 4.57}, {\"title\": \"Supporting Energy Policy Research with Large Language Models\", \"topic\": \"Legal NLP\", \"x\": 4.577, \"y\": 4.763}, {\"title\": \"Generalizable and Stable Finetuning of Pretrained Language Models on  Low-Resource Texts\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.459, \"y\": 2.16}, {\"title\": \"Agent-FLAN: Designing Data and Methods of Effective Agent Tuning for  Large Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.532, \"y\": 1.846}, {\"title\": \"Contextual Moral Value Alignment Through Context-Based Aggregation\", \"topic\": \"Bias in Language Models\", \"x\": 4.09, \"y\": 2.193}, {\"title\": \"Investigating Text Shortening Strategy in BERT: Truncation vs  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.282, \"y\": 5.157}, {\"title\": \"Sebastian, Basti, Wastl?! Recognizing Named Entities in Bavarian  Dialectal Data\", \"topic\": \"Named Entity Recognition\", \"x\": 6.205, \"y\": 6.844}, {\"title\": \"Instructing Large Language Models to Identify and Ignore Irrelevant  Conditions\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.559, \"y\": 1.346}, {\"title\": \"Multi-Dimensional Machine Translation Evaluation: Model Evaluation and  Resource for Korean\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.561, \"y\": 4.901}, {\"title\": \"Fine-Tuning Pre-trained Language Models to Detect In-Game Trash Talks\", \"topic\": \"Bias in Language Models\", \"x\": 2.49, \"y\": 3.408}, {\"title\": \"Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.486, \"y\": 7.53}, {\"title\": \"RigorLLM: Resilient Guardrails for Large Language Models against  Undesired Content\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.356, \"y\": 1.031}, {\"title\": \"A Large Collection of Model-generated Contradictory Responses for  Consistency-aware Dialogue Systems\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.379, \"y\": 3.338}, {\"title\": \"Embodied LLM Agents Learn to Cooperate in Organized Teams\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.762, \"y\": 1.725}, {\"title\": \"WoLF: Wide-scope Large Language Model Framework for CXR Understanding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.251, \"y\": 8.033}, {\"title\": \"When Do \\\"More Contexts\\\" Help with Sarcasm Recognition?\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.514, \"y\": 4.867}, {\"title\": \"MSLM-S2ST: A Multitask Speech Language Model for Textless  Speech-to-Speech Translation with Speaker Style Preservation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.096, \"y\": 5.637}, {\"title\": \"Cross-Lingual Transfer for Natural Language Inference via Multilingual  Prompt Translator\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.946, \"y\": 4.191}, {\"title\": \"Towards Interpretable Hate Speech Detection using Large Language  Model-extracted Rationales\", \"topic\": \"Bias in Language Models\", \"x\": 2.447, \"y\": 3.372}, {\"title\": \"An Empirical Study of Speech Language Models for Prompt-Conditioned  Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.931, \"y\": 6.041}, {\"title\": \"Improving Generalizability of Extracting Social Determinants of Health  Using Large Language Models through Prompt-tuning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.229, \"y\": 7.187}, {\"title\": \"RankPrompt: Step-by-Step Comparisons Make Language Models Better  Reasoners\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.112, \"y\": 2.259}, {\"title\": \"Emotion Detection with Transformers: A Comparative Study\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.624, \"y\": 5.294}, {\"title\": \"Leveraging Large Language Models to Extract Information on Substance Use  Disorder Severity from Clinical Notes: A Zero-shot Learning Approach\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.579, \"y\": 6.758}, {\"title\": \"Span-Oriented Information Extraction -- A Unifying Perspective on  Information Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.294, \"y\": 6.443}, {\"title\": \"EasyJailbreak: A Unified Framework for Jailbreaking Large Language  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.05, \"y\": 0.481}, {\"title\": \"Fusing Domain-Specific Content from Large Language Models into Knowledge  Graphs for Enhanced Zero Shot Object State Classification\", \"topic\": \"Multimodal Language Models\", \"x\": 8.267, \"y\": 7.501}, {\"title\": \"Syn-QA2: Evaluating False Assumptions in Long-tail Questions with  Synthetic QA Datasets\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.664, \"y\": 4.307}, {\"title\": \"From Pixels to Insights: A Survey on Automatic Chart Understanding in  the Era of Large Foundation Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.366, \"y\": 7.253}, {\"title\": \"FlexCap: Generating Rich, Localized, and Flexible Captions in Images\", \"topic\": \"Multimodal Language Models\", \"x\": 8.176, \"y\": 7.546}, {\"title\": \"A Toolbox for Surfacing Health Equity Harms and Biases in Large Language  Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.647, \"y\": 6.766}, {\"title\": \"Enhancing Taiwanese Hokkien Dual Translation by Exploring and  Standardizing of Four Writing Systems\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.64, \"y\": 4.624}, {\"title\": \"Supervised Fine-Tuning as Inverse Reinforcement Learning\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.683, \"y\": 0.625}, {\"title\": \"EnvGen: Generating and Adapting Environments via LLMs for Training  Embodied Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.043, \"y\": 1.374}, {\"title\": \"Using Generative Text Models to Create Qualitative Codebooks for Student  Evaluations of Teaching\", \"topic\": \"Large Language Models in Education\", \"x\": 6.208, \"y\": 2.418}, {\"title\": \"Towards Enabling FAIR Dataspaces Using Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.292, \"y\": 2.703}, {\"title\": \"Adaptative Bilingual Aligning Using Multilingual Sentence Embedding\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.071, \"y\": 4.567}, {\"title\": \"Investigating Markers and Drivers of Gender Bias in Machine Translations\", \"topic\": \"Bias in Language Models\", \"x\": 3.128, \"y\": 2.71}, {\"title\": \"From Explainable to Interpretable Deep Learning for Natural Language  Processing in Healthcare: How Far from Reality?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.881, \"y\": 7.34}, {\"title\": \"QueryAgent: A Reliable and Efficient Reasoning Framework with  Environmental Feedback-based Self-Correction\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.099, \"y\": 2.108}, {\"title\": \"CO3: Low-resource Contrastive Co-training for Generative Conversational  Query Rewrite\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.997, \"y\": 4.425}, {\"title\": \"Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.858, \"y\": 1.212}, {\"title\": \"SSCAE -- Semantic, Syntactic, and Context-aware natural language  Adversarial Examples generator\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.017, \"y\": 1.192}, {\"title\": \"How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming  Ability in Multi-Agent Environments\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.812, \"y\": 1.804}, {\"title\": \"Reasoning Abilities of Large Language Models: In-Depth Analysis on the  Abstraction and Reasoning Corpus\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.418, \"y\": 2.205}, {\"title\": \"Revisiting The Classics: A Study on Identifying and Rectifying Gender  Stereotypes in Rhymes and Poems\", \"topic\": \"Bias in Language Models\", \"x\": 3.199, \"y\": 2.728}, {\"title\": \"Embedded Named Entity Recognition using Probing Classifiers\", \"topic\": \"Named Entity Recognition\", \"x\": 6.24, \"y\": 6.74}, {\"title\": \"Let's Focus on Neuron: Neuron-Level Supervised Fine-tuning for Large  Language Model\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.668, \"y\": 1.886}, {\"title\": \"Linguacodus: A Synergistic Framework for Transformative Code Generation  in Machine Learning Pipelines\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.099, \"y\": 0.315}, {\"title\": \"Hatred Stems from Ignorance! Distillation of the Persuasion Modes in  Countering Conversational Hate Speech\", \"topic\": \"Bias in Language Models\", \"x\": 2.57, \"y\": 3.386}, {\"title\": \"A Disease Labeler for Chinese Chest X-Ray Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.233, \"y\": 7.93}, {\"title\": \"DEE: Dual-stage Explainable Evaluation Method for Text Generation\", \"topic\": \"Large Language Models in Education\", \"x\": 6.476, \"y\": 3.569}, {\"title\": \"HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive  Speech Detection via Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 2.462, \"y\": 3.392}, {\"title\": \"StyleChat: Learning Recitation-Augmented Memory in LLMs for Stylized  Dialogue Generation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.209, \"y\": 3.359}, {\"title\": \"A Novel Paradigm Boosting Translation Capabilities of Large Language  Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.649, \"y\": 4.56}, {\"title\": \"Narrative Feature or Structured Feature? A Study of Large Language  Models to Identify Cancer Patients at Risk of Heart Failure\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.152, \"y\": 7.344}, {\"title\": \"Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient  LLMs Under Compression\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.519, \"y\": 2.307}, {\"title\": \"X-LLaVA: Optimizing Bilingual Large Vision-Language Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.449, \"y\": 7.211}, {\"title\": \"Can LLM-Augmented autonomous agents cooperate?, An evaluation of their  cooperative capabilities through Melting Pot\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.929, \"y\": 1.572}, {\"title\": \"What Makes Math Word Problems Challenging for LLMs?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.697, \"y\": 1.237}, {\"title\": \"JORA: JAX Tensor-Parallel LoRA Library for Retrieval Augmented  Fine-Tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.995, \"y\": 2.121}, {\"title\": \"CantonMT: Cantonese to English NMT Platform with Fine-Tuned Models Using  Synthetic Back-Translation Data\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.64, \"y\": 4.626}, {\"title\": \"Improving Dialogue Agents by Decomposing One Global Explicit Annotation  with Local Implicit Multimodal Feedback\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.178, \"y\": 3.063}, {\"title\": \"StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.641, \"y\": 1.35}, {\"title\": \"Few-Shot VQA with Frozen LLMs: A Tale of Two Approaches\", \"topic\": \"Multimodal Language Models\", \"x\": 7.918, \"y\": 7.646}, {\"title\": \"Reasoning in Transformers -- Mitigating Spurious Correlations and  Reasoning Shortcuts\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.785, \"y\": 1.974}, {\"title\": \"Mixture-of-Prompt-Experts for Multi-modal Semantic Understanding\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.614, \"y\": 5.027}, {\"title\": \"SQ-LLaVA: Self-Questioning for Large Vision-Language Assistant\", \"topic\": \"Multimodal Language Models\", \"x\": 7.914, \"y\": 7.715}, {\"title\": \"A Modified Word Saliency-Based Adversarial Attack on Text Classification  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.098, \"y\": 1.118}, {\"title\": \"Forging the Forger: An Attempt to Improve Authorship Verification via  Data Augmentation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.976, \"y\": 1.658}, {\"title\": \"ChartThinker: A Contextual Chain-of-Thought Approach to Optimized Chart  Summarization\", \"topic\": \"Multimodal Language Models\", \"x\": 7.368, \"y\": 7.319}, {\"title\": \"Cheap Ways of Extracting Clinical Markers from Texts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.36, \"y\": 6.461}, {\"title\": \"TRELM: Towards Robust and Efficient Pre-training for Knowledge-Enhanced  Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.817, \"y\": 5.59}, {\"title\": \"Concept-Best-Matching: Evaluating Compositionality in Emergent  Communication\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.087, \"y\": 1.954}, {\"title\": \"Quality-Aware Image-Text Alignment for Real-World Image Quality  Assessment\", \"topic\": \"Multimodal Language Models\", \"x\": 8.598, \"y\": 7.227}, {\"title\": \"Correcting misinformation on social media with a large language model\", \"topic\": \"Bias in Language Models\", \"x\": 3.745, \"y\": 3.823}, {\"title\": \"Evaluation Ethics of LLMs in Legal Domain\", \"topic\": \"Legal NLP\", \"x\": 4.364, \"y\": 4.4}, {\"title\": \"Scaling Data Diversity for Fine-Tuning Language Models in Human  Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.715, \"y\": 0.813}, {\"title\": \"Granular Change Accuracy: A More Accurate Performance Metric for  Dialogue State Tracking\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.165, \"y\": 3.309}, {\"title\": \"HarmPot: An Annotation Framework for Evaluating Offline Harm Potential  of Social Media Text\", \"topic\": \"Bias in Language Models\", \"x\": 2.552, \"y\": 3.422}, {\"title\": \"ProgGen: Generating Named Entity Recognition Datasets Step-by-step with  Self-Reflexive Large Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.238, \"y\": 6.796}, {\"title\": \"m&m's: A Benchmark to Evaluate Tool-Use for multi-step multi-modal Tasks\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.445, \"y\": 1.372}, {\"title\": \"Customizing Visual-Language Foundation Models for Multi-modal Anomaly  Detection and Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.727, \"y\": 7.678}, {\"title\": \"Deep Learning-based Sentiment Analysis in Persian Language\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.104, \"y\": 4.961}, {\"title\": \"FlowMind: Automatic Workflow Generation with LLMs\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.379, \"y\": 1.862}, {\"title\": \"DIALECTBENCH: A NLP Benchmark for Dialects, Varieties, and  Closely-Related Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.899, \"y\": 4.257}, {\"title\": \"Pointer-Generator Networks for Low-Resource Machine Translation: Don't  Copy That!\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.737, \"y\": 4.57}, {\"title\": \"Energy-Based Models with Applications to Speech and Language Processing\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.848, \"y\": 3.304}, {\"title\": \"Initial Decoding with Minimally Augmented Language Model for Improved  Lattice Rescoring in Low Resource ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.608, \"y\": 5.691}, {\"title\": \"Towards Robustness and Diversity: Continual Learning in Dialog  Generation with Text-Mixup and Batch Nuclear-Norm Maximization\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.296, \"y\": 3.386}, {\"title\": \"Optimizing Language Augmentation for Multilingual Large Language Models:  A Case Study on Korean\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.961, \"y\": 3.983}, {\"title\": \"Zero-shot Generative Linguistic Steganography\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.537, \"y\": 0.985}, {\"title\": \"Deciphering Hate: Identifying Hateful Memes and Their Targets\", \"topic\": \"Bias in Language Models\", \"x\": 2.507, \"y\": 3.488}, {\"title\": \"Multi-party Response Generation with Relation Disentanglement\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.153, \"y\": 3.492}, {\"title\": \"Can Large Language Models abstract Medical Coded Language?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.972, \"y\": 7.203}, {\"title\": \"Efficient Pruning of Large Language Model with Adaptive Estimation  Fusion\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.214, \"y\": 2.538}, {\"title\": \"From Words to Routes: Applying Large Language Models to Vehicle Routing\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.537, \"y\": 1.438}, {\"title\": \"LLM-based Conversational AI Therapist for Daily Functioning Screening  and Psychotherapeutic Intervention via Everyday Smart Devices\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.009, \"y\": 6.447}, {\"title\": \"Detecting Bias in Large Language Models: Fine-tuned KcBERT\", \"topic\": \"Bias in Language Models\", \"x\": 3.047, \"y\": 2.914}, {\"title\": \"ECRC: Emotion-Causality Recognition in Korean Conversation for GCN\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.578, \"y\": 5.333}, {\"title\": \"Rules still work for Open Information Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.307, \"y\": 6.501}, {\"title\": \"Depression Detection on Social Media with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.388, \"y\": 6.436}, {\"title\": \"PERL: Parameter Efficient Reinforcement Learning from Human Feedback\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.53, \"y\": 0.591}, {\"title\": \"A Multilingual Perspective on Probing Gender Bias\", \"topic\": \"Bias in Language Models\", \"x\": 3.094, \"y\": 2.799}, {\"title\": \"EXPLORER: Exploration-guided Reasoning for Textual Reinforcement  Learning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.029, \"y\": 1.334}, {\"title\": \"MYTE: Morphology-Driven Byte Encoding for Better and Fairer Multilingual  Language Modeling\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.163, \"y\": 4.402}, {\"title\": \"DiPaCo: Distributed Path Composition\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.153, \"y\": 2.471}, {\"title\": \"VideoAgent: Long-form Video Understanding with Large Language Model as  Agent\", \"topic\": \"Multimodal Language Models\", \"x\": 8.576, \"y\": 7.532}, {\"title\": \"Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A  Pilot Study\", \"topic\": \"Multimodal Language Models\", \"x\": 8.384, \"y\": 7.38}, {\"title\": \"Enhancing LLM Factual Accuracy with RAG to Counter Hallucinations: A  Case Study on Domain-Specific Queries in Private Knowledge-Bases\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.151, \"y\": 4.427}, {\"title\": \"EXAMS-V: A Multi-Discipline Multilingual Multimodal Exam Benchmark for  Evaluating Vision Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.833, \"y\": 7.747}, {\"title\": \"TriSum: Learning Summarization Ability from Large Language Models with  Structured Rationale\", \"topic\": \"Text Summarization\", \"x\": 5.066, \"y\": 5.186}, {\"title\": \"Application of GPT Language Models for Innovation in Activities in  University Teaching\", \"topic\": \"Large Language Models in Education\", \"x\": 6.349, \"y\": 2.253}, {\"title\": \"Investigating grammatical abstraction in language models using few-shot  learning of novel noun gender\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 3.456, \"y\": 2.552}, {\"title\": \"Uni-SMART: Universal Science Multimodal Analysis and Research  Transformer\", \"topic\": \"Text Summarization\", \"x\": 5.058, \"y\": 6.012}, {\"title\": \"Large Language Model-informed ECG Dual Attention Network for Heart  Failure Risk Prediction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.157, \"y\": 7.488}, {\"title\": \"Is Translation All You Need? A Study on Solving Multilingual Tasks with  Large Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.966, \"y\": 4.299}, {\"title\": \"A Big Data Approach to Understand Sub-national Determinants of FDI in  Africa\", \"topic\": \"Bias in Language Models\", \"x\": 3.469, \"y\": 4.365}, {\"title\": \"HawkEye: Training Video-Text LLMs for Grounding Text in Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.842, \"y\": 7.407}, {\"title\": \"Read between the lines -- Functionality Extraction From READMEs\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.072, \"y\": 0.091}, {\"title\": \"Can Factual Statements be Deceptive? The DeFaBel Corpus of Belief-based  Deception\", \"topic\": \"Bias in Language Models\", \"x\": 3.682, \"y\": 3.516}, {\"title\": \"NLP Verification: Towards a General Methodology for Certifying  Robustness\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.86, \"y\": 1.23}, {\"title\": \"RAFT: Adapting Language Model to Domain Specific RAG\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.69, \"y\": 4.279}, {\"title\": \"Intent-conditioned and Non-toxic Counterspeech Generation using  Multi-Task Instruction Tuning with RLAIF\", \"topic\": \"Bias in Language Models\", \"x\": 2.498, \"y\": 3.359}, {\"title\": \"DRAGIN: Dynamic Retrieval Augmented Generation based on the Information  Needs of Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.354, \"y\": 4.184}, {\"title\": \"Triple GNNs: Introducing Syntactic and Semantic Information for  Conversational Aspect-Based Quadruple Sentiment Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.05, \"y\": 5.0}, {\"title\": \"Repoformer: Selective Retrieval for Repository-Level Code Completion\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.067, \"y\": 0.083}, {\"title\": \"Ignore Me But Don't Replace Me: Utilizing Non-Linguistic Elements for  Pretraining on the Cybersecurity Domain\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.344, \"y\": 1.355}, {\"title\": \"Exploring Language Model's Code Generation Ability with Auxiliary  Functions\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.213, \"y\": 0.105}, {\"title\": \"Identifying Health Risks from Family History: A Survey of Natural  Language Processing Techniques\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.928, \"y\": 7.143}, {\"title\": \"GET: Unlocking the Multi-modal Potential of CLIP for Generalized  Category Discovery\", \"topic\": \"Multimodal Language Models\", \"x\": 8.347, \"y\": 7.41}, {\"title\": \"Think Twice Before Trusting: Self-Detection for Large Language Models  through Comprehensive Answer Reflection\", \"topic\": \"Large Language Models in Education\", \"x\": 6.356, \"y\": 3.115}, {\"title\": \"Fisher Mask Nodes for Language Model Merging\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.446, \"y\": 2.111}, {\"title\": \"Sabi\\u00e1-2: A New Generation of Portuguese Large Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.164, \"y\": 4.043}, {\"title\": \"FakeWatch: A Framework for Detecting Fake News to Ensure Credible  Elections\", \"topic\": \"Bias in Language Models\", \"x\": 3.381, \"y\": 3.724}, {\"title\": \"Self-Consistency Boosts Calibration for Math Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.595, \"y\": 1.29}, {\"title\": \"Scaling Behavior of Machine Translation with Large Language Models under  Prompt Injection Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.278, \"y\": 0.719}, {\"title\": \"Helpful or Harmful? Exploring the Efficacy of Large Language Models for  Online Grooming Prevention\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.884, \"y\": 1.503}, {\"title\": \"Images are Achilles' Heel of Alignment: Exploiting Visual  Vulnerabilities for Jailbreaking Multimodal Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.015, \"y\": 0.584}, {\"title\": \"Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.216, \"y\": 2.841}, {\"title\": \"Transformers Get Stable: An End-to-End Signal Propagation Theory for  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.605, \"y\": 2.867}, {\"title\": \"Quiet-STaR: Language Models Can Teach Themselves to Think Before  Speaking\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.331, \"y\": 1.955}, {\"title\": \"MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.206, \"y\": 7.347}, {\"title\": \"MoPE: Parameter-Efficient and Scalable Multimodal Fusion via Mixture of  Prompt Experts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.431, \"y\": 7.145}, {\"title\": \"Less is More: Data Value Estimation for Visual Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.207, \"y\": 7.428}, {\"title\": \"Logits of API-Protected LLMs Leak Proprietary Information\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.573, \"y\": 0.547}, {\"title\": \"VisionGPT-3D: A Generalized Multimodal Agent for Enhanced 3D Vision  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.046, \"y\": 7.182}, {\"title\": \"MT-PATCHER: Selective and Extendable Knowledge Distillation from Large  Language Models for Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.704, \"y\": 4.632}, {\"title\": \"Leveraging Prototypical Representations for Mitigating Social Bias  without Demographic Information\", \"topic\": \"Bias in Language Models\", \"x\": 3.171, \"y\": 2.733}, {\"title\": \"Emotional Intelligence Through Artificial Intelligence : NLP and Deep  Learning in the Analysis of Healthcare Texts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.498, \"y\": 6.603}, {\"title\": \"From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward  Fake News\", \"topic\": \"Bias in Language Models\", \"x\": 3.523, \"y\": 3.557}, {\"title\": \"Laying the Foundation First? Investigating the Generalization from  Atomic Skills to Complex Reasoning Tasks\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.599, \"y\": 1.767}, {\"title\": \"Easy-to-Hard Generalization: Scalable Alignment Beyond Human Supervision\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.291, \"y\": 1.373}, {\"title\": \"Komodo: A Linguistic Expedition into Indonesia's Regional Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.078, \"y\": 4.101}, {\"title\": \"More than words: Advancements and challenges in speech recognition for  singing\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.903, \"y\": 5.865}, {\"title\": \"Incorporating Graph Attention Mechanism into Geometric Problem Solving  Based on Deep Reinforcement Learning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.625, \"y\": 1.282}, {\"title\": \"Methods for Matching English Language Addresses\", \"topic\": \"Named Entity Recognition\", \"x\": 6.241, \"y\": 6.478}, {\"title\": \"Retrieval augmented text-to-SQL generation for epidemiological question  answering using electronic health records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.298, \"y\": 7.356}, {\"title\": \"What Was Your Prompt? A Remote Keylogging Attack on AI Assistants\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.361, \"y\": 0.638}, {\"title\": \"Exploring the Comprehension of ChatGPT in Traditional Chinese Medicine  Knowledge\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.886, \"y\": 7.308}, {\"title\": \"Caveat Lector: Large Language Models in Legal Practice\", \"topic\": \"Legal NLP\", \"x\": 4.391, \"y\": 4.422}, {\"title\": \"Unveiling the Generalization Power of Fine-Tuned Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.872, \"y\": 2.488}, {\"title\": \"Basque and Spanish Counter Narrative Generation: Data Creation and  Evaluation\", \"topic\": \"Bias in Language Models\", \"x\": 2.537, \"y\": 3.346}, {\"title\": \"Evaluating LLMs for Gender Disparities in Notable Persons\", \"topic\": \"Bias in Language Models\", \"x\": 3.382, \"y\": 2.649}, {\"title\": \"Meta-Cognitive Analysis: Evaluating Declarative and Procedural Knowledge  in Datasets and Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.552, \"y\": 2.318}, {\"title\": \"AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based  on Meta Learning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.821, \"y\": 1.701}, {\"title\": \"AI on AI: Exploring the Utility of GPT as an Expert Annotator of AI  Publications\", \"topic\": \"Text Summarization\", \"x\": 5.001, \"y\": 5.957}, {\"title\": \"MCFEND: A Multi-source Benchmark Dataset for Chinese Fake News Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.446, \"y\": 3.735}, {\"title\": \"Meaningful Learning: Advancing Abstract Reasoning in Large Language  Models via Generic Fact Guidance\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.37, \"y\": 2.04}, {\"title\": \"Information Extraction: An application to the domain of hyper-local  financial data on developing countries\", \"topic\": \"Named Entity Recognition\", \"x\": 6.099, \"y\": 6.736}, {\"title\": \"Large Language Models are Parallel Multilingual Learners\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.272, \"y\": 3.809}, {\"title\": \"UniCode: Learning a Unified Codebook for Multimodal Large Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.288, \"y\": 7.246}, {\"title\": \"A Continued Pretrained LLM Approach for Automatic Medical Note  Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.155, \"y\": 7.422}, {\"title\": \"Keyformer: KV Cache Reduction through Key Tokens Selection for Efficient  Generative Inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.147, \"y\": 3.004}, {\"title\": \"RAGGED: Towards Informed Design of Retrieval Augmented Generation  Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.343, \"y\": 4.455}, {\"title\": \"The First to Know: How Token Distributions Reveal Hidden Knowledge in  Large Vision-Language Models?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.174, \"y\": 7.917}, {\"title\": \"CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language  Models to Coding Preferences\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.923, \"y\": 0.123}, {\"title\": \"ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.415, \"y\": 7.387}, {\"title\": \"Re-Search for The Truth: Multi-round Retrieval-augmented Large Language  Models are Strong Fake News Detectors\", \"topic\": \"Bias in Language Models\", \"x\": 3.727, \"y\": 3.844}, {\"title\": \"Ethos: Rectifying Language Models in Orthogonal Parameter Space\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.991, \"y\": 0.635}, {\"title\": \"AutoGuide: Automated Generation and Selection of State-Aware Guidelines  for Large Language Model Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.267, \"y\": 1.54}, {\"title\": \"Second-Order Information Matters: Revisiting Machine Unlearning for  Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.931, \"y\": 0.505}, {\"title\": \"From \\\"um\\\" to \\\"yeah\\\": Producing, predicting, and regulating information  flow in human conversation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.222, \"y\": 2.999}, {\"title\": \"Simple and Scalable Strategies to Continually Pre-train Large Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.19, \"y\": 2.384}, {\"title\": \"DAM: Dynamic Adapter Merging for Continual Video QA Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.827, \"y\": 7.544}, {\"title\": \"Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing  Framework\", \"topic\": \"Bias in Language Models\", \"x\": 3.402, \"y\": 2.744}, {\"title\": \"Improving Acoustic Word Embeddings through Correspondence Training of  Self-supervised Speech Representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.577, \"y\": 5.82}, {\"title\": \"ILCiteR: Evidence-grounded Interpretable Local Citation Recommendation\", \"topic\": \"Text Summarization\", \"x\": 5.054, \"y\": 5.846}, {\"title\": \"Strengthening Multimodal Large Language Model with Bootstrapped  Preference Optimization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.378, \"y\": 7.321}, {\"title\": \"Zero-shot and Few-shot Generation Strategies for Artificial Clinical  Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.103, \"y\": 7.429}, {\"title\": \"Distilling Named Entity Recognition Models for Endangered Species from  Large Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.077, \"y\": 6.799}, {\"title\": \"MedInsight: A Multi-Source Context Augmentation Framework for Generating  Patient-Centric Medical Responses using Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.692, \"y\": 7.075}, {\"title\": \"DevBench: A Comprehensive Benchmark for Software Development\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.139, \"y\": 0.099}, {\"title\": \"Non-discrimination Criteria for Generative Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.14, \"y\": 2.686}, {\"title\": \"Automatic Interactive Evaluation for Large Language Models with State  Aware Patient Simulator\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.812, \"y\": 7.365}, {\"title\": \"Data-oriented Dynamic Fine-tuning Parameter Selection Strategy for FISH  Mask based Efficient Fine-tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.631, \"y\": 2.035}, {\"title\": \"Tastle: Distract Large Language Models for Automatic Jailbreak Attack\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.024, \"y\": 0.473}, {\"title\": \"Misinformation is not about Bad Facts: An Analysis of the Production and  Consumption of Fringe Content\", \"topic\": \"Bias in Language Models\", \"x\": 3.356, \"y\": 3.69}, {\"title\": \"Learning to Describe for Predicting Zero-shot Drug-Drug Interactions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.53, \"y\": 6.911}, {\"title\": \"Log Summarisation for Defect Evolution Analysis\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.69, \"y\": 0.348}, {\"title\": \"Is Context Helpful for Chat Translation Evaluation?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.541, \"y\": 4.872}, {\"title\": \"Towards Personalized Evaluation of Large Language Models with An  Anonymous Crowd-Sourcing Platform\", \"topic\": \"Large Language Models in Education\", \"x\": 6.116, \"y\": 3.014}, {\"title\": \"A Moral Imperative: The Need for Continual Superalignment of Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.116, \"y\": 2.113}, {\"title\": \"Skipformer: A Skip-and-Recover Strategy for Efficient Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.548, \"y\": 5.568}, {\"title\": \"Research on the Application of Deep Learning-based BERT Model in  Sentiment Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.203, \"y\": 5.087}, {\"title\": \"Large Language Models are Contrastive Reasoners\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.396, \"y\": 2.048}, {\"title\": \"SpeechColab Leaderboard: An Open-Source Platform for Automatic Speech  Recognition Evaluation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.545, \"y\": 5.754}, {\"title\": \"Embedded Translations for Low-resource Automated Glossing\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.376, \"y\": 4.47}, {\"title\": \"Automatic Speech Recognition (ASR) for the Diagnosis of pronunciation of  Speech Sound Disorders in Korean children\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.465, \"y\": 5.978}, {\"title\": \"BAGEL: Bootstrapping Agents by Guiding Exploration with Language\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.193, \"y\": 1.501}, {\"title\": \"Legally Binding but Unfair? Towards Assessing Fairness of Privacy  Policies\", \"topic\": \"Legal NLP\", \"x\": 3.866, \"y\": 2.157}, {\"title\": \"Simulating Weighted Automata over Sequences and Trees with Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.347, \"y\": 2.855}, {\"title\": \"Mechanics of Next Token Prediction with Self-Attention\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.166, \"y\": 3.156}, {\"title\": \"Investigating the performance of Retrieval-Augmented Generation and  fine-tuning for the development of AI-driven knowledge-based systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.251, \"y\": 4.255}, {\"title\": \"CHAI: Clustered Head Attention for Efficient LLM Inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.197, \"y\": 2.867}, {\"title\": \"Generating Clarification Questions for Disambiguating Contracts\", \"topic\": \"Legal NLP\", \"x\": 4.532, \"y\": 4.428}, {\"title\": \"Big City Bias: Evaluating the Impact of Metropolitan Size on  Computational Job Market Abilities of Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.23, \"y\": 2.876}, {\"title\": \"Harnessing Artificial Intelligence to Combat Online Hate: Exploring the  Challenges and Opportunities of Large Language Models in Hate Speech  Detection\", \"topic\": \"Bias in Language Models\", \"x\": 2.469, \"y\": 3.383}, {\"title\": \"Gujarati-English Code-Switching Speech Recognition using ensemble  prediction of spoken language\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.453, \"y\": 5.665}, {\"title\": \"Pix2Pix-OnTheFly: Leveraging LLMs for Instruction-Guided Image Editing\", \"topic\": \"Multimodal Language Models\", \"x\": 8.233, \"y\": 7.078}, {\"title\": \"Towards a clinically accessible radiology foundation model: open-access  and lightweight, with automated evaluation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.336, \"y\": 8.124}, {\"title\": \"LiveCodeBench: Holistic and Contamination Free Evaluation of Large  Language Models for Code\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.108, \"y\": 0.11}, {\"title\": \"CodeAttack: Revealing Safety Generalization Challenges of Large Language  Models via Code Completion\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 6.509, \"y\": 0.312}, {\"title\": \"RAD-PHI2: Instruction Tuning PHI-2 for Radiology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.079, \"y\": 7.81}, {\"title\": \"ClaimVer: Explainable Claim-Level Verification and Evidence Attribution  of Text Through Knowledge Graphs\", \"topic\": \"Bias in Language Models\", \"x\": 3.84, \"y\": 3.818}, {\"title\": \"Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.82, \"y\": 2.161}, {\"title\": \"Transforming Competition into Collaboration: The Revolutionary Role of  Multi-Agent Systems and Language Models in Modern Organizations\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.645, \"y\": 1.819}, {\"title\": \"FineMath: A Fine-Grained Mathematical Evaluation Benchmark for Chinese  Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.678, \"y\": 1.225}, {\"title\": \"Improving Reinforcement Learning from Human Feedback Using Contrastive  Rewards\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.55, \"y\": 0.681}, {\"title\": \"ORPO: Monolithic Preference Optimization without Reference Model\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.704, \"y\": 0.459}, {\"title\": \"SATDAUG -- A Balanced and Augmented Dataset for Detecting Self-Admitted  Technical Debt\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.966, \"y\": 0.125}, {\"title\": \"Annotations on a Budget: Leveraging Geo-Data Similarity to Balance Model  Performance and Annotation Cost\", \"topic\": \"Multimodal Language Models\", \"x\": 8.291, \"y\": 7.722}, {\"title\": \"MoralBERT: Detecting Moral Values in Social Discourse\", \"topic\": \"Bias in Language Models\", \"x\": 3.283, \"y\": 3.35}, {\"title\": \"Harder Tasks Need More Experts: Dynamic Routing in MoE Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.691, \"y\": 2.19}, {\"title\": \"Triples-to-isiXhosa (T2X): Addressing the Challenges of Low-Resource  Agglutinative Data-to-Text Generation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.108, \"y\": 4.162}, {\"title\": \"SIFiD: Reassess Summary Factual Inconsistency Detection with LLM\", \"topic\": \"Text Summarization\", \"x\": 5.09, \"y\": 4.865}, {\"title\": \"MAMMOTH: Massively Multilingual Modular Open Translation @ Helsinki\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.728, \"y\": 4.582}, {\"title\": \"Enhancing Readmission Prediction with Deep Learning: Extracting  Biomedical Concepts from Clinical Texts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.063, \"y\": 7.374}, {\"title\": \"Fine-tuning vs Prompting, Can Language Models Understand Human Values?\", \"topic\": \"Bias in Language Models\", \"x\": 4.239, \"y\": 2.246}, {\"title\": \"Mevaker: Conclusion Extraction and Allocation Resources for the Hebrew  Language\", \"topic\": \"Text Summarization\", \"x\": 5.231, \"y\": 5.022}, {\"title\": \"SmallToLarge (S2L): Scalable Data Selection for Fine-tuning Large  Language Models by Summarizing Training Trajectories of Small Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.193, \"y\": 2.239}, {\"title\": \"Hallmarks of Optimization Trajectories in Neural Networks: Directional  Exploration and Redundancy\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.416, \"y\": 2.644}, {\"title\": \"SVD-LLM: Truncation-aware Singular Value Decomposition for Large  Language Model Compression\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.284, \"y\": 2.284}, {\"title\": \"IM-Unpack: Training and Inference with Arbitrarily Low Precision  Integers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.249, \"y\": 2.397}, {\"title\": \"Knowledge Graph Large Language Model (KG-LLM) for Link Prediction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.62, \"y\": 5.866}, {\"title\": \"A Framework for Cost-Effective and Self-Adaptive LLM Shaking and  Recovery Mechanism\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.799, \"y\": 0.174}, {\"title\": \"CKERC : Joint Large Language Models with Commonsense Knowledge for  Emotion Recognition in Conversation\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.59, \"y\": 5.423}, {\"title\": \"Curry-DPO: Enhancing Alignment using Curriculum Learning & Ranked  Preferences\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.457, \"y\": 0.495}, {\"title\": \"TMU at TREC Clinical Trials Track 2023\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.222, \"y\": 7.032}, {\"title\": \"$\\\\mathbf{(N,K)}$-Puzzle: A Cost-Efficient Testbed for Benchmarking  Reinforcement Learning Algorithms in Generative Language Model\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.708, \"y\": 0.701}, {\"title\": \"Monitoring AI-Modified Content at Scale: A Case Study on the Impact of  ChatGPT on AI Conference Peer Reviews\", \"topic\": \"Text Summarization\", \"x\": 4.89, \"y\": 5.87}, {\"title\": \"Textual analysis of End User License Agreement for red-flagging  potentially malicious software\", \"topic\": \"Legal NLP\", \"x\": 4.442, \"y\": 4.515}, {\"title\": \"Thought Graph: Generating Thought Process for Biological Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.765, \"y\": 6.98}, {\"title\": \"One Category One Prompt: Dataset Distillation using Diffusion Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.588, \"y\": 6.679}, {\"title\": \"SPA: Towards A Computational Friendly Cloud-Base and On-Devices  Collaboration Seq2seq Personalized Generation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.151, \"y\": 2.725}, {\"title\": \"SMART: Automatically Scaling Down Language Models with Accuracy  Guarantees for Reduced Processing Fees\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.831, \"y\": 2.774}, {\"title\": \"SELMA: Learning and Merging Skill-Specific Text-to-Image Experts with  Auto-Generated Data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.474, \"y\": 7.008}, {\"title\": \"Counterfactual Reasoning with Knowledge Graph Embeddings\", \"topic\": \"Named Entity Recognition\", \"x\": 6.633, \"y\": 5.604}, {\"title\": \"Naming, Describing, and Quantifying Visual Objects in Humans and LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.23, \"y\": 7.836}, {\"title\": \"Simplicity Bias of Transformers to Learn Low Sensitivity Functions\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.393, \"y\": 2.746}, {\"title\": \"Linguistic Structure Induction from Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.709, \"y\": 3.205}, {\"title\": \"Exploring Large Language Models and Hierarchical Frameworks for  Classification of Large Unstructured Legal Documents\", \"topic\": \"Legal NLP\", \"x\": 4.401, \"y\": 4.573}, {\"title\": \"Learning with Noisy Foundation Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.104, \"y\": 2.471}, {\"title\": \"Development of a Reliable and Accessible Caregiving Language Model  (CaLM)\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.715, \"y\": 7.087}, {\"title\": \"RA-ISF: Learning to Answer and Understand from Retrieval Augmentation  via Iterative Self-Feedback\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.369, \"y\": 4.289}, {\"title\": \"Medical Image Synthesis via Fine-Grained Image-Text Alignment and  Anatomy-Pathology Prompting\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.231, \"y\": 8.099}, {\"title\": \"Can LLMs Separate Instructions From Data? And What Do We Even Mean By  That?\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.869, \"y\": 0.271}, {\"title\": \"The Power of Noise: Toward a Unified Multi-modal Knowledge Graph  Representation Framework\", \"topic\": \"Named Entity Recognition\", \"x\": 6.766, \"y\": 6.014}, {\"title\": \"The evaluation of a code-switched Sepedi-English automatic speech  recognition system\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.484, \"y\": 5.698}, {\"title\": \"SPLADE-v3: New baselines for SPLADE\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.235, \"y\": 4.804}, {\"title\": \"Strength Lies in Differences! Towards Effective Non-collaborative  Dialogues via Tailored Strategy Planning\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.269, \"y\": 2.703}, {\"title\": \"ConspEmoLLM: Conspiracy Theory Detection Using an Emotion-Based Large  Language Model\", \"topic\": \"Bias in Language Models\", \"x\": 3.501, \"y\": 3.882}, {\"title\": \"An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference  Acceleration for Large Vision-Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.215, \"y\": 2.929}, {\"title\": \"ALaRM: Align Language Models via Hierarchical Rewards Modeling\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.557, \"y\": 0.788}, {\"title\": \"ACT-MNMT Auto-Constriction Turning for Multilingual Neural Machine  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.84, \"y\": 4.563}, {\"title\": \"Real-Time Multimodal Cognitive Assistant for Emergency Medical Services\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.885, \"y\": 7.518}, {\"title\": \"Improving Low-Resource Knowledge Tracing Tasks by Supervised  Pre-training and Importance Mechanism Fine-tuning\", \"topic\": \"Large Language Models in Education\", \"x\": 6.704, \"y\": 2.238}, {\"title\": \"Restoring Ancient Ideograph: A Multimodal Multitask Neural Network  Approach\", \"topic\": \"Multimodal Language Models\", \"x\": 8.246, \"y\": 6.897}, {\"title\": \"MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway  Encoding\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.89, \"y\": 7.324}, {\"title\": \"Guiding Clinical Reasoning with Large Language Models via Knowledge  Seeds\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.878, \"y\": 7.274}, {\"title\": \"Improving Speaker Assignment in Speaker-Attributed ASR for Real Meeting  Applications\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.517, \"y\": 5.899}, {\"title\": \"Unraveling the Mystery of Scaling Laws: Part I\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.562, \"y\": 2.551}, {\"title\": \"From English to ASIC: Hardware Implementation with Large Language Model\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.257, \"y\": 0.384}, {\"title\": \"How to Understand Named Entities: Using Common Sense for News Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.827, \"y\": 7.112}, {\"title\": \"Automatic Generation of Python Programs Using Context-Free Grammars\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.134, \"y\": 0.116}, {\"title\": \"Multilingual Turn-taking Prediction Using Voice Activity Projection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.926, \"y\": 5.666}, {\"title\": \"Prompt Selection and Augmentation for Few Examples Code Generation in  Large Language Model and its Application in Robotics Control\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.521, \"y\": 1.155}, {\"title\": \"CLIcK: A Benchmark Dataset of Cultural and Linguistic Intelligence in  Korean\", \"topic\": \"Bias in Language Models\", \"x\": 4.288, \"y\": 2.733}, {\"title\": \"GlossLM: Multilingual Pretraining for Low-Resource Interlinear Glossing\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.07, \"y\": 4.449}, {\"title\": \"Multi-modal Semantic Understanding with Contrastive Cross-modal Feature  Alignment\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.594, \"y\": 5.016}, {\"title\": \"Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages\", \"topic\": \"Multimodal Language Models\", \"x\": 8.72, \"y\": 6.916}, {\"title\": \"From Instructions to Constraints: Language Model Alignment with  Automatic Constraint Verification\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.627, \"y\": 0.863}, {\"title\": \"Transformer based Multitask Learning for Image Captioning and Object  Detection\", \"topic\": \"Multimodal Language Models\", \"x\": 8.555, \"y\": 7.418}, {\"title\": \"SCORE: Self-supervised Correspondence Fine-tuning for Improved Content  Representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.571, \"y\": 5.878}, {\"title\": \"TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned  Decision\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.268, \"y\": 1.424}, {\"title\": \"Mipha: A Comprehensive Overhaul of Multimodal Assistant with Small  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.157, \"y\": 7.388}, {\"title\": \"Large Language Models on Fine-grained Emotion Detection Dataset with  Data Augmentation and Transfer Learning\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.653, \"y\": 5.284}, {\"title\": \"Automatic design optimization of preference-based subjective evaluation  with online learning in crowdsourcing environment\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.584, \"y\": 6.112}, {\"title\": \"VidProM: A Million-scale Real Prompt-Gallery Dataset for Text-to-Video  Diffusion Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.597, \"y\": 6.837}, {\"title\": \"Can LLM Substitute Human Labeling? A Case Study of Fine-grained Chinese  Address Entity Recognition Dataset for UAV Delivery\", \"topic\": \"Named Entity Recognition\", \"x\": 6.133, \"y\": 6.834}, {\"title\": \"FrameQuant: Flexible Low-Bit Quantization for Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.3, \"y\": 2.434}, {\"title\": \"Target-constrained Bidirectional Planning for Generation of  Target-oriented Proactive Dialogue\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.249, \"y\": 3.324}, {\"title\": \"Ensemble Language Models for Multilingual Sentiment Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.922, \"y\": 4.728}, {\"title\": \"Understanding Social Perception, Interactions, and Safety Aspects of  Sidewalk Delivery Robots Using Sentiment Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.236, \"y\": 4.87}, {\"title\": \"Exploratory Data Analysis on Code-mixed Misogynistic Comments\", \"topic\": \"Bias in Language Models\", \"x\": 2.552, \"y\": 3.475}, {\"title\": \"Persian Slang Text Conversion to Formal and Deep Learning of Persian  Short Texts on Social Media for Sentiment Classification\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.046, \"y\": 4.817}, {\"title\": \"Few-Shot Cross-Lingual Transfer for Prompting Large Language Models in  Low-Resource Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.238, \"y\": 4.165}, {\"title\": \"Institutional-Level Monitoring of Immune Checkpoint Inhibitor IrAEs  Using a Novel Natural Language Processing Algorithmic Pipeline\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.155, \"y\": 7.119}, {\"title\": \"Enhanced Auto Language Prediction with Dictionary Capsule -- A Novel  Approach\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.431, \"y\": 4.475}, {\"title\": \"Measuring Bias in a Ranked List using Term-based Representations\", \"topic\": \"Bias in Language Models\", \"x\": 3.281, \"y\": 2.912}, {\"title\": \"Calibrating Large Language Models Using Their Generations Only\", \"topic\": \"Large Language Models in Education\", \"x\": 6.437, \"y\": 3.174}, {\"title\": \"Thread Detection and Response Generation using Transformers with Prompt  Optimisation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.247, \"y\": 3.111}, {\"title\": \"High Throughput Phenotyping of Physician Notes with Large Language and  Hybrid NLP Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.196, \"y\": 7.363}, {\"title\": \"KG-Rank: Enhancing Large Language Models for Medical QA with Knowledge  Graphs and Ranking Techniques\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.916, \"y\": 7.226}, {\"title\": \"Diffusion Lens: Interpreting Text Encoders in Text-to-Image Pipelines\", \"topic\": \"Multimodal Language Models\", \"x\": 8.593, \"y\": 6.811}, {\"title\": \"An Audio-textual Diffusion Model For Converting Speech Signals Into  Ultrasound Tongue Imaging Data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.239, \"y\": 6.102}, {\"title\": \"MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging  Knowledge Graphs\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.159, \"y\": 3.465}, {\"title\": \"UniSparse: An Intermediate Language for General Sparse Format  Customization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.391, \"y\": 2.398}, {\"title\": \"ClinicalMamba: A Generative Clinical Language Model on Longitudinal  Clinical Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.24, \"y\": 7.353}, {\"title\": \"ItD: Large Language Models Can Teach Themselves Induction through  Deduction\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.206, \"y\": 2.396}, {\"title\": \"On the Benefits of Fine-Grained Loss Truncation: A Case Study on  Factuality in Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.196, \"y\": 5.076}, {\"title\": \"FLAP: Flow-Adhering Planning with Constrained Decoding in LLMs\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.237, \"y\": 1.488}, {\"title\": \"A Novel Nuanced Conversation Evaluation Framework for Large Language  Models in Mental Health\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.013, \"y\": 6.393}, {\"title\": \"A Benchmark of Domain-Adapted Large Language Models for Generating Brief  Hospital Course Summaries\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.17, \"y\": 7.217}, {\"title\": \"SeeGULL Multilingual: a Dataset of Geo-Culturally Situated Stereotypes\", \"topic\": \"Bias in Language Models\", \"x\": 3.291, \"y\": 2.675}, {\"title\": \"PipeRAG: Fast Retrieval-Augmented Generation via Algorithm-System  Co-design\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.294, \"y\": 4.399}, {\"title\": \"Generating Hard-Negative Out-of-Scope Data with ChatGPT for Intent  Classification\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.358, \"y\": 3.48}, {\"title\": \"Tell, Don't Show!: Language Guidance Eases Transfer Across Domains in  Images and Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.575, \"y\": 7.423}, {\"title\": \"Bayesian Preference Elicitation with Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.494, \"y\": 1.041}, {\"title\": \"Gemini 1.5: Unlocking multimodal understanding across millions of tokens  of context\", \"topic\": \"Multimodal Language Models\", \"x\": 8.223, \"y\": 7.385}, {\"title\": \"GEAR: An Efficient KV Cache Compression Recipe for Near-Lossless  Generative Inference of LLM\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.491, \"y\": 2.655}, {\"title\": \"Bias-Augmented Consistency Training Reduces Biased Reasoning in  Chain-of-Thought\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.111, \"y\": 2.323}, {\"title\": \"Unfamiliar Finetuning Examples Control How Language Models Hallucinate\", \"topic\": \"Large Language Models in Education\", \"x\": 6.255, \"y\": 3.252}, {\"title\": \"FFSTC: Fongbe to French Speech Translation Corpus\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.059, \"y\": 5.566}, {\"title\": \"Will GPT-4 Run DOOM?\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.842, \"y\": 1.561}, {\"title\": \"Cost-Performance Optimization for Processing Low-Resource Language Tasks  Using Commercial LLMs\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.207, \"y\": 3.754}, {\"title\": \"The Impact of Quantization on the Robustness of Transformer-based Text  Classifiers\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.055, \"y\": 1.159}, {\"title\": \"ChatASU: Evoking LLM's Reflexion to Truly Understand Aspect Sentiment in  Dialogues\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.09, \"y\": 4.803}, {\"title\": \"RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in  Long-Horizon Generation\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.406, \"y\": 1.719}, {\"title\": \"ACLSum: A New Dataset for Aspect-based Summarization of Scientific  Publications\", \"topic\": \"Text Summarization\", \"x\": 5.052, \"y\": 5.316}, {\"title\": \"PEEB: Part-based Image Classifiers with an Explainable and Editable  Language Bottleneck\", \"topic\": \"Multimodal Language Models\", \"x\": 8.212, \"y\": 7.667}, {\"title\": \"LLM4Decompile: Decompiling Binary Code with Large Language Models\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.227, \"y\": 0.109}, {\"title\": \"Deep Prompt Multi-task Network for Abuse Language Detection\", \"topic\": \"Bias in Language Models\", \"x\": 2.485, \"y\": 3.336}, {\"title\": \"Harnessing Multi-Role Capabilities of Large Language Models for  Open-Domain Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.446, \"y\": 4.587}, {\"title\": \"CommitBench: A Benchmark for Commit Message Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.999, \"y\": 0.068}, {\"title\": \"ROUGE-K: Do Your Summaries Have Keywords?\", \"topic\": \"Text Summarization\", \"x\": 5.147, \"y\": 5.166}, {\"title\": \"Speech Robust Bench: A Robustness Benchmark For Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.636, \"y\": 5.752}, {\"title\": \"ChatUIE: Exploring Chat-based Unified Information Extraction using Large  Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.291, \"y\": 6.405}, {\"title\": \"A Concept-based Interpretable Model for the Diagnosis of Choroid  Neoplasias using Multimodal Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.324, \"y\": 8.09}, {\"title\": \"Rule-driven News Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.478, \"y\": 7.167}, {\"title\": \"Are Human Conversations Special? A Large Language Model Perspective\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.484, \"y\": 3.13}, {\"title\": \"Towards Multimodal Sentiment Analysis Debiasing via Bias Purification\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.554, \"y\": 5.051}, {\"title\": \"DiffChat: Learning to Chat with Text-to-Image Synthesis Models for  Interactive Image Creation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.424, \"y\": 6.799}, {\"title\": \"SecGPT: An Execution Isolation Architecture for LLM-Based Systems\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.357, \"y\": 0.43}, {\"title\": \"MEIT: Multi-Modal Electrocardiogram Instruction Tuning on Large Language  Models for Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.141, \"y\": 7.746}, {\"title\": \"Few shot chain-of-thought driven reasoning to prompt LLMs for open ended  medical question answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.845, \"y\": 7.263}, {\"title\": \"Code-Mixed Probes Show How Pre-Trained Models Generalise On  Code-Switched Text\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.172, \"y\": 4.613}, {\"title\": \"Evaluating Biases in Context-Dependent Health Questions\", \"topic\": \"Bias in Language Models\", \"x\": 3.351, \"y\": 2.893}, {\"title\": \"How Far Are We from Intelligent Visual Deductive Reasoning?\", \"topic\": \"Multimodal Language Models\", \"x\": 7.81, \"y\": 7.756}, {\"title\": \"Common 7B Language Models Already Possess Strong Math Capabilities\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.803, \"y\": 1.321}, {\"title\": \"Greater than the sum of its parts: The role of minority and majority  status in collaborative problem-solving communication\", \"topic\": \"Bias in Language Models\", \"x\": 3.524, \"y\": 2.762}, {\"title\": \"Chain of Thought Explanation for Dialogue State Tracking\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.194, \"y\": 3.172}, {\"title\": \"QAQ: Quality Adaptive Quantization for LLM KV Cache\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.403, \"y\": 2.814}, {\"title\": \"MaCmS: Magahi Code-mixed Dataset for Sentiment Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.81, \"y\": 4.717}, {\"title\": \"MedFLIP: Medical Vision-and-Language Self-supervised Fast Pre-Training  with Masked Autoencoder\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.452, \"y\": 8.161}, {\"title\": \"Strong Priority and Determinacy in Timed CCS\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.722, \"y\": 2.914}, {\"title\": \"Uncertainty-Aware Relational Graph Neural Network for Few-Shot Knowledge  Graph Completion\", \"topic\": \"Named Entity Recognition\", \"x\": 6.666, \"y\": 5.883}, {\"title\": \"Where does In-context Translation Happen in Large Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.68, \"y\": 4.395}, {\"title\": \"GraphInstruct: Empowering Large Language Models with Graph Understanding  and Reasoning Capability\", \"topic\": \"Named Entity Recognition\", \"x\": 6.591, \"y\": 5.822}, {\"title\": \"Low-Resource Court Judgment Summarization for Common Law Systems\", \"topic\": \"Legal NLP\", \"x\": 4.543, \"y\": 4.738}, {\"title\": \"Membership Inference Attacks and Privacy in Topic Modeling\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.828, \"y\": 0.179}, {\"title\": \"Classist Tools: Social Class Correlates with Performance in NLP\", \"topic\": \"Bias in Language Models\", \"x\": 3.28, \"y\": 2.754}, {\"title\": \"Presenting Terrorizer: an algorithm for consolidating company names in  patent assignees\", \"topic\": \"Legal NLP\", \"x\": 4.69, \"y\": 4.911}, {\"title\": \"From Graph to Word Bag: Introducing Domain Knowledge to Confusing Charge  Prediction\", \"topic\": \"Legal NLP\", \"x\": 4.395, \"y\": 4.562}, {\"title\": \"ProMoAI: Process Modeling with Generative AI\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.078, \"y\": 1.944}, {\"title\": \"Discriminative Probing and Tuning for Text-to-Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.477, \"y\": 6.9}, {\"title\": \"Can Your Model Tell a Negation from an Implicature? Unravelling  Challenges With Intent Encoders\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.552, \"y\": 3.567}, {\"title\": \"ALTO: An Efficient Network Orchestrator for Compound AI Systems\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.278, \"y\": 1.626}, {\"title\": \"Proxy-RLHF: Decoupling Generation and Alignment in Large Language Model  with Proxy\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.657, \"y\": 0.59}, {\"title\": \"A New Benchmark for Evaluating Automatic Speech Recognition in the  Arabic Call Domain\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.391, \"y\": 5.618}, {\"title\": \"Advancing Biomedical Text Mining with Community Challenges\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.321, \"y\": 7.148}, {\"title\": \"Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.154, \"y\": 0.047}, {\"title\": \"Aligners: Decoupling LLMs and Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.909, \"y\": 0.891}, {\"title\": \"Self-Evaluation of Large Language Model based on Glass-box Features\", \"topic\": \"Large Language Models in Education\", \"x\": 6.773, \"y\": 3.089}, {\"title\": \"On the Essence and Prospect: An Investigation of Alignment Approaches  for Big Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.164, \"y\": 1.009}, {\"title\": \"Attempt Towards Stress Transfer in Speech-to-Speech Machine Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.186, \"y\": 5.629}, {\"title\": \"DA-Net: A Disentangled and Adaptive Network for Multi-Source  Cross-Lingual Transfer Learning\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.471, \"y\": 4.3}, {\"title\": \"Can Large Language Models Reason and Plan?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.135, \"y\": 2.207}, {\"title\": \"Levels of AI Agents: from Rules to Large Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.762, \"y\": 1.549}, {\"title\": \"Semi-Supervised Dialogue Abstractive Summarization via High-Quality  Pseudolabel Selection\", \"topic\": \"Text Summarization\", \"x\": 5.14, \"y\": 5.07}, {\"title\": \"Quantifying Contamination in Evaluating Code Generation Capabilities of  Language Models\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.204, \"y\": 0.123}, {\"title\": \"Media Bias Matters: Understanding the Impact of Politically Biased News  on Vaccine Attitudes in Social Media\", \"topic\": \"Bias in Language Models\", \"x\": 3.325, \"y\": 4.189}, {\"title\": \"Backtracing: Retrieving the Cause of the Query\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.01, \"y\": 4.583}, {\"title\": \"Did Translation Models Get More Robust Without Anyone Even Noticing?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.59, \"y\": 4.702}, {\"title\": \"Enhancing Instructional Quality: Leveraging Computer-Assisted Textual  Analysis to Generate In-Depth Insights from Educational Artifacts\", \"topic\": \"Large Language Models in Education\", \"x\": 6.143, \"y\": 2.39}, {\"title\": \"A Measure for Transparent Comparison of Linguistic Diversity in  Multilingual NLP Data Sets\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.79, \"y\": 4.32}, {\"title\": \"IRCoder: Intermediate Representations Make Language Models Robust  Multilingual Code Generators\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.141, \"y\": 0.086}, {\"title\": \"From One to Many: Expanding the Scope of Toxicity Mitigation in Language  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.858, \"y\": 1.395}, {\"title\": \"SaulLM-7B: A pioneering Large Language Model for Law\", \"topic\": \"Legal NLP\", \"x\": 4.431, \"y\": 4.562}, {\"title\": \"Impoverished Language Technology: The Lack of (Social) Class in NLP\", \"topic\": \"Bias in Language Models\", \"x\": 3.269, \"y\": 2.754}, {\"title\": \"On the Origins of Linear Representations in Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.601, \"y\": 3.074}, {\"title\": \"ShortGPT: Layers in Large Language Models are More Redundant Than You  Expect\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.083, \"y\": 2.424}, {\"title\": \"The Boy Who Survived: Removing Harry Potter from an LLM is harder than  reported\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.064, \"y\": 0.794}, {\"title\": \"A Modular Approach for Multimodal Summarization of TV Shows\", \"topic\": \"Text Summarization\", \"x\": 5.29, \"y\": 5.257}, {\"title\": \"German also Hallucinates! Inconsistency Detection in News Summaries with  the Absinth Dataset\", \"topic\": \"Text Summarization\", \"x\": 5.241, \"y\": 4.878}, {\"title\": \"General2Specialized LLMs Translation for E-commerce\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.671, \"y\": 4.577}, {\"title\": \"Apollo: A Lightweight Multilingual Medical LLM towards Democratizing  Medical AI to 6B People\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.067, \"y\": 7.431}, {\"title\": \"Multimodal Large Language Models to Support Real-World Fact-Checking\", \"topic\": \"Bias in Language Models\", \"x\": 3.765, \"y\": 3.797}, {\"title\": \"Design of an Open-Source Architecture for Neural Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.733, \"y\": 4.508}, {\"title\": \"Enhancing ASD detection accuracy: a combined approach of machine  learning and deep learning models with natural language processing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.573, \"y\": 6.583}, {\"title\": \"gaHealth: An English-Irish Bilingual Corpus of Health Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.246, \"y\": 7.203}, {\"title\": \"Benchmarking Hallucination in Large Language Models based on  Unanswerable Math Word Problem\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.591, \"y\": 1.259}, {\"title\": \"Non-verbal information in spontaneous speech -- towards a new framework  of analysis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.327, \"y\": 5.883}, {\"title\": \"BiVert: Bidirectional Vocabulary Evaluation using Relations for Machine  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.532, \"y\": 4.995}, {\"title\": \"A Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.315, \"y\": 3.5}, {\"title\": \"Magic Markup: Maintaining Document-External Markup with an LLM\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.873, \"y\": 0.33}, {\"title\": \"VLSP 2023 -- LTER: A Summary of the Challenge on Legal Textual  Entailment Recognition\", \"topic\": \"Legal NLP\", \"x\": 4.426, \"y\": 4.506}, {\"title\": \"Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.45, \"y\": 1.932}, {\"title\": \"Negating Negatives: Alignment without Human Positive Samples via  Distributional Dispreference Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.388, \"y\": 0.628}, {\"title\": \"Japanese-English Sentence Translation Exercises Dataset for Automatic  Grading\", \"topic\": \"Large Language Models in Education\", \"x\": 6.786, \"y\": 3.03}, {\"title\": \"AttentionStitch: How Attention Solves the Speech Editing Problem\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.948, \"y\": 6.038}, {\"title\": \"DIVERSE: Deciphering Internet Views on the U.S. Military Through Video  Comment Stance Analysis, A Novel Benchmark Dataset for Stance Classification\", \"topic\": \"Bias in Language Models\", \"x\": 3.043, \"y\": 4.045}, {\"title\": \"Guardrail Baselines for Unlearning in LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.208, \"y\": 0.623}, {\"title\": \"Best of Both Worlds: A Pliable and Generalizable Neuro-Symbolic Approach  for Relation Classification\", \"topic\": \"Named Entity Recognition\", \"x\": 6.293, \"y\": 6.537}, {\"title\": \"Alpaca against Vicuna: Using LLMs to Uncover Memorization of LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.426, \"y\": 0.631}, {\"title\": \"The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.528, \"y\": 0.999}, {\"title\": \"MAGID: An Automated Pipeline for Generating Synthetic Multi-modal  Datasets\", \"topic\": \"Multimodal Language Models\", \"x\": 8.297, \"y\": 6.969}, {\"title\": \"Reliable, Adaptable, and Attributable Language Models with Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.384, \"y\": 4.331}, {\"title\": \"SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context  Misinformation Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.534, \"y\": 3.694}, {\"title\": \"PARADISE: Evaluating Implicit Planning Skills of Language Models with  Procedural Warnings and Tips Dataset\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.66, \"y\": 1.666}, {\"title\": \"Design2Code: How Far Are We From Automating Front-End Engineering?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.157, \"y\": 6.77}, {\"title\": \"Language Guided Exploration for RL Agents in Text Environments\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.964, \"y\": 1.284}, {\"title\": \"CoGenesis: A Framework Collaborating Large and Small Language Models for  Secure Context-Aware Instruction Following\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.716, \"y\": 0.314}, {\"title\": \"Angry Men, Sad Women: Large Language Models Reflect Gendered Stereotypes  in Emotion Attribution\", \"topic\": \"Bias in Language Models\", \"x\": 3.264, \"y\": 2.814}, {\"title\": \"\\\"In Dialogues We Learn\\\": Towards Personalized Dialogue Without  Pre-defined Profiles through In-Dialogue Learning\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.132, \"y\": 3.386}, {\"title\": \"KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.219, \"y\": 1.427}, {\"title\": \"NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and  Diffusion Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.016, \"y\": 6.069}, {\"title\": \"Detecting Concrete Visual Tokens for Multimodal Machine Translation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.501, \"y\": 7.085}, {\"title\": \"Adding Multimodal Capabilities to a Text-only Translation Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.795, \"y\": 6.634}, {\"title\": \"Learning to Use Tools via Cooperative and Interactive Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.592, \"y\": 1.434}, {\"title\": \"The Case for Evaluating Multimodal Translation Models on Text Datasets\", \"topic\": \"Multimodal Language Models\", \"x\": 8.696, \"y\": 6.785}, {\"title\": \"SimuCourt: Building Judicial Decision-Making Agents with Real-world  Judgement Documents\", \"topic\": \"Legal NLP\", \"x\": 4.374, \"y\": 4.522}, {\"title\": \"PaperWeaver: Enriching Topical Paper Alerts by Contextualizing  Recommended Papers with User-collected Papers\", \"topic\": \"Text Summarization\", \"x\": 5.021, \"y\": 5.914}, {\"title\": \"AIx Speed: Playback Speed Optimization Using Listening Comprehension of  Speech Recognition Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.007, \"y\": 5.98}, {\"title\": \"A Second Look on BASS -- Boosting Abstractive Summarization with Unified  Semantic Graphs -- A Replication Study\", \"topic\": \"Text Summarization\", \"x\": 5.123, \"y\": 5.205}, {\"title\": \"JMI at SemEval 2024 Task 3: Two-step approach for multimodal ECAC using  in-context learning with GPT and instruction-tuned Llama models\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.479, \"y\": 5.318}, {\"title\": \"Zero-Shot Cross-Lingual Document-Level Event Causality Identification  with Heterogeneous Graph Contrastive Transfer Learning\", \"topic\": \"Named Entity Recognition\", \"x\": 6.232, \"y\": 5.749}, {\"title\": \"MathScale: Scaling Instruction Tuning for Mathematical Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.641, \"y\": 1.242}, {\"title\": \"Enhancing Conceptual Understanding in Multimodal Contrastive Learning  through Hard Negative Samples\", \"topic\": \"Multimodal Language Models\", \"x\": 8.415, \"y\": 7.416}, {\"title\": \"On the Limitations of Fine-tuned Judge Models for LLM Evaluation\", \"topic\": \"Large Language Models in Education\", \"x\": 6.632, \"y\": 2.99}, {\"title\": \"DPPA: Pruning Method for Large Language Model to Model Merging\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.357, \"y\": 2.062}, {\"title\": \"Evaluating and Optimizing Educational Content with Large Language Model  Judgments\", \"topic\": \"Large Language Models in Education\", \"x\": 6.372, \"y\": 2.234}, {\"title\": \"Towards Measuring and Modeling \\\"Culture\\\" in LLMs: A Survey\", \"topic\": \"Bias in Language Models\", \"x\": 3.981, \"y\": 2.729}, {\"title\": \"CURATRON: Complete Robust Preference Data for Robust Alignment of Large  Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.396, \"y\": 0.604}, {\"title\": \"Towards Training A Chinese Large Language Model for Anesthesiology\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.074, \"y\": 7.425}, {\"title\": \"Causal Prompting: Debiasing Large Language Model Prompting based on  Front-Door Adjustment\", \"topic\": \"Bias in Language Models\", \"x\": 3.656, \"y\": 2.43}, {\"title\": \"DP-CRE: Continual Relation Extraction via Decoupled Contrastive Learning  and Memory Structure Preservation\", \"topic\": \"Named Entity Recognition\", \"x\": 6.33, \"y\": 6.535}, {\"title\": \"Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of  Vietnamese Large Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.97, \"y\": 4.039}, {\"title\": \"Causal Walk: Debiasing Multi-Hop Fact Verification with Front-Door  Adjustment\", \"topic\": \"Bias in Language Models\", \"x\": 3.802, \"y\": 3.972}, {\"title\": \"Privacy-Aware Semantic Cache for Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.893, \"y\": 0.165}, {\"title\": \"InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated  Large Language Model Agents\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.437, \"y\": 0.622}, {\"title\": \"Finetuned Multimodal Language Models Are High-Quality Image-Text Data  Filters\", \"topic\": \"Multimodal Language Models\", \"x\": 8.497, \"y\": 7.256}, {\"title\": \"Found in the Middle: How Language Models Use Long Contexts Better via  Plug-and-Play Positional Encoding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.476, \"y\": 3.275}, {\"title\": \"Exploring the Limitations of Large Language Models in Compositional  Relation Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.508, \"y\": 2.165}, {\"title\": \"ChatCite: LLM Agent with Human Workflow Guidance for Comparative  Literature Summary\", \"topic\": \"Text Summarization\", \"x\": 5.003, \"y\": 5.692}, {\"title\": \"Eliciting Better Multilingual Structured Reasoning from LLMs through  Code\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.495, \"y\": 1.932}, {\"title\": \"Updating the Minimum Information about CLinical Artificial Intelligence  (MI-CLAIM) checklist for generative modeling research\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.086, \"y\": 7.03}, {\"title\": \"Trial and Error: Exploration-Based Trajectory Optimization for LLM  Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.175, \"y\": 1.287}, {\"title\": \"Choose Your Own Adventure: Interactive E-Books to Improve Word Knowledge  and Comprehension Skills\", \"topic\": \"Large Language Models in Education\", \"x\": 6.33, \"y\": 2.583}, {\"title\": \"Enhancing LLM Safety via Constrained Direct Preference Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.075, \"y\": 0.715}, {\"title\": \"The Emotion Dynamics of Literary Novels\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.713, \"y\": 5.272}, {\"title\": \"OffensiveLang: A Community Based Implicit Offensive Language Dataset\", \"topic\": \"Bias in Language Models\", \"x\": 2.543, \"y\": 3.373}, {\"title\": \"How does Architecture Influence the Base Capabilities of Pre-trained  Language Models? A Case Study Based on FFN-Wider Transformer Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.725, \"y\": 2.431}, {\"title\": \"Are More LLM Calls All You Need? Towards Scaling Laws of Compound  Inference Systems\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.225, \"y\": 2.243}, {\"title\": \"Key-Point-Driven Data Synthesis with its Enhancement on Mathematical  Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.597, \"y\": 1.322}, {\"title\": \"Contrastive Region Guidance: Improving Grounding in Vision-Language  Models without Training\", \"topic\": \"Multimodal Language Models\", \"x\": 8.184, \"y\": 7.649}, {\"title\": \"Emotion Granularity from Text: An Aggregate-Level Indicator of Mental  Health\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.242, \"y\": 6.24}, {\"title\": \"FENICE: Factuality Evaluation of summarization based on Natural language  Inference and Claim Extraction\", \"topic\": \"Text Summarization\", \"x\": 5.102, \"y\": 5.062}, {\"title\": \"Subjective $\\\\textit{Isms}$? On the Danger of Conflating Hate and Offence  in Abusive Language Detection\", \"topic\": \"Bias in Language Models\", \"x\": 2.485, \"y\": 3.341}, {\"title\": \"KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for  Enhancing Reference-Based Phishing Detection\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.148, \"y\": 1.704}, {\"title\": \"Birbal: An efficient 7B instruct-model fine-tuned with curated datasets\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.079, \"y\": 2.129}, {\"title\": \"Not all Layers of LLMs are Necessary during Inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.992, \"y\": 2.797}, {\"title\": \"Masked Thought: Simply Masking Partial Reasoning Steps Can Improve  Mathematical Reasoning Learning of Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.529, \"y\": 1.876}, {\"title\": \"EEE-QA: Exploring Effective and Efficient Question-Answer  Representations\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.676, \"y\": 4.491}, {\"title\": \"NeuroVoz: a Castillian Spanish corpus of parkinsonian speech\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.411, \"y\": 6.195}, {\"title\": \"EMOVOME Database: Advancing Emotion Recognition in Speech Beyond Staged  Scenarios\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.5, \"y\": 5.446}, {\"title\": \"Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed  Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 2.495, \"y\": 3.45}, {\"title\": \"adaptMLLM: Fine-Tuning Multilingual Language Models on Low-Resource  Languages with Integrated LLM Playgrounds\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.534, \"y\": 4.624}, {\"title\": \"Modeling Multimodal Social Interactions: New Challenges and Baselines  with Densely Aligned Representations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.438, \"y\": 7.214}, {\"title\": \"Automated Generation of Multiple-Choice Cloze Questions for Assessing  English Vocabulary Using GPT-turbo 3.5\", \"topic\": \"Large Language Models in Education\", \"x\": 6.42, \"y\": 2.552}, {\"title\": \"Breaking the Language Barrier: Can Direct Inference Outperform  Pre-Translation in Multilingual LLM Applications?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.273, \"y\": 4.153}, {\"title\": \"LLM-Oriented Retrieval Tuner\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.466, \"y\": 4.301}, {\"title\": \"Vanilla Transformers are Transfer Capability Teachers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.626, \"y\": 2.196}, {\"title\": \"FakeNewsGPT4: Advancing Multimodal Fake News Detection through  Knowledge-Augmented LVLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.509, \"y\": 3.819}, {\"title\": \"Transformers for Low-Resource Languages:Is F\\u00e9idir Linn!\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.692, \"y\": 4.558}, {\"title\": \"Language and Speech Technology for Central Kurdish Varieties\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.032, \"y\": 5.441}, {\"title\": \"SciAssess: Benchmarking LLM Proficiency in Scientific Literature  Analysis\", \"topic\": \"Text Summarization\", \"x\": 5.107, \"y\": 6.239}, {\"title\": \"Multi-perspective Improvement of Knowledge Graph Completion with Large  Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.676, \"y\": 5.883}, {\"title\": \"AS-ES Learning: Towards Efficient CoT Learning in Small Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.628, \"y\": 1.929}, {\"title\": \"adaptNMT: an open-source, language-agnostic development environment for  Neural Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.76, \"y\": 4.405}, {\"title\": \"Human Evaluation of English--Irish Transformer-Based NMT\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.682, \"y\": 4.727}, {\"title\": \"Analyzing and Adapting Large Language Models for Few-Shot Multilingual  NLU: Are We There Yet?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.199, \"y\": 3.924}, {\"title\": \"IndicVoices: Towards building an Inclusive Multilingual Speech Dataset  for Indian Languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.157, \"y\": 5.664}, {\"title\": \"To Generate or to Retrieve? On the Effectiveness of Artificial Contexts  for Medical Open-Domain Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.898, \"y\": 7.266}, {\"title\": \"Arabic Text Sentiment Analysis: Reinforcing Human-Performed Surveys with  Wider Topic Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.153, \"y\": 4.714}, {\"title\": \"Inference Acceleration for Large Language Models on CPUs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.415, \"y\": 2.897}, {\"title\": \"LLM vs. Lawyers: Identifying a Subset of Summary Judgments in a Large UK  Case Law Dataset\", \"topic\": \"Legal NLP\", \"x\": 4.38, \"y\": 4.586}, {\"title\": \"Fostering the Ecosystem of Open Neural Encoders for Portuguese with  Albertina PT* Family\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.284, \"y\": 4.058}, {\"title\": \"FCDS: Fusing Constituency and Dependency Syntax into Document-Level  Relation Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.283, \"y\": 6.374}, {\"title\": \"Rethinking LLM Language Adaptation: A Case Study on Chinese Mixtral\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.436, \"y\": 3.844}, {\"title\": \"CET2: Modelling Topic Transitions for Coherent and Engaging  Knowledge-Grounded Conversations\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.142, \"y\": 3.557}, {\"title\": \"TopicDiff: A Topic-enriched Diffusion Approach for Multimodal  Conversational Emotion Detection\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.523, \"y\": 5.262}, {\"title\": \"Predicting Learning Performance with Large Language Models: A Study in  Adult Literacy\", \"topic\": \"Large Language Models in Education\", \"x\": 6.445, \"y\": 2.473}, {\"title\": \"NusaBERT: Teaching IndoBERT to be Multilingual and Multicultural\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.129, \"y\": 4.214}, {\"title\": \"NPHardEval4V: A Dynamic Reasoning Benchmark of Multimodal Large Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.832, \"y\": 7.62}, {\"title\": \"Derivative-Free Optimization for Low-Rank Adaptation in Large Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.844, \"y\": 1.769}, {\"title\": \"Differentially Private Synthetic Data via Foundation Model APIs 2: Text\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.844, \"y\": 0.188}, {\"title\": \"Brilla AI: AI Contestant for the National Science and Maths Quiz\", \"topic\": \"Large Language Models in Education\", \"x\": 6.504, \"y\": 2.298}, {\"title\": \"Hypertext Entity Extraction in Webpage\", \"topic\": \"Named Entity Recognition\", \"x\": 6.235, \"y\": 6.605}, {\"title\": \"You Need to Pay Better Attention: Rethinking the Mathematics of  Attention Mechanism\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.763, \"y\": 2.82}, {\"title\": \"Towards Comprehensive Vietnamese Retrieval-Augmented Generation and  Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.458, \"y\": 4.298}, {\"title\": \"SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional  Videos\", \"topic\": \"Multimodal Language Models\", \"x\": 8.588, \"y\": 6.983}, {\"title\": \"Enhancing Neural Machine Translation of Low-Resource Languages: Corpus  Development, Human Evaluation and Explainable AI Architectures\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.611, \"y\": 4.741}, {\"title\": \"SERVAL: Synergy Learning between Vertical Models and LLMs towards  Oracle-Level Zero-shot Medical Prediction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.117, \"y\": 7.351}, {\"title\": \"Revisiting Dynamic Evaluation: Online Adaptation for Large Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.183, \"y\": 2.144}, {\"title\": \"Fantastic Semantics and Where to Find Them: Investigating Which Layers  of Generative LLMs Reflect Lexical Semantics\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.687, \"y\": 3.108}, {\"title\": \"KorMedMCQA: Multi-Choice Question Answering Benchmark for Korean  Healthcare Professional Licensing Examinations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.868, \"y\": 7.375}, {\"title\": \"Answerability in Retrieval-Augmented Open-Domain Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.472, \"y\": 4.493}, {\"title\": \"Logic Rules as Explanations for Legal Case Retrieval\", \"topic\": \"Legal NLP\", \"x\": 4.385, \"y\": 4.521}, {\"title\": \"Ever-Evolving Memory by Blending and Refining the Past\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.381, \"y\": 3.385}, {\"title\": \"Fine Tuning vs. Retrieval Augmented Generation for Less Popular  Knowledge\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.563, \"y\": 4.475}, {\"title\": \"OVEL: Large Language Model as Memory Manager for Online Video Entity  Linking\", \"topic\": \"Named Entity Recognition\", \"x\": 6.606, \"y\": 6.334}, {\"title\": \"What Is Missing in Multilingual Visual Reasoning and How to Fix It\", \"topic\": \"Multimodal Language Models\", \"x\": 7.831, \"y\": 7.684}, {\"title\": \"Breaking Down the Defenses: A Comparative Survey of Attacks on Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.325, \"y\": 0.935}, {\"title\": \"On the Compressibility of Quantized Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.484, \"y\": 2.372}, {\"title\": \"Automatic Question-Answer Generation for Long-Tail Knowledge\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.607, \"y\": 4.559}, {\"title\": \"SyllabusQA: A Course Logistics Question Answering Dataset\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.521, \"y\": 4.49}, {\"title\": \"Quantity Matters: Towards Assessing and Mitigating Number Hallucination  in Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.336, \"y\": 8.04}, {\"title\": \"Large Language Multimodal Models for 5-Year Chronic Disease Cohort  Prediction Using EHR Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.199, \"y\": 7.517}, {\"title\": \"VBART: The Turkish LLM\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.766, \"y\": 4.074}, {\"title\": \"NoMAD-Attention: Efficient LLM Inference on CPUs Through  Multiply-add-free Attention\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.286, \"y\": 2.83}, {\"title\": \"A comprehensive cross-language framework for harmful content detection  with the aid of sentiment analysis\", \"topic\": \"Bias in Language Models\", \"x\": 2.532, \"y\": 3.396}, {\"title\": \"Dissecting Language Models: Machine Unlearning via Selective Pruning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.937, \"y\": 2.378}, {\"title\": \"AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.141, \"y\": 0.518}, {\"title\": \"Accelerating Greedy Coordinate Gradient via Probe Sampling\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.218, \"y\": 0.787}, {\"title\": \"A Survey on Temporal Knowledge Graph: Representation Learning and  Applications\", \"topic\": \"Named Entity Recognition\", \"x\": 6.536, \"y\": 5.702}, {\"title\": \"SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code\", \"topic\": \"Multimodal Language Models\", \"x\": 8.145, \"y\": 6.85}, {\"title\": \"IntactKV: Improving Large Language Model Quantization by Keeping Pivot  Tokens Intact\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.539, \"y\": 2.294}, {\"title\": \"Emotion Analysis in NLP: Trends, Gaps and Roadmap for Future Directions\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.7, \"y\": 5.285}, {\"title\": \"API Is Enough: Conformal Prediction for Large Language Models Without  Logit-Access\", \"topic\": \"Large Language Models in Education\", \"x\": 6.653, \"y\": 3.249}, {\"title\": \"DMoERM: Recipes of Mixture-of-Experts for Effective Reward Modeling\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.697, \"y\": 0.588}, {\"title\": \"Machine Translation in the Covid domain: an English-Irish case study for  LoResMT 2021\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.744, \"y\": 4.713}, {\"title\": \"Balancing Exploration and Exploitation in LLM using Soft RLLF for  Enhanced Negation Understanding\", \"topic\": \"Legal NLP\", \"x\": 4.652, \"y\": 4.279}, {\"title\": \"STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient  Fine-Tuning of Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.493, \"y\": 1.893}, {\"title\": \"BootTOD: Bootstrap Task-oriented Dialogue Representations by Aligning  Diverse Responses\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.194, \"y\": 3.426}, {\"title\": \"LLaMoCo: Instruction Tuning of Large Language Models for Optimization  Code Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.226, \"y\": 0.174}, {\"title\": \"Reading Subtext: Evaluating Large Language Models on Short Story  Summarization with Writers\", \"topic\": \"Text Summarization\", \"x\": 5.266, \"y\": 4.997}, {\"title\": \"Peacock: A Family of Arabic Multimodal Large Language Models and  Benchmarks\", \"topic\": \"Multimodal Language Models\", \"x\": 7.961, \"y\": 7.693}, {\"title\": \"Attribute Structuring Improves LLM-Based Evaluation of Clinical Text  Summaries\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.195, \"y\": 6.934}, {\"title\": \"Predictions from language models for multiple-choice tasks are not  robust under variation of scoring methods\", \"topic\": \"Large Language Models in Education\", \"x\": 6.461, \"y\": 2.903}, {\"title\": \"Merging Text Transformer Models from Different Initializations\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.609, \"y\": 2.475}, {\"title\": \"LocalRQA: From Generating Data to Locally Training, Testing, and  Deploying Retrieval-Augmented QA Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.594, \"y\": 4.42}, {\"title\": \"AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge  Graph Construction Based on Ontologies-enhanced Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.308, \"y\": 7.27}, {\"title\": \"MediSwift: Efficient Sparse Pre-trained Biomedical Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.377, \"y\": 7.357}, {\"title\": \"Differentially Private Knowledge Distillation via Synthetic Text  Generation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.859, \"y\": 0.18}, {\"title\": \"AtP*: An efficient and scalable method for localizing LLM behaviour to  components\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.816, \"y\": 2.773}, {\"title\": \"Dialect prejudice predicts AI decisions about people's character,  employability, and criminality\", \"topic\": \"Bias in Language Models\", \"x\": 3.237, \"y\": 2.786}, {\"title\": \"Few-Shot Relation Extraction with Hybrid Visual Evidence\", \"topic\": \"Named Entity Recognition\", \"x\": 6.59, \"y\": 6.632}, {\"title\": \"A Bit of a Problem: Measurement Disparities in Dataset Sizes Across  Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.185, \"y\": 4.311}, {\"title\": \"A systematic evaluation of large language models for generating  programming code\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.071, \"y\": 0.159}, {\"title\": \"LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.184, \"y\": 3.245}, {\"title\": \"SEGAA: A Unified Approach to Predicting Age, Gender, and Emotion in  Speech\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.446, \"y\": 5.389}, {\"title\": \"Your Model Is Not Predicting Depression Well And That Is Why: A Case  Study of PRIMATE Dataset\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.349, \"y\": 6.41}, {\"title\": \"Hierarchical Indexing for Retrieval-Augmented Opinion Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.03, \"y\": 5.142}, {\"title\": \"LLMs for Targeted Sentiment in News Headlines: Exploring the  Descriptive-Prescriptive Dilemma\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.052, \"y\": 4.759}, {\"title\": \"Cross-Lingual Learning vs. Low-Resource Fine-Tuning: A Case Study with  Fact-Checking in Turkish\", \"topic\": \"Bias in Language Models\", \"x\": 3.576, \"y\": 3.842}, {\"title\": \"Provably Robust DPO: Aligning Language Models with Noisy Feedback\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.392, \"y\": 0.597}, {\"title\": \"TRUCE: Private Benchmarking to Prevent Contamination and Improve  Comparative Evaluation of LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.71, \"y\": 0.312}, {\"title\": \"Post-decoder Biasing for End-to-End Speech Recognition of Multi-turn  Medical Interview\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.584, \"y\": 7.327}, {\"title\": \"Self-Consistent Reasoning-based Aspect-Sentiment Quad Prediction with  Extract-Then-Assign Strategy\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.996, \"y\": 4.96}, {\"title\": \"Semi-Instruct: Bridging Natural-Instruct and Self-Instruct for Code  Large Language Models\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.167, \"y\": 0.118}, {\"title\": \"Teach LLMs to Phish: Stealing Private Information from Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.632, \"y\": 0.552}, {\"title\": \"DPP-Based Adversarial Prompt Searching for Lanugage Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.254, \"y\": 0.943}, {\"title\": \"Gender Bias in Large Language Models across Multiple Languages\", \"topic\": \"Bias in Language Models\", \"x\": 3.178, \"y\": 2.74}, {\"title\": \"SoftTiger: A Clinical Foundation Model for Healthcare Workflows\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.179, \"y\": 7.403}, {\"title\": \"EUROPA: A Legal Multilingual Keyphrase Generation Dataset\", \"topic\": \"Legal NLP\", \"x\": 4.548, \"y\": 4.807}, {\"title\": \"Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by  Exploring Refusal Loss Landscapes\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.135, \"y\": 0.623}, {\"title\": \"CASIMIR: A Corpus of Scientific Articles enhanced with Multiple  Author-Integrated Revisions\", \"topic\": \"Text Summarization\", \"x\": 5.006, \"y\": 5.788}, {\"title\": \"Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of  Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.633, \"y\": 7.574}, {\"title\": \"Transcription and translation of videos using fine-tuned XLSR Wav2Vec2  on custom dataset and mBART\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.297, \"y\": 5.775}, {\"title\": \"Improving Socratic Question Generation using Data Augmentation and  Preference Optimization\", \"topic\": \"Large Language Models in Education\", \"x\": 6.472, \"y\": 2.334}, {\"title\": \"AXOLOTL: Fairness through Assisted Self-Debiasing of Large Language  Model Outputs\", \"topic\": \"Bias in Language Models\", \"x\": 3.277, \"y\": 2.61}, {\"title\": \"\\\"Flex Tape Can't Fix That\\\": Bias and Misinformation in Edited Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.36, \"y\": 2.69}, {\"title\": \"EBBS: An Ensemble with Bi-Level Beam Search for Zero-Shot Machine  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.675, \"y\": 4.687}, {\"title\": \"EROS: Entity-Driven Controlled Policy Document Summarization\", \"topic\": \"Legal NLP\", \"x\": 4.634, \"y\": 4.617}, {\"title\": \"FAC$^2$E: Better Understanding Large Language Model Capabilities by  Dissociating Language and Cognition\", \"topic\": \"Large Language Models in Education\", \"x\": 6.761, \"y\": 3.171}, {\"title\": \"LoRA-as-an-Attack! Piercing LLM Safety Under The Share-and-Play Scenario\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.321, \"y\": 0.657}, {\"title\": \"PROC2PDDL: Open-Domain Planning Representations from Texts\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.385, \"y\": 1.416}, {\"title\": \"Resonance RoPE: Improving Context Length Generalization of Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.532, \"y\": 3.18}, {\"title\": \"TV-TREES: Multimodal Entailment Trees for Neuro-Symbolic Video Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.289, \"y\": 7.672}, {\"title\": \"Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period  of Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.261, \"y\": 1.256}, {\"title\": \"Curiosity-driven Red-teaming for Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.068, \"y\": 1.232}, {\"title\": \"$\\\\texttt{COSMIC}$: Mutual Information for Task-Agnostic Summarization  Evaluation\", \"topic\": \"Text Summarization\", \"x\": 5.097, \"y\": 5.124}, {\"title\": \"Functional Benchmarks for Robust Evaluation of Reasoning Performance,  and the Reasoning Gap\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.651, \"y\": 1.445}, {\"title\": \"ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.883, \"y\": 1.124}, {\"title\": \"Speaker-Independent Dysarthria Severity Classification using  Self-Supervised Transformers and Multi-Task Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.535, \"y\": 6.225}, {\"title\": \"Compositional API Recommendation for Library-Oriented Code Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.194, \"y\": 0.156}, {\"title\": \"Griffin: Mixing Gated Linear Recurrences with Local Attention for  Efficient Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.851, \"y\": 2.979}, {\"title\": \"EAMA : Entity-Aware Multimodal Alignment Based Approach for News Image  Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.339, \"y\": 7.116}, {\"title\": \"OpenMedLM: Prompt engineering can out-perform fine-tuning in medical  question-answering with open-source large language models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.872, \"y\": 7.321}, {\"title\": \"Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.268, \"y\": 0.811}, {\"title\": \"Compact Speech Translation Models via Discrete Speech Units Pretraining\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.13, \"y\": 5.65}, {\"title\": \"SEED: Customize Large Language Models with Sample-Efficient Adaptation  for Code Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.266, \"y\": -0.022}, {\"title\": \"Robust Guidance for Unsupervised Data Selection: Capturing Perplexing  Named Entities for Domain-Specific Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.654, \"y\": 4.55}, {\"title\": \"GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of  LLMs as Mathematical Problem Solvers\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.652, \"y\": 1.258}, {\"title\": \"Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question  Answering Benchmark\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.708, \"y\": 4.429}, {\"title\": \"Memory-Augmented Generative Adversarial Transformers\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.191, \"y\": 3.262}, {\"title\": \"PeLLE: Encoder-based language models for Brazilian Portuguese based on  open data\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.18, \"y\": 4.062}, {\"title\": \"PRSA: PRompt Stealing Attacks against Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.278, \"y\": 0.625}, {\"title\": \"Towards Modeling Learner Performance with Large Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.461, \"y\": 2.289}, {\"title\": \"Improving Legal Judgement Prediction in Romanian with Long Text Encoders\", \"topic\": \"Legal NLP\", \"x\": 4.422, \"y\": 4.596}, {\"title\": \"Teaching Large Language Models an Unseen Language on the Fly\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.542, \"y\": 4.363}, {\"title\": \"VIXEN: Visual Text Comparison Network for Image Difference Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.444, \"y\": 7.262}, {\"title\": \"How to Understand \\\"Support\\\"? An Implicit-enhanced Causal Inference  Approach for Weakly-supervised Phrase Grounding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.007, \"y\": 7.36}, {\"title\": \"Controllable Preference Optimization: Toward Controllable  Multi-Objective Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 4.995, \"y\": 1.001}, {\"title\": \"Pointing out the Shortcomings of Relation Extraction Models with  Semantically Motivated Adversarials\", \"topic\": \"Named Entity Recognition\", \"x\": 6.361, \"y\": 6.476}, {\"title\": \"Exploring the Efficacy of Large Language Models in Summarizing Mental  Health Counseling Sessions: A Benchmark Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.035, \"y\": 6.477}, {\"title\": \"EyeGPT: Ophthalmic Assistant with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.715, \"y\": 7.542}, {\"title\": \"PopALM: Popularity-Aligned Language Models for Social Media Trendy  Response Prediction\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.287, \"y\": 0.806}, {\"title\": \"SynGhost: Imperceptible and Universal Task-agnostic Backdoor Attack in  Pre-trained Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.219, \"y\": 0.822}, {\"title\": \"SemEval 2024 -- Task 10: Emotion Discovery and Reasoning its Flip in  Conversation (EDiReF)\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.559, \"y\": 5.294}, {\"title\": \"Inappropriate Pause Detection In Dysarthric Speech Using Large-Scale  Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.541, \"y\": 6.084}, {\"title\": \"AdaMergeX: Cross-Lingual Transfer with Large Language Models via  Adaptive Adapter Merging\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.418, \"y\": 4.156}, {\"title\": \"Evolving to the Future: Unseen Event Adaptive Fake News Detection on  Social Media\", \"topic\": \"Bias in Language Models\", \"x\": 3.413, \"y\": 3.739}, {\"title\": \"Reducing Hallucinations in Entity Abstract Summarization with  Facts-Template Decomposition\", \"topic\": \"Text Summarization\", \"x\": 5.135, \"y\": 5.153}, {\"title\": \"Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP  Models on Accuracy and Semantic Coherence\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.545, \"y\": 1.082}, {\"title\": \"How do Large Language Models Handle Multilingualism?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.247, \"y\": 3.814}, {\"title\": \"MPAT: Building Robust Deep Neural Networks against Textual Adversarial  Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.004, \"y\": 1.151}, {\"title\": \"FlexLLM: A System for Co-Serving Large Language Model Inference and  Parameter-Efficient Finetuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.489, \"y\": 2.858}, {\"title\": \"Advancing Generative AI for Portuguese with Open Decoder Gerv\\u00e1sio PT*\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.301, \"y\": 4.057}, {\"title\": \"How Much Annotation is Needed to Compare Summarization Models?\", \"topic\": \"Text Summarization\", \"x\": 5.117, \"y\": 5.117}, {\"title\": \"Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.601, \"y\": 4.915}, {\"title\": \"Priority Sampling of Large Language Models for Compilers\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.162, \"y\": 0.054}, {\"title\": \"NeuroPrune: A Neuro-inspired Topological Sparse Training Algorithm for  Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.029, \"y\": 2.421}, {\"title\": \"Grounding Language Models for Visual Entity Recognition\", \"topic\": \"Multimodal Language Models\", \"x\": 7.732, \"y\": 7.279}, {\"title\": \"CLLMs: Consistency Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.498, \"y\": 3.195}, {\"title\": \"Simple linear attention language models balance the recall-throughput  tradeoff\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.01, \"y\": 3.026}, {\"title\": \"Large Language Models and Games: A Survey and Roadmap\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.799, \"y\": 1.766}, {\"title\": \"Arithmetic Control of LLMs for Diverse User Preferences: Directional  Preference Alignment with Multi-Objective Rewards\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.453, \"y\": 0.61}, {\"title\": \"Implicit Bias of Next-Token Prediction\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.104, \"y\": 3.214}, {\"title\": \"RNNs are not Transformers (Yet): The Key Bottleneck on In-context  Retrieval\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.306, \"y\": 2.925}, {\"title\": \"Few-Shot Fairness: Unveiling LLM's Potential for Fairness-Aware  Classification\", \"topic\": \"Bias in Language Models\", \"x\": 3.271, \"y\": 2.695}, {\"title\": \"NewsQs: Multi-Source Question Generation for the Inquiring Mind\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.046, \"y\": 4.218}, {\"title\": \"Beyond Natural Language: LLMs Leveraging Alternative Formats for  Enhanced Reasoning and Communication\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.259, \"y\": 1.604}, {\"title\": \"Leveraging Diverse Modeling Contexts with Collaborating Learning for  Neural Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.899, \"y\": 4.588}, {\"title\": \"Emotion Classification in Low and Moderate Resource Languages\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.556, \"y\": 5.258}, {\"title\": \"Can GPT Improve the State of Prior Authorization via Guideline Based  Automated Question Answering?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.852, \"y\": 7.404}, {\"title\": \"A Cognitive Evaluation Benchmark of Image Reasoning and Description for  Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.909, \"y\": 7.819}, {\"title\": \"Decomposed Prompting: Unveiling Multilingual Linguistic Structure  Knowledge in English-Centric Large Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.609, \"y\": 3.941}, {\"title\": \"The First Place Solution of WSDM Cup 2024: Leveraging Large Language  Models for Conversational Multi-Doc QA\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.46, \"y\": 4.552}, {\"title\": \"Focus on Your Question! Interpreting and Mitigating Toxic CoT Problems  in Commonsense Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.296, \"y\": 2.272}, {\"title\": \"How to think step-by-step: A mechanistic understanding of  chain-of-thought reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.371, \"y\": 2.194}, {\"title\": \"Is Crowdsourcing Breaking Your Bank? Cost-Effective Fine-Tuning of  Pre-trained Language Models with Proximal Policy Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.467, \"y\": 0.924}, {\"title\": \"Exploration of Adapter for Noise Robust Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.647, \"y\": 5.725}, {\"title\": \"A Survey on Neural Question Generation: Methods, Applications, and  Prospects\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.388, \"y\": 4.116}, {\"title\": \"Hierarchical Multimodal Pre-training for Visually Rich Webpage  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 7.597, \"y\": 7.028}, {\"title\": \"LLM Task Interference: An Initial Study on the Impact of Task-Switch in  Conversational History\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.372, \"y\": 3.047}, {\"title\": \"DANSK and DaCy 2.6.0: Domain Generalization of Danish Named Entity  Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 6.138, \"y\": 6.857}, {\"title\": \"Challenges in Pre-Training Graph Neural Networks for Context-Based Fake  News Detection: An Evaluation of Current Strategies and Resource Limitations\", \"topic\": \"Bias in Language Models\", \"x\": 3.401, \"y\": 3.755}, {\"title\": \"MIKO: Multimodal Intention Knowledge Distillation from Large Language  Models for Social-Media Commonsense Discovery\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.696, \"y\": 4.779}, {\"title\": \"Evaluating Quantized Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.522, \"y\": 2.297}, {\"title\": \"From Summary to Action: Enhancing Large Language Models for Complex  Tasks with Open World APIs\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.747, \"y\": 1.428}, {\"title\": \"MedAide: Leveraging Large Language Models for On-Premise Medical  Assistance on Edge Devices\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.865, \"y\": 7.384}, {\"title\": \"MMSR: Symbolic Regression is a Multimodal Task\", \"topic\": \"Multimodal Language Models\", \"x\": 8.259, \"y\": 7.185}, {\"title\": \"Unsupervised Information Refinement Training of Large Language Models  for Retrieval-Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.363, \"y\": 4.237}, {\"title\": \"Exploring Multilingual Concepts of Human Value in Large Language Models:  Is Value Alignment Consistent, Transferable and Controllable across  Languages?\", \"topic\": \"Bias in Language Models\", \"x\": 4.181, \"y\": 2.413}, {\"title\": \"UniVS: Unified and Universal Video Segmentation with Prompts as Queries\", \"topic\": \"Multimodal Language Models\", \"x\": 8.804, \"y\": 7.454}, {\"title\": \"LoRA-SP: Streamlined Partial Parameter Adaptation for Resource-Efficient  Fine-Tuning of Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.788, \"y\": 1.786}, {\"title\": \"Editing Factual Knowledge and Explanatory Ability of Medical Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.12, \"y\": 7.099}, {\"title\": \"Polos: Multimodal Metric Learning from Human Feedback for Image  Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.507, \"y\": 7.284}, {\"title\": \"On the use of Silver Standard Data for Zero-shot Classification Tasks in  Information Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.341, \"y\": 6.521}, {\"title\": \"Benchmarking Large Language Models on Answering and Explaining  Challenging Medical Questions\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.809, \"y\": 7.366}, {\"title\": \"Contextualizing Generated Citation Texts\", \"topic\": \"Text Summarization\", \"x\": 5.094, \"y\": 5.657}, {\"title\": \"Characterizing Truthfulness in Large Language Model Generations with  Local Intrinsic Dimension\", \"topic\": \"Large Language Models in Education\", \"x\": 6.208, \"y\": 3.186}, {\"title\": \"ResLoRA: Identity Residual Mapping in Low-Rank Adaption\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.826, \"y\": 1.745}, {\"title\": \"Corpus-Steered Query Expansion with Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.016, \"y\": 4.634}, {\"title\": \"Hire a Linguist!: Learning Endangered Languages with In-Context  Linguistic Descriptions\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.34, \"y\": 4.448}, {\"title\": \"TroubleLLM: Align to Red Team Expert\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.975, \"y\": 1.373}, {\"title\": \"Merino: Entropy-driven Design for Generative Language Models on IoT  Devices\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.392, \"y\": 2.689}, {\"title\": \"A Survey on Recent Advances in LLM-Based Multi-turn Dialogue Systems\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.298, \"y\": 3.155}, {\"title\": \"A Sentiment Consolidation Framework for Meta-Review Generation\", \"topic\": \"Text Summarization\", \"x\": 4.95, \"y\": 5.439}, {\"title\": \"FlattenQuant: Breaking Through the Inference Compute-bound for Large  Language Models with Per-tensor Quantization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.458, \"y\": 2.398}, {\"title\": \"M3-VRD: Multimodal Multi-task Multi-teacher Visually-Rich Form Document  Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 7.634, \"y\": 7.241}, {\"title\": \"All in an Aggregated Image for In-Image Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.61, \"y\": 7.676}, {\"title\": \"An Iterative Associative Memory Model for Empathetic Response Generation\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.659, \"y\": 5.734}, {\"title\": \"Twists, Humps, and Pebbles: Multilingual Speech Recognition Models  Exhibit Gender Performance Gaps\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.45, \"y\": 5.826}, {\"title\": \"SparseLLM: Towards Global Pruning for Pre-trained Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.05, \"y\": 2.289}, {\"title\": \"Acquiring Linguistic Knowledge from Multimodal Input\", \"topic\": \"Multimodal Language Models\", \"x\": 8.18, \"y\": 7.589}, {\"title\": \"Multitask Multilingual Model Adaptation with Featurized Low-Rank  Mixtures\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.742, \"y\": 1.837}, {\"title\": \"Pragmatic Instruction Following and Goal Assistance via Cooperative  Language-Guided Inverse Planning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.1, \"y\": 1.477}, {\"title\": \"Adversarial Math Word Problem Generation\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.495, \"y\": 1.145}, {\"title\": \"Researchy Questions: A Dataset of Multi-Perspective, Decompositional  Questions for LLM Web Agents\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.591, \"y\": 4.56}, {\"title\": \"JMLR: Joint Medical LLM and Retrieval Training for Enhancing Reasoning  and Professional Question Answering Capability\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.939, \"y\": 7.196}, {\"title\": \"Follow My Instruction and Spill the Beans: Scalable Data Extraction from  Retrieval-Augmented Generation Systems\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.378, \"y\": 0.685}, {\"title\": \"The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.316, \"y\": 2.416}, {\"title\": \"Massive Activations in Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.294, \"y\": 2.72}, {\"title\": \"Towards Optimal Learning of Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.347, \"y\": 2.721}, {\"title\": \"Evaluating Very Long-Term Conversational Memory of LLM Agents\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.226, \"y\": 3.41}, {\"title\": \"Tower: An Open Multilingual Large Language Model for Translation-Related  Tasks\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.717, \"y\": 4.532}, {\"title\": \"AmbigNLG: Addressing Task Ambiguity in Instruction for NLG\", \"topic\": \"Large Language Models in Education\", \"x\": 6.62, \"y\": 3.696}, {\"title\": \"Case-Based or Rule-Based: How Do Transformers Do the Math?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.939, \"y\": 1.521}, {\"title\": \"RAVEL: Evaluating Interpretability Methods on Disentangling Language  Model Representations\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.339, \"y\": 2.698}, {\"title\": \"Are LLMs Capable of Data-based Statistical and Causal Reasoning?  Benchmarking Advanced Quantitative Reasoning with Data\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.31, \"y\": 1.995}, {\"title\": \"Variational Learning is Effective for Large Deep Networks\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.852, \"y\": 2.292}, {\"title\": \"From Text Segmentation to Smart Chaptering: A Novel Benchmark for  Structuring Video Transcriptions\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.83, \"y\": 5.721}, {\"title\": \"Fine-Grained Natural Language Inference Based Faithfulness Evaluation  for Diverse Summarisation Tasks\", \"topic\": \"Text Summarization\", \"x\": 5.135, \"y\": 5.047}, {\"title\": \"Agent-Pro: Learning to Evolve via Policy-Level Reflection and  Optimization\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.953, \"y\": 1.434}, {\"title\": \"DropBP: Accelerating Fine-Tuning of Large Language Models by Dropping  Backward Propagation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.029, \"y\": 2.239}, {\"title\": \"TruthX: Alleviating Hallucinations by Editing Large Language Models in  Truthful Space\", \"topic\": \"Large Language Models in Education\", \"x\": 6.022, \"y\": 3.242}, {\"title\": \"Predict the Next Word: Humans exhibit uncertainty in this task and  language models _____\", \"topic\": \"Large Language Models in Education\", \"x\": 6.551, \"y\": 3.057}, {\"title\": \"Latent Attention for Linear Time Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.853, \"y\": 3.146}, {\"title\": \"Extreme Miscalibration and the Illusion of Adversarial Robustness\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.98, \"y\": 1.152}, {\"title\": \"REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain  Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.453, \"y\": 4.562}, {\"title\": \"Emotional Voice Messages (EMOVOME) database: emotion recognition in  spontaneous voice messages\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.51, \"y\": 5.408}, {\"title\": \"Predicting postoperative risks using large language models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.164, \"y\": 7.252}, {\"title\": \"Can GPT-4 Identify Propaganda? Annotation and Detection of Propaganda  Spans in News Articles\", \"topic\": \"Bias in Language Models\", \"x\": 3.333, \"y\": 3.777}, {\"title\": \"Training-Free Long-Context Scaling of Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.715, \"y\": 3.226}, {\"title\": \"Exploiting Emotion-Semantic Correlations for Empathetic Response  Generation\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.615, \"y\": 5.608}, {\"title\": \"Consistency Matters: Explore LLMs Consistency From a Black-Box  Perspective\", \"topic\": \"Large Language Models in Education\", \"x\": 6.705, \"y\": 3.012}, {\"title\": \"A Neural Rewriting System to Solve Algorithmic Problems\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.685, \"y\": 1.261}, {\"title\": \"FairBelief -- Assessing Harmful Beliefs in Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.241, \"y\": 2.809}, {\"title\": \"LLMGuard: Guarding Against Unsafe LLM Behavior\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.821, \"y\": 1.239}, {\"title\": \"KoDialogBench: Evaluating Conversational Understanding of Language  Models with Korean Dialogue Benchmark\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.42, \"y\": 3.272}, {\"title\": \"SoFA: Shielded On-the-fly Alignment via Priority Rule Following\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.661, \"y\": 0.734}, {\"title\": \"Unsupervised multiple choices question answering via universal corpus\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.797, \"y\": 4.315}, {\"title\": \"SKT5SciSumm -- A Hybrid Generative Approach for Multi-Document  Scientific Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.057, \"y\": 5.66}, {\"title\": \"Probing Multimodal Large Language Models for Global and Local Semantic  Representations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.155, \"y\": 7.508}, {\"title\": \"XMoE: Sparse Models with Fine-grained and Adaptive Expert Selection\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.872, \"y\": 2.309}, {\"title\": \"MELoRA: Mini-Ensemble Low-Rank Adapters for Parameter-Efficient  Fine-Tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.735, \"y\": 1.778}, {\"title\": \"Speak Out of Turn: Safety Vulnerability of Large Language Models in  Multi-turn Dialogue\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.581, \"y\": 1.012}, {\"title\": \"Beyond the Known: Investigating LLMs Performance on Out-of-Domain Intent  Detection\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.306, \"y\": 3.169}, {\"title\": \"Image-Text Matching with Multi-View Attention\", \"topic\": \"Multimodal Language Models\", \"x\": 8.148, \"y\": 7.028}, {\"title\": \"MATHSENSEI: A Tool-Augmented Large Language Model for Mathematical  Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.567, \"y\": 1.298}, {\"title\": \"Measuring Vision-Language STEM Skills of Neural Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.737, \"y\": 1.451}, {\"title\": \"An Effective Mixture-Of-Experts Approach For Code-Switching Speech  Recognition Leveraging Encoder Disentanglement\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.357, \"y\": 5.659}, {\"title\": \"Extreme Encoder Output Frame Rate Reduction: Improving Computational  Latencies of Large End-to-End Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.612, \"y\": 5.607}, {\"title\": \"Clustering Document Parts: Detecting and Characterizing Influence  Campaigns from Documents\", \"topic\": \"Bias in Language Models\", \"x\": 3.37, \"y\": 3.838}, {\"title\": \"MAGPIE: Multi-Task Media-Bias Analysis Generalization for Pre-Trained  Identification of Expressions\", \"topic\": \"Bias in Language Models\", \"x\": 3.186, \"y\": 3.704}, {\"title\": \"OSCaR: Object State Captioning and State Change Representation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.489, \"y\": 7.437}, {\"title\": \"Fact-and-Reflection (FaR) Improves Confidence Calibration of Large  Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.679, \"y\": 2.865}, {\"title\": \"Information Flow Routes: Automatically Interpreting Language Models at  Scale\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.899, \"y\": 2.727}, {\"title\": \"Re-Ex: Revising after Explanation Reduces the Factual Errors in LLM  Responses\", \"topic\": \"Large Language Models in Education\", \"x\": 6.104, \"y\": 2.824}, {\"title\": \"Adapting to Teammates in a Cooperative Language Game\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.857, \"y\": 1.648}, {\"title\": \"Leveraging Large Language Models for Learning Complex Legal Concepts  through Storytelling\", \"topic\": \"Legal NLP\", \"x\": 4.375, \"y\": 4.493}, {\"title\": \"Z-AGI Labs at ClimateActivism 2024: Stance and Hate Event Detection on  Social Media\", \"topic\": \"Bias in Language Models\", \"x\": 2.587, \"y\": 3.565}, {\"title\": \"Towards Explainability and Fairness in Swiss Judgement Prediction:  Benchmarking on a Multilingual Dataset\", \"topic\": \"Legal NLP\", \"x\": 4.349, \"y\": 4.521}, {\"title\": \"Benchmarking LLMs on the Semantic Overlap Summarization Task\", \"topic\": \"Text Summarization\", \"x\": 5.259, \"y\": 5.062}, {\"title\": \"What Do Language Models Hear? Probing for Auditory Representations in  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.99, \"y\": 6.838}, {\"title\": \"Long Dialog Summarization: An Analysis\", \"topic\": \"Text Summarization\", \"x\": 5.116, \"y\": 4.973}, {\"title\": \"Successfully Guiding Humans with Imperfect Instructions by Highlighting  Potential Errors and Suggesting Corrections\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.124, \"y\": 1.938}, {\"title\": \"GROUNDHOG: Grounding Large Language Models to Holistic Segmentation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.138, \"y\": 7.501}, {\"title\": \"Think Big, Generate Quick: LLM-to-SLM for Fast Autoregressive Decoding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.274, \"y\": 3.308}, {\"title\": \"Multi-LoRA Composition for Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.51, \"y\": 6.777}, {\"title\": \"MobiLlama: Towards Accurate and Lightweight Fully Transparent GPT\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.268, \"y\": 2.532}, {\"title\": \"Do Large Language Models Latently Perform Multi-Hop Reasoning?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.597, \"y\": 2.384}, {\"title\": \"PhyGrasp: Generalizing Robotic Grasping with Physics-informed Large  Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.05, \"y\": 7.069}, {\"title\": \"Eight Methods to Evaluate Robust Unlearning in LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.14, \"y\": 0.624}, {\"title\": \"Mysterious Projections: Multimodal LLMs Gain Domain-Specific Visual  Capabilities Without Richer Cross-Modal Projections\", \"topic\": \"Multimodal Language Models\", \"x\": 8.185, \"y\": 7.529}, {\"title\": \"SKILL: Similarity-aware Knowledge distILLation for Speech  Self-Supervised Learning\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.486, \"y\": 5.746}, {\"title\": \"Language Agents as Optimizable Graphs\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.343, \"y\": 1.802}, {\"title\": \"Rainbow Teaming: Open-Ended Generation of Diverse Adversarial Prompts\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.523, \"y\": 0.993}, {\"title\": \"Nemotron-4 15B Technical Report\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.182, \"y\": 3.944}, {\"title\": \"Investigating the Effectiveness of HyperTuning via Gisting\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.612, \"y\": 2.602}, {\"title\": \"A Surprising Failure? Multimodal LLMs and the NLVR Challenge\", \"topic\": \"Multimodal Language Models\", \"x\": 7.88, \"y\": 7.641}, {\"title\": \"OncoGPT: A Medical Conversational Model Tailored with Oncology Domain  Expertise on a Large Language Model Meta-AI (LLaMA)\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.783, \"y\": 7.32}, {\"title\": \"Political Compass or Spinning Arrow? Towards More Meaningful Evaluations  for Values and Opinions in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.138, \"y\": 2.714}, {\"title\": \"A Comprehensive Evaluation of Quantization Strategies for Large Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.572, \"y\": 2.236}, {\"title\": \"CorpusBrain++: A Continual Generative Pre-Training Framework for  Knowledge-Intensive Language Tasks\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.311, \"y\": 4.545}, {\"title\": \"Value Preferences Estimation and Disambiguation in Hybrid Participatory  Systems\", \"topic\": \"Bias in Language Models\", \"x\": 4.171, \"y\": 2.512}, {\"title\": \"CodeChameleon: Personalized Encryption Framework for Jailbreaking Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.99, \"y\": 0.463}, {\"title\": \"Quantum linear algebra is all you need for Transformer architectures\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.632, \"y\": 2.677}, {\"title\": \"Social Media as a Sensor: Analyzing Twitter Data for Breast Cancer  Medication Effects Using Natural Language Processing\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.71, \"y\": 6.681}, {\"title\": \"Generating Effective Ensembles for Sentiment Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.0, \"y\": 4.861}, {\"title\": \"HumanEval-XL: A Multilingual Code Generation Benchmark for Cross-lingual  Natural Language Generalization\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.148, \"y\": 0.177}, {\"title\": \"Adaptation of Biomedical and Clinical Pretrained Models to French Long  Documents: A Comparative Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.578, \"y\": 7.314}, {\"title\": \"RepoAgent: An LLM-Powered Open-Source Framework for Repository-level  Code Documentation Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.051, \"y\": 0.109}, {\"title\": \"GigaPevt: Multimodal Medical Assistant\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.839, \"y\": 7.651}, {\"title\": \"ESG Sentiment Analysis: comparing human and language model performance  including GPT\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.194, \"y\": 4.755}, {\"title\": \"PAQA: Toward ProActive Open-Retrieval Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.245, \"y\": 4.418}, {\"title\": \"Rethinking Negative Instances for Generative Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 6.218, \"y\": 6.806}, {\"title\": \"Two-stage Generative Question Answering on Temporal Knowledge Graph  Using Large Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.609, \"y\": 5.329}, {\"title\": \"Retrieval Augmented Generation Systems: Automatic Dataset Creation,  Evaluation and Boolean Agent Setup\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.112, \"y\": 4.487}, {\"title\": \"LLM-based Privacy Data Augmentation Guided by Knowledge Distillation  with a Distribution Tutor for Medical Text Classification\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.836, \"y\": 0.181}, {\"title\": \"Pre-training Cross-lingual Open Domain Question Answering with  Large-scale Synthetic Supervision\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 7.146, \"y\": 4.355}, {\"title\": \"LLMArena: Assessing Capabilities of Large Language Models in Dynamic  Multi-Agent Environments\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.734, \"y\": 1.665}, {\"title\": \"Unveiling Vulnerability of Self-Attention\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.084, \"y\": 1.023}, {\"title\": \"Defending LLMs against Jailbreaking Attacks via Backtranslation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.129, \"y\": 0.545}, {\"title\": \"ID-XCB: Data-independent Debiasing for Fair and Accurate  Transformer-based Cyberbullying Detection\", \"topic\": \"Bias in Language Models\", \"x\": 2.492, \"y\": 3.335}, {\"title\": \"RetrievalQA: Assessing Adaptive Retrieval-Augmented Generation for  Short-form Open-Domain Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.477, \"y\": 4.502}, {\"title\": \"ShieldLM: Empowering LLMs as Aligned, Customizable and Explainable  Safety Detectors\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.904, \"y\": 1.297}, {\"title\": \"RoCoIns: Enhancing Robustness of Large Language Models through  Code-Style Instructions\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.191, \"y\": 1.012}, {\"title\": \"DenseMamba: State Space Models with Dense Hidden Connection for  Efficient Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.922, \"y\": 2.59}, {\"title\": \"From RAGs to riches: Using large language models to write documents for  clinical trials\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.077, \"y\": 7.021}, {\"title\": \"MoZIP: A Multilingual Benchmark to Evaluate Large Language Models in  Intellectual Property\", \"topic\": \"Legal NLP\", \"x\": 4.792, \"y\": 4.768}, {\"title\": \"Immunization against harmful fine-tuning attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.479, \"y\": 0.807}, {\"title\": \"An Automated End-to-End Open-Source Software for High-Quality  Text-to-Speech Dataset Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.164, \"y\": 5.857}, {\"title\": \"TEaR: Improving LLM-based Machine Translation with Systematic  Self-Refinement\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.785, \"y\": 4.684}, {\"title\": \"LLM Inference Unveiled: Survey and Roofline Model Insights\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.475, \"y\": 2.735}, {\"title\": \"Layer-wise Regularized Dropout for Neural Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.791, \"y\": 2.523}, {\"title\": \"Language-guided Skill Learning with Temporal Variational Inference\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.175, \"y\": 1.322}, {\"title\": \"MathGenie: Generating Synthetic Data with Question Back-translation for  Enhancing Mathematical Reasoning of LLMs\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.628, \"y\": 1.272}, {\"title\": \"Unveiling the Truth and Facilitating Change: Towards Agent-based  Large-scale Social Movement Simulation\", \"topic\": \"Bias in Language Models\", \"x\": 4.101, \"y\": 2.828}, {\"title\": \"Data-freeWeight Compress and Denoise for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.27, \"y\": 2.323}, {\"title\": \"Finer: Investigating and Enhancing Fine-Grained Visual Concept  Recognition in Large Vision Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.196, \"y\": 7.668}, {\"title\": \"QASE Enhanced PLMs: Improved Control in Text Generation for MRC\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.898, \"y\": 4.226}, {\"title\": \"Chain-of-Discussion: A Multi-Model Framework for Complex Evidence-Based  Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.408, \"y\": 4.538}, {\"title\": \"UniRetriever: Multi-task Candidates Selection for Various  Context-Adaptive Conversational Retrieval\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.333, \"y\": 3.641}, {\"title\": \"Learning Translations: Emergent Communication Pretraining for  Cooperative Language Acquisition\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.989, \"y\": 1.461}, {\"title\": \"RAM-EHR: Retrieval Augmentation Meets Clinical Predictions on Electronic  Health Records\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.233, \"y\": 7.49}, {\"title\": \"IR2: Information Regularization for Information Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.098, \"y\": 4.682}, {\"title\": \"ASEM: Enhancing Empathy in Chatbot through Attention-based Sentiment and  Emotion Modeling\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.644, \"y\": 5.58}, {\"title\": \"Defending Large Language Models against Jailbreak Attacks via Semantic  Smoothing\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.139, \"y\": 0.517}, {\"title\": \"Hitting \\\"Probe\\\"rty with Non-Linearity, and More\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.764, \"y\": 3.015}, {\"title\": \"DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM  Jailbreakers\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.074, \"y\": 0.513}, {\"title\": \"DistALANER: Distantly Supervised Active Learning Augmented Named Entity  Recognition in the Open Source Software Ecosystem\", \"topic\": \"Named Entity Recognition\", \"x\": 6.043, \"y\": 6.541}, {\"title\": \"PeriodicLoRA: Breaking the Low-Rank Bottleneck in LoRA Optimization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.857, \"y\": 1.762}, {\"title\": \"Knowledge Fusion of Chat LLMs: A Preliminary Technical Report\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.481, \"y\": 1.996}, {\"title\": \"Training a Bilingual Language Model by Mapping Tokens onto a Shared  Character Space\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.349, \"y\": 4.596}, {\"title\": \"Evaluating Robustness of Generative Search Engine on Adversarial Factual  Questions\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.378, \"y\": 0.906}, {\"title\": \"LSTP: Language-guided Spatial-Temporal Prompt Learning for Long-form  Video-Text Understanding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.742, \"y\": 7.478}, {\"title\": \"LLMs with Chain-of-Thought Are Non-Causal Reasoners\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.393, \"y\": 2.131}, {\"title\": \"EHRNoteQA: An LLM Benchmark for Real-World Clinical Practice Using  Discharge Summaries\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.996, \"y\": 7.265}, {\"title\": \"Deep Learning Approaches for Improving Question Answering Systems in  Hepatocellular Carcinoma Research\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.841, \"y\": 7.27}, {\"title\": \"Emotion Classification in Short English Texts using Deep Learning  Techniques\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.622, \"y\": 5.322}, {\"title\": \"Don't Forget Your Reward Values: Language Model Alignment via  Value-based Calibration\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.583, \"y\": 0.577}, {\"title\": \"LoRA Meets Dropout under a Unified Framework\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.661, \"y\": 2.239}, {\"title\": \"PST-Bench: Tracing and Benchmarking the Source of Publications\", \"topic\": \"Text Summarization\", \"x\": 5.08, \"y\": 5.832}, {\"title\": \"ASETF: A Novel Method for Jailbreak Attack on LLMs through Translate  Suffix Embeddings\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.132, \"y\": 0.661}, {\"title\": \"A Machine Learning Approach to Detect Customer Satisfaction From  Multiple Tweet Parameters\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.236, \"y\": 4.983}, {\"title\": \"$C^3$: Confidence Calibration Model Cascade for Inference-Efficient  Cross-Lingual Natural Language Understanding\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.121, \"y\": 4.173}, {\"title\": \"Likelihood-based Mitigation of Evaluation Bias in Large Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.536, \"y\": 3.5}, {\"title\": \"Phonetic and Lexical Discovery of a Canine Language using HuBERT\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.193, \"y\": 5.897}, {\"title\": \"Direct Punjabi to English speech translation using discrete units\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.045, \"y\": 5.667}, {\"title\": \"Cognitive Bias in High-Stakes Decision-Making with LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.758, \"y\": 2.751}, {\"title\": \"Bootstrapping Cognitive Agents with a Large Language Model\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.091, \"y\": 1.381}, {\"title\": \"Debug like a Human: A Large Language Model Debugger via Verifying  Runtime Execution Step-by-step\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.11, \"y\": 0.161}, {\"title\": \"Bridging the Gap between 2D and 3D Visual Question Answering: A Fusion  Approach for 3D VQA\", \"topic\": \"Multimodal Language Models\", \"x\": 7.914, \"y\": 7.554}, {\"title\": \"QuaCer-C: Quantitative Certification of Knowledge Comprehension in LLMs\", \"topic\": \"Large Language Models in Education\", \"x\": 7.046, \"y\": 2.879}, {\"title\": \"MultiContrievers: Analysis of Dense Retrieval Representations\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.292, \"y\": 4.537}, {\"title\": \"PRP: Propagating Universal Perturbations to Attack Large Language Model  Guard-Rails\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.131, \"y\": 0.667}, {\"title\": \"Abdelhak at SemEval-2024 Task 9 : Decoding Brainteasers, The Efficacy of  Dedicated Models Versus ChatGPT\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.203, \"y\": 1.965}, {\"title\": \"SemEval-2024 Task 8: Weighted Layer Averaging RoBERTa for Black-Box  Machine-Generated Text Detection\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.69, \"y\": 1.739}, {\"title\": \"MATHWELL: Generating Age-Appropriate Educational Math Word Problems\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.646, \"y\": 1.239}, {\"title\": \"On Efficiently Representing Regular Languages as RNNs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.25, \"y\": 2.91}, {\"title\": \"OAG-Bench: A Human-Curated Benchmark for Academic Graph Mining\", \"topic\": \"Text Summarization\", \"x\": 5.11, \"y\": 5.966}, {\"title\": \"Empowering Large Language Model Agents through Action Learning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.201, \"y\": 1.288}, {\"title\": \"Enhancing Cloud-Based Large Language Model Processing with Elasticsearch  and Transformer Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.538, \"y\": 4.424}, {\"title\": \"Look Before You Leap: Problem Elaboration Prompting Improves  Mathematical Reasoning in Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.683, \"y\": 1.406}, {\"title\": \"Stepwise Self-Consistent Mathematical Reasoning with Large Language  Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.674, \"y\": 1.233}, {\"title\": \"Chimera: A Lossless Decoding Method for Accelerating Large Language  Models Inference by Fusing all Tokens\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.43, \"y\": 3.252}, {\"title\": \"Dental Severity Assessment through Few-shot Learning and SBERT  Fine-tuning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.111, \"y\": 7.663}, {\"title\": \"Sparse MeZO: Less Parameters for Better Performance in Zeroth-Order LLM  Fine-Tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.975, \"y\": 2.016}, {\"title\": \"GAOKAO-MM: A Chinese Human-Level Benchmark for Multimodal Models  Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.002, \"y\": 7.769}, {\"title\": \"MemeCraft: Contextual and Stance-Driven Multimodal Meme Generation\", \"topic\": \"Bias in Language Models\", \"x\": 2.765, \"y\": 3.52}, {\"title\": \"How Do Humans Write Code? Large Models Do It the Same Way Too\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.538, \"y\": 1.314}, {\"title\": \"Making Pre-trained Language Models Better Continual Few-Shot Relation  Extractors\", \"topic\": \"Named Entity Recognition\", \"x\": 6.311, \"y\": 6.546}, {\"title\": \"Query Augmentation by Decoding Semantics from Brain Signals\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.021, \"y\": 4.596}, {\"title\": \"CoRelation: Boosting Automatic ICD Coding Through Contextualized Code  Relation Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.228, \"y\": 7.538}, {\"title\": \"Foot In The Door: Understanding Large Language Model Jailbreaking via  Cognitive Psychology\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.99, \"y\": 0.406}, {\"title\": \"Leveraging ChatGPT in Pharmacovigilance Event Extraction: An Empirical  Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.175, \"y\": 7.013}, {\"title\": \"Uncovering Customer Issues through Topological Natural Language Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.355, \"y\": 4.925}, {\"title\": \"Exploring Failure Cases in Multimodal Reasoning About Physical Dynamics\", \"topic\": \"Multimodal Language Models\", \"x\": 7.717, \"y\": 7.364}, {\"title\": \"Fine-Grained Self-Endorsement Improves Factuality and Reasoning\", \"topic\": \"Large Language Models in Education\", \"x\": 6.078, \"y\": 3.348}, {\"title\": \"Selective \\\"Selective Prediction\\\": Reducing Unnecessary Abstention in  Vision-Language Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.011, \"y\": 7.63}, {\"title\": \"Alternating Weak Triphone/BPE Alignment Supervision from Hybrid Model  Improves End-to-End ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.615, \"y\": 5.651}, {\"title\": \"Prompting LLMs to Compose Meta-Review Drafts from Peer-Review Narratives  of Scholarly Manuscripts\", \"topic\": \"Text Summarization\", \"x\": 4.983, \"y\": 5.762}, {\"title\": \"DOSA: A Dataset of Social Artifacts from Different Indian Geographical  Subcultures\", \"topic\": \"Bias in Language Models\", \"x\": 4.126, \"y\": 2.739}, {\"title\": \"CI w/o TN: Context Injection without Task Name for Procedure Planning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.474, \"y\": 7.239}, {\"title\": \"Social Convos: Capturing Agendas and Emotions on Social Media\", \"topic\": \"Bias in Language Models\", \"x\": 3.213, \"y\": 3.941}, {\"title\": \"Fast Adversarial Attacks on Language Models In One GPU Minute\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.173, \"y\": 0.748}, {\"title\": \"AgentOhana: Design Unified Data and Training Pipeline for Effective  Agent Learning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.251, \"y\": 1.441}, {\"title\": \"Self-Retrieval: Building an Information Retrieval System with One Large  Language Model\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.074, \"y\": 4.627}, {\"title\": \"The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented  Generation (RAG)\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.736, \"y\": 0.262}, {\"title\": \"Prejudice and Volatility: A Statistical Framework for Measuring Social  Discrimination in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.243, \"y\": 2.77}, {\"title\": \"Leveraging Domain Knowledge for Efficient Reward Modelling in RLHF: A  Case-Study in E-Commerce Opinion Summarization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.266, \"y\": 0.877}, {\"title\": \"Brain-Inspired Two-Stage Approach: Enhancing Mathematical Reasoning by  Imitating Human Thought Processes\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.614, \"y\": 1.254}, {\"title\": \"An Empirical Study of Data Ability Boundary in LLMs' Math Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.653, \"y\": 1.252}, {\"title\": \"A Data-Centric Approach To Generate Faithful and High Quality Patient  Summaries with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.023, \"y\": 7.498}, {\"title\": \"PREDILECT: Preferences Delineated with Zero-Shot Language-based  Reasoning in Reinforcement Learning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.85, \"y\": 1.08}, {\"title\": \"Faithful Temporal Question Answering over Heterogeneous Sources\", \"topic\": \"Named Entity Recognition\", \"x\": 6.548, \"y\": 5.264}, {\"title\": \"NuNER: Entity Recognition Encoder Pre-training via LLM-Annotated Data\", \"topic\": \"Named Entity Recognition\", \"x\": 6.242, \"y\": 6.871}, {\"title\": \"GPTVQ: The Blessing of Dimensionality for LLM Quantization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.603, \"y\": 2.24}, {\"title\": \"ArabianGPT: Native Arabic GPT-based Large Language Model\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.811, \"y\": 4.656}, {\"title\": \"How (un)ethical are instruction-centric responses of LLMs? Unveiling the  vulnerabilities of safety guardrails to harmful queries\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.702, \"y\": 1.238}, {\"title\": \"Seeing is Believing: Mitigating Hallucination in Large Vision-Language  Models via CLIP-Guided Decoding\", \"topic\": \"Multimodal Language Models\", \"x\": 8.379, \"y\": 8.013}, {\"title\": \"Chitchat as Interference: Adding User Backstories to Task-Oriented  Dialogues\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.243, \"y\": 3.151}, {\"title\": \"GPT-HateCheck: Can LLMs Write Better Functional Tests for Hate Speech  Detection?\", \"topic\": \"Bias in Language Models\", \"x\": 2.454, \"y\": 3.351}, {\"title\": \"ChunkAttention: Efficient Self-Attention with Prefix-Aware KV Cache and  Two-Phase Partition\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.321, \"y\": 2.843}, {\"title\": \"BSPA: Exploring Black-box Stealthy Prompt Attacks against Image  Generators\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.885, \"y\": 1.217}, {\"title\": \"DeMPT: Decoding-enhanced Multi-phase Prompt Tuning for Making LLMs Be  Better Context-aware Translators\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.805, \"y\": 4.468}, {\"title\": \"Biomedical Entity Linking as Multiple Choice Question Answering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.664, \"y\": 7.159}, {\"title\": \"Break the Breakout: Reinventing LM Defense Against Jailbreak Attacks  with Self-Refinement\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.167, \"y\": 0.669}, {\"title\": \"Advancing Parameter Efficiency in Fine-tuning via Representation Editing\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.766, \"y\": 1.784}, {\"title\": \"Entity-level Factual Adaptiveness of Fine-tuning based Abstractive  Summarization Models\", \"topic\": \"Text Summarization\", \"x\": 5.136, \"y\": 5.111}, {\"title\": \"Machine Unlearning of Pre-trained Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.035, \"y\": 0.602}, {\"title\": \"Speech Corpus for Korean Children with Autism Spectrum Disorder: Towards  Automatic Assessment Systems\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.409, \"y\": 6.239}, {\"title\": \"A First Look at GPT Apps: Landscape and Vulnerability\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.119, \"y\": 0.442}, {\"title\": \"Evaluating the Performance of ChatGPT for Spam Email Detection\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.163, \"y\": 1.768}, {\"title\": \"PEMT: Multi-Task Correlation Guided Mixture-of-Experts Enables  Parameter-Efficient Transfer Learning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.248, \"y\": 2.073}, {\"title\": \"Fine-tuning Large Language Models for Domain-specific Machine  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.639, \"y\": 4.494}, {\"title\": \"On the Multi-turn Instruction Following for Conversational Web Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.999, \"y\": 1.663}, {\"title\": \"Interpreting Context Look-ups in Transformers: Investigating  Attention-MLP Interactions\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.076, \"y\": 2.836}, {\"title\": \"KIEval: A Knowledge-grounded Interactive Evaluation Framework for Large  Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.661, \"y\": 3.207}, {\"title\": \"CLoVe: Encoding Compositional Language in Contrastive Vision-Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.407, \"y\": 7.53}, {\"title\": \"Towards Few-Shot Adaptation of Foundation Models via Multitask  Finetuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.237, \"y\": 2.068}, {\"title\": \"CommVQA: Situating Visual Question Answering in Communicative Contexts\", \"topic\": \"Multimodal Language Models\", \"x\": 7.808, \"y\": 7.853}, {\"title\": \"Divide-or-Conquer? Which Part Should You Distill Your LLM?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.521, \"y\": 1.901}, {\"title\": \"tinyBenchmarks: evaluating LLMs with fewer examples\", \"topic\": \"Large Language Models in Education\", \"x\": 6.908, \"y\": 3.035}, {\"title\": \"Optimizing Language Models for Human Preferences is a Causal Inference  Problem\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.277, \"y\": 0.606}, {\"title\": \"Introducing GenCeption for Multimodal LLM Benchmarking: You May Bypass  Annotations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.175, \"y\": 7.386}, {\"title\": \"Mitigating Fine-tuning based Jailbreak Attack with Backdoor Enhanced  Safety Alignment\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.308, \"y\": 0.653}, {\"title\": \"Mirror: A Multiple-perspective Self-Reflection Method for Knowledge-rich  Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.181, \"y\": 1.977}, {\"title\": \"In-Context Learning of a Linear Transformer Block: Benefits of the MLP  Component and One-Step GD Initialization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.195, \"y\": 2.711}, {\"title\": \"Re-Examine Distantly Supervised NER: A New Benchmark and a Simple  Approach\", \"topic\": \"Named Entity Recognition\", \"x\": 6.205, \"y\": 6.8}, {\"title\": \"PALO: A Polyglot Large Multimodal Model for 5B People\", \"topic\": \"Multimodal Language Models\", \"x\": 8.028, \"y\": 7.739}, {\"title\": \"CriticBench: Benchmarking LLMs for Critique-Correct Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.127, \"y\": 2.016}, {\"title\": \"MobileLLM: Optimizing Sub-billion Parameter Language Models for  On-Device Use Cases\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.255, \"y\": 2.608}, {\"title\": \"RelayAttention for Efficient Large Language Model Serving with Long  System Prompts\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.252, \"y\": 2.876}, {\"title\": \"Measuring Multimodal Mathematical Reasoning with MATH-Vision Dataset\", \"topic\": \"Multimodal Language Models\", \"x\": 7.551, \"y\": 7.639}, {\"title\": \"Not All Experts are Equal: Efficient Expert Pruning and Skipping for  Mixture-of-Experts Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.923, \"y\": 2.242}, {\"title\": \"MT-Bench-101: A Fine-Grained Benchmark for Evaluating Large Language  Models in Multi-Turn Dialogues\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.25, \"y\": 3.173}, {\"title\": \"Generalizing Reward Modeling for Out-of-Distribution Preference Learning\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.47, \"y\": 0.634}, {\"title\": \"Tokenization counts: the impact of tokenization on arithmetic in  frontier LLMs\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.944, \"y\": 1.465}, {\"title\": \"Scaling Efficient LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.918, \"y\": 2.346}, {\"title\": \"Large Language Models as Urban Residents: An LLM Agent Framework for  Personal Mobility Generation\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.35, \"y\": 1.715}, {\"title\": \"Efficient and Effective Vocabulary Expansion Towards Multilingual Large  Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.001, \"y\": 3.862}, {\"title\": \"IEPile: Unearthing Large-Scale Schema-Based Information Extraction  Corpus\", \"topic\": \"Named Entity Recognition\", \"x\": 6.42, \"y\": 6.434}, {\"title\": \"InfFeed: Influence Functions as a Feedback to Improve the Performance of  Subjective Tasks\", \"topic\": \"Bias in Language Models\", \"x\": 2.637, \"y\": 3.607}, {\"title\": \"COMPASS: Computational Mapping of Patient-Therapist Alliance Strategies  with Language Modeling\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.034, \"y\": 6.51}, {\"title\": \"Unveiling Linguistic Regions in Large Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.061, \"y\": 3.786}, {\"title\": \"Middleware for LLMs: Tools Are Instrumental for Language Agents in  Complex Environments\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.313, \"y\": 1.62}, {\"title\": \"ConceptMath: A Bilingual Concept-wise Benchmark for Measuring  Mathematical Reasoning of Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.669, \"y\": 1.296}, {\"title\": \"OpenCodeInterpreter: Integrating Code Generation with Execution and  Refinement\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.119, \"y\": 0.057}, {\"title\": \"RoboScript: Code Generation for Free-Form Manipulation Tasks across Real  and Simulation\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.329, \"y\": 1.213}, {\"title\": \"From Keywords to Structured Summaries: Streamlining Scholarly Knowledge  Access\", \"topic\": \"Text Summarization\", \"x\": 5.051, \"y\": 5.968}, {\"title\": \"LLM-DA: Data Augmentation via Large Language Models for Few-Shot Named  Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 6.262, \"y\": 6.823}, {\"title\": \"SIMPLOT: Enhancing Chart Question Answering by Distilling Essentials\", \"topic\": \"Multimodal Language Models\", \"x\": 7.388, \"y\": 7.364}, {\"title\": \"Less is More: Mitigating Multimodal Hallucination from an EOS Decision  Perspective\", \"topic\": \"Multimodal Language Models\", \"x\": 8.381, \"y\": 8.042}, {\"title\": \"Should We Respect LLMs? A Cross-Lingual Study on the Influence of Prompt  Politeness on LLM Performance\", \"topic\": \"Bias in Language Models\", \"x\": 4.275, \"y\": 2.504}, {\"title\": \"Malaysian English News Decoded: A Linguistic Resource for Named Entity  and Relation Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.153, \"y\": 6.833}, {\"title\": \"\\\"My Answer is C\\\": First-Token Probabilities Do Not Match Text Answers in  Instruction-Tuned Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.588, \"y\": 2.745}, {\"title\": \"LLMBind: A Unified Modality-Task Integration Framework\", \"topic\": \"Multimodal Language Models\", \"x\": 8.18, \"y\": 6.951}, {\"title\": \"Towards Robust Instruction Tuning on Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.52, \"y\": 7.088}, {\"title\": \"Annotation and Classification of Relevant Clauses in  Terms-and-Conditions Contracts\", \"topic\": \"Legal NLP\", \"x\": 4.416, \"y\": 4.499}, {\"title\": \"Do LLMs Implicitly Determine the Suitable Text Difficulty for Users?\", \"topic\": \"Large Language Models in Education\", \"x\": 6.542, \"y\": 2.495}, {\"title\": \"COBIAS: Contextual Reliability in Bias Assessment\", \"topic\": \"Bias in Language Models\", \"x\": 3.248, \"y\": 2.721}, {\"title\": \"KoCoSa: Korean Context-aware Sarcasm Detection Dataset\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.549, \"y\": 4.856}, {\"title\": \"Transferring BERT Capabilities from High-Resource to Low-Resource  Languages Using Vocabulary Matching\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.094, \"y\": 3.964}, {\"title\": \"Efficient data selection employing Semantic Similarity-based Graph  Structures for model training\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.759, \"y\": 5.504}, {\"title\": \"Chain-of-History Reasoning for Temporal Knowledge Graph Forecasting\", \"topic\": \"Named Entity Recognition\", \"x\": 6.611, \"y\": 5.526}, {\"title\": \"Novi jezi\\u010dki modeli za srpski jezik\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.797, \"y\": 4.535}, {\"title\": \"Small Language Model Is a Good Guide for Large Language Model in Chinese  Entity Relation Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.295, \"y\": 6.545}, {\"title\": \"Rethinking Scientific Summarization Evaluation: Grounding Explainable  Metrics on Facet-aware Benchmark\", \"topic\": \"Text Summarization\", \"x\": 5.068, \"y\": 5.489}, {\"title\": \"INSTRUCTIR: A Benchmark for Instruction Following of Information  Retrieval Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.146, \"y\": 4.545}, {\"title\": \"Understanding and Patching Compositional Reasoning in LLMs\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.491, \"y\": 2.122}, {\"title\": \"Subobject-level Image Tokenization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.229, \"y\": 7.638}, {\"title\": \"Assessing generalization capability of text ranking models in Polish\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.962, \"y\": 4.631}, {\"title\": \"Hint-before-Solving Prompting: Guiding LLMs to Effectively Utilize  Encoded Knowledge\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.306, \"y\": 1.782}, {\"title\": \"TinyLLaVA: A Framework of Small-scale Large Multimodal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.338, \"y\": 7.291}, {\"title\": \"Mitigating the Linguistic Gap with Phonemic Representations for Robust  Multilingual Language Understanding\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.108, \"y\": 4.211}, {\"title\": \"GATE X-E : A Challenge Set for Gender-Fair Translations from  Weakly-Gendered Languages\", \"topic\": \"Bias in Language Models\", \"x\": 3.132, \"y\": 2.652}, {\"title\": \"Can Large Language Models Detect Misinformation in Scientific News  Reporting?\", \"topic\": \"Bias in Language Models\", \"x\": 3.76, \"y\": 3.918}, {\"title\": \"Word-Sequence Entropy: Towards Uncertainty Estimation in Free-Form  Medical Question Answering Applications and Beyond\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.991, \"y\": 7.121}, {\"title\": \"Framing in the Presence of Supporting Data: A Case Study in U.S.  Economic News\", \"topic\": \"Bias in Language Models\", \"x\": 3.366, \"y\": 4.032}, {\"title\": \"LLM-Assisted Content Conditional Debiasing for Fair Text Embedding\", \"topic\": \"Bias in Language Models\", \"x\": 3.079, \"y\": 2.635}, {\"title\": \"Towards Understanding Counseling Conversations: Domain Knowledge and  Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 2.968, \"y\": 6.394}, {\"title\": \"A Study on the Vulnerability of Test Questions against ChatGPT-based  Cheating\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.695, \"y\": 7.191}, {\"title\": \"Bangla AI: A Framework for Machine Translation Utilizing Large Language  Models for Ethnic Media\", \"topic\": \"Bias in Language Models\", \"x\": 3.73, \"y\": 2.64}, {\"title\": \"Can Similarity-Based Domain-Ordering Reduce Catastrophic Forgetting for  Intent Recognition?\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.354, \"y\": 3.346}, {\"title\": \"BIRCO: A Benchmark of Information Retrieval Tasks with Complex  Objectives\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.052, \"y\": 4.668}, {\"title\": \"Combining Language and Graph Models for Semi-structured Information  Extraction on the Web\", \"topic\": \"Named Entity Recognition\", \"x\": 6.323, \"y\": 6.403}, {\"title\": \"LexC-Gen: Generating Data for Extremely Low-Resource Languages with  Large Language Models and Bilingual Lexicons\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.226, \"y\": 4.433}, {\"title\": \"Improving Language Understanding from Screenshots\", \"topic\": \"Multimodal Language Models\", \"x\": 8.25, \"y\": 7.311}, {\"title\": \"Coercing LLMs to do and reveal (almost) anything\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.297, \"y\": 0.801}, {\"title\": \"Is LLM-as-a-Judge Robust? Investigating Universal Adversarial Attacks on  Zero-shot LLM Assessment\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.431, \"y\": 0.989}, {\"title\": \"OlympiadBench: A Challenging Benchmark for Promoting AGI with  Olympiad-Level Bilingual Multimodal Scientific Problems\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.684, \"y\": 1.567}, {\"title\": \"What's in a Name? Auditing Large Language Models for Race and Gender  Bias\", \"topic\": \"Bias in Language Models\", \"x\": 3.33, \"y\": 2.683}, {\"title\": \"Towards Building Multilingual Language Model for Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.029, \"y\": 7.468}, {\"title\": \"Measuring Social Biases in Masked Language Models by Proxy of Prediction  Quality\", \"topic\": \"Bias in Language Models\", \"x\": 3.169, \"y\": 2.737}, {\"title\": \"Making Reasoning Matter: Measuring and Improving Faithfulness of  Chain-of-Thought Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.376, \"y\": 1.961}, {\"title\": \"Technical Report on the Checkfor.ai AI-Generated Text Classifier\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.813, \"y\": 1.758}, {\"title\": \"Distinctive Image Captioning: Leveraging Ground Truth Captions in CLIP  Guided Reinforcement Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.516, \"y\": 7.403}, {\"title\": \"Do Efficient Transformers Really Save Computation?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.209, \"y\": 2.812}, {\"title\": \"Large Language Models are Vulnerable to Bait-and-Switch Attacks for  Generating Harmful Content\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.509, \"y\": 1.044}, {\"title\": \"SYNFAC-EDIT: Synthetic Imitation Edit Feedback for Factual Alignment in  Clinical Summarization\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.051, \"y\": 7.323}, {\"title\": \"Could We Have Had Better Multilingual LLMs If English Was Not the  Central Language?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.416, \"y\": 4.362}, {\"title\": \"Calibrating Large Language Models with Sample Consistency\", \"topic\": \"Large Language Models in Education\", \"x\": 6.893, \"y\": 2.876}, {\"title\": \"Beyond Probabilities: Unveiling the Misalignment in Evaluating Large  Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.69, \"y\": 2.976}, {\"title\": \"Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts  Against Open-source LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.989, \"y\": 0.397}, {\"title\": \"Large Language Models are Advanced Anonymizers\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.674, \"y\": 0.337}, {\"title\": \"Beyond Hate Speech: NLP's Challenges and Opportunities in Uncovering  Dehumanizing Language\", \"topic\": \"Bias in Language Models\", \"x\": 2.473, \"y\": 3.31}, {\"title\": \"The Geography of Information Diffusion in Online Discourse on Europe and  Migration\", \"topic\": \"Bias in Language Models\", \"x\": 3.187, \"y\": 4.064}, {\"title\": \"Factual Consistency Evaluation of Summarisation in the Era of Large  Language Models\", \"topic\": \"Text Summarization\", \"x\": 4.913, \"y\": 5.353}, {\"title\": \"LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.617, \"y\": 2.968}, {\"title\": \"Unlocking Instructive In-Context Learning with Tabular Prompting for  Relational Triple Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.375, \"y\": 6.551}, {\"title\": \"SaGE: Evaluating Moral Consistency in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.029, \"y\": 2.165}, {\"title\": \"CMNER: A Chinese Multimodal NER Dataset based on Social Media\", \"topic\": \"Named Entity Recognition\", \"x\": 6.503, \"y\": 6.933}, {\"title\": \"Self-Distillation Bridges Distribution Gap in Language Model Fine-Tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.974, \"y\": 2.229}, {\"title\": \"Privacy-Preserving Instructions for Aligning Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.799, \"y\": 0.197}, {\"title\": \"A Unified Framework and Dataset for Assessing Societal Bias in  Vision-Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.219, \"y\": 2.706}, {\"title\": \"MORE: Multi-mOdal REtrieval Augmented Generative Commonsense Reasoning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.065, \"y\": 7.397}, {\"title\": \"CODIS: Benchmarking Context-Dependent Visual Comprehension for  Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.93, \"y\": 7.61}, {\"title\": \"KorNAT: LLM Alignment Benchmark for Korean Social Values and Common  Knowledge\", \"topic\": \"Bias in Language Models\", \"x\": 4.069, \"y\": 2.68}, {\"title\": \"APTQ: Attention-aware Post-Training Mixed-Precision Quantization for  Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.559, \"y\": 2.273}, {\"title\": \"A Multimodal In-Context Tuning Approach for E-Commerce Product  Description Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.267, \"y\": 7.303}, {\"title\": \"WinoViz: Probing Visual Properties of Objects Under Different States\", \"topic\": \"Multimodal Language Models\", \"x\": 7.898, \"y\": 7.68}, {\"title\": \"BBA: Bi-Modal Behavioral Alignment for Reasoning with Large  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.658, \"y\": 7.62}, {\"title\": \"PCA-Bench: Evaluating Multimodal Large Language Models in  Perception-Cognition-Action Chain\", \"topic\": \"Multimodal Language Models\", \"x\": 7.993, \"y\": 7.163}, {\"title\": \"Analysis of Multi-Source Language Training in Cross-Lingual Transfer\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.251, \"y\": 4.252}, {\"title\": \"Cognitive Visual-Language Mapper: Advancing Multimodal Comprehension  with Enhanced Visual Knowledge Alignment\", \"topic\": \"Multimodal Language Models\", \"x\": 7.896, \"y\": 7.7}, {\"title\": \"ActiveRAG: Revealing the Treasures of Knowledge via Active Learning\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.41, \"y\": 4.32}, {\"title\": \"LLMs Meet Long Video: Advancing Long Video Comprehension with An  Interactive Visual Adapter in LLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.723, \"y\": 7.41}, {\"title\": \"ARL2: Aligning Retrievers for Black-box Large Language Models via  Self-guided Adaptive Relevance Labeling\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.546, \"y\": 4.384}, {\"title\": \"FinGPT-HPC: Efficient Pretraining and Finetuning Large Language Models  for Financial Applications with High-Performance Computing\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.148, \"y\": 2.219}, {\"title\": \"Backdoor Attacks on Dense Passage Retrievers for Disseminating  Misinformation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.333, \"y\": 0.756}, {\"title\": \"RecMind: Japanese Movie Recommendation Dialogue with Seeker's Internal  State\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.197, \"y\": 3.719}, {\"title\": \"RITFIS: Robust input testing framework for LLMs-based intelligent  software\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.775, \"y\": 1.094}, {\"title\": \"Round Trip Translation Defence against Large Language Model Jailbreaking  Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.185, \"y\": 0.701}, {\"title\": \"ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity  within Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.17, \"y\": 2.426}, {\"title\": \"Self-DC: When to retrieve and When to generate? Self Divide-and-Conquer  for Compositional Unknown Questions\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.683, \"y\": 4.658}, {\"title\": \"From Self-Attention to Markov Models: Unveiling the Dynamics of  Generative Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.253, \"y\": 3.165}, {\"title\": \"Evaluation of a semi-autonomous attentive listening system with takeover  prompting\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.136, \"y\": 3.091}, {\"title\": \"Leveraging Translation For Optimal Recall: Tailoring LLM Personalization  With User Profiles\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.85, \"y\": 4.609}, {\"title\": \"GradSafe: Detecting Jailbreak Prompts for LLMs via Safety-Critical  Gradient Analysis\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.118, \"y\": 0.569}, {\"title\": \"Retrieval Helps or Hurts? A Deeper Dive into the Efficacy of Retrieval  Augmentation to Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.553, \"y\": 4.456}, {\"title\": \"ProPD: Dynamic Token Tree Pruning and Generation for LLM Parallel  Decoding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.528, \"y\": 3.256}, {\"title\": \"Potential and Challenges of Model Editing for Social Debiasing\", \"topic\": \"Bias in Language Models\", \"x\": 3.209, \"y\": 2.617}, {\"title\": \"Learning to Poison Large Language Models During Instruction Tuning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.278, \"y\": 0.824}, {\"title\": \"LocalTweets to LocalHealth: A Mental Health Surveillance Framework Based  on Twitter Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.321, \"y\": 6.289}, {\"title\": \"CAMELoT: Towards Large Language Models with Training-Free Consolidated  Associative Memory\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.735, \"y\": 3.068}, {\"title\": \"Ranking Large Language Models without Ground Truth\", \"topic\": \"Large Language Models in Education\", \"x\": 6.462, \"y\": 3.038}, {\"title\": \"ED-Copilot: Reduce Emergency Department Wait Time with Language Model  Diagnostic Assistance\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.927, \"y\": 7.416}, {\"title\": \"DrBenchmark: A Large Language Understanding Evaluation Benchmark for  French Biomedical Domain\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.672, \"y\": 7.28}, {\"title\": \"Explaining Relationships Among Research Papers\", \"topic\": \"Text Summarization\", \"x\": 4.983, \"y\": 5.839}, {\"title\": \"Healthcare Copilot: Eliciting the Power of General LLMs for Medical  Consultation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.713, \"y\": 7.313}, {\"title\": \"Reliable LLM-based User Simulator for Task-Oriented Dialogue Systems\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.284, \"y\": 3.01}, {\"title\": \"ChatEL: Entity Linking with Chatbots\", \"topic\": \"Named Entity Recognition\", \"x\": 6.387, \"y\": 6.111}, {\"title\": \"A Simple but Effective Approach to Improve Structured Language Model  Output for Information Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.238, \"y\": 6.519}, {\"title\": \"CounterCurate: Enhancing Physical and Semantic Visio-Linguistic  Compositional Reasoning via Counterfactual Examples\", \"topic\": \"Multimodal Language Models\", \"x\": 8.267, \"y\": 7.529}, {\"title\": \"BiMediX: Bilingual Medical Mixture of Experts LLM\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.991, \"y\": 7.574}, {\"title\": \"TofuEval: Evaluating Hallucinations of LLMs on Topic-Focused Dialogue  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.146, \"y\": 4.992}, {\"title\": \"Exploring the Frontier of Vision-Language Models: A Survey of Current  Methodologies and Future Directions\", \"topic\": \"Multimodal Language Models\", \"x\": 8.119, \"y\": 7.667}, {\"title\": \"Investigating Cultural Alignment of Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.001, \"y\": 2.698}, {\"title\": \"Smaug: Fixing Failure Modes of Preference Optimisation with DPO-Positive\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.492, \"y\": 0.6}, {\"title\": \"AgentMD: Empowering Language Agents for Risk Prediction with Large-Scale  Clinical Tool Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.854, \"y\": 7.267}, {\"title\": \"RoCode: A Dataset for Measuring Code Intelligence from Problem  Definitions in Romanian\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.135, \"y\": 0.087}, {\"title\": \"How Easy is It to Fool Your Multimodal LLMs? An Empirical Analysis on  Deceptive Prompts\", \"topic\": \"Multimodal Language Models\", \"x\": 8.241, \"y\": 7.948}, {\"title\": \"Softmax Probabilities (Mostly) Predict Large Language Model Correctness  on Multiple-Choice Q&A\", \"topic\": \"Large Language Models in Education\", \"x\": 6.833, \"y\": 2.847}, {\"title\": \"How do Hyenas deal with Human Speech? Speech Recognition and Translation  with ConfHyena\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.871, \"y\": 2.921}, {\"title\": \"Question Calibration and Multi-Hop Modeling for Temporal Question  Answering\", \"topic\": \"Named Entity Recognition\", \"x\": 6.596, \"y\": 5.318}, {\"title\": \"Benchmarking Retrieval-Augmented Generation for Medicine\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.937, \"y\": 7.141}, {\"title\": \"Is the System Message Really Important to Jailbreaks in Large Language  Models?\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.965, \"y\": 0.357}, {\"title\": \"AnnoTheia: A Semi-Automatic Annotation Toolkit for Audio-Visual Speech  Technologies\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.063, \"y\": 6.34}, {\"title\": \"The Hidden Space of Transformer Language Adapters\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.318, \"y\": 2.546}, {\"title\": \"TreeEval: Benchmark-Free Evaluation of Large Language Models through  Tree Planning\", \"topic\": \"Large Language Models in Education\", \"x\": 6.916, \"y\": 3.083}, {\"title\": \"When Only Time Will Tell: Interpreting How Transformers Process Local  Ambiguities Through the Lens of Restart-Incrementality\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.137, \"y\": 2.999}, {\"title\": \"ELAD: Explanation-Guided Large Language Models Active Distillation\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.749, \"y\": 2.057}, {\"title\": \"Identifying Semantic Induction Heads to Understand In-Context Learning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.53, \"y\": 2.761}, {\"title\": \"Effective and Efficient Conversation Retrieval for Dialogue State  Tracking with Implicit Text Summaries\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.248, \"y\": 3.531}, {\"title\": \"SiLLM: Large Language Models for Simultaneous Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.871, \"y\": 4.65}, {\"title\": \"Learning to Check: Unleashing Potentials for Self-Correction in Large  Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.248, \"y\": 1.741}, {\"title\": \"CFEVER: A Chinese Fact Extraction and VERification Dataset\", \"topic\": \"Bias in Language Models\", \"x\": 3.9, \"y\": 3.936}, {\"title\": \"SoMeLVLM: A Large Vision Language Model for Social Media Processing\", \"topic\": \"Multimodal Language Models\", \"x\": 7.995, \"y\": 7.273}, {\"title\": \"Understanding the effects of language-specific class imbalance in  multilingual fine-tuning\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.007, \"y\": 4.1}, {\"title\": \"Code Needs Comments: Enhancing Code LLMs with Comment Augmentation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.075, \"y\": 0.012}, {\"title\": \"Towards Trustworthy Reranking: A Simple yet Effective Abstention  Mechanism\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.948, \"y\": 4.622}, {\"title\": \"TRAP: Targeted Random Adversarial Prompt Honeypot for Black-Box  Identification\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.005, \"y\": 0.515}, {\"title\": \"Can GNN be Good Adapter for LLMs?\", \"topic\": \"Named Entity Recognition\", \"x\": 6.477, \"y\": 5.85}, {\"title\": \"Comparing Inferential Strategies of Humans and Large Language Models in  Deductive Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.347, \"y\": 2.181}, {\"title\": \"Gl\\u00f3rIA -- A Generative and Open Large Language Model for Portuguese\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.197, \"y\": 4.072}, {\"title\": \"Prompt Stealing Attacks Against Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.38, \"y\": 0.619}, {\"title\": \"Large Language Model-based Human-Agent Collaboration for Complex Task  Solving\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.99, \"y\": 1.432}, {\"title\": \"GRAFFORD: A Benchmark Dataset for Testing the Knowledge of Object  Affordances of Language and Vision Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.204, \"y\": 7.629}, {\"title\": \"Autism Detection in Speech -- A Survey\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.333, \"y\": 6.297}, {\"title\": \"Backward Lens: Projecting Language Model Gradients into the Vocabulary  Space\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.081, \"y\": 2.716}, {\"title\": \"Handling Ambiguity in Emotion: From Out-of-Domain Detection to  Distribution Estimation\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.543, \"y\": 5.351}, {\"title\": \"MoELoRA: Contrastive Learning Guided Mixture of Experts on  Parameter-Efficient Fine-Tuning for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.539, \"y\": 1.964}, {\"title\": \"ICON: Improving Inter-Report Consistency of Radiology Report Generation  via Lesion-aware Mix-up Augmentation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.239, \"y\": 8.126}, {\"title\": \"PANDA: Preference Adaptation for Enhancing Domain-Specific Abilities of  LLMs\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.732, \"y\": 0.888}, {\"title\": \"Identifying Factual Inconsistencies in Summaries: Grounding Model  Inference via Task Taxonomy\", \"topic\": \"Text Summarization\", \"x\": 5.15, \"y\": 4.958}, {\"title\": \"SymBa: Symbolic Backward Chaining for Multi-step Natural Language  Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.349, \"y\": 1.895}, {\"title\": \"Few shot clinical entity recognition in three languages: Masked language  models outperform LLM prompting\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.654, \"y\": 7.308}, {\"title\": \"Advancing Large Language Models to Capture Varied Speaking Styles and  Respond Properly in Spoken Conversations\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.195, \"y\": 3.495}, {\"title\": \"Understanding and Mitigating the Threat of Vec2Text to Dense Retrieval  Systems\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.701, \"y\": 0.379}, {\"title\": \"Acknowledgment of Emotional States: Generating Validating Responses for  Empathetic Dialogue\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.661, \"y\": 5.716}, {\"title\": \"Model Composition for Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.528, \"y\": 7.167}, {\"title\": \"Me LLaMA: Foundation Large Language Models for Medical Applications\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.146, \"y\": 7.403}, {\"title\": \"A Dual-Prompting for Interpretable Mental Health Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.35, \"y\": 6.529}, {\"title\": \"Modality-Aware Integration with Large Language Models for  Knowledge-based Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 7.837, \"y\": 7.652}, {\"title\": \"PRECISE Framework: GPT-based Text For Improved Readability, Reliability,  and Understandability of Radiology Reports For Patient-Centered Care\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.138, \"y\": 7.896}, {\"title\": \"HumanEval on Latest GPT Models -- 2024\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.119, \"y\": 0.15}, {\"title\": \"FormulaReasoning: A Dataset for Formula-Based Numerical Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.56, \"y\": 1.255}, {\"title\": \"Simpson's Paradox and the Accuracy-Fluency Tradeoff in Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.625, \"y\": 4.939}, {\"title\": \"SoftQE: Learned Representations of Queries Expanded by LLMs\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.357, \"y\": 4.76}, {\"title\": \"OWSM-CTC: An Open Encoder-Only Speech Foundation Model for Speech  Recognition, Translation, and Language Identification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.464, \"y\": 5.631}, {\"title\": \"CHATATC: Large Language Model-Driven Conversational Agents for  Supporting Strategic Air Traffic Flow Management\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.915, \"y\": 1.895}, {\"title\": \"Bias in Language Models: Beyond Trick Tests and Toward RUTEd Evaluation\", \"topic\": \"Bias in Language Models\", \"x\": 3.525, \"y\": 2.67}, {\"title\": \"StyleDubber: Towards Multi-Scale Style Learning for Movie Dubbing\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.041, \"y\": 6.082}, {\"title\": \"Generative AI Security: Challenges and Countermeasures\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.299, \"y\": 0.817}, {\"title\": \"Multimodal Fusion of EHR in Structures and Semantics: Integrating  Clinical Records and Notes with Hypergraph and LLM\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.207, \"y\": 7.625}, {\"title\": \"Evolving AI Collectives to Enhance Human Diversity and Enable  Self-Regulation\", \"topic\": \"Bias in Language Models\", \"x\": 4.072, \"y\": 2.349}, {\"title\": \"Detecting misinformation through Framing Theory: the Frame Element-based  Model\", \"topic\": \"Bias in Language Models\", \"x\": 3.545, \"y\": 3.751}, {\"title\": \"Asynchronous and Segmented Bidirectional Encoding for NMT\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.922, \"y\": 4.53}, {\"title\": \"Artifacts or Abduction: How Do LLMs Answer Multiple-Choice Questions  Without the Question?\", \"topic\": \"Large Language Models in Education\", \"x\": 6.841, \"y\": 2.978}, {\"title\": \"The Revolution of Multimodal Large Language Models: A Survey\", \"topic\": \"Multimodal Language Models\", \"x\": 8.395, \"y\": 7.172}, {\"title\": \"Understanding Fine-grained Distortions in Reports of Scientific Findings\", \"topic\": \"Bias in Language Models\", \"x\": 3.771, \"y\": 3.964}, {\"title\": \"A Critical Evaluation of AI Feedback for Aligning Large Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 6.027, \"y\": 1.049}, {\"title\": \"GTBench: Uncovering the Strategic Reasoning Limitations of LLMs via  Game-Theoretic Evaluations\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.116, \"y\": 1.659}, {\"title\": \"Emulated Disalignment: Safety Alignment for Large Language Models May  Backfire!\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.064, \"y\": 1.081}, {\"title\": \"Triple-Encoders: Representations That Fire Together, Wire Together\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.13, \"y\": 3.574}, {\"title\": \"Query-Based Adversarial Prompt Generation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.236, \"y\": 0.88}, {\"title\": \"Large Language Model for Mental Health: A Systematic Review\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.153, \"y\": 6.444}, {\"title\": \"ARKS: Active Retrieval in Knowledge Soup for Code Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.063, \"y\": 0.128}, {\"title\": \"TILP: Differentiable Learning of Temporal Logical Rules on Knowledge  Graphs\", \"topic\": \"Named Entity Recognition\", \"x\": 6.486, \"y\": 5.601}, {\"title\": \"Is Open-Source There Yet? A Comparative Study on Commercial and  Open-Source LLMs in Their Ability to Label Chest X-Ray Reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.165, \"y\": 7.884}, {\"title\": \"KARL: Knowledge-Aware Retrieval and Representations aid Retention and  Learning in Students\", \"topic\": \"Large Language Models in Education\", \"x\": 6.569, \"y\": 2.344}, {\"title\": \"Adaptive Skeleton Graph Decoding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.394, \"y\": 3.276}, {\"title\": \"Key ingredients for effective zero-shot cross-lingual knowledge transfer  in generative tasks\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.373, \"y\": 4.293}, {\"title\": \"WorldCoder, a Model-Based LLM Agent: Building World Models by Writing  Code and Interacting with the Environment\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.232, \"y\": 1.315}, {\"title\": \"Uncertainty quantification in fine-tuned LLMs using LoRA ensembles\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.57, \"y\": 1.779}, {\"title\": \"On the Semantic Latent Space of Diffusion-Based Text-to-Speech Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.923, \"y\": 6.134}, {\"title\": \"Shallow Synthesis of Knowledge in GPT-Generated Texts: A Case Study in  Automatic Related Work Composition\", \"topic\": \"Text Summarization\", \"x\": 5.004, \"y\": 5.772}, {\"title\": \"Analysis of Levenshtein Transformer's Decoder and Its Variants\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.773, \"y\": 4.651}, {\"title\": \"Same Task, More Tokens: the Impact of Input Length on the Reasoning  Performance of Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.526, \"y\": 2.329}, {\"title\": \"Task-Oriented Dialogue with In-Context Learning\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.357, \"y\": 2.817}, {\"title\": \"Empirical Study on Updating Key-Value Memories in Transformer  Feed-forward Layers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.014, \"y\": 2.281}, {\"title\": \"AnyGPT: Unified Multimodal LLM with Discrete Sequence Modeling\", \"topic\": \"Multimodal Language Models\", \"x\": 8.69, \"y\": 7.169}, {\"title\": \"CovRL: Fuzzing JavaScript Engines with Coverage-Guided Reinforcement  Learning for LLM-based Mutation\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.748, \"y\": 0.097}, {\"title\": \"Reformatted Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.887, \"y\": 0.839}, {\"title\": \"Polarization of Autonomous Generative AI Agents Under Echo Chambers\", \"topic\": \"Bias in Language Models\", \"x\": 4.265, \"y\": 2.799}, {\"title\": \"Enhancing Multilingual Capabilities of Large Language Models through  Self-Distillation from Resource-Rich Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.18, \"y\": 4.185}, {\"title\": \"Zero shot VLMs for hate meme detection: Are we there yet?\", \"topic\": \"Bias in Language Models\", \"x\": 2.479, \"y\": 3.445}, {\"title\": \"Browse and Concentrate: Comprehending Multimodal Content via prior-LLM  Context Fusion\", \"topic\": \"Multimodal Language Models\", \"x\": 8.258, \"y\": 7.362}, {\"title\": \"A Chinese Dataset for Evaluating the Safeguards in Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.898, \"y\": 1.357}, {\"title\": \"Stick to Your Role! Context-dependence and Stability of Personal Value  Expression in Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.358, \"y\": 2.516}, {\"title\": \"Amplifying Training Data Exposure through Fine-Tuning with  Pseudo-Labeled Memberships\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.757, \"y\": 0.578}, {\"title\": \"BIDER: Bridging Knowledge Inconsistency for Efficient  Retrieval-Augmented LLMs via Key Supporting Evidence\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.37, \"y\": 4.514}, {\"title\": \"Defending Against Weight-Poisoning Backdoor Attacks for  Parameter-Efficient Fine-Tuning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.215, \"y\": 0.835}, {\"title\": \"Your Large Language Model is Secretly a Fairness Proponent and You  Should Prompt it Like One\", \"topic\": \"Bias in Language Models\", \"x\": 3.278, \"y\": 2.72}, {\"title\": \"Purifying Large Language Models by Ensembling a Small Language Model\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.92, \"y\": 0.815}, {\"title\": \"Surprising Efficacy of Fine-Tuned Transformers for Fact-Checking over  Larger Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.921, \"y\": 3.952}, {\"title\": \"Evaluating Image Review Ability of Vision Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.503, \"y\": 7.276}, {\"title\": \"Is It a Free Lunch for Removing Outliers during Pretraining?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.62, \"y\": 2.15}, {\"title\": \"Groot: Adversarial Testing for Generative Text-to-Image Models with  Tree-based Semantic Transformation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.273, \"y\": 1.257}, {\"title\": \"Do Large Language Models Understand Logic or Just Mimick Context?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.429, \"y\": 2.234}, {\"title\": \"Can LLMs Compute with Reasons?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.262, \"y\": 2.237}, {\"title\": \"LVCHAT: Facilitating Long Video Comprehension\", \"topic\": \"Multimodal Language Models\", \"x\": 8.881, \"y\": 7.358}, {\"title\": \"EmoBench: Evaluating the Emotional Intelligence of Large Language Models\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.641, \"y\": 5.484}, {\"title\": \"WKVQuant: Quantizing Weight and Key/Value Cache for Large Language  Models Gains More\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.495, \"y\": 2.501}, {\"title\": \"Scaffolding Coordinates to Promote Vision-Language Coordination in Large  Multi-Modal Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.799, \"y\": 7.564}, {\"title\": \"Small Models, Big Insights: Leveraging Slim Proxy Models To Decide When  and What to Retrieve for LLMs\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.664, \"y\": 4.615}, {\"title\": \"Model Tailor: Mitigating Catastrophic Forgetting in Multi-modal Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.196, \"y\": 1.988}, {\"title\": \"Acquiring Clean Language Models from Backdoor Poisoned Datasets by  Downscaling Frequency Space\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.288, \"y\": 0.814}, {\"title\": \"Speech Translation with Speech Foundation Models and Large Language  Models: What is There and What is Missing?\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.783, \"y\": 5.766}, {\"title\": \"Distilling Large Language Models for Text-Attributed Graph Learning\", \"topic\": \"Named Entity Recognition\", \"x\": 6.535, \"y\": 5.926}, {\"title\": \"EBFT: Effective and Block-Wise Fine-Tuning for Sparse LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.996, \"y\": 1.914}, {\"title\": \"Compress to Impress: Unleashing the Potential of Compressive Memory in  Real-World Long-Term Conversations\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.282, \"y\": 3.266}, {\"title\": \"Automatic Evaluation for Mental Health Counseling using LLMs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.005, \"y\": 6.462}, {\"title\": \"Analysis of Multidomain Abstractive Summarization Using Salience  Allocation\", \"topic\": \"Text Summarization\", \"x\": 5.136, \"y\": 5.196}, {\"title\": \"LEMMA: Towards LVLM-Enhanced Multimodal Misinformation Detection with  External Knowledge Augmentation\", \"topic\": \"Bias in Language Models\", \"x\": 3.515, \"y\": 3.82}, {\"title\": \"Semantic Textual Similarity Assessment in Chest X-ray Reports Using a  Domain-Specific Cosine-Based Metric\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.202, \"y\": 7.948}, {\"title\": \"Direct Large Language Model Alignment Through Self-Rewarding Contrastive  Prompt Distillation\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.62, \"y\": 0.566}, {\"title\": \"DiLA: Enhancing LLM Tool Learning with Differential Logic Layer\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.104, \"y\": 1.67}, {\"title\": \"SIBO: A Simple Booster for Parameter-Efficient Fine-Tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.508, \"y\": 2.074}, {\"title\": \"Bridging or Breaking: Impact of Intergroup Interactions on Religious  Polarization\", \"topic\": \"Bias in Language Models\", \"x\": 3.013, \"y\": 3.647}, {\"title\": \"FeB4RAG: Evaluating Federated Search in the Context of Retrieval  Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.12, \"y\": 4.587}, {\"title\": \"RJUA-MedDQA: A Multimodal Benchmark for Medical Document Question  Answering and Clinical Reasoning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.25, \"y\": 7.95}, {\"title\": \"M2K-VDG: Model-Adaptive Multimodal Knowledge Anchor Enhanced  Video-grounded Dialogue Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.369, \"y\": 8.071}, {\"title\": \"Modularized Networks for Few-shot Hateful Meme Detection\", \"topic\": \"Bias in Language Models\", \"x\": 2.496, \"y\": 3.421}, {\"title\": \"Ask Optimal Questions: Aligning Large Language Models with Retriever's  Preference in Conversational Search\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.02, \"y\": 4.425}, {\"title\": \"Microstructures and Accuracy of Graph Recall by Large Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.582, \"y\": 5.747}, {\"title\": \"Head-wise Shareable Attention for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.04, \"y\": 2.782}, {\"title\": \"HU at SemEval-2024 Task 8A: Can Contrastive Learning Learn Embeddings to  Detect Machine-Generated Text?\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.793, \"y\": 1.66}, {\"title\": \"Generation Meets Verification: Accelerating Large Language Model  Inference with Smart Parallel Auto-Correct Decoding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.507, \"y\": 3.233}, {\"title\": \"LLM as Prompter: Low-resource Inductive Reasoning on Arbitrary Knowledge  Graphs\", \"topic\": \"Named Entity Recognition\", \"x\": 6.635, \"y\": 5.576}, {\"title\": \"Unveiling the Magic: Investigating Attention Distillation in  Retrieval-augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.357, \"y\": 4.341}, {\"title\": \"What Evidence Do Language Models Find Convincing?\", \"topic\": \"Bias in Language Models\", \"x\": 3.853, \"y\": 3.829}, {\"title\": \"Uncovering Latent Human Wellbeing in Language Model Embeddings\", \"topic\": \"Bias in Language Models\", \"x\": 4.08, \"y\": 2.192}, {\"title\": \"Structured Chain-of-Thought Prompting for Few-Shot Generation of  Content-Grounded QA Conversations\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.515, \"y\": 3.552}, {\"title\": \"ChatGPT Based Data Augmentation for Improved Parameter-Efficient  Debiasing of LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.379, \"y\": 2.532}, {\"title\": \"SPML: A DSL for Defending Language Models Against Prompt Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.46, \"y\": 0.797}, {\"title\": \"ArtPrompt: ASCII Art-based Jailbreak Attacks against Aligned LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.934, \"y\": 0.635}, {\"title\": \"RFBES at SemEval-2024 Task 8: Investigating Syntactic and Semantic  Features for Distinguishing AI-Generated and Human-Written Texts\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.703, \"y\": 1.741}, {\"title\": \"Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned  Language Models through Task Arithmetic\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.074, \"y\": 1.182}, {\"title\": \"Utilizing BERT for Information Retrieval: Survey, Applications,  Resources, and Challenges\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.46, \"y\": 4.767}, {\"title\": \"MORL-Prompt: An Empirical Analysis of Multi-Objective Reinforcement  Learning for Discrete Prompt Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.372, \"y\": 0.558}, {\"title\": \"A Note on Bias to Complete\", \"topic\": \"Bias in Language Models\", \"x\": 3.373, \"y\": 2.744}, {\"title\": \"Why Lift so Heavy? Slimming Large Language Models by Cutting Off the  Layers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.536, \"y\": 2.402}, {\"title\": \"Vision-Flan: Scaling Human-Labeled Tasks in Visual Instruction Tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.129, \"y\": 7.388}, {\"title\": \"ALLaVA: Harnessing GPT4V-Synthesized Data for Lite Vision-Language  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.237, \"y\": 7.716}, {\"title\": \"One Prompt To Rule Them All: LLMs for Opinion Summary Evaluation\", \"topic\": \"Text Summarization\", \"x\": 4.894, \"y\": 5.093}, {\"title\": \"A Multi-Aspect Framework for Counter Narrative Evaluation using Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 2.509, \"y\": 3.35}, {\"title\": \"Integrating Pre-Trained Language Model with Physical Layer  Communications\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.436, \"y\": 2.524}, {\"title\": \"Stealthy Attack on Large Language Model based Recommendation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.294, \"y\": 0.589}, {\"title\": \"In-Context Learning with Transformers: Softmax Attention Adapts to  Function Lipschitzness\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.15, \"y\": 2.786}, {\"title\": \"Stumbling Blocks: Stress Testing the Robustness of Machine-Generated  Text Detectors Under Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.813, \"y\": 1.496}, {\"title\": \"Self-seeding and Multi-intent Self-instructing LLMs for Generating  Intent-aware Information-Seeking dialogs\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.314, \"y\": 3.348}, {\"title\": \"Discrete Neural Algorithmic Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.643, \"y\": 1.782}, {\"title\": \"Metacognitive Retrieval-Augmented Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.19, \"y\": 3.97}, {\"title\": \"Logical Closed Loop: Uncovering Object Hallucinations in Large  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.361, \"y\": 8.106}, {\"title\": \"Decoding News Narratives: A Critical Analysis of Large Language Models  in Framing Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.351, \"y\": 3.96}, {\"title\": \"Metric-Learning Encoding Models Identify Processing Profiles of  Linguistic Features in BERT's Representations\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.647, \"y\": 3.047}, {\"title\": \"Multi-Task Inference: Can Large Language Models Follow Multiple  Instructions at Once?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.281, \"y\": 2.875}, {\"title\": \"Revisiting Zeroth-Order Optimization for Memory-Efficient LLM  Fine-Tuning: A Benchmark\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.925, \"y\": 2.068}, {\"title\": \"BESA: Pruning Large Language Models with Blockwise Parameter-Efficient  Sparsity Allocation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.149, \"y\": 2.328}, {\"title\": \"Visual In-Context Learning for Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.931, \"y\": 7.573}, {\"title\": \"Cobra Effect in Reference-Free Image Captioning Metrics\", \"topic\": \"Multimodal Language Models\", \"x\": 8.489, \"y\": 7.335}, {\"title\": \"Question Answering Over Spatio-Temporal Knowledge Graph\", \"topic\": \"Named Entity Recognition\", \"x\": 6.747, \"y\": 5.436}, {\"title\": \"Deciphering the Impact of Pretraining Data on Large Language Models  through Machine Unlearning\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.766, \"y\": 3.702}, {\"title\": \"PreAct: Predicting Future in ReAct Enhances Agent's Planning Ability\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.12, \"y\": 1.57}, {\"title\": \"Advancing Translation Preference Modeling with RLHF: A Step Towards  Cost-Effective Solution\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.454, \"y\": 0.597}, {\"title\": \"Large Language Model-driven Meta-structure Discovery in Heterogeneous  Information Network\", \"topic\": \"Named Entity Recognition\", \"x\": 6.58, \"y\": 5.659}, {\"title\": \"From Prejudice to Parity: A New Approach to Debiasing Large Language  Model Word Embeddings\", \"topic\": \"Bias in Language Models\", \"x\": 3.17, \"y\": 2.677}, {\"title\": \"Federated Fine-tuning of Large Language Models under Heterogeneous Tasks  and Client Resources\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.154, \"y\": -0.022}, {\"title\": \"What's the Plan? Evaluating and Developing Planning-Aware Techniques for  Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.29, \"y\": 1.425}, {\"title\": \"MIKE: A New Benchmark for Fine-grained Multimodal Entity Knowledge  Editing\", \"topic\": \"Multimodal Language Models\", \"x\": 7.901, \"y\": 7.083}, {\"title\": \"DictLLM: Harnessing Key-Value Data Structures with Large Language Models  for Enhanced Medical Diagnostics\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.175, \"y\": 7.539}, {\"title\": \"A Curious Case of Searching for the Correlation between Training Data  and Adversarial Robustness of Transformer Textual Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.1, \"y\": 1.071}, {\"title\": \"MSynFD: Multi-hop Syntax aware Fake News Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.4, \"y\": 3.719}, {\"title\": \"LoRA-Flow: Dynamic LoRA Fusion for Large Language Models in Generative  Tasks\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.35, \"y\": 1.957}, {\"title\": \"AutoPRM: Automating Procedural Supervision for Multi-Step Reasoning via  Controllable Question Decomposition\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.49, \"y\": 1.839}, {\"title\": \"SciAgent: Tool-augmented Language Models for Scientific Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.448, \"y\": 1.377}, {\"title\": \"Can LLMs Reason with Rules? Logic Scaffolding for Stress-Testing and  Improving LLMs\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.287, \"y\": 2.066}, {\"title\": \"Can Deception Detection Go Deeper? Dataset, Evaluation, and Benchmark  for Deception Reasoning\", \"topic\": \"Bias in Language Models\", \"x\": 3.634, \"y\": 3.575}, {\"title\": \"LoRETTA: Low-Rank Economic Tensor-Train Adaptation for  Ultra-Low-Parameter Fine-Tuning of Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.846, \"y\": 1.923}, {\"title\": \"Fine-grained and Explainable Factuality Evaluation for Multimodal  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.238, \"y\": 5.371}, {\"title\": \"Aligning Modalities in Vision Large Language Models via Preference  Fine-tuning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.404, \"y\": 8.123}, {\"title\": \"Don't Go To Extremes: Revealing the Excessive Sensitivity and  Calibration Limitations of LLMs in Implicit Hate Speech Detection\", \"topic\": \"Bias in Language Models\", \"x\": 2.478, \"y\": 3.312}, {\"title\": \"Reasoning before Comparison: LLM-Enhanced Semantic Similarity Metrics  for Domain Specialized Text Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.211, \"y\": 7.721}, {\"title\": \"MMMModal -- Multi-Images Multi-Audio Multi-turn Multi-Modal\", \"topic\": \"Multimodal Language Models\", \"x\": 8.468, \"y\": 7.223}, {\"title\": \"OneBit: Towards Extremely Low-bit Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.511, \"y\": 2.285}, {\"title\": \"Puzzle Solving using Reasoning of Large Language Models: A Survey\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.141, \"y\": 1.964}, {\"title\": \"Can Large Multimodal Models Uncover Deep Semantics Behind Images?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.14, \"y\": 7.445}, {\"title\": \"Multi-Perspective Consistency Enhances Confidence Estimation in Large  Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.584, \"y\": 3.031}, {\"title\": \"C-ICL: Contrastive In-context Learning for Information Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.273, \"y\": 6.698}, {\"title\": \"Aligning Large Language Models by On-Policy Self-Judgment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.551, \"y\": 0.52}, {\"title\": \"Detecting a Proxy for Potential Comorbid ADHD in People Reporting  Anxiety Symptoms from Social Media Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.342, \"y\": 6.379}, {\"title\": \"Asclepius: A Spectrum Evaluation Benchmark for Medical Multi-Modal Large  Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.019, \"y\": 7.4}, {\"title\": \"Watch Out for Your Agents! Investigating Backdoor Threats to LLM-Based  Agents\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.279, \"y\": 0.544}, {\"title\": \"Turn Waste into Worth: Rectifying Top-$k$ Router of MoE\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.002, \"y\": 2.193}, {\"title\": \"Exploring ChatGPT for Next-generation Information Retrieval:  Opportunities and Challenges\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.017, \"y\": 4.566}, {\"title\": \"Centroid-Based Efficient Minimum Bayes Risk Decoding\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.821, \"y\": 4.702}, {\"title\": \"Disclosure and Mitigation of Gender Bias in LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.176, \"y\": 2.652}, {\"title\": \"LaCo: Large Language Model Pruning via Layer Collapse\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.01, \"y\": 2.336}, {\"title\": \"RENOVI: A Benchmark Towards Remediating Norm Violations in  Socio-Cultural Conversations\", \"topic\": \"Bias in Language Models\", \"x\": 4.3, \"y\": 2.699}, {\"title\": \"A Question Answering Based Pipeline for Comprehensive Chinese EHR  Information Extraction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.228, \"y\": 7.358}, {\"title\": \"Token-Ensemble Text Generation: On Attacking the Automatic AI-Generated  Text Detection\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.954, \"y\": 1.296}, {\"title\": \"Assessing News Thumbnail Representativeness: Counterfactual text can  enhance the cross-modal matching ability\", \"topic\": \"Multimodal Language Models\", \"x\": 8.253, \"y\": 7.302}, {\"title\": \"Grasping the Essentials: Tailoring Large Language Models for Zero-Shot  Relation Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.317, \"y\": 6.516}, {\"title\": \"Boosting of Thoughts: Trial-and-Error Problem Solving with Large  Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.203, \"y\": 1.636}, {\"title\": \"Orca-Math: Unlocking the potential of SLMs in Grade School Math\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.761, \"y\": 1.255}, {\"title\": \"Speculative Streaming: Fast LLM Inference without Auxiliary Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.519, \"y\": 3.162}, {\"title\": \"BlendFilter: Advancing Retrieval-Augmented Large Language Models via  Query Generation Blending and Knowledge Filtering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.421, \"y\": 4.626}, {\"title\": \"Born With a Silver Spoon? Investigating Socioeconomic Bias in Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.355, \"y\": 2.748}, {\"title\": \"Regulating Large Language Models: A Roundtable Report\", \"topic\": \"Bias in Language Models\", \"x\": 3.927, \"y\": 2.374}, {\"title\": \"AFaCTA: Assisting the Annotation of Factual Claim Detection with  Reliable LLM Annotators\", \"topic\": \"Bias in Language Models\", \"x\": 3.775, \"y\": 3.916}, {\"title\": \"II-MMR: Identifying and Improving Multi-modal Multi-hop Reasoning in  Visual Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 7.713, \"y\": 7.725}, {\"title\": \"Retrieval-Augmented Generation: Is Dense Passage Retrieval Retrieving?\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.465, \"y\": 4.387}, {\"title\": \"PAT-Questions: A Self-Updating Benchmark for Present-Anchored Temporal  Question-Answering\", \"topic\": \"Named Entity Recognition\", \"x\": 6.501, \"y\": 5.194}, {\"title\": \"RLVF: Learning from Verbal Feedback without Overgeneralization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.402, \"y\": 0.862}, {\"title\": \"When is Tree Search Useful for LLM Planning? It Depends on the  Discriminator\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.352, \"y\": 1.527}, {\"title\": \"Multi-modal preference alignment remedies regression of visual  instruction tuning on language model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.033, \"y\": 7.601}, {\"title\": \"Universal Prompt Optimizer for Safe Text-to-Image Generation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.377, \"y\": 1.647}, {\"title\": \"Using Hallucinations to Bypass GPT4's Filter\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.495, \"y\": 0.889}, {\"title\": \"Quantifying the Persona Effect in LLM Simulations\", \"topic\": \"Bias in Language Models\", \"x\": 4.483, \"y\": 2.667}, {\"title\": \"Generative Cross-Modal Retrieval: Memorizing Images in Multimodal  Language Models for Retrieval and Beyond\", \"topic\": \"Multimodal Language Models\", \"x\": 8.118, \"y\": 7.387}, {\"title\": \"EdgeQAT: Entropy and Distribution Guided Quantization-Aware Training for  the Acceleration of Lightweight LLMs on the Edge\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.511, \"y\": 2.429}, {\"title\": \"Distillation Enhanced Generative Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.148, \"y\": 4.648}, {\"title\": \"ToolSword: Unveiling Safety Issues of Large Language Models in Tool  Learning Across Three Stages\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.677, \"y\": 0.884}, {\"title\": \"GenRES: Rethinking Evaluation for Generative Relation Extraction in the  Era of Large Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.314, \"y\": 6.443}, {\"title\": \"Construction of a Syntactic Analysis Map for Yi Shui School through Text  Mining and Natural Language Processing Research\", \"topic\": \"Named Entity Recognition\", \"x\": 6.047, \"y\": 6.514}, {\"title\": \"Assessing the Reasoning Abilities of ChatGPT in the Context of Claim  Verification\", \"topic\": \"Bias in Language Models\", \"x\": 3.721, \"y\": 3.86}, {\"title\": \"A Novel BERT-based Classifier to Detect Political Leaning of YouTube  Videos based on their Titles\", \"topic\": \"Bias in Language Models\", \"x\": 3.089, \"y\": 3.716}, {\"title\": \"An Empirical Study on Cross-lingual Vocabulary Adaptation for Efficient  Language Model Inference\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.211, \"y\": 4.075}, {\"title\": \"Rethinking Human-like Translation Strategy: Integrating Drift-Diffusion  Model with Large Language Models for Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.764, \"y\": 4.675}, {\"title\": \"Python is Not Always the Best Choice: Embracing Multilingual Program of  Thoughts\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.182, \"y\": 1.628}, {\"title\": \"Multi-Cultural Commonsense Knowledge Distillation\", \"topic\": \"Bias in Language Models\", \"x\": 4.151, \"y\": 2.727}, {\"title\": \"OpenFMNav: Towards Open-Set Zero-Shot Object Navigation via  Vision-Language Foundation Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.01, \"y\": 7.075}, {\"title\": \"Fine Tuning Named Entity Extraction Models for the Fantasy Domain\", \"topic\": \"Named Entity Recognition\", \"x\": 6.072, \"y\": 6.778}, {\"title\": \"Network Formation and Dynamics Among Multi-LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 4.28, \"y\": 2.657}, {\"title\": \"Enhancing Numerical Reasoning with the Guidance of Reliable Reasoning  Processes\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.484, \"y\": 1.489}, {\"title\": \"AbsInstruct: Eliciting Abstraction Ability from LLMs through Explanation  Tuning with Plausibility Estimation\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.383, \"y\": 2.018}, {\"title\": \"Can Separators Improve Chain-of-Thought Prompting?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.297, \"y\": 1.838}, {\"title\": \"Linear Transformers with Learnable Kernel Functions are Better  In-Context Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.521, \"y\": 2.832}, {\"title\": \"`Keep it Together': Enforcing Cohesion in Extractive Summaries by  Simulating Human Memory\", \"topic\": \"Text Summarization\", \"x\": 5.129, \"y\": 5.094}, {\"title\": \"Generalizability of Mixture of Domain-Specific Adapters from the Lens of  Signed Weight Directions and its Application to Effective Model Pruning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.473, \"y\": 2.071}, {\"title\": \"BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via  Self-Distillation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.44, \"y\": 2.201}, {\"title\": \"Jailbreaking Proprietary Large Language Models using Word Substitution  Cipher\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.997, \"y\": 0.45}, {\"title\": \"Efficiency at Scale: Investigating the Performance of Diminutive  Language Models in Clinical Tasks\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.227, \"y\": 7.314}, {\"title\": \"LinkNER: Linking Local Named Entity Recognition Models to Large Language  Models using Uncertainty\", \"topic\": \"Named Entity Recognition\", \"x\": 6.22, \"y\": 6.772}, {\"title\": \"Direct Preference Optimization with an Offset\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.404, \"y\": 0.563}, {\"title\": \"InSaAF: Incorporating Safety through Accuracy and Fairness | Are LLMs  ready for the Indian Legal Domain?\", \"topic\": \"Legal NLP\", \"x\": 4.375, \"y\": 4.519}, {\"title\": \"Disordered-DABS: A Benchmark for Dynamic Aspect-Based Summarization in  Disordered Texts\", \"topic\": \"Text Summarization\", \"x\": 5.088, \"y\": 5.08}, {\"title\": \"Conversational SimulMT: Efficient Simultaneous Translation with Large  Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.882, \"y\": 4.592}, {\"title\": \"Can We Verify Step by Step for Incorrect Answer Detection?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.297, \"y\": 2.085}, {\"title\": \"Zero-shot sampling of adversarial entities in biomedical question  answering\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.134, \"y\": 1.043}, {\"title\": \"LLM Comparator: Visual Analytics for Side-by-Side Evaluation of Large  Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.669, \"y\": 2.951}, {\"title\": \"Active Preference Optimization for Sample Efficient RLHF\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.502, \"y\": 0.535}, {\"title\": \"Large Language Models as Zero-shot Dialogue State Tracker through  Function Calling\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.267, \"y\": 3.235}, {\"title\": \"QDyLoRA: Quantized Dynamic Low-Rank Adaptation for Efficient Large  Language Model Tuning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.98, \"y\": 1.786}, {\"title\": \"I Am Not Them: Fluid Identities and Persistent Out-group Bias in Large  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.846, \"y\": 2.669}, {\"title\": \"DELL: Generating Reactions and Explanations for LLM-Based Misinformation  Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.596, \"y\": 3.832}, {\"title\": \"Pushing the Limits of Zero-shot End-to-End Speech Translation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.043, \"y\": 5.745}, {\"title\": \"Measuring and Reducing LLM Hallucination without Gold-Standard Answers\", \"topic\": \"Large Language Models in Education\", \"x\": 5.97, \"y\": 3.272}, {\"title\": \"Understanding Survey Paper Taxonomy about Large Language Models via  Graph Representation Learning\", \"topic\": \"Named Entity Recognition\", \"x\": 6.505, \"y\": 5.802}, {\"title\": \"Chain of Logic: Rule-Based Reasoning with Large Language Models\", \"topic\": \"Legal NLP\", \"x\": 4.465, \"y\": 4.452}, {\"title\": \"BioMistral: A Collection of Open-Source Pretrained Large Language Models  for Medical Domains\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.974, \"y\": 7.398}, {\"title\": \"Prompt-Based Bias Calibration for Better Zero/Few-Shot Learning of  Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.366, \"y\": 2.538}, {\"title\": \"Analyzing the Roles of Language and Vision in Learning from Limited Data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.029, \"y\": 7.838}, {\"title\": \"Exploration-Driven Policy Optimization in RLHF: Theoretical Insights on  Efficient Data Utilization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.7, \"y\": 0.701}, {\"title\": \"Self-Play Fine-Tuning of Diffusion Models for Text-to-Image Generation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.571, \"y\": 6.716}, {\"title\": \"Rewards-in-Context: Multi-objective Alignment of Foundation Models with  Dynamic Preference Adjustment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.338, \"y\": 0.607}, {\"title\": \"A StrongREJECT for Empty Jailbreaks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.101, \"y\": 0.542}, {\"title\": \"Chain-of-Thought Reasoning Without Prompting\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.542, \"y\": 2.126}, {\"title\": \"A Trembling House of Cards? Mapping Adversarial Attacks against Language  Agents\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.394, \"y\": 0.718}, {\"title\": \"BitDelta: Your Fine-Tune May Only Be Worth One Bit\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.32, \"y\": 2.22}, {\"title\": \"Uncertainty Quantification for In-Context Learning of Large Language  Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.805, \"y\": 2.949}, {\"title\": \"Reward Generalization in RLHF: A Topological Perspective\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.601, \"y\": 0.688}, {\"title\": \"Language Models with Conformal Factuality Guarantees\", \"topic\": \"Large Language Models in Education\", \"x\": 6.613, \"y\": 3.101}, {\"title\": \"TDAG: A Multi-Agent Framework based on Dynamic Task Decomposition and  Agent Generation\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.09, \"y\": 1.427}, {\"title\": \"OpenMathInstruct-1: A 1.8 Million Math Instruction Tuning Dataset\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.772, \"y\": 1.149}, {\"title\": \"Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study  for Diabetes Patients\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.617, \"y\": 7.267}, {\"title\": \"TOAD: Task-Oriented Automatic Dialogs with Diverse Response Styles\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.295, \"y\": 3.28}, {\"title\": \"Towards Reducing Diagnostic Errors with Interpretable Risk Prediction\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.002, \"y\": 7.466}, {\"title\": \"GeoEval: Benchmark for Evaluating LLMs and Multi-Modal Models on  Geometry Problem-Solving\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.695, \"y\": 1.24}, {\"title\": \"QUICK: Quantization-aware Interleaving and Conflict-free Kernel for  efficient LLM inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.605, \"y\": 2.47}, {\"title\": \"Both Matter: Enhancing the Emotional Intelligence of Large Language  Models without Compromising the General Intelligence\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.631, \"y\": 5.619}, {\"title\": \"Towards Safer Large Language Models through Machine Unlearning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.977, \"y\": 0.698}, {\"title\": \"Unmemorization in Large Language Models via Self-Distillation and  Deliberate Imagination\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.897, \"y\": 0.452}, {\"title\": \"RS-DPO: A Hybrid Rejection Sampling and Direct Preference Optimization  Method for Alignment of Large Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.498, \"y\": 0.575}, {\"title\": \"Self-Augmented In-Context Learning for Unsupervised Word Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.704, \"y\": 4.503}, {\"title\": \"Bridging the Empirical-Theoretical Gap in Neural Network Formal Language  Learning Using Minimum Description Length\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.118, \"y\": 2.578}, {\"title\": \"Neural Information Organizing and Processing -- Neural Machines\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.949, \"y\": 2.803}, {\"title\": \"LoraRetriever: Input-Aware LoRA Retrieval and Composition for Mixed  Tasks in the Wild\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.501, \"y\": 1.916}, {\"title\": \"LLMs as Bridges: Reformulating Grounded Multimodal Named Entity  Recognition\", \"topic\": \"Multimodal Language Models\", \"x\": 7.731, \"y\": 7.207}, {\"title\": \"Fast Vocabulary Transfer for Language Model Compression\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.293, \"y\": 2.406}, {\"title\": \"Case Study: Testing Model Capabilities in Some Reasoning Tasks\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.122, \"y\": 2.027}, {\"title\": \"Crafting a Good Prompt or Providing Exemplary Dialogues? A Study of  In-Context Learning for Persona-based Dialogue Generation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.158, \"y\": 3.382}, {\"title\": \"Paying Attention to Deflections: Mining Pragmatic Nuances for  Whataboutism Detection in Online Discourse\", \"topic\": \"Bias in Language Models\", \"x\": 3.199, \"y\": 3.78}, {\"title\": \"A Dataset of Open-Domain Question Answering with Multiple-Span Answers\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.731, \"y\": 4.424}, {\"title\": \"DE-COP: Detecting Copyrighted Content in Language Models Training Data\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.379, \"y\": 1.265}, {\"title\": \"Camouflage is all you need: Evaluating and Enhancing Language Model  Robustness Against Camouflage Adversarial Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.011, \"y\": 1.211}, {\"title\": \"EFUF: Efficient Fine-grained Unlearning Framework for Mitigating  Hallucinations in Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.382, \"y\": 8.019}, {\"title\": \"NutePrune: Efficient Progressive Pruning with Numerous Teachers for  Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.104, \"y\": 2.379}, {\"title\": \"Grounding Language Model with Chunking-Free In-Context Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.131, \"y\": 4.603}, {\"title\": \"Efficient Language Adaptive Pre-training: Extending State-of-the-Art  Large Language Models for Polish\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.223, \"y\": 4.169}, {\"title\": \"Model Compression and Efficient Inference for Large Language Models: A  Survey\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.18, \"y\": 2.406}, {\"title\": \"AI Hospital: Benchmarking Large Language Models in a Multi-agent Medical  Interaction Simulator\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.723, \"y\": 7.44}, {\"title\": \"Align before Attend: Aligning Visual and Textual Features for Multimodal  Hateful Content Detection\", \"topic\": \"Bias in Language Models\", \"x\": 2.499, \"y\": 3.479}, {\"title\": \"Improving Non-autoregressive Machine Translation with Error Exposure and  Consistency Regularization\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.861, \"y\": 4.538}, {\"title\": \"PAL: Proxy-Guided Black-Box Attack on Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.276, \"y\": 0.669}, {\"title\": \"EntailE: Introducing Textual Entailment in Commonsense Knowledge Graph  Completion\", \"topic\": \"Named Entity Recognition\", \"x\": 6.713, \"y\": 5.546}, {\"title\": \"CodeMind: A Framework to Challenge Large Language Models for Code  Reasoning\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.062, \"y\": 0.188}, {\"title\": \"GPT-4's assessment of its performance in a USMLE-based case study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.718, \"y\": 7.178}, {\"title\": \"Answer is All You Need: Instruction-following Text Embedding via  Answering the Question\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.752, \"y\": 4.004}, {\"title\": \"Representation Surgery: Theory and Practice of Affine Steering\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.828, \"y\": 1.549}, {\"title\": \"API Pack: A Massive Multi-Programming Language Dataset for API Call  Generation\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.965, \"y\": 0.628}, {\"title\": \"Probabilistic Reasoning in Generative Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 6.984, \"y\": 2.457}, {\"title\": \"LogicPrpBank: A Corpus for Logical Implication and Equivalence\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.413, \"y\": 2.083}, {\"title\": \"AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential  Reasoning Ability\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.189, \"y\": 1.768}, {\"title\": \"Reinforcement Learning from Human Feedback with Active Queries\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.556, \"y\": 0.678}, {\"title\": \"Long-form evaluation of model editing\", \"topic\": \"Large Language Models in Education\", \"x\": 6.699, \"y\": 3.109}, {\"title\": \"HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context  Learning in Factuality Evaluation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.976, \"y\": 4.694}, {\"title\": \"Transformers Can Achieve Length Generalization But Not Robustly\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.459, \"y\": 2.96}, {\"title\": \"Massively Multi-Cultural Knowledge Acquisition & LM Benchmarking\", \"topic\": \"Bias in Language Models\", \"x\": 4.06, \"y\": 2.702}, {\"title\": \"Copyright Traps for Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.306, \"y\": 1.156}, {\"title\": \"Generating Diverse Translation with Perturbed kNN-MT\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.801, \"y\": 4.692}, {\"title\": \"ICDPO: Effectively Borrowing Alignment Capability of Others via  In-context Direct Preference Optimization\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.61, \"y\": 0.471}, {\"title\": \"Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.474, \"y\": 0.809}, {\"title\": \"Leveraging Large Language Models for Enhanced NLP Task Performance  through Knowledge Distillation and Optimized Training Strategies\", \"topic\": \"Named Entity Recognition\", \"x\": 6.182, \"y\": 6.858}, {\"title\": \"Spectral Filters, Dark Signals, and Attention Sinks\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.387, \"y\": 2.886}, {\"title\": \"AutoTutor meets Large Language Models: A Language Model Tutor with Rich  Pedagogy and Guardrails\", \"topic\": \"Large Language Models in Education\", \"x\": 6.311, \"y\": 2.275}, {\"title\": \"Tell Me More! Towards Implicit User Intention Understanding of Language  Model Driven Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.081, \"y\": 1.689}, {\"title\": \"Ten Words Only Still Help: Improving Black-Box AI-Generated Text  Detection via Proxy-Guided Efficient Re-Sampling\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.75, \"y\": 1.677}, {\"title\": \"Leveraging the Context through Multi-Round Interactions for Jailbreaking  Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.12, \"y\": 0.544}, {\"title\": \"Chinese MentalBERT: Domain-Adaptive Pre-training on Social Media for  Chinese Mental Health Text Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.299, \"y\": 6.164}, {\"title\": \"DolphCoder: Echo-Locating Code Large Language Models with Diverse and  Multi-Objective Instruction Tuning\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.156, \"y\": 0.125}, {\"title\": \"MPIrigen: MPI Code Generation through Domain-Specific Language Models\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.109, \"y\": 0.045}, {\"title\": \"SLEB: Streamlining LLMs through Redundancy Verification and Elimination  of Transformer Blocks\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.218, \"y\": 2.624}, {\"title\": \"Towards better Human-Agent Alignment: Assessing Task Utility in  LLM-Powered Applications\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.048, \"y\": 1.757}, {\"title\": \"Multi-Query Focused Disaster Summarization via Instruction-Based  Prompting\", \"topic\": \"Text Summarization\", \"x\": 5.12, \"y\": 5.068}, {\"title\": \"SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware  Decoding\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.018, \"y\": 0.429}, {\"title\": \"Generalization in Healthcare AI: Evaluation of a Clinical Large Language  Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.006, \"y\": 7.401}, {\"title\": \"Pretraining Vision-Language Model for Difference Visual Question  Answering in Longitudinal Chest X-rays\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.395, \"y\": 8.121}, {\"title\": \"MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.564, \"y\": 1.184}, {\"title\": \"Premise Order Matters in Reasoning with Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.444, \"y\": 1.907}, {\"title\": \"MaxMin-RLHF: Towards Equitable Alignment of Large Language Models with  Diverse Human Preferences\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.371, \"y\": 0.566}, {\"title\": \"UniEnc-CASSNAT: An Encoder-only Non-autoregressive ASR for Speech SSL  Models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.482, \"y\": 5.699}, {\"title\": \"An Embarrassingly Simple Approach for LLM with Strong ASR Capacity\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.421, \"y\": 5.755}, {\"title\": \"Sequence graphs realizations and ambiguity in language models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.814, \"y\": 3.073}, {\"title\": \"Syllable based DNN-HMM Cantonese Speech to Text System\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.528, \"y\": 5.716}, {\"title\": \"Rethinking Machine Unlearning for Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.916, \"y\": 0.612}, {\"title\": \"GLoRe: When, Where, and How to Improve LLM Reasoning via Global and  Local Refinements\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.274, \"y\": 1.605}, {\"title\": \"Measuring and Controlling Instruction (In)Stability in Language Model  Dialogs\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.289, \"y\": 2.946}, {\"title\": \"A Dataset for the Detection of Dehumanizing Language\", \"topic\": \"Bias in Language Models\", \"x\": 2.508, \"y\": 3.319}, {\"title\": \"JAMDEC: Unsupervised Authorship Obfuscation using Constrained Decoding  over Small Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.427, \"y\": 0.531}, {\"title\": \"Learning How To Ask: Cycle-Consistency Refines Prompts in Multimodal  Foundation Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.008, \"y\": 7.597}, {\"title\": \"Mitigating Object Hallucination in Large Vision-Language Models via  Classifier-Free Guidance\", \"topic\": \"Multimodal Language Models\", \"x\": 8.337, \"y\": 8.091}, {\"title\": \"COLD-Attack: Jailbreaking LLMs with Stealthiness and Controllability\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.991, \"y\": 0.75}, {\"title\": \"Tandem Transformers for Inference Efficient LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.34, \"y\": 3.142}, {\"title\": \"Knowledge Editing on Black-box Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.03, \"y\": 0.678}, {\"title\": \"Improving Factual Error Correction for Abstractive Summarization via  Data Distillation and Conditional-generation Cloze\", \"topic\": \"Text Summarization\", \"x\": 5.17, \"y\": 5.048}, {\"title\": \"Test-Time Backdoor Attacks on Multimodal Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.143, \"y\": 0.846}, {\"title\": \"Agent Smith: A Single Image Can Jailbreak One Million Multimodal LLM  Agents Exponentially Fast\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.069, \"y\": 0.502}, {\"title\": \"Higher Layers Need More LoRA Experts\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.699, \"y\": 1.869}, {\"title\": \"Auditing Counterfire: Evaluating Advanced Counterargument Generation  with Evidence and Style\", \"topic\": \"Bias in Language Models\", \"x\": 3.973, \"y\": 3.776}, {\"title\": \"Lying Blindly: Bypassing ChatGPT's Safeguards to Generate Hard-to-Detect  Disinformation Claims at Scale\", \"topic\": \"Bias in Language Models\", \"x\": 3.553, \"y\": 3.748}, {\"title\": \"Large Language Models as Minecraft Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.912, \"y\": 1.744}, {\"title\": \"PreFLMR: Scaling Up Fine-Grained Late-Interaction Multi-modal Retrievers\", \"topic\": \"Multimodal Language Models\", \"x\": 7.687, \"y\": 7.586}, {\"title\": \"Values That Are Explicitly Present in Fairy Tales: Comparing Samples  from German, Italian and Portuguese Traditions\", \"topic\": \"Bias in Language Models\", \"x\": 4.03, \"y\": 2.543}, {\"title\": \"Prompted Contextual Vectors for Spear-Phishing Detection\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.133, \"y\": 1.684}, {\"title\": \"Privacy-Preserving Language Model Inference with Instance Obfuscation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.723, \"y\": 0.244}, {\"title\": \"Pixel Sentence Representation Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.269, \"y\": 7.375}, {\"title\": \"CMA-R:Causal Mediation Analysis for Explaining Rumour Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.652, \"y\": 3.859}, {\"title\": \"Active Preference Learning for Large Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.524, \"y\": 0.562}, {\"title\": \"Addressing cognitive bias in medical language models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.701, \"y\": 7.094}, {\"title\": \"Relative Preference Optimization: Enhancing LLM Alignment through  Contrasting Responses across Identical and Diverse Prompts\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.478, \"y\": 0.601}, {\"title\": \"BASE TTS: Lessons from building a billion-parameter Text-to-Speech model  on 100K hours of data\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.121, \"y\": 6.006}, {\"title\": \"Text-centric Alignment for Multi-Modality Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.238, \"y\": 7.345}, {\"title\": \"Large Language Models as Agents in Two-Player Games\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.828, \"y\": 1.363}, {\"title\": \"Beyond LLMs: Advancing the Landscape of Complex Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.204, \"y\": 1.609}, {\"title\": \"Lumos : Empowering Multimodal LLMs with Scene Text Recognition\", \"topic\": \"Multimodal Language Models\", \"x\": 7.998, \"y\": 7.386}, {\"title\": \"Walia-LLM: Enhancing Amharic-LLaMA by Integrating Task-Specific and  Generative Datasets\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.884, \"y\": 4.228}, {\"title\": \"Refined Direct Preference Optimization with Synthetic Data for  Behavioral Alignment of LLMs\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.605, \"y\": 0.618}, {\"title\": \"EvoGPT-f: An Evolutionary GPT Framework for Benchmarking Formal Math  Languages\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.671, \"y\": 1.141}, {\"title\": \"Suppressing Pink Elephants with Direct Principle Feedback\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.36, \"y\": 1.196}, {\"title\": \"Scaling Laws for Fine-Grained Mixture of Experts\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.718, \"y\": 2.389}, {\"title\": \"PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 7.858, \"y\": 7.319}, {\"title\": \"Prismatic VLMs: Investigating the Design Space of Visually-Conditioned  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.135, \"y\": 7.799}, {\"title\": \"Mercury: A Code Efficiency Benchmark for Code Large Language Models\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.19, \"y\": 0.002}, {\"title\": \"Do Membership Inference Attacks Work on Large Language Models?\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.646, \"y\": 0.804}, {\"title\": \"Aya Model: An Instruction Finetuned Open-Access Multilingual Language  Model\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.071, \"y\": 3.928}, {\"title\": \"Differentially Private Zeroth-Order Methods for Scalable Large Language  Model Finetuning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.855, \"y\": 0.168}, {\"title\": \"Retrieval-Augmented Thought Process as Sequential Decision Making\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.298, \"y\": 4.226}, {\"title\": \"TELLER: A Trustworthy Framework for Explainable, Generalizable and  Controllable Fake News Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.5, \"y\": 3.703}, {\"title\": \"Diffusion of Thoughts: Chain-of-Thought Reasoning in Diffusion Language  Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.477, \"y\": 1.943}, {\"title\": \"Towards Unified Alignment Between Agents, Humans, and Environment\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.812, \"y\": 1.578}, {\"title\": \"Asking Multimodal Clarifying Questions in Mixed-Initiative  Conversational Search\", \"topic\": \"Multimodal Language Models\", \"x\": 7.66, \"y\": 6.999}, {\"title\": \"AIR-Bench: Benchmarking Large Audio-Language Models via Generative  Comprehension\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.777, \"y\": 6.045}, {\"title\": \"LoRA-drop: Efficient LoRA Parameter Pruning based on Output Evaluation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.841, \"y\": 1.73}, {\"title\": \"OrderBkd: Textual backdoor attack through repositioning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.056, \"y\": 1.012}, {\"title\": \"Large Language Models \\\"Ad Referendum\\\": How Good Are They at Machine  Translation in the Legal Domain?\", \"topic\": \"Legal NLP\", \"x\": 4.691, \"y\": 4.671}, {\"title\": \"The Sound of Healthcare: Improving Medical Transcription ASR Accuracy  with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.19, \"y\": 7.416}, {\"title\": \"Detecting the Clinical Features of Difficult-to-Treat Depression using  Synthetic Data from Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.455, \"y\": 6.641}, {\"title\": \"Autonomous Data Selection with Language Models for Mathematical Texts\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.751, \"y\": 1.139}, {\"title\": \"Anchor-based Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.185, \"y\": 2.954}, {\"title\": \"MAFIA: Multi-Adapter Fused Inclusive LanguAge Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.205, \"y\": 2.644}, {\"title\": \"The Balancing Act: Unmasking and Alleviating ASR Biases in Portuguese\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.457, \"y\": 5.776}, {\"title\": \"T-RAG: Lessons from the LLM Trenches\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.182, \"y\": 4.53}, {\"title\": \"Quality Does Matter: A Detailed Look at the Quality and Utility of  Web-Mined Parallel Corpora\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.24, \"y\": 4.591}, {\"title\": \"Intrinsic Task-based Evaluation for Referring Expression Generation\", \"topic\": \"Large Language Models in Education\", \"x\": 6.3, \"y\": 3.593}, {\"title\": \"Making Flow-Matching-Based Zero-Shot Text-to-Speech Laugh as You Like\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.938, \"y\": 6.082}, {\"title\": \"Assessing Generalization for Subpopulation Representative Modeling via  In-Context Learning\", \"topic\": \"Bias in Language Models\", \"x\": 3.826, \"y\": 2.992}, {\"title\": \"ODIN: Disentangled Reward Mitigates Hacking in RLHF\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.679, \"y\": 0.79}, {\"title\": \"Open-ended VQA benchmarking of Vision-Language models by exploiting  Classification datasets and their semantic hierarchy\", \"topic\": \"Multimodal Language Models\", \"x\": 7.901, \"y\": 7.755}, {\"title\": \"Low-Resource Counterspeech Generation for Indic Languages: The Case of  Bengali and Hindi\", \"topic\": \"Bias in Language Models\", \"x\": 2.425, \"y\": 3.388}, {\"title\": \"TransGPT: Multi-modal Generative Pre-trained Transformer for  Transportation\", \"topic\": \"Multimodal Language Models\", \"x\": 7.898, \"y\": 6.476}, {\"title\": \"Natural Language Reinforcement Learning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.889, \"y\": 1.17}, {\"title\": \"Generalizing Conversational Dense Retrieval via LLM-Cognition Data  Augmentation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.348, \"y\": 3.707}, {\"title\": \"Speech Rhythm-Based Speaker Embeddings Extraction from Phonemes and  Phoneme Duration for Multi-Speaker Speech Synthesis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.096, \"y\": 6.016}, {\"title\": \"Using Large Language Models for Student-Code Guided Test Case Generation  in Computer Science Education\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.045, \"y\": 0.381}, {\"title\": \"Using Large Language Models to Automate and Expedite Reinforcement  Learning with Reward Machine\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.992, \"y\": 1.223}, {\"title\": \"Semi-Supervised Learning for Bilingual Lexicon Induction\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.009, \"y\": 4.344}, {\"title\": \"Gemini Goes to Med School: Exploring the Capabilities of Multimodal  Large Language Models on Medical Challenge Problems & Hallucinations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.887, \"y\": 7.636}, {\"title\": \"DAEDRA: A language model for predicting outcomes in passive  pharmacovigilance reporting\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.131, \"y\": 7.028}, {\"title\": \"Event-Keyed Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.353, \"y\": 5.28}, {\"title\": \"Instruct Once, Chat Consistently in Multiple Rounds: An Efficient Tuning  Framework for Dialogue\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.164, \"y\": 3.056}, {\"title\": \"OpenFedLLM: Training Large Language Models on Decentralized Private Data  via Federated Learning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.116, \"y\": -0.009}, {\"title\": \"Should I try multiple optimizers when fine-tuning pre-trained  Transformers for NLP tasks? Should I tune their hyperparameters?\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.616, \"y\": 2.208}, {\"title\": \"Generating Chain-of-Thoughts with a Pairwise-Comparison Approach to  Searching for the Most Promising Intermediate Thought\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.25, \"y\": 1.789}, {\"title\": \"TL;DR Progress: Multi-faceted Literature Exploration in Text  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.162, \"y\": 5.282}, {\"title\": \"Investigating Consistency in Query-Based Meeting Summarization: A  Comparative Study of Different Embedding Methods\", \"topic\": \"Text Summarization\", \"x\": 5.113, \"y\": 5.076}, {\"title\": \"Understanding the Progression of Educational Topics via Semantic  Matching\", \"topic\": \"Large Language Models in Education\", \"x\": 6.38, \"y\": 2.275}, {\"title\": \"Can LLMs Recognize Toxicity? Definition-Based Toxicity Metric\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.57, \"y\": 1.745}, {\"title\": \"GenTranslate: Large Language Models are Generative Multilingual Speech  and Machine Translators\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.786, \"y\": 4.76}, {\"title\": \"Sentinels of the Stream: Unleashing Large Language Models for Dynamic  Packet Classification in Software Defined Networks -- Position Paper\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.386, \"y\": 1.015}, {\"title\": \"Feedback Loops With Language Models Drive In-Context Reward Hacking\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.747, \"y\": 1.283}, {\"title\": \"TIC: Translate-Infer-Compile for accurate \\\"text to plan\\\" using LLMs and  Logical Representations\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.437, \"y\": 1.39}, {\"title\": \"Self-consistent context aware conformer transducer for speech  recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.684, \"y\": 5.664}, {\"title\": \"G-SciEdBERT: A Contextualized LLM for Science Assessment Tasks in German\", \"topic\": \"Large Language Models in Education\", \"x\": 6.389, \"y\": 2.563}, {\"title\": \"What is Hiding in Medicine's Dark Matter? Learning with Missing Data in  Medical Practices\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.902, \"y\": 7.534}, {\"title\": \"Diffusion-ES: Gradient-free Planning with Diffusion for Autonomous  Driving and Zero-Shot Instruction Following\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.122, \"y\": 1.235}, {\"title\": \"Bryndza at ClimateActivism 2024: Stance, Target and Hate Event Detection  via Retrieval-Augmented GPT-4 and LLaMA\", \"topic\": \"Bias in Language Models\", \"x\": 2.568, \"y\": 3.713}, {\"title\": \"A Multi-faceted Semi-Synthetic Dataset for Automated Cyberbullying  Detection\", \"topic\": \"Bias in Language Models\", \"x\": 2.458, \"y\": 3.363}, {\"title\": \"Introspective Planning: Aligning Robots' Uncertainty with Inherent Task  Ambiguity\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.231, \"y\": 1.379}, {\"title\": \"Multimodal Clinical Trial Outcome Prediction with Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.366, \"y\": 7.921}, {\"title\": \"Scalable Interactive Machine Learning for Future Command and Control\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.456, \"y\": 1.794}, {\"title\": \"Inducing Systematicity in Transformers by Attending to Structurally  Quantized Embeddings\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.365, \"y\": 3.151}, {\"title\": \"V-STaR: Training Verifiers for Self-Taught Reasoners\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.282, \"y\": 1.627}, {\"title\": \"Explaining Veracity Predictions with Evidence Summarization: A  Multi-Task Model Approach\", \"topic\": \"Bias in Language Models\", \"x\": 3.719, \"y\": 3.833}, {\"title\": \"Findings of the First Workshop on Simulating Conversational Intelligence  in Chat\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.116, \"y\": 2.965}, {\"title\": \"Promoting Target Data in Context-aware Neural Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.777, \"y\": 4.588}, {\"title\": \"RareBench: Can LLMs Serve as Rare Diseases Specialists?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.058, \"y\": 7.272}, {\"title\": \"ExaRanker-Open: Synthetic Explanation for IR using Open-Source LLMs\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.259, \"y\": 4.389}, {\"title\": \"InternLM-Math: Open Math Large Language Models Toward Verifiable  Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.664, \"y\": 1.219}, {\"title\": \"Verif.ai: Towards an Open-Source Scientific Generative  Question-Answering System with Referenced and Verifiable Answers\", \"topic\": \"Text Summarization\", \"x\": 5.086, \"y\": 5.916}, {\"title\": \"Zero-shot Explainable Mental Health Analysis on Social Media by  Incorporating Mental Scales\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.324, \"y\": 6.357}, {\"title\": \"On the Efficacy of Eviction Policy for Key-Value Constrained Generative  Language Model Inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.305, \"y\": 2.987}, {\"title\": \"Fight Back Against Jailbreaking via Prompt Adversarial Tuning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.069, \"y\": 0.53}, {\"title\": \"The Generative AI Paradox on Evaluation: What It Can Solve, It May Not  Evaluate\", \"topic\": \"Large Language Models in Education\", \"x\": 6.329, \"y\": 3.235}, {\"title\": \"CultureLLM: Incorporating Cultural Differences into Large Language  Models\", \"topic\": \"Bias in Language Models\", \"x\": 4.139, \"y\": 2.64}, {\"title\": \"Learn To be Efficient: Build Structured Sparsity in Large Language  Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.158, \"y\": 2.416}, {\"title\": \"Exploring Group and Symmetry Principles in Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.818, \"y\": 1.461}, {\"title\": \"LightCAM: A Fast and Light Implementation of Context-Aware Masking based  D-TDNN for Speaker Verification\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.537, \"y\": 6.029}, {\"title\": \"Large Language Model Augmented Exercise Retrieval for Personalized  Language Learning\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.442, \"y\": 4.333}, {\"title\": \"A Prompt Response to the Demand for Automatic Gender-Neutral Translation\", \"topic\": \"Bias in Language Models\", \"x\": 3.123, \"y\": 2.641}, {\"title\": \"Doing Experiments and Revising Rules with Natural Language and  Probabilistic Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 6.952, \"y\": 2.476}, {\"title\": \"Exploring Visual Culture Awareness in GPT-4V: A Comprehensive Probing\", \"topic\": \"Multimodal Language Models\", \"x\": 8.417, \"y\": 7.646}, {\"title\": \"SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large  Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.479, \"y\": 7.379}, {\"title\": \"Driving Everywhere with Large Language Model Policy Adaptation\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.33, \"y\": 1.428}, {\"title\": \"On the Convergence of Zeroth-Order Federated Tuning for Large Language  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.121, \"y\": 0.002}, {\"title\": \"Efficient Stagewise Pretraining via Progressive Subnetworks\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.904, \"y\": 2.357}, {\"title\": \"FACT-GPT: Fact-Checking Augmentation via Claim Matching with LLMs\", \"topic\": \"Bias in Language Models\", \"x\": 3.722, \"y\": 3.886}, {\"title\": \"CREMA: Generalizable and Efficient Video-Language Reasoning via  Multimodal Modular Fusion\", \"topic\": \"Multimodal Language Models\", \"x\": 8.26, \"y\": 7.609}, {\"title\": \"Generative Echo Chamber? Effects of LLM-Powered Search Systems on  Diverse Information Seeking\", \"topic\": \"Bias in Language Models\", \"x\": 3.591, \"y\": 3.163}, {\"title\": \"EmojiCrypt: Prompt Encryption for Secure Communication with Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.527, \"y\": 0.408}, {\"title\": \"Neural Models for Source Code Synthesis and Completion\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.144, \"y\": 0.024}, {\"title\": \"Selective Forgetting: Advancing Machine Unlearning Techniques and  Evaluation in Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 4.009, \"y\": 0.453}, {\"title\": \"Training Large Language Models for Reasoning through Reverse Curriculum  Reinforcement Learning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.447, \"y\": 1.626}, {\"title\": \"Phonetically rich corpus construction for a low-resourced language\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.295, \"y\": 5.71}, {\"title\": \"Text-to-Code Generation with Modality-relative Pre-training\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.153, \"y\": 0.105}, {\"title\": \"Examining Gender and Racial Bias in Large Vision-Language Models Using a  Novel Dataset of Parallel Images\", \"topic\": \"Bias in Language Models\", \"x\": 3.162, \"y\": 2.719}, {\"title\": \"UFO: A UI-Focused Agent for Windows OS Interaction\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.996, \"y\": 1.717}, {\"title\": \"TimeArena: Shaping Efficient Multitasking Language Agents in a  Time-Aware Simulation\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.01, \"y\": 1.518}, {\"title\": \"Unified Speech-Text Pretraining for Spoken Dialog Modeling\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.246, \"y\": 3.434}, {\"title\": \"Self-Alignment of Large Language Models via Monopolylogue-based Social  Scene Simulation\", \"topic\": \"Bias in Language Models\", \"x\": 4.496, \"y\": 2.095}, {\"title\": \"Comprehensive Assessment of Jailbreak Attacks Against LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.001, \"y\": 0.459}, {\"title\": \"Text Role Classification in Scientific Charts Using Multimodal  Transformers\", \"topic\": \"Multimodal Language Models\", \"x\": 7.435, \"y\": 7.15}, {\"title\": \"Efficient Models for the Detection of Hate, Abuse and Profanity\", \"topic\": \"Bias in Language Models\", \"x\": 2.443, \"y\": 3.403}, {\"title\": \"AttnLRP: Attention-Aware Layer-Wise Relevance Propagation for  Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.327, \"y\": 2.827}, {\"title\": \"Establishing degrees of closeness between audio recordings along  different dimensions using large-scale cross-lingual models\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.072, \"y\": 5.813}, {\"title\": \"Traditional Machine Learning Models and Bidirectional Encoder  Representations From Transformer (BERT)-Based Automatic Classification of  Tweets About Eating Disorders: Algorithm Development and Validation Study\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.386, \"y\": 6.285}, {\"title\": \"Benchmarking Large Language Models on Communicative Medical Coaching: a  Novel System and Dataset\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.587, \"y\": 7.321}, {\"title\": \"Empowering machine learning models with contextual knowledge for  enhancing the detection of eating disorders in social media posts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.493, \"y\": 6.42}, {\"title\": \"Rapid Optimization for Jailbreaking LLMs via Subconscious Exploitation  and Echopraxia\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.929, \"y\": 0.425}, {\"title\": \"It's Never Too Late: Fusing Acoustic Information into Large Language  Models for Automatic Speech Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.571, \"y\": 5.753}, {\"title\": \"Improving Agent Interactions in Virtual Environments with Language  Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.715, \"y\": 1.727}, {\"title\": \"Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.204, \"y\": 2.221}, {\"title\": \"In-Context Principle Learning from Mistakes\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.492, \"y\": 1.997}, {\"title\": \"Text2Data: Low-Resource Data Generation with Textual Control\", \"topic\": \"Multimodal Language Models\", \"x\": 8.55, \"y\": 6.711}, {\"title\": \"Zero-Shot Chain-of-Thought Reasoning Guided by Evolutionary Algorithms  in Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.458, \"y\": 1.822}, {\"title\": \"CIC: A framework for Culturally-aware Image Captioning\", \"topic\": \"Multimodal Language Models\", \"x\": 8.359, \"y\": 7.565}, {\"title\": \"Noise Contrastive Alignment of Language Models with Explicit Rewards\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.383, \"y\": 0.622}, {\"title\": \"Navigating the Knowledge Sea: Planet-scale answer retrieval using LLMs\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.057, \"y\": 4.671}, {\"title\": \"Large Language User Interfaces: Voice Interactive User Interfaces  powered by LLMs\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.882, \"y\": 1.897}, {\"title\": \"Neural machine translation of clinical procedure codes for medical  diagnosis and uncertainty quantification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.892, \"y\": 7.361}, {\"title\": \"VerAs: Verify then Assess STEM Lab Reports\", \"topic\": \"Large Language Models in Education\", \"x\": 6.417, \"y\": 2.507}, {\"title\": \"$\\u03bb$-ECLIPSE: Multi-Concept Personalized Text-to-Image Diffusion  Models by Leveraging CLIP Latent Space\", \"topic\": \"Multimodal Language Models\", \"x\": 8.455, \"y\": 7.009}, {\"title\": \"Image captioning for Brazilian Portuguese using GRIT model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.565, \"y\": 7.389}, {\"title\": \"Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank  Modifications\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.546, \"y\": 0.758}, {\"title\": \"A Roadmap to Pluralistic Alignment\", \"topic\": \"Bias in Language Models\", \"x\": 4.137, \"y\": 2.341}, {\"title\": \"SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large  Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.504, \"y\": 0.927}, {\"title\": \"Text or Image? What is More Important in Cross-Domain Generalization  Capabilities of Hate Meme Detection Models?\", \"topic\": \"Bias in Language Models\", \"x\": 2.49, \"y\": 3.44}, {\"title\": \"Reconfidencing LLMs from the Grouping Loss Perspective\", \"topic\": \"Large Language Models in Education\", \"x\": 6.436, \"y\": 3.1}, {\"title\": \"L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.428, \"y\": 2.107}, {\"title\": \"On Provable Length and Compositional Generalization\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.42, \"y\": 2.952}, {\"title\": \"Hierarchical Tree-structured Knowledge Graph For Academic Insight Survey\", \"topic\": \"Text Summarization\", \"x\": 5.103, \"y\": 6.01}, {\"title\": \"CapsF: Capsule Fusion for Extracting psychiatric stressors for suicide  from twitter\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.331, \"y\": 6.332}, {\"title\": \"PaDeLLM-NER: Parallel Decoding in Large Language Models for Named Entity  Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 6.244, \"y\": 6.824}, {\"title\": \"News Source Credibility Assessment: A Reddit Case Study\", \"topic\": \"Bias in Language Models\", \"x\": 3.462, \"y\": 3.704}, {\"title\": \"Learning Communication Policies for Different Follower Behaviors in a  Collaborative Reference Game\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.771, \"y\": 1.408}, {\"title\": \"Direct Language Model Alignment from Online AI Feedback\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.563, \"y\": 0.577}, {\"title\": \"MLLM-as-a-Judge: Assessing Multimodal LLM-as-a-Judge with  Vision-Language Benchmark\", \"topic\": \"Multimodal Language Models\", \"x\": 7.845, \"y\": 7.619}, {\"title\": \"StableMask: Refining Causal Masking in Decoder-only Transformer\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.646, \"y\": 3.147}, {\"title\": \"ApiQ: Finetuning of 2-Bit Quantized Large Language Model\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.515, \"y\": 2.224}, {\"title\": \"Source Identification in Abstractive Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.126, \"y\": 5.204}, {\"title\": \"TransLLaMa: LLM-based Simultaneous Translation System\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.975, \"y\": 4.73}, {\"title\": \"TinyLLM: Learning a Small Student from Multiple Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.651, \"y\": 2.004}, {\"title\": \"UltraLink: An Open-Source Knowledge-Enhanced Multilingual Supervised  Fine-tuning Dataset\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.074, \"y\": 4.048}, {\"title\": \"Share What You Already Know: Cross-Language-Script Transfer and  Alignment for Sentiment Detection in Code-Mixed Data\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.804, \"y\": 4.705}, {\"title\": \"The Fine-Grained Complexity of Gradient Computation for Training Large  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.773, \"y\": 2.638}, {\"title\": \"ColorSwap: A Color and Word Order Dataset for Multimodal Evaluation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.495, \"y\": 7.493}, {\"title\": \"Evaluating Embeddings for One-Shot Classification of Doctor-AI  Consultations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.006, \"y\": 7.463}, {\"title\": \"Learning to Extract Structured Entities Using Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.205, \"y\": 6.575}, {\"title\": \"DFA-RAG: Conversational Semantic Router for Large Language Model with  Definite Finite Automaton\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.399, \"y\": 3.148}, {\"title\": \"Monitoring the evolution of antisemitic discourse on extremist social  media using BERT\", \"topic\": \"Bias in Language Models\", \"x\": 2.761, \"y\": 3.671}, {\"title\": \"The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax  Mimicry\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.786, \"y\": 2.897}, {\"title\": \"LegalLens: Leveraging LLMs for Legal Violation Identification in  Unstructured Text\", \"topic\": \"Legal NLP\", \"x\": 4.302, \"y\": 4.46}, {\"title\": \"SceMQA: A Scientific College Entrance Level Multimodal Question  Answering Benchmark\", \"topic\": \"Multimodal Language Models\", \"x\": 7.566, \"y\": 7.591}, {\"title\": \"Linear-time Minimum Bayes Risk Decoding with Reference Aggregation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.768, \"y\": 4.842}, {\"title\": \"HarmBench: A Standardized Evaluation Framework for Automated Red Teaming  and Robust Refusal\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.169, \"y\": 0.867}, {\"title\": \"Prioritizing Safeguarding Over Autonomy: Risks of LLM Agents for Science\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.919, \"y\": 1.101}, {\"title\": \"CogCoM: Train Large Vision-Language Models Diving into Details through  Chain of Manipulations\", \"topic\": \"Multimodal Language Models\", \"x\": 7.659, \"y\": 7.631}, {\"title\": \"Can Generative Agents Predict Emotion?\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.607, \"y\": 5.609}, {\"title\": \"What is \\\"Typological Diversity\\\" in NLP?\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.71, \"y\": 4.246}, {\"title\": \"Attention with Markov: A Framework for Principled Analysis of  Transformers via Markov Chains\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.572, \"y\": 2.869}, {\"title\": \"Measuring Implicit Bias in Explicitly Unbiased Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.29, \"y\": 2.735}, {\"title\": \"The Use of a Large Language Model for Cyberbullying Detection\", \"topic\": \"Bias in Language Models\", \"x\": 2.502, \"y\": 3.412}, {\"title\": \"Iterative Prompt Refinement for Radiation Oncology Symptom Extraction  Using Teacher-Student Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.932, \"y\": 7.345}, {\"title\": \"Retrieve to Explain: Evidence-driven Predictions with Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.726, \"y\": 6.719}, {\"title\": \"Systematic Biases in LLM Simulations of Debates\", \"topic\": \"Bias in Language Models\", \"x\": 4.107, \"y\": 2.774}, {\"title\": \"Google Translate Error Analysis for Mental Healthcare Information:  Evaluating Accuracy, Comprehensibility, and Implications for Multilingual  Healthcare Communication\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.966, \"y\": 7.172}, {\"title\": \"REBORN: Reinforcement-Learned Boundary Segmentation with Iterative  Training for Unsupervised ASR\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.5, \"y\": 5.686}, {\"title\": \"Enhancing Retrieval Processes for Language Generation with Augmented  Queries\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.135, \"y\": 4.452}, {\"title\": \"Sparse Graph Representations for Procedural Instructional Documents\", \"topic\": \"Named Entity Recognition\", \"x\": 6.419, \"y\": 5.908}, {\"title\": \"Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in  Closed-Source LLMs\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.927, \"y\": 0.809}, {\"title\": \"Can Large Language Models Detect Rumors on Social Media?\", \"topic\": \"Bias in Language Models\", \"x\": 3.515, \"y\": 3.829}, {\"title\": \"CADReN: Contextual Anchor-Driven Relational Network for Controllable  Cross-Graphs Node Importance Estimation\", \"topic\": \"Named Entity Recognition\", \"x\": 6.552, \"y\": 5.905}, {\"title\": \"Pro-HAN: A Heterogeneous Graph Attention Network for Profile-Based  Spoken Language Understanding\", \"topic\": \"Named Entity Recognition\", \"x\": 6.581, \"y\": 5.184}, {\"title\": \"Shifting social norms as a driving force for linguistic change:  Struggles about language and gender in the German Bundestag\", \"topic\": \"Bias in Language Models\", \"x\": 3.207, \"y\": 2.82}, {\"title\": \"Less than one percent of words would be affected by gender-inclusive  language in German press texts\", \"topic\": \"Bias in Language Models\", \"x\": 3.183, \"y\": 2.732}, {\"title\": \"BiLLM: Pushing the Limit of Post-Training Quantization for LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.6, \"y\": 2.215}, {\"title\": \"Soft Prompt Tuning for Cross-Lingual Transfer: When Less is More\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.086, \"y\": 4.083}, {\"title\": \"Exposing propaganda: an analysis of stylistic cues comparing human  annotations and machine classification\", \"topic\": \"Bias in Language Models\", \"x\": 3.294, \"y\": 3.631}, {\"title\": \"Large Language Models As MOOCs Graders\", \"topic\": \"Large Language Models in Education\", \"x\": 6.35, \"y\": 2.427}, {\"title\": \"Learning a Decision Tree Algorithm with Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.911, \"y\": 2.645}, {\"title\": \"The Instinctive Bias: Spurious Images lead to Hallucination in MLLMs\", \"topic\": \"Multimodal Language Models\", \"x\": 8.329, \"y\": 8.092}, {\"title\": \"Deep Outdated Fact Detection in Knowledge Graphs\", \"topic\": \"Named Entity Recognition\", \"x\": 6.593, \"y\": 5.729}, {\"title\": \"Listen, Chat, and Edit: Text-Guided Soundscape Modification for Enhanced  Auditory Experience\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.797, \"y\": 6.149}, {\"title\": \"Personalized Language Modeling from Personalized Human Feedback\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.427, \"y\": 0.836}, {\"title\": \"Are Machines Better at Complex Reasoning? Unveiling Human-Machine  Inference Gaps in Entailment Verification\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.281, \"y\": 2.219}, {\"title\": \"Large Language Models as an Indirect Reasoner: Contrapositive and  Contradiction for Automated Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.451, \"y\": 1.843}, {\"title\": \"Sentiment-enhanced Graph-based Sarcasm Explanation in Dialogue\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.463, \"y\": 5.027}, {\"title\": \"Stanceosaurus 2.0: Classifying Stance Towards Russian and Spanish  Misinformation\", \"topic\": \"Bias in Language Models\", \"x\": 3.341, \"y\": 3.905}, {\"title\": \"Professional Agents -- Evolving Large Language Models into Autonomous  Experts with Human-Level Competencies\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.102, \"y\": 1.668}, {\"title\": \"Partially Recentralization Softmax Loss for Vision-Language Models  Robustness\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.037, \"y\": 1.031}, {\"title\": \"Self-Discover: Large Language Models Self-Compose Reasoning Structures\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.457, \"y\": 1.822}, {\"title\": \"RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal  LLM Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.148, \"y\": 1.471}, {\"title\": \"Improving Contextual Congruence Across Modalities for Effective  Multimodal Marketing using Knowledge-infused Learning\", \"topic\": \"Multimodal Language Models\", \"x\": 7.88, \"y\": 7.472}, {\"title\": \"Breaking Symmetry When Training Transformers\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.521, \"y\": 2.844}, {\"title\": \"Identifying Reasons for Contraceptive Switching from Real-World Data  Using Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.871, \"y\": 6.849}, {\"title\": \"TexShape: Information Theoretic Sentence Embedding for Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.9, \"y\": 0.649}, {\"title\": \"Financial Report Chunking for Effective Retrieval Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.008, \"y\": 4.717}, {\"title\": \"VLN-Video: Utilizing Driving Videos for Outdoor Vision-and-Language  Navigation\", \"topic\": \"Multimodal Language Models\", \"x\": 8.038, \"y\": 6.945}, {\"title\": \"Resolving Transcription Ambiguity in Spanish: A Hybrid Acoustic-Lexical  System for Punctuation Restoration\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.508, \"y\": 5.681}, {\"title\": \"Evaluating the Factuality of Zero-shot Summarizers Across Varied Domains\", \"topic\": \"Text Summarization\", \"x\": 5.128, \"y\": 5.189}, {\"title\": \"Neural networks for abstraction and reasoning: Towards broad  generalization in machines\", \"topic\": \"Multimodal Language Models\", \"x\": 7.978, \"y\": 7.763}, {\"title\": \"An Inpainting-Infused Pipeline for Attire and Background Replacement\", \"topic\": \"Multimodal Language Models\", \"x\": 8.473, \"y\": 6.874}, {\"title\": \"Arabic Synonym BERT-based Adversarial Examples for Text Classification\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.965, \"y\": 1.187}, {\"title\": \"Psychological Assessments with Large Language Models: A Privacy-Focused  and Cost-Effective Approach\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.413, \"y\": 6.379}, {\"title\": \"DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open  Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.685, \"y\": 1.255}, {\"title\": \"GUARD: Role-playing to Generate Natural-language Jailbreakings to Test  Guideline Adherence of Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.206, \"y\": 0.618}, {\"title\": \"Deal, or no deal (or who knows)? Forecasting Uncertainty in  Conversations using Large Language Models\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.402, \"y\": 2.652}, {\"title\": \"ISPA: Inter-Species Phonetic Alphabet for Transcribing Animal Sounds\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.219, \"y\": 5.914}, {\"title\": \"Understanding Reasoning Ability of Language Models From the Perspective  of Reasoning Paths Aggregation\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.437, \"y\": 2.319}, {\"title\": \"Skill Set Optimization: Reinforcing Language Model Behavior via  Transferable Skills\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.968, \"y\": 1.253}, {\"title\": \"English Prompts are Better for NLI-based Zero-Shot Emotion  Classification than Target-Language Prompts\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.607, \"y\": 5.26}, {\"title\": \"\\\"Define Your Terms\\\" : Enhancing Efficient Offensive Speech  Classification with Definition\", \"topic\": \"Bias in Language Models\", \"x\": 2.438, \"y\": 3.32}, {\"title\": \"Unified Hallucination Detection for Multimodal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.357, \"y\": 8.064}, {\"title\": \"LB-KBQA: Large-language-model and BERT based Knowledge-Based Question  and Answering System\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.109, \"y\": 4.406}, {\"title\": \"C-RAG: Certified Generation Risks for Retrieval-Augmented Language  Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.252, \"y\": 4.207}, {\"title\": \"MULTI: Multimodal Understanding Leaderboard with Text and Images\", \"topic\": \"Multimodal Language Models\", \"x\": 7.646, \"y\": 7.525}, {\"title\": \"Accurate and Well-Calibrated ICD Code Assignment Through Attention Over  Diverse Label Embeddings\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.268, \"y\": 7.497}, {\"title\": \"Video-LaVIT: Unified Video-Language Pre-training with Decoupled  Visual-Motional Tokenization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.782, \"y\": 7.403}, {\"title\": \"Less is KEN: a Universal and Simple Non-Parametric Pruning Algorithm for  Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.06, \"y\": 2.361}, {\"title\": \"Sociolinguistically Informed Interpretability: A Case Study on Hinglish  Emotion Classification\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.588, \"y\": 5.082}, {\"title\": \"Constrained Decoding for Cross-lingual Label Projection\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.039, \"y\": 4.538}, {\"title\": \"Enhancing the Stability of LLM-based Speech Generation Systems through  Self-Supervised Representations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.142, \"y\": 6.011}, {\"title\": \"A Comprehensive Study of the Current State-of-the-Art in Nepali  Automatic Speech Recognition Systems\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.291, \"y\": 5.733}, {\"title\": \"Decoding-time Realignment of Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.599, \"y\": 0.718}, {\"title\": \"Conversation Reconstruction Attack Against GPT Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.402, \"y\": 0.442}, {\"title\": \"Towards Understanding the Word Sensitivity of Attention Layers: A Study  via Random Features\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.602, \"y\": 2.8}, {\"title\": \"A Survey on Transformer Compression\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.011, \"y\": 2.621}, {\"title\": \"Enhancing Textbook Question Answering Task with Large Language Models  and Retrieval Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.684, \"y\": 4.499}, {\"title\": \"Comparing Knowledge Sources for Open-Domain Scientific Claim  Verification\", \"topic\": \"Bias in Language Models\", \"x\": 3.916, \"y\": 3.984}, {\"title\": \"Shortened LLaMA: Depth Pruning for Large Language Models with Comparison  of Retraining Methods\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.027, \"y\": 2.343}, {\"title\": \"Graph-enhanced Large Language Models in Asynchronous Plan Reasoning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.448, \"y\": 1.503}, {\"title\": \"Rethinking Optimization and Architecture for Tiny Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.059, \"y\": 2.546}, {\"title\": \"Dual Knowledge Distillation for Efficient Sound Event Detection\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.993, \"y\": 6.105}, {\"title\": \"List-aware Reranking-Truncation Joint Model for Search and  Retrieval-augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 5.962, \"y\": 4.613}, {\"title\": \"DeAL: Decoding-time Alignment for Large Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.54, \"y\": 0.738}, {\"title\": \"Illuminate: A novel approach for depression detection with explainable  analysis and proactive therapy using prompt engineering\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.04, \"y\": 6.415}, {\"title\": \"KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.54, \"y\": 2.511}, {\"title\": \"Understanding the planning of LLM agents: A survey\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.207, \"y\": 1.547}, {\"title\": \"Exploiting Class Probabilities for Black-box Sentence-level Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.059, \"y\": 1.139}, {\"title\": \"Graph Neural Network and NER-Based Text Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.235, \"y\": 5.33}, {\"title\": \"Adversarial Text Purification: A Large Language Model Approach for  Defense\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.996, \"y\": 1.182}, {\"title\": \"Large Language Models are Geographically Biased\", \"topic\": \"Bias in Language Models\", \"x\": 3.416, \"y\": 2.871}, {\"title\": \"Image-Caption Encoding for Improving Zero-Shot Generalization\", \"topic\": \"Multimodal Language Models\", \"x\": 8.42, \"y\": 7.606}, {\"title\": \"Multi-step Problem Solving Through a Verifier: An Empirical Analysis on  Model-induced Process Supervision\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.418, \"y\": 1.599}, {\"title\": \"RACER: An LLM-powered Methodology for Scalable Analysis of  Semi-structured Mental Health Interviews\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.036, \"y\": 6.542}, {\"title\": \"Recursive Chain-of-Feedback Prevents Performance Degradation from  Redundant Prompting\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.068, \"y\": 2.083}, {\"title\": \"Zero-Shot Clinical Trial Patient Matching with LLMs\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.193, \"y\": 7.08}, {\"title\": \"\\\"It's how you do things that matters\\\": Attending to Process to Better  Serve Indigenous Communities with Language Technologies\", \"topic\": \"Bias in Language Models\", \"x\": 3.906, \"y\": 2.655}, {\"title\": \"Predicting Machine Translation Performance on Low-Resource Languages:  The Role of Domain Similarity\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.556, \"y\": 4.483}, {\"title\": \"GIRT-Model: Automated Generation of Issue Report Templates\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.944, \"y\": 0.164}, {\"title\": \"UniTSyn: A Large-Scale Dataset Capable of Enhancing the Prowess of Large  Language Models for Program Testing\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.034, \"y\": 0.193}, {\"title\": \"Enhancing Transformer RNNs with Multiple Temporal Perspectives\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.777, \"y\": 3.06}, {\"title\": \"DenseFormer: Enhancing Information Flow in Transformers via Depth  Weighted Averaging\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.868, \"y\": 2.748}, {\"title\": \"Layer-Wise Analysis of Self-Supervised Acoustic Word Embeddings: A Study  on Speech Emotion Recognition\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.438, \"y\": 5.422}, {\"title\": \"PuzzleBench: Can LLMs Solve Challenging First-Order Combinatorial  Reasoning Problems?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.256, \"y\": 1.701}, {\"title\": \"A Quantitative Discourse Analysis of Asian Workers in the US Historical  Newspapers\", \"topic\": \"Bias in Language Models\", \"x\": 3.023, \"y\": 2.984}, {\"title\": \"Synergy-of-Thoughts: Eliciting Efficient Reasoning in Hybrid Language  Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.249, \"y\": 1.761}, {\"title\": \"Enhancing Robustness in Biomedical NLI Models: A Probing Approach for  Clinical Trials\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.216, \"y\": 7.12}, {\"title\": \"Generalizable Entity Grounding via Assistance of Large Language Model\", \"topic\": \"Multimodal Language Models\", \"x\": 7.95, \"y\": 7.289}, {\"title\": \"\\\"What's my model inside of?\\\": Exploring the role of environments for  grounded natural language understanding\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.678, \"y\": 1.857}, {\"title\": \"Knowledge Generation for Zero-shot Knowledge-based VQA\", \"topic\": \"Multimodal Language Models\", \"x\": 7.805, \"y\": 7.725}, {\"title\": \"GeReA: Question-Aware Prompt Captions for Knowledge-based Visual  Question Answering\", \"topic\": \"Multimodal Language Models\", \"x\": 7.811, \"y\": 7.74}, {\"title\": \"Navigating the Peril of Generated Alternative Facts: A ChatGPT-4  Fabricated Omega Variant Case as a Cautionary Tale in Medical Misinformation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.989, \"y\": 6.75}, {\"title\": \"BRAIn: Bayesian Reward-conditioned Amortized Inference for natural  language generation from feedback\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.619, \"y\": 0.876}, {\"title\": \"tnGPS: Discovering Unknown Tensor Network Structure Search Algorithms  via Large Language Models (LLMs)\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.966, \"y\": 2.184}, {\"title\": \"Breaking MLPerf Training: A Case Study on Optimizing BERT\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.941, \"y\": 2.54}, {\"title\": \"LQER: Low-Rank Quantization Error Reconstruction for LLMs\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.579, \"y\": 2.211}, {\"title\": \"Aligner: Efficient Alignment by Learning to Correct\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.5, \"y\": 0.876}, {\"title\": \"KICGPT: Large Language Model with Knowledge in Context for Knowledge  Graph Completion\", \"topic\": \"Named Entity Recognition\", \"x\": 6.751, \"y\": 5.837}, {\"title\": \"Solution-oriented Agent-based Models Generation with Verifier-assisted  Iterative In-context Learning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.026, \"y\": 1.863}, {\"title\": \"Evaluating Large Language Models in Analysing Classroom Dialogue\", \"topic\": \"Large Language Models in Education\", \"x\": 6.271, \"y\": 2.393}, {\"title\": \"M$^3$Face: A Unified Multi-Modal Multilingual Framework for Human Face  Generation and Editing\", \"topic\": \"Multimodal Language Models\", \"x\": 8.265, \"y\": 6.863}, {\"title\": \"The Developmental Landscape of In-Context Learning\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.907, \"y\": 2.798}, {\"title\": \"Enhance Reasoning for Large Language Models in the Game Werewolf\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.965, \"y\": 1.812}, {\"title\": \"Selecting Large Language Model to Fine-tune via Rectified Scaling Law\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.414, \"y\": 2.227}, {\"title\": \"Jailbreaking Attack against Multimodal Large Language Model\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.065, \"y\": 0.521}, {\"title\": \"Predicting positive transfer for improved low-resource speech  recognition using acoustic pseudo-tokens\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.46, \"y\": 5.661}, {\"title\": \"SemPool: Simple, robust, and interpretable KG pooling for enhancing  language models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.67, \"y\": 5.436}, {\"title\": \"SynthDST: Synthetic Data is All You Need for Few-Shot Dialog State  Tracking\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.184, \"y\": 3.334}, {\"title\": \"Data Quality Matters: Suicide Intention Detection on Social Media Posts  Using a RoBERTa-CNN Model\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.292, \"y\": 6.404}, {\"title\": \"Beyond the Limits: A Survey of Techniques to Extend the Context Length  in Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.609, \"y\": 3.234}, {\"title\": \"DE$^3$-BERT: Distance-Enhanced Early Exiting for BERT based on  Prototypical Networks\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.626, \"y\": 2.694}, {\"title\": \"Analyzing Sentiment Polarity Reduction in News Presentation through  Contextual Perturbation and Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 3.28, \"y\": 3.854}, {\"title\": \"Probing Critical Learning Dynamics of PLMs for Hate Speech Detection\", \"topic\": \"Bias in Language Models\", \"x\": 2.438, \"y\": 3.33}, {\"title\": \"Do Moral Judgment and Reasoning Capability of LLMs Change with Language?  A Study using the Multilingual Defining Issues Test\", \"topic\": \"Bias in Language Models\", \"x\": 4.049, \"y\": 2.241}, {\"title\": \"Zero-shot Sentiment Analysis in Low-Resource Languages Using a  Multilingual Sentiment Lexicon\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.817, \"y\": 4.779}, {\"title\": \"Analyzing the Evaluation of Cross-Lingual Knowledge Transfer in  Multilingual Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.252, \"y\": 4.361}, {\"title\": \"Revisiting the Markov Property for Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.947, \"y\": 4.527}, {\"title\": \"Translation Errors Significantly Impact Low-Resource Languages in  Cross-Lingual Learning\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.397, \"y\": 4.479}, {\"title\": \"Exploring the Robustness of Task-oriented Dialogue Systems for  Colloquial German Varieties\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.295, \"y\": 3.344}, {\"title\": \"Investigating Content Planning for Navigating Trade-offs in  Knowledge-Grounded Dialogue\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.363, \"y\": 3.534}, {\"title\": \"Break the Sequential Dependency of LLM Inference Using Lookahead  Decoding\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.559, \"y\": 3.071}, {\"title\": \"AnthroScore: A Computational Linguistic Measure of Anthropomorphism\", \"topic\": \"Bias in Language Models\", \"x\": 3.429, \"y\": 2.802}, {\"title\": \"EffiBench: Benchmarking the Efficiency of Automatically Generated Code\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.14, \"y\": 0.042}, {\"title\": \"Panacea: Pareto Alignment via Preference Adaptation for LLMs\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.517, \"y\": 0.48}, {\"title\": \"How well do LLMs cite relevant medical references? An evaluation  framework and analyses\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.828, \"y\": 7.087}, {\"title\": \"Self-Debiasing Large Language Models: Zero-Shot Recognition and  Reduction of Stereotypes\", \"topic\": \"Bias in Language Models\", \"x\": 3.27, \"y\": 2.55}, {\"title\": \"MasonPerplexity at ClimateActivism 2024: Integrating Advanced Ensemble  Techniques and Data Augmentation for Climate Activism Stance and Hate Event  Identification\", \"topic\": \"Bias in Language Models\", \"x\": 2.847, \"y\": 3.87}, {\"title\": \"MasonPerplexity at Multimodal Hate Speech Event Detection 2024: Hate  Speech and Target Detection Using Transformer Ensembles\", \"topic\": \"Bias in Language Models\", \"x\": 2.446, \"y\": 3.472}, {\"title\": \"Improving Large-Scale k-Nearest Neighbor Text Categorization with Label  Autoencoders\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.523, \"y\": 7.349}, {\"title\": \"A Case Study on Filtering for End-to-End Speech Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.887, \"y\": 5.032}, {\"title\": \"A Morphologically-Aware Dictionary-based Data Augmentation Technique for  Machine Translation of Under-Represented Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.477, \"y\": 4.567}, {\"title\": \"Code Representation Learning At Scale\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.232, \"y\": -0.028}, {\"title\": \"Digits micro-model for accurate and secure transactions\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.727, \"y\": 5.52}, {\"title\": \"Preference Poisoning Attacks on Reward Model Learning\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.277, \"y\": 0.776}, {\"title\": \"Whispering in Norwegian: Navigating Orthographic and Dialectic  Challenges\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.446, \"y\": 5.774}, {\"title\": \"CoLe and LYS at BioASQ MESINESP8 Task: similarity based descriptor  assignment in Spanish\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.516, \"y\": 7.242}, {\"title\": \"Natural language guidance of high-fidelity text-to-speech with synthetic  annotations\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.875, \"y\": 6.077}, {\"title\": \"LiPO: Listwise Preference Optimization through Learning-to-Rank\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.474, \"y\": 0.563}, {\"title\": \"The RL/LLM Taxonomy Tree: Reviewing Synergies Between Reinforcement  Learning and Large Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.93, \"y\": 1.153}, {\"title\": \"InferCept: Efficient Intercept Support for Augmented Large Language  Model Inference\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.533, \"y\": 2.823}, {\"title\": \"What Will My Model Forget? Forecasting Forgotten Examples in Language  Model Refinement\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.993, \"y\": 2.189}, {\"title\": \"Explaining latent representations of generative models with large  multimodal models\", \"topic\": \"Multimodal Language Models\", \"x\": 7.75, \"y\": 7.539}, {\"title\": \"COMET: Generating Commit Messages using Delta Graph Context  Representation\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.912, \"y\": 0.064}, {\"title\": \"PiCO: Peer Review in LLMs based on the Consistency Optimization\", \"topic\": \"Large Language Models in Education\", \"x\": 6.493, \"y\": 3.066}, {\"title\": \"Position Paper: Generalized grammar rules and structure-based  generalization beyond classical equivariance for lexical tasks and  transduction\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.999, \"y\": 2.904}, {\"title\": \"TravelPlanner: A Benchmark for Real-World Planning with Language Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.4, \"y\": 1.491}, {\"title\": \"MAGDi: Structured Distillation of Multi-Agent Interaction Graphs  Improves Reasoning in Smaller Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.59, \"y\": 1.832}, {\"title\": \"Retrieval Augmented End-to-End Spoken Dialog Models\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.365, \"y\": 3.583}, {\"title\": \"Leveraging Large Language Models for Analyzing Blood Pressure Variations  Across Biological Sex from Scientific Literature\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.077, \"y\": 7.183}, {\"title\": \"Towards Sustainable Workplace Mental Health: A Novel Approach to Early  Intervention and Support\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.049, \"y\": 6.34}, {\"title\": \"BAT: Learning to Reason about Spatial Sounds with Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.879, \"y\": 7.064}, {\"title\": \"TrustAgent: Towards Safe and Trustworthy LLM-based Agents through Agent  Constitution\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.073, \"y\": 1.4}, {\"title\": \"How Paralingual are Paralinguistic Representations? A Case Study in  Speech Emotion Recognition\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.388, \"y\": 5.5}, {\"title\": \"Fractal Patterns May Illuminate the Success of Next-Token Prediction\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.894, \"y\": 3.178}, {\"title\": \"Building Guardrails for Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.768, \"y\": 1.135}, {\"title\": \"Multilingual Gradient Word-Order Typology from Universal Dependencies\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.685, \"y\": 4.201}, {\"title\": \"A Hybrid Strategy for Chat Transcript Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.132, \"y\": 5.079}, {\"title\": \"AMOR: A Recipe for Building Adaptable Modular Knowledge Agents Through  Process Feedback\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.216, \"y\": 1.542}, {\"title\": \"Different Tastes of Entities: Investigating Human Label Variation in  Named Entity Annotations\", \"topic\": \"Named Entity Recognition\", \"x\": 6.142, \"y\": 6.778}, {\"title\": \"Sequence Shortening for Context-Aware Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.883, \"y\": 4.394}, {\"title\": \"On Measuring Context Utilization in Document-Level MT Systems\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.502, \"y\": 4.873}, {\"title\": \"Distilling LLMs' Decomposition Abilities into Compact Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.241, \"y\": 1.733}, {\"title\": \"StepCoder: Improve Code Generation with Reinforcement Learning from  Compiler Feedback\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.12, \"y\": 0.101}, {\"title\": \"LLM-based NLG Evaluation: Current Status and Challenges\", \"topic\": \"Large Language Models in Education\", \"x\": 6.368, \"y\": 3.575}, {\"title\": \"LoTR: Low Tensor Rank Weight Adaptation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.024, \"y\": 1.874}, {\"title\": \"What Makes Medical Claims (Un)Verifiable? Analyzing Entity and Relation  Properties for Fact Verification\", \"topic\": \"Bias in Language Models\", \"x\": 3.849, \"y\": 4.092}, {\"title\": \"Describing Images $\\\\textit{Fast and Slow}$: Quantifying and Predicting  the Variation in Human Signals during Visuo-Linguistic Processes\", \"topic\": \"Multimodal Language Models\", \"x\": 8.251, \"y\": 7.731}, {\"title\": \"Skip \\\\n: A Simple Method to Reduce Hallucination in Large  Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.37, \"y\": 8.124}, {\"title\": \"Rethinking the Role of Proxy Rewards in Language Model Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.575, \"y\": 0.712}, {\"title\": \"Can MLLMs Perform Text-to-Image In-Context Learning?\", \"topic\": \"Multimodal Language Models\", \"x\": 8.393, \"y\": 7.237}, {\"title\": \"HQA-Attack: Toward High Quality Black-Box Hard-Label Adversarial Attack  on Text\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.984, \"y\": 1.168}, {\"title\": \"Detection of tortured phrases in scientific literature\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.017, \"y\": 1.536}, {\"title\": \"In-Context Learning for Few-Shot Nested Named Entity Recognition\", \"topic\": \"Named Entity Recognition\", \"x\": 6.35, \"y\": 6.827}, {\"title\": \"CorpusLM: Towards a Unified Language Model on Corpus for  Knowledge-Intensive Tasks\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.126, \"y\": 4.659}, {\"title\": \"Streaming Sequence Transduction through Dynamic Compression\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.452, \"y\": 5.556}, {\"title\": \"Faster and Lighter LLMs: A Survey on Current Challenges and Way Forward\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.537, \"y\": 2.371}, {\"title\": \"AccentFold: A Journey through African Accents for Zero-Shot ASR  Adaptation to Target Accents\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.438, \"y\": 5.681}, {\"title\": \"Speech foundation models in healthcare: Effect of layer selection on  pathological speech feature prediction\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.416, \"y\": 6.169}, {\"title\": \"PokeLLMon: A Human-Parity Agent for Pokemon Battles with Large Language  Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.845, \"y\": 1.504}, {\"title\": \"Interpretation of Intracardiac Electrograms Through Textual  Representations\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.296, \"y\": 7.581}, {\"title\": \"Evaluation of Google's Voice Recognition and Sentence Classification for  Health Care Applications\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.941, \"y\": 7.392}, {\"title\": \"Vaccine: Perturbation-aware Alignment for Large Language Model\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.491, \"y\": 0.809}, {\"title\": \"Reasoning Capacity in Multi-Agent Systems: Limitations, Challenges and  Human-Centered Solutions\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.937, \"y\": 1.777}, {\"title\": \"LitLLM: A Toolkit for Scientific Literature Review\", \"topic\": \"Text Summarization\", \"x\": 5.03, \"y\": 5.912}, {\"title\": \"Specialized Language Models with Cheap Inference from Limited Domain  Data\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.452, \"y\": 2.545}, {\"title\": \"Reading Between the Tweets: Deciphering Ideological Stances of  Interconnected Mixed-Ideology Communities\", \"topic\": \"Bias in Language Models\", \"x\": 3.251, \"y\": 3.867}, {\"title\": \"Plan-Grounded Large Language Models for Dual Goal Conversational  Settings\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.315, \"y\": 2.876}, {\"title\": \"COA-GPT: Generative Pre-trained Transformers for Accelerated Course of  Action Development in Military Operations\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.887, \"y\": 1.367}, {\"title\": \"Getting the most out of your tokenizer for pre-training and domain  adaptation\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.346, \"y\": 0.127}, {\"title\": \"Repeat After Me: Transformers are Better than State Space Models at  Copying\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.761, \"y\": 3.046}, {\"title\": \"Executable Code Actions Elicit Better LLM Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.365, \"y\": 1.36}, {\"title\": \"Domain-Independent Deception: A New Taxonomy and Linguistic Analysis\", \"topic\": \"Bias in Language Models\", \"x\": 3.428, \"y\": 3.443}, {\"title\": \"HR-MultiWOZ: A Task Oriented Dialogue (TOD) Dataset for HR LLM Agent\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.113, \"y\": 3.211}, {\"title\": \"An Information-Theoretic Approach to Analyze NLP Classification Tasks\", \"topic\": \"Large Language Models in Education\", \"x\": 6.542, \"y\": 2.637}, {\"title\": \"When Benchmarks are Targets: Revealing the Sensitivity of Large Language  Model Leaderboards\", \"topic\": \"Large Language Models in Education\", \"x\": 6.788, \"y\": 2.896}, {\"title\": \"Towards Efficient Exact Optimization of Language Model Alignment\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.515, \"y\": 0.565}, {\"title\": \"Tiny Titans: Can Smaller Large Language Models Punch Above Their Weight  in the Real World for Meeting Summarization?\", \"topic\": \"Text Summarization\", \"x\": 5.203, \"y\": 5.005}, {\"title\": \"ALISON: Fast and Effective Stylometric Authorship Obfuscation\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.537, \"y\": 0.562}, {\"title\": \"Introduction to speech recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.353, \"y\": 5.766}, {\"title\": \"Formal-LLM: Integrating Formal Language and Natural Language for  Controllable LLM-based Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.336, \"y\": 1.427}, {\"title\": \"ReAGent: A Model-agnostic Feature Attribution Method for Generative  Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.981, \"y\": 3.417}, {\"title\": \"CroissantLLM: A Truly Bilingual French-English Language Model\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.302, \"y\": 4.15}, {\"title\": \"Health-LLM: Personalized Retrieval-Augmented Disease Prediction System\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.846, \"y\": 7.205}, {\"title\": \"BATON: Aligning Text-to-Audio Model with Human Preference Feedback\", \"topic\": \"Speech Recognition and Translation\", \"x\": 9.666, \"y\": 6.14}, {\"title\": \"Theoretical Understanding of In-Context Learning in Shallow Transformers  with Unstructured Data\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 8.975, \"y\": 2.919}, {\"title\": \"Transforming and Combining Rewards for Aligning Large Language Models\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.438, \"y\": 0.563}, {\"title\": \"Improving Semantic Control in Discrete Latent Spaces with Transformer  Quantized Variational Autoencoders\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.627, \"y\": 3.097}, {\"title\": \"Learning Planning-based Reasoning by Trajectories Collection and Process  Reward Synthesizing\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.209, \"y\": 1.498}, {\"title\": \"A Chain-of-Thought Is as Strong as Its Weakest Link: A Benchmark for  Verifiers of Reasoning Chains\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.318, \"y\": 2.075}, {\"title\": \"EE-Tuning: An Economical yet Scalable Solution for Tuning Early-Exit  Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.682, \"y\": 2.175}, {\"title\": \"Institutional Platform for Secure Self-Service Large Language Model  Exploration\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.768, \"y\": 0.371}, {\"title\": \"Disentangling the Roles of Target-Side Transfer and Regularization in  Multilingual Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.447, \"y\": 4.488}, {\"title\": \"SA-MDKIF: A Scalable and Adaptable Medical Domain Knowledge Injection  Framework for Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.085, \"y\": 7.351}, {\"title\": \"Instruction Makes a Difference\", \"topic\": \"Multimodal Language Models\", \"x\": 7.672, \"y\": 7.477}, {\"title\": \"From PARIS to LE-PARIS: Toward Patent Response Automation with  Recommender Systems and Collaborative Large Language Models\", \"topic\": \"Legal NLP\", \"x\": 4.697, \"y\": 4.835}, {\"title\": \"Hidding the Ghostwriters: An Adversarial Evaluation of AI-Generated  Student Essay Detection\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.851, \"y\": 1.485}, {\"title\": \"Investigating Bias Representations in Llama 2 Chat via Activation  Steering\", \"topic\": \"Bias in Language Models\", \"x\": 3.467, \"y\": 2.736}, {\"title\": \"BlackMamba: Mixture of Experts for State-Space Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.078, \"y\": 2.578}, {\"title\": \"What Does the Bot Say? Opportunities and Risks of Large Language Models  in Social Media Bot Detection\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.103, \"y\": 1.426}, {\"title\": \"IndiVec: An Exploration of Leveraging Large Language Models for Media  Bias Detection with Fine-Grained Bias Indicators\", \"topic\": \"Bias in Language Models\", \"x\": 3.222, \"y\": 3.731}, {\"title\": \"Bias in Opinion Summarisation from Pre-training to Adaptation: A Case  Study in Political Bias\", \"topic\": \"Text Summarization\", \"x\": 4.866, \"y\": 5.056}, {\"title\": \"HiQA: A Hierarchical Contextual Augmentation RAG for Massive Documents  QA\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.397, \"y\": 4.535}, {\"title\": \"Does DetectGPT Fully Utilize Perturbation? Bridge Selective Perturbation  to Fine-tuned Contrastive Learning Detector would be Better\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.767, \"y\": 1.705}, {\"title\": \"A Survey on Hallucination in Large Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.351, \"y\": 8.112}, {\"title\": \"Exploring the limits of decoder-only models trained on public speech  recognition corpora\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.595, \"y\": 5.594}, {\"title\": \"Are Generative AI systems Capable of Supporting Information Needs of  Patients?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.083, \"y\": 7.855}, {\"title\": \"De-identification is not always enough\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.757, \"y\": 0.369}, {\"title\": \"Emergency Department Decision Support using Clinical Pseudo-notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.281, \"y\": 7.711}, {\"title\": \"Large Language Models for Mathematical Reasoning: Progresses and  Challenges\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.669, \"y\": 1.223}, {\"title\": \"The Impact of Language Adapters in Cross-Lingual Transfer for NLU\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.33, \"y\": 4.261}, {\"title\": \"An Early Categorization of Prompt Injection Attacks on Large Language  Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.293, \"y\": 0.471}, {\"title\": \"Making a Long Story Short in Conversation Modeling\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.085, \"y\": 3.146}, {\"title\": \"Common Sense Reasoning for Deep Fake Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.519, \"y\": 3.76}, {\"title\": \"Comparing Template-based and Template-free Language Model Probing\", \"topic\": \"Large Language Models in Education\", \"x\": 7.127, \"y\": 2.937}, {\"title\": \"Do Language Models Exhibit the Same Cognitive Biases in Problem Solving  as Human Learners?\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.711, \"y\": 1.473}, {\"title\": \"RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.404, \"y\": 4.67}, {\"title\": \"LongAlign: A Recipe for Long Context Alignment of Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.132, \"y\": 3.348}, {\"title\": \"SpeechComposer: Unifying Multiple Speech Tasks with Prompt Composition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.143, \"y\": 5.87}, {\"title\": \"Enhancing End-to-End Multi-Task Dialogue Systems: A Study on Intrinsic  Motivation Reinforcement Learning Algorithms for Improved Training and  Adaptability\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.24, \"y\": 2.799}, {\"title\": \"Paramanu: A Family of Novel Efficient Indic Generative Foundation  Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.883, \"y\": 4.221}, {\"title\": \"Evaluating the Capabilities of LLMs for Supporting Anticipatory Impact  Assessment\", \"topic\": \"Bias in Language Models\", \"x\": 4.03, \"y\": 2.582}, {\"title\": \"On Prompt-Driven Safeguarding for Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.721, \"y\": 1.048}, {\"title\": \"Desiderata for the Context Use of Question Answering Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.657, \"y\": 4.386}, {\"title\": \"GUMsley: Evaluating Entity Salience in Summarization for 12 English  Genres\", \"topic\": \"Text Summarization\", \"x\": 5.199, \"y\": 5.172}, {\"title\": \"Ontologia para monitorar a defici\\u00eancia mental em seus d\\u00e9ficts no  processamento da informa\\u00e7\\u00e3o por decl\\u00ednio cognitivo e evitar  agress\\u00f5es psicol\\u00f3gicas e f\\u00edsicas em ambientes educacionais com ajuda da  I.A*\", \"topic\": \"Bias in Language Models\", \"x\": 2.621, \"y\": 3.526}, {\"title\": \"LOCOST: State-Space Models for Long Document Abstractive Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.385, \"y\": 5.055}, {\"title\": \"Revisiting speech segmentation and lexicon learning with better features\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.369, \"y\": 5.726}, {\"title\": \"Employing Label Models on ChatGPT Answers Improves Legal Text Entailment  Performance\", \"topic\": \"Legal NLP\", \"x\": 4.386, \"y\": 4.462}, {\"title\": \"LLM Voting: Human Choices and AI Collective Decision Making\", \"topic\": \"Bias in Language Models\", \"x\": 4.299, \"y\": 2.651}, {\"title\": \"Global-Liar: Factuality of LLMs over Time and Geographic Regions\", \"topic\": \"Bias in Language Models\", \"x\": 3.593, \"y\": 3.029}, {\"title\": \"Enhancing Large Language Model with Decomposed Reasoning for Emotion  Cause Pair Extraction\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.547, \"y\": 5.359}, {\"title\": \"Deductive Beam Search: Decoding Deducible Rationale for Chain-of-Thought  Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.385, \"y\": 1.939}, {\"title\": \"What Do Self-Supervised Speech and Speaker Models Learn? New Findings  From a Cross Model Layer-Wise Analysis\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.556, \"y\": 5.915}, {\"title\": \"Assertion Detection Large Language Model In-context Learning LoRA  Fine-tuning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.052, \"y\": 7.256}, {\"title\": \"Good at captioning, bad at counting: Benchmarking GPT-4V on Earth  observation data\", \"topic\": \"Multimodal Language Models\", \"x\": 8.137, \"y\": 7.707}, {\"title\": \"SPECTRUM: Speaker-Enhanced Pre-Training for Long Dialogue Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.127, \"y\": 4.836}, {\"title\": \"Local and Global Contexts for Conversation\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.158, \"y\": 3.485}, {\"title\": \"Scavenging Hyena: Distilling Transformers into Long Convolution Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.803, \"y\": 2.954}, {\"title\": \"Linguistically Communicating Uncertainty in Patient-Facing Risk  Prediction Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.801, \"y\": 7.365}, {\"title\": \"Arrows of Time for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.019, \"y\": 2.946}, {\"title\": \"Detecting mental disorder on social media: a ChatGPT-augmented  explainable approach\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.272, \"y\": 6.364}, {\"title\": \"Efficient Tool Use with Chain-of-Abstraction Reasoning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.429, \"y\": 1.664}, {\"title\": \"EvoMerge: Neuroevolution for Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.297, \"y\": 2.107}, {\"title\": \"Arabic Tweet Act: A Weighted Ensemble Pre-Trained Transformer Model for  Classifying Arabic Speech Acts on Twitter\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 3.02, \"y\": 4.85}, {\"title\": \"Robust Prompt Optimization for Defending Language Models Against  Jailbreaking Attacks\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.13, \"y\": 0.493}, {\"title\": \"Weak-to-Strong Jailbreaking on Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.172, \"y\": 0.652}, {\"title\": \"Morality is Non-Binary: Building a Pluralist Moral Sentence Embedding  Space using Contrastive Learning\", \"topic\": \"Bias in Language Models\", \"x\": 3.986, \"y\": 2.244}, {\"title\": \"MouSi: Poly-Visual-Expert Vision-Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.291, \"y\": 7.447}, {\"title\": \"Single Word Change is All You Need: Designing Attacks and Defenses for  Text Classifiers\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.983, \"y\": 1.181}, {\"title\": \"Conditional and Modal Reasoning in Large Language Models\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.461, \"y\": 2.334}, {\"title\": \"Large Language Models in Cybersecurity: State-of-the-Art\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.398, \"y\": 1.059}, {\"title\": \"Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool  Utilization in Real-World Complex Scenarios\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.475, \"y\": 1.366}, {\"title\": \"Systematic Literature Review: Computational Approaches for Humour Style  Classification\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.488, \"y\": 4.792}, {\"title\": \"MT-Ranker: Reference-free machine translation evaluation by inter-system  ranking\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.498, \"y\": 5.002}, {\"title\": \"StrokeNUWA: Tokenizing Strokes for Vector Graphic Synthesis\", \"topic\": \"Multimodal Language Models\", \"x\": 7.749, \"y\": 7.006}, {\"title\": \"SemScore: Automated Evaluation of Instruction-Tuned LLMs based on  Semantic Textual Similarity\", \"topic\": \"Large Language Models in Education\", \"x\": 6.425, \"y\": 3.495}, {\"title\": \"CRUD-RAG: A Comprehensive Chinese Benchmark for Retrieval-Augmented  Generation of Large Language Models\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.112, \"y\": 4.502}, {\"title\": \"Taking Action Towards Graceful Interaction: The Effects of Performing  Actions on Modelling Policies for Instruction Clarification Requests\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.856, \"y\": 1.727}, {\"title\": \"QACP: An Annotated Question Answering Dataset for Assisting Chinese  Python Programming Learners\", \"topic\": \"Large Language Models in Education\", \"x\": 6.406, \"y\": 2.447}, {\"title\": \"Aalap: AI Assistant for Legal & Paralegal Functions in India\", \"topic\": \"Legal NLP\", \"x\": 4.366, \"y\": 4.507}, {\"title\": \"Cross-Lingual Transfer from Related Languages: Treating Low-Resource  Maltese as Multilingual Code-Switching\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.305, \"y\": 4.503}, {\"title\": \"State Value Generation with Prompt Learning and Self-Training for  Low-Resource Dialogue State Tracking\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.162, \"y\": 3.303}, {\"title\": \"Identifying False Content and Hate Speech in Sinhala YouTube Videos by  Analyzing the Audio\", \"topic\": \"Bias in Language Models\", \"x\": 2.481, \"y\": 3.333}, {\"title\": \"Performance Assessment of ChatGPT vs Bard in Detecting Alzheimer's  Dementia\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.587, \"y\": 7.04}, {\"title\": \"Can Large Language Models be Trusted for Evaluation? Scalable  Meta-Evaluation of LLMs as Evaluators via Agent Debate\", \"topic\": \"Large Language Models in Education\", \"x\": 6.143, \"y\": 2.749}, {\"title\": \"PACE: A Pragmatic Agent for Enhancing Communication Efficiency Using  Large Language Models\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.112, \"y\": 1.508}, {\"title\": \"Detecting Racist Text in Bengali: An Ensemble Deep Learning Framework\", \"topic\": \"Bias in Language Models\", \"x\": 2.375, \"y\": 3.437}, {\"title\": \"MT-Eval: A Multi-Turn Capabilities Evaluation Benchmark for Large  Language Models\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.3, \"y\": 3.179}, {\"title\": \"Engineering A Large Language Model From Scratch\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.687, \"y\": 2.899}, {\"title\": \"Security and Privacy Challenges of Large Language Models: A Survey\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.547, \"y\": 0.396}, {\"title\": \"Recent Advances in Hate Speech Moderation: Multimodality and the Role of  Large Models\", \"topic\": \"Bias in Language Models\", \"x\": 2.515, \"y\": 3.329}, {\"title\": \"Prospects for inconsistency detection using large language models and  sheaves\", \"topic\": \"Bias in Language Models\", \"x\": 3.888, \"y\": 3.902}, {\"title\": \"OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on  E-Branchformer\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.511, \"y\": 5.629}, {\"title\": \"Gradient-Based Language Model Red Teaming\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.804, \"y\": 1.182}, {\"title\": \"TeenyTinyLlama: open-source tiny language models trained in Brazilian  Portuguese\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.992, \"y\": 3.914}, {\"title\": \"Large Multi-Modal Models (LMMs) as Universal Foundation Models for  AI-Native Wireless Systems\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.522, \"y\": 1.706}, {\"title\": \"Improving Reinforcement Learning from Human Feedback with Efficient  Reward Model Ensemble\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.554, \"y\": 0.581}, {\"title\": \"Massively Multilingual Text Translation For Low-Resource Languages\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.63, \"y\": 4.637}, {\"title\": \"Leveraging Professional Radiologists' Expertise to Enhance LLMs'  Evaluation for Radiology Reports\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.112, \"y\": 7.857}, {\"title\": \"LLMs as On-demand Customizable Service\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.319, \"y\": 1.481}, {\"title\": \"Beyond Image-Text Matching: Verb Understanding in Multimodal  Transformers Using Guided Masking\", \"topic\": \"Multimodal Language Models\", \"x\": 8.23, \"y\": 7.542}, {\"title\": \"Multi-class Regret Detection in Hindi Devanagari Script\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.683, \"y\": 5.233}, {\"title\": \"GuReT: Distinguishing Guilt and Regret related Text\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.758, \"y\": 5.376}, {\"title\": \"Two Stones Hit One Bird: Bilevel Positional Encoding for Better Length  Extrapolation\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.481, \"y\": 3.236}, {\"title\": \"InternLM-XComposer2: Mastering Free-form Text-Image Composition and  Comprehension in Vision-Language Large Model\", \"topic\": \"Multimodal Language Models\", \"x\": 8.185, \"y\": 7.384}, {\"title\": \"ReGAL: Refactoring Programs to Discover Generalizable Abstractions\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.143, \"y\": 0.166}, {\"title\": \"Scaling Sparse Fine-Tuning to Large Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.783, \"y\": 1.925}, {\"title\": \"TQCompressor: improving tensor decomposition methods in neural networks  via permutations\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.182, \"y\": 2.287}, {\"title\": \"Iterative Data Smoothing: Mitigating Reward Overfitting and  Overoptimization in RLHF\", \"topic\": \"Large Language Model Alignment\", \"x\": 5.53, \"y\": 0.65}, {\"title\": \"Machine Translation Meta Evaluation through Translation Accuracy  Challenge Sets\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.535, \"y\": 4.979}, {\"title\": \"GAPS: Geometry-Aware Problem Solver\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.69, \"y\": 1.208}, {\"title\": \"Capturing Pertinent Symbolic Features for Enhanced Content-Based  Misinformation Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.616, \"y\": 3.736}, {\"title\": \"MAPLE: Micro Analysis of Pairwise Language Evolution for Few-Shot Claim  Verification\", \"topic\": \"Bias in Language Models\", \"x\": 3.811, \"y\": 3.964}, {\"title\": \"CO2: Efficient Distributed Training with Full Communication-Computation  Overlap\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.04, \"y\": 2.512}, {\"title\": \"Development and Testing of a Novel Large Language Model-Based Clinical  Decision Support Systems for Medication Safety in 12 Clinical Specialties\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.936, \"y\": 7.164}, {\"title\": \"Towards Red Teaming in Multimodal and Multilingual Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.614, \"y\": 5.173}, {\"title\": \"Combining Hierachical VAEs with LLMs for clinically meaningful timeline  summarisation in social media\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.335, \"y\": 7.574}, {\"title\": \"MultiMUC: Multilingual Template Filling on MUC-4\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.634, \"y\": 4.452}, {\"title\": \"LLaMandement: Large Language Models for Summarization of French  Legislative Proposals\", \"topic\": \"Legal NLP\", \"x\": 4.573, \"y\": 4.659}, {\"title\": \"Mobile-Agent: Autonomous Multi-Modal Mobile Device Agent with Visual  Perception\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.171, \"y\": 1.552}, {\"title\": \"X-PEFT: eXtremely Parameter-Efficient Fine-Tuning for Extreme  Multi-Profile Scenarios\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.65, \"y\": 1.957}, {\"title\": \"Beyond Direct Diagnosis: LLM-based Multi-Specialist Agent Consultation  for Automatic Diagnosis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.697, \"y\": 7.403}, {\"title\": \"OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.796, \"y\": 2.331}, {\"title\": \"Multilingual Text-to-Image Generation Magnifies Gender Stereotypes and  Prompt Engineering May Not Help You\", \"topic\": \"Bias in Language Models\", \"x\": 3.24, \"y\": 2.596}, {\"title\": \"Image-Text Out-Of-Context Detection Using Synthetic Multimodal  Misinformation\", \"topic\": \"Bias in Language Models\", \"x\": 3.471, \"y\": 3.731}, {\"title\": \"Non-Fluent Synthetic Target-Language Data Improve Neural Machine  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.624, \"y\": 4.588}, {\"title\": \"Understanding the effects of word-level linguistic annotations in  under-resourced neural machine translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.652, \"y\": 4.783}, {\"title\": \"Stolen Subwords: Importance of Vocabularies for Machine Translation  Model Stealing\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.377, \"y\": 0.729}, {\"title\": \"SADAS: A Dialogue Assistant System Towards Remediating Norm Violations  in Bilingual Socio-Cultural Conversations\", \"topic\": \"Bias in Language Models\", \"x\": 4.21, \"y\": 2.735}, {\"title\": \"NoFunEval: Funny How Code LMs Falter on Requirements Beyond Functional  Correctness\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.055, \"y\": 0.063}, {\"title\": \"VIALM: A Survey and Benchmark of Visually Impaired Assistance with Large  Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.004, \"y\": 7.338}, {\"title\": \"E-EVAL: A Comprehensive Chinese K-12 Education Evaluation Benchmark for  Large Language Models\", \"topic\": \"Large Language Models in Education\", \"x\": 6.6, \"y\": 2.743}, {\"title\": \"Development and Testing of Retrieval Augmented Generation in Large  Language Models -- A Case Study Report\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.853, \"y\": 7.218}, {\"title\": \"Corrective Retrieval Augmented Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.155, \"y\": 4.556}, {\"title\": \"LSTM-based Deep Neural Network With A Focus on Sentence Representation  for Sequential Sentence Classification in Medical Scientific Abstracts\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.212, \"y\": 7.246}, {\"title\": \"Muffin or Chihuahua? Challenging Multimodal Large Language Models with  Multipanel VQA\", \"topic\": \"Multimodal Language Models\", \"x\": 7.853, \"y\": 7.55}, {\"title\": \"UnMASKed: Quantifying Gender Biases in Masked Language Models through  Linguistically Informed Job Market Prompts\", \"topic\": \"Bias in Language Models\", \"x\": 3.222, \"y\": 2.747}, {\"title\": \"Fine-Tuned Large Language Models for Symptom Recognition from Spanish  Clinical Text\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.953, \"y\": 7.01}, {\"title\": \"cantnlp@LT-EDI-2024: Automatic Detection of Anti-LGBTQ+ Hate Speech in  Under-resourced Languages\", \"topic\": \"Bias in Language Models\", \"x\": 2.424, \"y\": 3.458}, {\"title\": \"PILOT: Legal Case Outcome Prediction with Case Law\", \"topic\": \"Legal NLP\", \"x\": 4.399, \"y\": 4.569}, {\"title\": \"Check News in One Click: NLP-Empowered Pro-Kremlin Propaganda Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.409, \"y\": 3.733}, {\"title\": \"LLsM: Generative Linguistic Steganography with Large Language Model\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 2.602, \"y\": 0.968}, {\"title\": \"PRE: A Peer Review Based Large Language Model Evaluator\", \"topic\": \"Text Summarization\", \"x\": 5.093, \"y\": 5.21}, {\"title\": \"C Analyzer : A Static Program Analysis Tool for C Programs\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.069, \"y\": 0.218}, {\"title\": \"TA&AT: Enhancing Task-Oriented Dialog with Turn-Level Auxiliary Tasks  and Action-Tree Based Scheduled Sampling\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.134, \"y\": 3.285}, {\"title\": \"Evaluating LLM -- Generated Multimodal Diagnosis from Medical Images and  Symptom Analysis\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.079, \"y\": 7.779}, {\"title\": \"Contextualization Distillation from Large Language Model for Knowledge  Graph Completion\", \"topic\": \"Named Entity Recognition\", \"x\": 6.802, \"y\": 5.989}, {\"title\": \"Evaluating Gender Bias in Large Language Models via Chain-of-Thought  Prompting\", \"topic\": \"Bias in Language Models\", \"x\": 3.3, \"y\": 2.675}, {\"title\": \"MunTTS: A Text-to-Speech System for Mundari\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.182, \"y\": 5.682}, {\"title\": \"PPM: Automated Generation of Diverse Programming Problems for  Benchmarking Code Generation Models\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.074, \"y\": 0.097}, {\"title\": \"Quantifying Stereotypes in Language\", \"topic\": \"Bias in Language Models\", \"x\": 3.219, \"y\": 2.886}, {\"title\": \"Byte Pair Encoding Is All You Need For Automatic Bengali Speech  Recognition\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.193, \"y\": 5.524}, {\"title\": \"Style-News: Incorporating Stylized News Generation and Adversarial  Verification for Neural Fake News Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.439, \"y\": 3.647}, {\"title\": \"Semantic Properties of cosine based bias scores for word embeddings\", \"topic\": \"Bias in Language Models\", \"x\": 3.333, \"y\": 2.757}, {\"title\": \"Do We Need Language-Specific Fact-Checking Models? The Case of Chinese\", \"topic\": \"Bias in Language Models\", \"x\": 3.796, \"y\": 3.885}, {\"title\": \"Baichuan2-Sum: Instruction Finetune Baichuan2-7B Model for Dialogue  Summarization\", \"topic\": \"Text Summarization\", \"x\": 5.172, \"y\": 5.06}, {\"title\": \"Navigating the Post-API Dilemma | Search Engine Results Pages Present a  Biased View of Social Media Data\", \"topic\": \"Bias in Language Models\", \"x\": 3.376, \"y\": 3.507}, {\"title\": \"Pre-training and Diagnosing Knowledge Base Completion Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.765, \"y\": 5.73}, {\"title\": \"FaKnow: A Unified Library for Fake News Detection\", \"topic\": \"Bias in Language Models\", \"x\": 3.417, \"y\": 3.716}, {\"title\": \"Semantics of Multiword Expressions in Transformer-Based Models: A Survey\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.005, \"y\": 2.907}, {\"title\": \"MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop  Queries\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.339, \"y\": 4.532}, {\"title\": \"A RAG-based Question Answering System Proposal for Understanding Islam:  MufassirQAS LLM\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.159, \"y\": 3.967}, {\"title\": \"LegalDuet: Learning Effective Representations for Legal Judgment  Prediction through a Dual-View Legal Clue Reasoning\", \"topic\": \"Legal NLP\", \"x\": 4.377, \"y\": 4.491}, {\"title\": \"Importance-Aware Data Augmentation for Document-Level Neural Machine  Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.789, \"y\": 4.556}, {\"title\": \"A Comprehensive Survey of Compression Algorithms for Language Models\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.329, \"y\": 2.317}, {\"title\": \"Fortifying Ethical Boundaries in AI: Advanced Strategies for Enhancing  Security in Large Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.702, \"y\": 1.221}, {\"title\": \"How We Refute Claims: Automatic Fact-Checking through Flaw  Identification and Explanation\", \"topic\": \"Bias in Language Models\", \"x\": 3.825, \"y\": 3.928}, {\"title\": \"Improving Medical Reasoning through Retrieval and Self-Reflection with  Retrieval-Augmented Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.971, \"y\": 6.994}, {\"title\": \"Enhancing Large Language Model Performance To Answer Questions and  Extract Information More Accurately\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.017, \"y\": 4.566}, {\"title\": \"Unlearning Traces the Influential Training Data of Language Models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.971, \"y\": 0.85}, {\"title\": \"Transfer Learning for the Prediction of Entity Modifiers in Clinical  Text: Application to Opioid Use Disorder Case Detection\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.982, \"y\": 6.996}, {\"title\": \"HiFT: A Hierarchical Full Parameter Fine-Tuning Strategy\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.98, \"y\": 1.998}, {\"title\": \"EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.578, \"y\": 3.283}, {\"title\": \"Health Text Simplification: An Annotated Corpus for Digestive Cancer  Education and Novel Strategies for Reinforcement Learning\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.311, \"y\": 7.04}, {\"title\": \"SliceGPT: Compress Large Language Models by Deleting Rows and Columns\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.167, \"y\": 2.392}, {\"title\": \"Embedding-based search in JetBrains IDEs\", \"topic\": \"Code Generation with LLMs\", \"x\": 6.926, \"y\": 0.255}, {\"title\": \"Comparison of parameters of vowel sounds of russian and english  languages\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.198, \"y\": 5.762}, {\"title\": \"The Power of Noise: Redefining Retrieval for RAG Systems\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.174, \"y\": 4.467}, {\"title\": \"F-Eval: Asssessing Fundamental Abilities with Refined Evaluation Methods\", \"topic\": \"Large Language Models in Education\", \"x\": 6.963, \"y\": 3.281}, {\"title\": \"Evaluation of LLM Chatbots for OSINT-based Cyber Threat Awareness\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.378, \"y\": 1.33}, {\"title\": \"Turn-taking and Backchannel Prediction with Acoustic and Large Language  Model Fusion\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.198, \"y\": 3.252}, {\"title\": \"Taiyi-Diffusion-XL: Advancing Bilingual Text-to-Image Generation with  Large Vision-Language Model Support\", \"topic\": \"Multimodal Language Models\", \"x\": 8.555, \"y\": 6.95}, {\"title\": \"MasonTigers@LT-EDI-2024: An Ensemble Approach Towards Detecting  Homophobia and Transphobia in Social Media Comments\", \"topic\": \"Bias in Language Models\", \"x\": 2.476, \"y\": 3.478}, {\"title\": \"MaLLaM -- Malaysia Large Language Model\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.962, \"y\": 3.88}, {\"title\": \"UNIT-DSR: Dysarthric Speech Reconstruction System Using Speech Unit  Normalization\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.417, \"y\": 5.946}, {\"title\": \"A Korean Legal Judgment Prediction Dataset for Insurance Disputes\", \"topic\": \"Legal NLP\", \"x\": 4.41, \"y\": 4.602}, {\"title\": \"Toward Practical Automatic Speech Recognition and Post-Processing: a  Call for Explainable Error Benchmark Guideline\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.58, \"y\": 5.724}, {\"title\": \"Alternative Speech: Complementary Method to Counter-Narrative for Better  Discourse\", \"topic\": \"Bias in Language Models\", \"x\": 2.472, \"y\": 3.259}, {\"title\": \"Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using  Large Language Models to Mitigate Cognitive Bias\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.691, \"y\": 7.406}, {\"title\": \"ChatGPT vs Gemini vs LLaMA on Multilingual Sentiment Analysis\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.915, \"y\": 4.769}, {\"title\": \"Language Modelling Approaches to Adaptive Machine Translation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.712, \"y\": 4.611}, {\"title\": \"Evaluating GPT-3.5's Awareness and Summarization Abilities for European  Constitutional Texts with Shared Topics\", \"topic\": \"Text Summarization\", \"x\": 4.856, \"y\": 4.893}, {\"title\": \"TrICy: Trigger-guided Data-to-text Generation with Intent aware  Attention-Copy\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.528, \"y\": 3.442}, {\"title\": \"Prompting Large Language Models for Zero-Shot Clinical Prediction with  Structured Longitudinal Electronic Health Record Data\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.218, \"y\": 7.31}, {\"title\": \"K-QA: A Real-World Medical Q&A Benchmark\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.853, \"y\": 7.236}, {\"title\": \"LongHealth: A Question Answering Benchmark with Long Clinical Documents\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.038, \"y\": 7.394}, {\"title\": \"Modular Adaptation of Multilingual Encoders to Written Swiss German  Dialect\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.158, \"y\": 4.394}, {\"title\": \"Socially Aware Synthetic Data Generation for Suicidal Ideation Detection  Using Large Language Models\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.273, \"y\": 6.389}, {\"title\": \"TURNA: A Turkish Encoder-Decoder Language Model for Enhanced  Understanding and Generation\", \"topic\": \"Multilingual Machine Translation\", \"x\": 8.825, \"y\": 4.15}, {\"title\": \"Genie: Achieving Human Parity in Content-Grounded Datasets Generation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.222, \"y\": 4.127}, {\"title\": \"A Comparative Analysis of Noise Reduction Methods in Sentiment Analysis  on Noisy Bangla Texts\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.943, \"y\": 4.721}, {\"title\": \"Demystifying Chains, Trees, and Graphs of Thoughts\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.256, \"y\": 2.029}, {\"title\": \"RomanSetu: Efficiently unlocking multilingual capabilities of Large  Language Models via Romanization\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.205, \"y\": 4.298}, {\"title\": \"Improving Natural Language Capability of Code Large Language Model\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.144, \"y\": 0.105}, {\"title\": \"Enhanced Labeling Technique for Reddit Text and Fine-Tuned Longformer  Models for Classifying Depression Severity in English and Luganda\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.365, \"y\": 6.365}, {\"title\": \"Assessing the Portability of Parameter Matrices Trained by  Parameter-Efficient Finetuning Methods\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.484, \"y\": 2.071}, {\"title\": \"Commonsense-augmented Memory Construction and Management in Long-term  Conversations via Context-aware Persona Refinement\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.174, \"y\": 3.454}, {\"title\": \"Explicitly Representing Syntax Improves Sentence-to-layout Prediction of  Unexpected Situations\", \"topic\": \"Multimodal Language Models\", \"x\": 8.342, \"y\": 6.946}, {\"title\": \"DeepSeek-Coder: When the Large Language Model Meets Programming -- The  Rise of Code Intelligence\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.149, \"y\": 0.066}, {\"title\": \"True Knowledge Comes from Practice: Aligning LLMs with Embodied  Environments via Reinforcement Learning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 5.949, \"y\": 1.165}, {\"title\": \"Convolutional Neural Networks can achieve binary bail judgement  classification\", \"topic\": \"Legal NLP\", \"x\": 4.369, \"y\": 4.542}, {\"title\": \"CompactifAI: Extreme Compression of Large Language Models using  Quantum-Inspired Tensor Networks\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.243, \"y\": 2.354}, {\"title\": \"Ta'keed: The First Generative Fact-Checking System for Arabic Claims\", \"topic\": \"Bias in Language Models\", \"x\": 3.905, \"y\": 3.905}, {\"title\": \"Accelerating Retrieval-Augmented Language Model Serving with Speculation\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.356, \"y\": 4.42}, {\"title\": \"Towards Uncertainty-Aware Language Agent\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.253, \"y\": 1.672}, {\"title\": \"Investigate-Consolidate-Exploit: A General Strategy for Inter-Task Agent  Self-Evolution\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.086, \"y\": 1.437}, {\"title\": \"Leeroo Orchestrator: Elevating LLMs Performance Through Model  Integration\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.563, \"y\": 1.429}, {\"title\": \"LocMoE: A Low-Overhead MoE for Large Language Model Training\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 9.862, \"y\": 2.247}, {\"title\": \"MULTIVERSE: Exposing Large Language Model Alignment Problems in Diverse  Worlds\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.351, \"y\": 0.646}, {\"title\": \"A comparative study of zero-shot inference with large language models  and supervised modeling in breast cancer pathology classification\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.293, \"y\": 7.393}, {\"title\": \"Beyond Behaviorist Representational Harms: A Plan for Measurement and  Mitigation\", \"topic\": \"Bias in Language Models\", \"x\": 3.358, \"y\": 2.583}, {\"title\": \"Unmasking and Quantifying Racial Bias of Large Language Models in  Medical Report Generation\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.69, \"y\": 6.828}, {\"title\": \"TPD: Enhancing Student Language Model Reasoning via Principle Discovery  and Guidance\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.256, \"y\": 1.698}, {\"title\": \"Investigating the Efficacy of Large Language Models for Code Clone  Detection\", \"topic\": \"Code Generation with LLMs\", \"x\": 7.094, \"y\": 0.045}, {\"title\": \"A Unified Approach to Emotion Detection and Task-Oriented Dialogue  Modeling\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.613, \"y\": 5.572}, {\"title\": \"MambaByte: Token-free Selective State Space Model\", \"topic\": \"Large Language Models Efficiency and Compression\", \"x\": 10.108, \"y\": 3.304}, {\"title\": \"Fluent dreaming for language models\", \"topic\": \"Jailbreak Attacks and Defense\", \"x\": 3.326, \"y\": 0.965}, {\"title\": \"MM-LLMs: Recent Advances in MultiModal Large Language Models\", \"topic\": \"Multimodal Language Models\", \"x\": 8.176, \"y\": 7.373}, {\"title\": \"Consistency Guided Knowledge Retrieval and Denoising in LLMs for  Zero-shot Document-level Relation Triplet Extraction\", \"topic\": \"Named Entity Recognition\", \"x\": 6.369, \"y\": 6.411}, {\"title\": \"Graph Guided Question Answer Generation for Procedural  Question-Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.441, \"y\": 4.219}, {\"title\": \"Evaluation of General Large Language Models in Contextually Assessing  Semantic Concepts Extracted from Adult Critical Care Electronic Health Record  Notes\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.898, \"y\": 7.335}, {\"title\": \"SpeechGPT-Gen: Scaling Chain-of-Information Speech Generation\", \"topic\": \"Speech Recognition and Translation\", \"x\": 10.048, \"y\": 6.073}, {\"title\": \"Can GPT-3.5 Generate and Code Discharge Summaries?\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 4.153, \"y\": 7.581}, {\"title\": \"SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval\", \"topic\": \"Multimodal Language Models\", \"x\": 7.988, \"y\": 7.234}, {\"title\": \"SpeechDPR: End-to-End Spoken Passage Retrieval for Open-Domain Spoken  Question Answering\", \"topic\": \"Retrieval-Augmented Generation\", \"x\": 6.144, \"y\": 4.327}, {\"title\": \"Question answering systems for health professionals at the point of care  -- a systematic review\", \"topic\": \"Natural Language Processing in Healthcare\", \"x\": 3.785, \"y\": 7.34}, {\"title\": \"Large language model empowered participatory urban planning\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.232, \"y\": 1.561}, {\"title\": \"InstructDoc: A Dataset for Zero-Shot Generalization of Visual Document  Understanding with Instructions\", \"topic\": \"Multimodal Language Models\", \"x\": 7.666, \"y\": 7.383}, {\"title\": \"MaLA-500: Massive Language Adaptation of Large Language Models\", \"topic\": \"Multilingual Machine Translation\", \"x\": 9.197, \"y\": 3.959}, {\"title\": \"Towards Explainable Harmful Meme Detection through Multimodal Debate  between Large Language Models\", \"topic\": \"Bias in Language Models\", \"x\": 2.89, \"y\": 3.581}, {\"title\": \"Can AI Assistants Know What They Don't Know?\", \"topic\": \"Large Language Models in Education\", \"x\": 6.15, \"y\": 3.146}, {\"title\": \"MF-AED-AEC: Speech Emotion Recognition by Leveraging Multimodal Fusion,  Asr Error Detection, and Asr Error Correction\", \"topic\": \"Emotion Analysis in Multimodal Contexts\", \"x\": 2.434, \"y\": 5.415}, {\"title\": \"UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for  Personalized Dialogue Systems\", \"topic\": \"Natural Language Processing for Dialogue Systems\", \"x\": 5.406, \"y\": 3.593}, {\"title\": \"SEER: Facilitating Structured Reasoning and Explanation via  Reinforcement Learning\", \"topic\": \"Chain-of-Thought Reasoning in Large Language Models\", \"x\": 7.358, \"y\": 2.048}, {\"title\": \"LPNL: Scalable Link Prediction with Large Language Models\", \"topic\": \"Named Entity Recognition\", \"x\": 6.566, \"y\": 5.892}, {\"title\": \"Better Call GPT, Comparing Large Language Models Against Lawyers\", \"topic\": \"Legal NLP\", \"x\": 4.398, \"y\": 4.436}, {\"title\": \"Language-Guided World Models: A Model-Based Approach to AI Control\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.076, \"y\": 1.412}, {\"title\": \"MLLMReID: Multimodal Large Language Model-based Person Re-identification\", \"topic\": \"Multimodal Language Models\", \"x\": 8.404, \"y\": 7.273}, {\"title\": \"AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents\", \"topic\": \"Autonomous Agents and Planning with Language Models\", \"x\": 6.267, \"y\": 1.556}, {\"title\": \"Misgendering and Assuming Gender in Machine Translation when Working  with Low-Resource Languages\", \"topic\": \"Bias in Language Models\", \"x\": 3.287, \"y\": 2.746}]}, {\"name\": \"source_0_x_domain_x\", \"values\": [{\"min\": 2.375, \"max\": 10.759}]}, {\"name\": \"source_0_y_domain_y\", \"values\": [{\"min\": -0.028, \"max\": 8.17}]}, {\"name\": \"source_0_color_domain_topic\", \"values\": [{\"topic\": \"Autonomous Agents and Planning with Language Models\"}, {\"topic\": \"Multimodal Language Models\"}, {\"topic\": \"Multilingual Machine Translation\"}, {\"topic\": \"Bias in Language Models\"}, {\"topic\": \"Jailbreak Attacks and Defense\"}, {\"topic\": \"Large Language Models in Education\"}, {\"topic\": \"Text Summarization\"}, {\"topic\": \"Chain-of-Thought Reasoning in Large Language Models\"}, {\"topic\": \"Speech Recognition and Translation\"}, {\"topic\": \"Code Generation with LLMs\"}, {\"topic\": \"Natural Language Processing in Healthcare\"}, {\"topic\": \"Large Language Model Alignment\"}, {\"topic\": \"Natural Language Processing for Dialogue Systems\"}, {\"topic\": \"Large Language Models Efficiency and Compression\"}, {\"topic\": \"Emotion Analysis in Multimodal Contexts\"}, {\"topic\": \"Retrieval-Augmented Generation\"}, {\"topic\": \"Named Entity Recognition\"}, {\"topic\": \"Legal NLP\"}]}], \"signals\": [{\"name\": \"unit\", \"value\": {}, \"on\": [{\"events\": \"pointermove\", \"update\": \"isTuple(group()) ? group() : unit\"}]}, {\"name\": \"param_4\", \"update\": \"vlSelectionResolve(\\\"param_4_store\\\", \\\"union\\\")\"}, {\"name\": \"param_4_x\", \"on\": [{\"events\": [{\"source\": \"view\", \"type\": \"dblclick\"}], \"update\": \"null\"}, {\"events\": {\"signal\": \"param_4_translate_delta\"}, \"update\": \"panLinear(param_4_translate_anchor.extent_x, -param_4_translate_delta.x / width)\"}, {\"events\": {\"signal\": \"param_4_zoom_delta\"}, \"update\": \"zoomLinear(domain(\\\"x\\\"), param_4_zoom_anchor.x, param_4_zoom_delta)\"}]}, {\"name\": \"param_4_y\", \"on\": [{\"events\": [{\"source\": \"view\", \"type\": \"dblclick\"}], \"update\": \"null\"}, {\"events\": {\"signal\": \"param_4_translate_delta\"}, \"update\": \"panLinear(param_4_translate_anchor.extent_y, param_4_translate_delta.y / height)\"}, {\"events\": {\"signal\": \"param_4_zoom_delta\"}, \"update\": \"zoomLinear(domain(\\\"y\\\"), param_4_zoom_anchor.y, param_4_zoom_delta)\"}]}, {\"name\": \"param_4_tuple\", \"on\": [{\"events\": [{\"signal\": \"param_4_x || param_4_y\"}], \"update\": \"param_4_x && param_4_y ? {unit: \\\"\\\", fields: param_4_tuple_fields, values: [param_4_x,param_4_y]} : null\"}]}, {\"name\": \"param_4_tuple_fields\", \"value\": [{\"field\": \"x\", \"channel\": \"x\", \"type\": \"R\"}, {\"field\": \"y\", \"channel\": \"y\", \"type\": \"R\"}]}, {\"name\": \"param_4_translate_anchor\", \"value\": {}, \"on\": [{\"events\": [{\"source\": \"scope\", \"type\": \"pointerdown\"}], \"update\": \"{x: x(unit), y: y(unit), extent_x: domain(\\\"x\\\"), extent_y: domain(\\\"y\\\")}\"}]}, {\"name\": \"param_4_translate_delta\", \"value\": {}, \"on\": [{\"events\": [{\"source\": \"window\", \"between\": [{\"source\": \"scope\", \"type\": \"pointerdown\"}, {\"source\": \"window\", \"type\": \"pointerup\"}], \"consume\": true, \"type\": \"pointermove\"}], \"update\": \"{x: param_4_translate_anchor.x - x(unit), y: param_4_translate_anchor.y - y(unit)}\"}]}, {\"name\": \"param_4_zoom_anchor\", \"on\": [{\"events\": [{\"source\": \"scope\", \"type\": \"wheel\", \"consume\": true}], \"update\": \"{x: invert(\\\"x\\\", x(unit)), y: invert(\\\"y\\\", y(unit))}\"}]}, {\"name\": \"param_4_zoom_delta\", \"on\": [{\"events\": [{\"source\": \"scope\", \"consume\": true, \"type\": \"wheel\"}], \"update\": \"pow(1.001, event.deltaY * pow(16, event.deltaMode))\", \"force\": true}]}, {\"name\": \"param_4_modify\", \"on\": [{\"events\": {\"signal\": \"param_4_tuple\"}, \"update\": \"modify(\\\"param_4_store\\\", param_4_tuple, true)\"}]}], \"marks\": [{\"type\": \"symbol\", \"name\": \"marks\", \"from\": {\"data\": \"source_0\"}, \"encode\": {\"update\": {\"opacity\": {\"value\": 0.7}, \"tooltip\": {\"signal\": \"{\\\"title\\\": isValid(datum[\\\"title\\\"]) ? datum[\\\"title\\\"] : \\\"\\\"+datum[\\\"title\\\"], \\\"topic\\\": isValid(datum[\\\"topic\\\"]) ? datum[\\\"topic\\\"] : \\\"\\\"+datum[\\\"topic\\\"]}\"}, \"y\": {\"field\": \"y\", \"scale\": \"y\"}, \"size\": {\"value\": 5}, \"fill\": {\"field\": \"topic\", \"scale\": \"color\"}, \"x\": {\"field\": \"x\", \"scale\": \"x\"}, \"shape\": {\"value\": \"circle\"}}}, \"clip\": true, \"interactive\": true, \"style\": [\"circle\"]}], \"scales\": [{\"name\": \"x\", \"type\": \"linear\", \"domain\": [{\"signal\": \"(data(\\\"source_0_x_domain_x\\\")[0] || {}).min\"}, {\"signal\": \"(data(\\\"source_0_x_domain_x\\\")[0] || {}).max\"}], \"range\": [0, {\"signal\": \"width\"}], \"zero\": true, \"domainRaw\": {\"signal\": \"param_4[\\\"x\\\"]\"}, \"nice\": true}, {\"name\": \"y\", \"type\": \"linear\", \"domain\": [{\"signal\": \"(data(\\\"source_0_y_domain_y\\\")[0] || {}).min\"}, {\"signal\": \"(data(\\\"source_0_y_domain_y\\\")[0] || {}).max\"}], \"range\": [{\"signal\": \"height\"}, 0], \"domainRaw\": {\"signal\": \"param_4[\\\"y\\\"]\"}, \"nice\": true, \"zero\": true}, {\"name\": \"color\", \"type\": \"ordinal\", \"domain\": {\"data\": \"source_0_color_domain_topic\", \"field\": \"topic\", \"sort\": true}, \"range\": \"category\"}], \"axes\": [{\"scale\": \"x\", \"labels\": false, \"orient\": \"bottom\", \"maxExtent\": 0, \"grid\": true, \"tickCount\": {\"signal\": \"ceil(width/40)\"}, \"gridScale\": \"y\", \"zindex\": 0, \"domain\": false, \"aria\": false, \"minExtent\": 0, \"ticks\": false}, {\"scale\": \"y\", \"ticks\": false, \"zindex\": 0, \"gridScale\": \"x\", \"aria\": false, \"grid\": true, \"orient\": \"left\", \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"domain\": false, \"maxExtent\": 0, \"labels\": false, \"minExtent\": 0}, {\"scale\": \"x\", \"zindex\": 0, \"title\": \"x\", \"orient\": \"bottom\", \"tickCount\": {\"signal\": \"ceil(width/40)\"}, \"grid\": false, \"labelOverlap\": true, \"labelFlush\": true}, {\"scale\": \"y\", \"zindex\": 0, \"labelOverlap\": true, \"tickCount\": {\"signal\": \"ceil(height/40)\"}, \"grid\": false, \"orient\": \"left\", \"title\": \"y\"}], \"title\": {\"text\": \"10K arXiv Abstracts in NLP | Embeddings | UMAP | HDBSCAN | Mistral-7B\", \"frame\": \"group\"}, \"legends\": [{\"fill\": \"color\", \"symbolType\": \"circle\", \"title\": \"topic\", \"encode\": {\"symbols\": {\"update\": {\"opacity\": {\"value\": 0.7}}}}}], \"style\": \"cell\", \"background\": \"white\", \"width\": 600, \"padding\": 5, \"height\": 400}, {\"mode\": \"vega\"});\n",
              "</script>"
            ],
            "text/plain": [
              "alt.Chart(...)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "h9DHAbaZbyL2"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4157078bb2374809a9d20f0b8f9ba57b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_970a60f1222a49639ee9a3b97a1b5f7b",
              "IPY_MODEL_d0871b4078e440de9b6a541e4f1e27d4",
              "IPY_MODEL_5babd32d8c7e48189dc8d5b52403a646"
            ],
            "layout": "IPY_MODEL_cfd9250f97b649ae9d9e8be2cfe9f75a"
          }
        },
        "970a60f1222a49639ee9a3b97a1b5f7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_553a5736cc6f452cbf4694251fb85f3a",
            "placeholder": "​",
            "style": "IPY_MODEL_34129117bfed48d2a1af829275dd3607",
            "value": "Downloading data: 100%"
          }
        },
        "d0871b4078e440de9b6a541e4f1e27d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39267c41913c4bd1a3ac88968f56ec85",
            "max": 177704158,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3892b6560634c6bacb567d6fba2e046",
            "value": 177704158
          }
        },
        "5babd32d8c7e48189dc8d5b52403a646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a08abc106744991b0448d2ed042d073",
            "placeholder": "​",
            "style": "IPY_MODEL_16d4f529ff9441b997eb7ec6a665458c",
            "value": " 178M/178M [00:02&lt;00:00, 70.9MB/s]"
          }
        },
        "cfd9250f97b649ae9d9e8be2cfe9f75a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "553a5736cc6f452cbf4694251fb85f3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34129117bfed48d2a1af829275dd3607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39267c41913c4bd1a3ac88968f56ec85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3892b6560634c6bacb567d6fba2e046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a08abc106744991b0448d2ed042d073": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16d4f529ff9441b997eb7ec6a665458c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "076fc8f757934ae1b493d41834251357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88806abd3bd548a1a05410476e9d5fd3",
              "IPY_MODEL_e6e5bd5d71b94217bdf2e000ce6dd7a2",
              "IPY_MODEL_8c62455b42594e9e98226ecc4b4e2396"
            ],
            "layout": "IPY_MODEL_e2369b043dcb493a8c55813cc3df4898"
          }
        },
        "88806abd3bd548a1a05410476e9d5fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0974924023044149e220a2b47850dab",
            "placeholder": "​",
            "style": "IPY_MODEL_d604bc6dc08c4aa5aec6f86a05ce3d56",
            "value": "Generating train split: 100%"
          }
        },
        "e6e5bd5d71b94217bdf2e000ce6dd7a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2abe2c137cf4c689a3753233eedbff3",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a3e0300e9bf48dbbad076e6c64def4a",
            "value": 10000
          }
        },
        "8c62455b42594e9e98226ecc4b4e2396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5d3b78cae5842c99c27ad00565578d1",
            "placeholder": "​",
            "style": "IPY_MODEL_12002e9f2b6445b09a0588a9352b970f",
            "value": " 10000/10000 [00:06&lt;00:00, 1722.95 examples/s]"
          }
        },
        "e2369b043dcb493a8c55813cc3df4898": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0974924023044149e220a2b47850dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d604bc6dc08c4aa5aec6f86a05ce3d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a2abe2c137cf4c689a3753233eedbff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a3e0300e9bf48dbbad076e6c64def4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5d3b78cae5842c99c27ad00565578d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12002e9f2b6445b09a0588a9352b970f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}